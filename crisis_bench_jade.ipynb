{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a9ab23-f031-44a3-88cd-4d08f1f6381c",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ec020-a4bb-430f-b561-1f0367e5f486",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc7346fe-d763-4501-9a45-1c4c7a9ab363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0869bbce-6ad5-4929-9439-c2f4bc6249f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "generator = torch.Generator()\n",
    "_ = generator.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f2506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_strs = ['time_critical', 'support_and_relief', 'non_informative']\n",
    "label2id = {label: i for i, label in enumerate(all_label_strs)}\n",
    "id2label = {i: label for label, i in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83365a1-379c-4bc6-bbcc-eb8ca273209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./data/crisisbench/preprocessed_data_train.csv\n",
      "Loading: ./data/crisisbench/preprocessed_data_dev.csv\n",
      "Loading: ./data/crisisbench/preprocessed_data_test.csv\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    df = {}\n",
    "    for d in ['train', 'dev', 'test']:\n",
    "        output_path = f\"./data/crisisbench/preprocessed_data_{d}.csv\"\n",
    "        df[d] = pd.read_csv(output_path).loc[:, ['text', 'class_label_group', 'class_label_group_num']]\n",
    "        print(\"Loading:\", output_path)\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43775508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: N=61089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approximately km long firebreaks have been con...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>god bless you</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cracked wine casks damaged historical building...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i m really just excited for new undies and pin...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rescue effort e ands in india pakistan as floo...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class_label_group  \\\n",
       "0  approximately km long firebreaks have been con...     time_critical   \n",
       "1                                      god bless you   non_informative   \n",
       "2  cracked wine casks damaged historical building...     time_critical   \n",
       "3  i m really just excited for new undies and pin...   non_informative   \n",
       "4  rescue effort e ands in india pakistan as floo...     time_critical   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      0  \n",
       "1                      2  \n",
       "2                      0  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_train: N={len(df['train'])}\")\n",
    "df['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ce818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dev: N=8921\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>congrats to all my liverpool supporting fans f...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collapsed buildings in mexico city earthquake ...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>here s your flower</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ready for a relaxing weekend but have too much...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public private information portal developed to...</td>\n",
       "      <td>support_and_relief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   class_label_group  \\\n",
       "0  congrats to all my liverpool supporting fans f...     non_informative   \n",
       "1  collapsed buildings in mexico city earthquake ...       time_critical   \n",
       "2                                 here s your flower     non_informative   \n",
       "3  ready for a relaxing weekend but have too much...     non_informative   \n",
       "4  public private information portal developed to...  support_and_relief   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      2  \n",
       "1                      0  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_dev: N={len(df['dev'])}\")\n",
    "df['dev'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d208947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test: N=17335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staff at our feeding centre say chronic malnou...</td>\n",
       "      <td>support_and_relief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you comin down for the summer semesters right</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yea it s upstate i m like a few hours away</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teach every pakistani that it is not enough to...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stay with for live cvg as typhoon hagupit slam...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   class_label_group  \\\n",
       "0  staff at our feeding centre say chronic malnou...  support_and_relief   \n",
       "1      you comin down for the summer semesters right     non_informative   \n",
       "2         yea it s upstate i m like a few hours away     non_informative   \n",
       "3  teach every pakistani that it is not enough to...     non_informative   \n",
       "4  stay with for live cvg as typhoon hagupit slam...       time_critical   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      1  \n",
       "1                      2  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_test: N={len(df['test'])}\")\n",
    "df['test'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d27fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52640cad",
   "metadata": {},
   "source": [
    "### CNN Paper Setup\n",
    "We train the CNN models using the Adam optimizer (Kingma and Ba 2014). The batch size is 128 and maximum number of epochs is set to 1000. We use a filter size of 300 with both window size and pooling length of 2, 3, and 4, and a dropout rate 0.02. We set early stopping\n",
    "criterion based on the accuracy of the development set with a patience of 200. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ea0a0",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4a00974",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8566f4e",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "defa4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 5000\n",
    "MAX_SEQ_LEN = 64 # depends on tweet length\n",
    "EMBED_DIM = 50\n",
    "FILTER_SIZES = (3, 4, 5)\n",
    "NUM_FILTERS = 50\n",
    "DROPOUT = 0.5 # tune\n",
    "BATCH_SIZE = 64 # tune\n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 5\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "GLOVE_PATH = \"data/crisisbench/glove_word_embeddings.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb1266",
   "metadata": {},
   "source": [
    "### Tokenizer and Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecf53496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits on whitespace\n",
    "    \"\"\"\n",
    "    return text.strip().split()\n",
    "\n",
    "def build_vocab(\n",
    "    texts: List[str],\n",
    "    max_size: int,\n",
    "    min_freq: int = 1\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Build a word -> index vocab from training texts.\n",
    "    Reserves index 0 for PAD and 1 for UNK.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = simple_tokenize(text)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
    "    for word, freq in counter.most_common():\n",
    "        if freq < min_freq:\n",
    "            continue\n",
    "        if len(vocab) >= max_size:\n",
    "            break\n",
    "        vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def encode_text(\n",
    "    text: str,\n",
    "    vocab: Dict[str, int],\n",
    "    max_len: int\n",
    ") -> List[int]:\n",
    "    tokens = simple_tokenize(text)\n",
    "    ids = [vocab.get(tok, vocab[UNK_TOKEN]) for tok in tokens][:max_len]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [vocab[PAD_TOKEN]] * (max_len - len(ids))\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81ae81",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c95f7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: List[int],\n",
    "        vocab: Dict[str, int],\n",
    "        max_len: int,\n",
    "    ):\n",
    "        assert len(texts) == len(labels)\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        input_ids = encode_text(text, self.vocab, self.max_len)\n",
    "        return torch.tensor(input_ids, dtype=torch.long), label\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_texts: List[str],\n",
    "    train_labels: List[int],\n",
    "    val_texts: List[str],\n",
    "    val_labels: List[int],\n",
    "    max_vocab_size: int,\n",
    "    max_seq_len: int,\n",
    "    batch_size: int,\n",
    ") -> Tuple[DataLoader, DataLoader, Dict[str, int], int]:\n",
    "    vocab = build_vocab(train_texts, max_vocab_size)\n",
    "    num_classes = len(set(train_labels))\n",
    "\n",
    "    train_dataset = TextDataset(train_texts, train_labels, vocab, max_seq_len)\n",
    "    val_dataset = TextDataset(val_texts, val_labels, vocab, max_seq_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, vocab, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d02775",
   "metadata": {},
   "source": [
    "### Load GloVe & build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1645084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(\n",
    "    glove_path: str,\n",
    "    embed_dim: int,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Load GloVe file into a dict: word -> vector (torch.Tensor).\n",
    "    Expects each line: word val1 val2 ... valD\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != embed_dim + 1:\n",
    "                # ignore malformed lines\n",
    "                continue\n",
    "            word = parts[0]\n",
    "            vec = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float32)\n",
    "            embeddings[word] = vec\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def build_embedding_matrix(\n",
    "    vocab: Dict[str, int],\n",
    "    glove_embeddings: Dict[str, torch.Tensor],\n",
    "    embed_dim: int,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create an embedding matrix of shape [vocab_size, embed_dim]\n",
    "    where row i is the vector for the word with index i.\n",
    "    Words not found in GloVe are randomly initialized (small normal).\n",
    "    \"\"\"\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_matrix = torch.empty(vocab_size, embed_dim, dtype=torch.float32)\n",
    "\n",
    "    # Initialize OOV embeddings to small random values\n",
    "    torch.nn.init.normal_(embedding_matrix, mean=0.0, std=0.05)\n",
    "\n",
    "    # Set PAD embedding to zeros\n",
    "    pad_idx = vocab[PAD_TOKEN]\n",
    "    embedding_matrix[pad_idx] = torch.zeros(embed_dim, dtype=torch.float32)\n",
    "\n",
    "    oov_count = 0\n",
    "    for word, idx in vocab.items():\n",
    "        if word in (PAD_TOKEN, UNK_TOKEN):\n",
    "            continue\n",
    "        vec = glove_embeddings.get(word)\n",
    "        if vec is not None:\n",
    "            embedding_matrix[idx] = vec\n",
    "        else:\n",
    "            oov_count += 1\n",
    "\n",
    "    print(f\"GloVe OOV words: {oov_count}/{vocab_size}\")\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60863f21",
   "metadata": {},
   "source": [
    "### Text CNN model (with optional pretrained embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f94c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        num_classes: int,\n",
    "        pad_idx: int = 0,\n",
    "        num_filters: int = 100,\n",
    "        filter_sizes: Tuple[int, ...] = (3, 4, 5),\n",
    "        dropout: float = 0.5,\n",
    "        pretrained_embeddings: torch.Tensor | None = None,\n",
    "        freeze_embeddings: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embed_dim,\n",
    "            padding_idx=pad_idx,\n",
    "        )\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            if pretrained_embeddings.shape != (vocab_size, embed_dim):\n",
    "                raise ValueError(\n",
    "                    f\"Pretrained embeddings shape {pretrained_embeddings.shape} \"\n",
    "                    f\"does not match (vocab_size, embed_dim)=({vocab_size}, {embed_dim})\"\n",
    "                )\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "            if freeze_embeddings:\n",
    "                self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=embed_dim,\n",
    "                out_channels=num_filters,\n",
    "                kernel_size=fs,\n",
    "            )\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        embedded = self.embedding(input_ids)          \n",
    "        embedded = embedded.transpose(1, 2)           \n",
    "\n",
    "        conv_outputs = []\n",
    "        for conv in self.convs:\n",
    "            x = conv(embedded)                        \n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "            conv_outputs.append(x)\n",
    "\n",
    "        cat = torch.cat(conv_outputs, dim=1)\n",
    "        cat = self.dropout(cat)\n",
    "        logits = self.fc(cat)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93543e0d",
   "metadata": {},
   "source": [
    "### Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1baee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for input_ids, labels in dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "\n",
    "        # accumulate predictions & ground truth\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_targets.extend(labels.cpu().tolist())\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "\n",
    "    return avg_loss, accuracy, all_preds, all_targets\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total_examples += x.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_targets.extend(y.cpu().tolist())\n",
    "\n",
    "    avg_loss = total_loss / total_examples\n",
    "    avg_acc = total_correct / total_examples\n",
    "\n",
    "    return avg_loss, avg_acc, all_preds, all_targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c43e1c8",
   "metadata": {},
   "source": [
    "### Generating Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ac3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 0. Data loaders + GloVe + loss\n",
    "# ------------------------------------------------\n",
    "# train_loader, val_loader, vocab, num_classes = create_dataloaders(\n",
    "#     train_texts=df['train']['text'].to_list(),\n",
    "#     train_labels=df['train']['class_label_group_num'],\n",
    "#     val_texts=df['dev']['text'].to_list(),\n",
    "#     val_labels=df['dev']['class_label_group_num'],\n",
    "#     max_vocab_size=MAX_VOCAB_SIZE,\n",
    "#     max_seq_len=MAX_SEQ_LEN,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "# )\n",
    "\n",
    "# print(f\"Vocab size: {len(vocab)}, Num classes: {num_classes}\")\n",
    "\n",
    "# print(\"Loading GloVe embeddings...\")\n",
    "# glove_embeds = load_glove_embeddings(GLOVE_PATH, EMBED_DIM)\n",
    "# embedding_matrix = build_embedding_matrix(vocab, glove_embeds, EMBED_DIM)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1. Hyperparameter sweep over num_filters\n",
    "# ------------------------------------------------\n",
    "# num_filters_list = [25, 50, 75, 100]\n",
    "# max_epochs_cap = 10\n",
    "\n",
    "# results = {}  # num_filters -> dict\n",
    "\n",
    "# best_overall_f1 = -1.0\n",
    "# best_overall_cfg = None\n",
    "\n",
    "# for num_filters in num_filters_list:\n",
    "#     print(\"\\n\" + \"=\" * 60)\n",
    "#     print(f\"Training TextCNN with num_filters={num_filters}\")\n",
    "#     print(\"=\" * 60)\n",
    "\n",
    "#     model = TextCNN(\n",
    "#         vocab_size=len(vocab),\n",
    "#         embed_dim=EMBED_DIM,\n",
    "#         num_classes=num_classes,\n",
    "#         pad_idx=vocab[PAD_TOKEN],\n",
    "#         num_filters=num_filters,\n",
    "#         filter_sizes=FILTER_SIZES,\n",
    "#         dropout=DROPOUT,\n",
    "#         pretrained_embeddings=embedding_matrix,\n",
    "#         freeze_embeddings=False,\n",
    "#     ).to(device)\n",
    "\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "#     train_f1s = []\n",
    "#     val_f1s = []\n",
    "#     best_val_f1 = -1.0\n",
    "#     best_epoch = 0\n",
    "\n",
    "#     ckpt_path = GOOGLE_DRIVE_PATH + f\"/best_textcnn_glove_numfilters_{num_filters}.pt\"\n",
    "\n",
    "#     for epoch in range(1, max_epochs_cap + 1):\n",
    "#         # ---- Train one epoch ----\n",
    "#         train_loss, train_acc, train_preds, train_targets = train_one_epoch(\n",
    "#             model, train_loader, optimizer, criterion, device\n",
    "#         )\n",
    "#         train_f1 = f1_score(train_targets, train_preds, average=\"macro\")\n",
    "\n",
    "#         # ---- Validation ----\n",
    "#         val_loss, val_acc, val_preds, val_targets = evaluate(\n",
    "#             model, val_loader, criterion, device\n",
    "#         )\n",
    "#         val_f1 = f1_score(val_targets, val_preds, average=\"macro\")\n",
    "\n",
    "#         train_f1s.append(train_f1)\n",
    "#         val_f1s.append(val_f1)\n",
    "\n",
    "#         print(\n",
    "#             f\"[num_filters={num_filters}] \"\n",
    "#             f\"Epoch {epoch:02d} | \"\n",
    "#             f\"Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f} | \"\n",
    "#             f\"Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\"\n",
    "#         )\n",
    "\n",
    "#         # update best for this num_filters\n",
    "#         if val_f1 > best_val_f1:\n",
    "#             best_val_f1 = val_f1\n",
    "#             best_epoch = epoch\n",
    "#             torch.save(model.state_dict(), ckpt_path)\n",
    "#         # simple overfitting signal: first time val_f1 drops below best\n",
    "#         elif val_f1 < best_val_f1:\n",
    "#             print(\n",
    "#                 f\"Overfitting signal detected at epoch {epoch} \"\n",
    "#                 f\"(prev best val F1={best_val_f1:.4f} at epoch {best_epoch})\"\n",
    "#             )\n",
    "#             break\n",
    "\n",
    "#     results[num_filters] = {\n",
    "#         \"train_f1s\": train_f1s,\n",
    "#         \"val_f1s\": val_f1s,\n",
    "#         \"best_val_f1\": best_val_f1,\n",
    "#         \"best_epoch\": best_epoch,\n",
    "#         \"ckpt_path\": ckpt_path,\n",
    "#     }\n",
    "\n",
    "#     # track global best across all num_filters\n",
    "#     if best_val_f1 > best_overall_f1:\n",
    "#         best_overall_f1 = best_val_f1\n",
    "#         best_overall_cfg = {\n",
    "#             \"num_filters\": num_filters,\n",
    "#             \"ckpt_path\": ckpt_path,\n",
    "#             \"best_epoch\": best_epoch,\n",
    "#         }\n",
    "\n",
    "# print(\"\\n=== Sweep complete ===\")\n",
    "# print(f\"Best overall num_filters: {best_overall_cfg['num_filters']} \"\n",
    "#       f\"(val F1={best_overall_f1:.4f} at epoch={best_overall_cfg['best_epoch']})\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Validation curve: num_filters vs best validation F1\n",
    "#    + hard-coded list of best F1s\n",
    "# ------------------------------------------------\n",
    "# best_f1s = [results[nf][\"best_val_f1\"] for nf in num_filters_list]\n",
    "best_f1s = [0.82, 0.8266, 0.8235, 0.8144]\n",
    "\n",
    "# After you run once and see the values, you can hard-code them, e.g.:\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot([25,50,75,100], best_f1s, marker=\"o\")\n",
    "plt.xlabel(\"Number of Filters\", fontsize=16)\n",
    "plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n",
    "plt.xticks([25,50,75,100], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.title(\"TextCNN Validation Curve\", fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/textcnn_validation_curve_num_filters.png\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Using the best model config, load checkpoint and\n",
    "#    plot learning curve for 10 epochs (Train + Val F1)\n",
    "# ------------------------------------------------\n",
    "best_num_filters = 50\n",
    "best_ckpt_path = \"/best_textcnn_glove_numfilters_{best_num_filters}.pt\"\n",
    "\n",
    "print(f\"\\nReloading best model: num_filters={best_num_filters}, ckpt={best_ckpt_path}\")\n",
    "\n",
    "# Rebuild model with best num_filters\n",
    "# best_model = TextCNN(\n",
    "#     vocab_size=len(vocab),\n",
    "#     embed_dim=EMBED_DIM,\n",
    "#     num_classes=num_classes,\n",
    "#     pad_idx=vocab[PAD_TOKEN],\n",
    "#     num_filters=best_num_filters,\n",
    "#     filter_sizes=FILTER_SIZES,\n",
    "#     dropout=DROPOUT,\n",
    "#     pretrained_embeddings=embedding_matrix,\n",
    "#     freeze_embeddings=False,\n",
    "# ).to(device)\n",
    "\n",
    "# best_model.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
    "\n",
    "# best_optimizer = torch.optim.Adam(best_model.parameters(), lr=LR)\n",
    "\n",
    "final_train_f1s = []\n",
    "final_val_f1s = []\n",
    "EPOCHS_FOR_CURVE = 10\n",
    "epochs = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# print(\"\\nTraining best configuration for 10 epochs to plot learning curve...\")\n",
    "# for epoch in range(1, EPOCHS_FOR_CURVE + 1):\n",
    "#     best_model.train()\n",
    "#     train_loss, train_acc, train_preds, train_targets = train_one_epoch(\n",
    "#         best_model, train_loader, best_optimizer, criterion, device\n",
    "#     )\n",
    "#     train_f1 = f1_score(train_targets, train_preds, average=\"macro\")\n",
    "\n",
    "#     val_loss, val_acc, val_preds, val_targets = evaluate(\n",
    "#         best_model, val_loader, criterion, device\n",
    "#     )\n",
    "#     val_f1 = f1_score(val_targets, val_preds, average=\"macro\")\n",
    "\n",
    "#     final_train_f1s.append(train_f1)\n",
    "#     final_val_f1s.append(val_f1)\n",
    "\n",
    "#     print(\n",
    "#         f\"[BEST num_filters={best_num_filters}] \"\n",
    "#         f\"Epoch {epoch:02d} | \"\n",
    "#         f\"Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f} | \"\n",
    "#         f\"Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\"\n",
    "#     )\n",
    "\n",
    "final_val_f1s = [0.8192, 0.8176, 0.8216, 0.8203, 0.8180, 0.8165, 0.8161, 0.8118, 0.8097, 0.8093]\n",
    "final_train_f1s = [0.8602, 0.8675, 0.8752, 0.8819, 0.8888, 0.8952, 0.9010, 0.9063, 0.9115, 0.9171]\n",
    "# Plot learning curve (train + val F1) for best configuration\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(final_val_f1s)+1), final_train_f1s, label=\"Train\")\n",
    "plt.plot(range(1, len(final_val_f1s)+1), final_val_f1s, label=\"Validation\")\n",
    "plt.xticks([i for i in range(1, len(final_val_f1s)+1)], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Epoch\", fontsize=16)\n",
    "plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n",
    "plt.title(f\"TextCNN Learning Curve\", fontsize=18)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(GOOGLE_DRIVE_PATH + f\"/textcnn_learning_curve_best_{best_num_filters}.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404be072",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91769e83",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02235411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        num_labels = 3,\n",
    "        max_length = 64,\n",
    "        d_model = 256, # hidden size\n",
    "        nhead = 4, # number of attention heads\n",
    "        num_layers = 2, # number of encoder layers\n",
    "        dim_feedforward = 512,  # FFN inner dim\n",
    "        dropout = 0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Embedding(max_length, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True, # (batch, seq, dim)\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, num_labels),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch_size, seq_len = input_ids.size()\n",
    "        if seq_len > self.max_length:\n",
    "            raise ValueError(f\"seq_len {seq_len} > max_length {self.max_length}\")\n",
    "\n",
    "        token_emb = self.token_embedding(input_ids)  # (B, L, D)\n",
    "\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)  # (1, L)\n",
    "        pos_emb = self.pos_embedding(positions)  # (1, L, D)\n",
    "\n",
    "        x = token_emb + pos_emb  # (B, L, D)\n",
    "\n",
    "        src_key_padding_mask = (attention_mask == 0)  # (B, L), bool\n",
    "\n",
    "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)  # (B, L, D)\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        mask = attention_mask.unsqueeze(-1)  # (B, L, 1)\n",
    "        masked_x = x * mask  # (B, L, D)\n",
    "\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)  # (B, 1)\n",
    "        pooled = masked_x.sum(dim=1) / lengths  # (B, D)\n",
    "\n",
    "        logits = self.classifier(pooled)  # (B, num_labels)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec80daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_preds(all_logits, all_labels):\n",
    "    logits = np.concatenate(all_logits, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685e616",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "306f27c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_texts = df[\"train\"][\"text\"].tolist()\n",
    "dev_texts   = df[\"dev\"][\"text\"].tolist()\n",
    "test_texts   = df[\"test\"][\"text\"].tolist()\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=30000, # could be adjusted\n",
    "    min_frequency=2,\n",
    "    special_tokens=special_tokens,\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(train_texts, trainer=trainer)\n",
    "\n",
    "max_length = 64\n",
    "pad_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "tokenizer.enable_truncation(max_length=max_length)\n",
    "tokenizer.enable_padding(\n",
    "    length=max_length,\n",
    "    pad_id=pad_id,\n",
    "    pad_token=\"[PAD]\",\n",
    ")\n",
    "\n",
    "def encode_batch(texts):\n",
    "    encodings = tokenizer.encode_batch(texts)\n",
    "    input_ids = [e.ids for e in encodings]\n",
    "    attention_mask = [e.attention_mask for e in encodings]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "train_enc = encode_batch(train_texts)\n",
    "dev_enc   = encode_batch(dev_texts)\n",
    "test_enc   = encode_batch(test_texts)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      train_enc[\"input_ids\"],\n",
    "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"train\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      dev_enc[\"input_ids\"],\n",
    "    \"attention_mask\": dev_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"dev\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      test_enc[\"input_ids\"],\n",
    "    \"attention_mask\": test_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"test\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22588d1",
   "metadata": {},
   "source": [
    "### Plot Curves Using Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        num_labels = 3,\n",
    "        max_length = 64,\n",
    "        d_model = 256, # hidden size\n",
    "        nhead = 4, # number of attention heads\n",
    "        num_layers = 2, # number of encoder layers\n",
    "        dim_feedforward = 512,  # FFN inner dim\n",
    "        dropout = 0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Embedding(max_length, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True, # (batch, seq, dim)\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, num_labels),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch_size, seq_len = input_ids.size()\n",
    "        if seq_len > self.max_length:\n",
    "            raise ValueError(f\"seq_len {seq_len} > max_length {self.max_length}\")\n",
    "\n",
    "        token_emb = self.token_embedding(input_ids)  # (B, L, D)\n",
    "\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)  # (1, L)\n",
    "        pos_emb = self.pos_embedding(positions)  # (1, L, D)\n",
    "\n",
    "        x = token_emb + pos_emb  # (B, L, D)\n",
    "\n",
    "        src_key_padding_mask = (attention_mask == 0)  # (B, L), bool\n",
    "\n",
    "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)  # (B, L, D)\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        mask = attention_mask.unsqueeze(-1)  # (B, L, 1)\n",
    "        masked_x = x * mask  # (B, L, D)\n",
    "\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)  # (B, 1)\n",
    "        pooled = masked_x.sum(dim=1) / lengths  # (B, D)\n",
    "\n",
    "        logits = self.classifier(pooled)  # (B, num_labels)\n",
    "        return logits\n",
    "\n",
    "def compute_metrics_from_preds(all_logits, all_labels):\n",
    "    logits = np.concatenate(all_logits, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_texts = df[\"train\"][\"text\"].tolist()\n",
    "dev_texts   = df[\"dev\"][\"text\"].tolist()\n",
    "test_texts   = df[\"test\"][\"text\"].tolist()\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=30000, # could be adjusted\n",
    "    min_frequency=2,\n",
    "    special_tokens=special_tokens,\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(train_texts, trainer=trainer)\n",
    "\n",
    "max_length = 64\n",
    "pad_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "tokenizer.enable_truncation(max_length=max_length)\n",
    "tokenizer.enable_padding(\n",
    "    length=max_length,\n",
    "    pad_id=pad_id,\n",
    "    pad_token=\"[PAD]\",\n",
    ")\n",
    "\n",
    "def encode_batch(texts):\n",
    "    encodings = tokenizer.encode_batch(texts)\n",
    "    input_ids = [e.ids for e in encodings]\n",
    "    attention_mask = [e.attention_mask for e in encodings]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "train_enc = encode_batch(train_texts)\n",
    "dev_enc   = encode_batch(dev_texts)\n",
    "test_enc   = encode_batch(test_texts)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      train_enc[\"input_ids\"],\n",
    "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"train\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      dev_enc[\"input_ids\"],\n",
    "    \"attention_mask\": dev_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"dev\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      test_enc[\"input_ids\"],\n",
    "    \"attention_mask\": test_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"test\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Plotting helpers\n",
    "# ------------------------------------------------\n",
    "def plot_learning_curve(train_f1s, val_f1s):\n",
    "    N = len(train_f1s)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.xlabel(\"Epoch\", fontsize=16)\n",
    "    plt.plot(range(1, N+1), train_f1s, label=\"Train\")\n",
    "    plt.plot(range(1, N+1), val_f1s, label=\"Validation\")\n",
    "    plt.axvline(x=4, color='red', linestyle='--', linewidth=1.5)\n",
    "    plt.xticks([i for i in range(1, N+1)], fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n",
    "    plt.title(\"Custom Transformer Learning Curve\", fontsize=18)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(GOOGLE_DRIVE_PATH + \"/custom_transformer_learning_curve.png\")\n",
    "\n",
    "def plot_validation_curve(xticks, log_scale, val_f1s):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    if log_scale:\n",
    "        plt.semilogx(xticks, val_f1s, marker=\"o\")\n",
    "        plt.xticks(xticks, [f\"{x:.0e}\" for x in xticks], fontsize=14)\n",
    "    else:\n",
    "        plt.plot(xticks, val_f1s, marker=\"o\")\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel(\"Learning Rate (log scale)\" if log_scale else \"Learning Rate\", fontsize=16)\n",
    "    plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n",
    "    plt.title(\"Custom Transformer Validation Curve\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(GOOGLE_DRIVE_PATH + \"/custom_transformer_validation_curve.png\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Fixed architecture hyperparameters\n",
    "# ------------------------------------------------\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "BATCH_SIZE = 32\n",
    "NHEAD = 4\n",
    "DIM_FEEDFORWARD = 512\n",
    "WEIGHT_DECAY = 0.01\n",
    "MAX_LENGTH = 64\n",
    "\n",
    "MAX_EPOCHS_LEARNING_CURVE = 10  # epochs for final learning curve\n",
    "\n",
    "num_labels = len(label2id)\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "\n",
    "# Build DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    tokenized_datasets[\"test\"],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            all_logits.append(logits.detach().cpu().numpy())\n",
    "            all_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(data_loader)\n",
    "    metrics = compute_metrics_from_preds(all_logits, all_labels)\n",
    "    metrics[\"loss\"] = val_loss\n",
    "    return metrics\n",
    "\n",
    "# ============================================================\n",
    "# 1) SWEEP OVER LEARNING RATES: find best model and save it\n",
    "# ============================================================\n",
    "LR_VALUES = [5e-5, 1e-4, 3e-4, 1e-3]\n",
    "VAL_F1_PER_LR = []\n",
    "\n",
    "best_overall_f1 = -1.0\n",
    "best_lr = None\n",
    "best_model_path = GOOGLE_DRIVE_PATH + \"/best_custom_transformer_lr.pt\"\n",
    "\n",
    "EPOCHS_LR = 3  # small number of epochs for LR sweep\n",
    "\n",
    "# for lr in LR_VALUES:\n",
    "#     print(f\"\\n=== Validation curve run: lr={lr} ===\")\n",
    "\n",
    "#     # fresh model for each lr\n",
    "#     model_lr = TransformerClassifier(\n",
    "#         vocab_size=vocab_size,\n",
    "#         num_labels=num_labels,\n",
    "#         max_length=MAX_LENGTH,\n",
    "#         d_model=D_MODEL,\n",
    "#         nhead=NHEAD,\n",
    "#         num_layers=NUM_LAYERS,\n",
    "#         dim_feedforward=DIM_FEEDFORWARD,\n",
    "#         dropout=DROPOUT,\n",
    "#     ).to(device)\n",
    "\n",
    "#     optimizer_lr = AdamW(\n",
    "#         model_lr.parameters(),\n",
    "#         lr=lr,\n",
    "#         weight_decay=WEIGHT_DECAY,\n",
    "#     )\n",
    "\n",
    "#     best_val_f1_for_lr = -1.0\n",
    "\n",
    "#     for epoch in range(1, EPOCHS_LR + 1):\n",
    "#         # ----- train one epoch -----\n",
    "#         model_lr.train()\n",
    "#         total_loss = 0.0\n",
    "#         for batch in train_loader:\n",
    "#             input_ids = batch[\"input_ids\"].to(device)\n",
    "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#             labels = batch[\"label\"].to(device)\n",
    "\n",
    "#             optimizer_lr.zero_grad()\n",
    "#             logits = model_lr(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(logits, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer_lr.step()\n",
    "\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#         avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "#         # ----- evaluate on validation -----\n",
    "#         val_metrics_lr = evaluate_model(model_lr, val_loader)\n",
    "#         val_f1 = val_metrics_lr[\"f1\"]\n",
    "#         best_val_f1_for_lr = max(best_val_f1_for_lr, val_f1)\n",
    "\n",
    "#         print(\n",
    "#             f\"[lr={lr}] Epoch {epoch}/{EPOCHS_LR} | \"\n",
    "#             f\"train_loss={avg_train_loss:.4f}, \"\n",
    "#             f\"val_loss={val_metrics_lr['loss']:.4f}, \"\n",
    "#             f\"val_f1={val_f1:.4f}\"\n",
    "#         )\n",
    "\n",
    "#         # Track global best model across all LRs\n",
    "#         if val_f1 > best_overall_f1:\n",
    "#             best_overall_f1 = val_f1\n",
    "#             best_lr = lr\n",
    "#             torch.save(model_lr.state_dict(), best_model_path)\n",
    "\n",
    "#     VAL_F1_PER_LR.append(best_val_f1_for_lr)\n",
    "#     print(f\"Best val F1 for lr={lr}: {best_val_f1_for_lr:.4f}\")\n",
    "\n",
    "# print(\"\\n=== LR sweep complete ===\")\n",
    "# print(f\"Best LR: {best_lr} with val F1={best_overall_f1:.4f}\")\n",
    "# print(\"Best model saved to:\", best_model_path)\n",
    "\n",
    "VAL_F1_PER_LR = [0.7609, 0.7762, 0.7979, 0.7636]\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) Plot validation curve (LR vs best val F1)\n",
    "# ------------------------------------------------\n",
    "plot_validation_curve(\n",
    "    xticks=LR_VALUES,\n",
    "    log_scale=True,\n",
    "    val_f1s=VAL_F1_PER_LR,\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3) Load best model and plot learning curve for 10 epochs\n",
    "# ============================================================\n",
    "print(\"\\n=== Training learning-curve model from best LR ===\")\n",
    "print(f\"Reloading best LR={best_lr} and model from {best_model_path}\")\n",
    "\n",
    "# Rebuild model with same architecture and best LR\n",
    "best_model = TransformerClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    num_labels=num_labels,\n",
    "    max_length=MAX_LENGTH,\n",
    "    d_model=D_MODEL,\n",
    "    nhead=NHEAD,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dim_feedforward=DIM_FEEDFORWARD,\n",
    "    dropout=DROPOUT,\n",
    ").to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "\n",
    "# best_optimizer = AdamW(\n",
    "#     best_model.parameters(),\n",
    "#     lr=best_lr,\n",
    "#     weight_decay=WEIGHT_DECAY,\n",
    "# )\n",
    "\n",
    "train_f1s = [0.8851, 0.9041, 0.9190, 0.9334, 0.9410, 0.9543, 0.9628, 0.9641, 0.9677, 0.9730]\n",
    "val_f1s = [0.8067, 0.8078, 0.8103, 0.8141, 0.8066, 0.8088, 0.8075, 0.7996, 0.8027, 0.8018]\n",
    "\n",
    "# for epoch in range(1, MAX_EPOCHS_LEARNING_CURVE + 1):\n",
    "#     # ----- train one epoch -----\n",
    "#     best_model.train()\n",
    "#     total_loss = 0.0\n",
    "#     for batch in train_loader:\n",
    "#         input_ids = batch[\"input_ids\"].to(device)\n",
    "#         attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#         labels = batch[\"label\"].to(device)\n",
    "\n",
    "#         best_optimizer.zero_grad()\n",
    "#         logits = best_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         loss = criterion(logits, labels)\n",
    "#         loss.backward()\n",
    "#         best_optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "#     # Evaluate on train + validation for F1 curves\n",
    "#     train_metrics = evaluate_model(best_model, train_loader)\n",
    "#     val_metrics = evaluate_model(best_model, val_loader)\n",
    "\n",
    "#     train_f1 = train_metrics[\"f1\"]\n",
    "#     val_f1 = val_metrics[\"f1\"]\n",
    "\n",
    "#     train_f1s.append(train_f1)\n",
    "#     val_f1s.append(val_f1)\n",
    "\n",
    "#     print(\n",
    "#         f\"[Best LR={best_lr}] Epoch {epoch}/{MAX_EPOCHS_LEARNING_CURVE} | \"\n",
    "#         f\"train_loss={avg_train_loss:.4f}, \"\n",
    "#         f\"train_f1={train_f1:.4f}, \"\n",
    "#         f\"val_loss={val_metrics['loss']:.4f}, \"\n",
    "#         f\"val_f1={val_f1:.4f}\"\n",
    "#     )\n",
    "\n",
    "# Plot learning curve using your specified format\n",
    "plot_learning_curve(train_f1s, val_f1s)\n",
    "\n",
    "# test model\n",
    "test_metrics = evaluate_model(best_model, test_loader)\n",
    "\n",
    "print(f\"\\nTest Metrics (Best LR={best_lr}):\")\n",
    "print(f\"  Test Loss: {test_metrics['loss']:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Test Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"  Test Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"  Test F1 (macro): {test_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33376f76",
   "metadata": {},
   "source": [
    "## Pretrained Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682540d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class TrainMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, train_dataset, val_dataset, last_epoch = None):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.trainer = None\n",
    "        self.last_epoch = last_epoch\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.trainer is None:\n",
    "            return control\n",
    "\n",
    "        if self.last_epoch is None:\n",
    "            epoch = state.epoch\n",
    "        else:\n",
    "            self.last_epoch += 1\n",
    "            epoch = self.last_epoch\n",
    "\n",
    "        # --- train metrics ---\n",
    "        train_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.train_dataset,\n",
    "            metric_key_prefix=\"train\",  # train_accuracy, train_f1, ...\n",
    "        )\n",
    "\n",
    "        # --- validation metrics ---\n",
    "        val_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.val_dataset,\n",
    "            metric_key_prefix=\"eval\",   # eval_accuracy, eval_f1, ...\n",
    "        )\n",
    "\n",
    "        val_loss = val_metrics.get(\"eval_loss\")\n",
    "        val_acc  = val_metrics.get(\"eval_accuracy\")\n",
    "        val_prec = val_metrics.get(\"eval_precision\")\n",
    "        val_rec  = val_metrics.get(\"eval_recall\")\n",
    "        val_f1   = val_metrics.get(\"eval_f1\")\n",
    "\n",
    "        train_loss = train_metrics.get(\"train_loss\")\n",
    "        train_acc  = train_metrics.get(\"train_accuracy\")\n",
    "        train_prec = train_metrics.get(\"train_precision\")\n",
    "        train_rec  = train_metrics.get(\"train_recall\")\n",
    "        train_f1   = train_metrics.get(\"train_f1\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[EPOCH {epoch:.0f}]\")\n",
    "        if train_acc is not None:\n",
    "            print(f\"[train] loss={train_loss:.4f}, acc={train_acc:.4f}, prec={train_prec:.4f}, rec={train_rec:.4f}, f1={train_f1:.4f}\")\n",
    "        if val_acc is not None:\n",
    "            print(f\"[valid] loss={val_loss:.4f}, acc={val_acc:.4f}, prec={val_prec:.4f}, rec={val_rec:.4f}, f1={val_f1:.4f}\")\n",
    "        return control\n",
    "\n",
    "def train(model_name=\"./deberta\", last_epoch = None, epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\"):\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(\n",
    "      model_name,\n",
    "      num_labels=len(label2id),\n",
    "      id2label=id2label,\n",
    "      label2id=label2id,\n",
    "  )\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "      output_dir=output_dir,\n",
    "      eval_strategy=\"no\", # \"epoch\",\n",
    "      save_strategy=\"epoch\",\n",
    "      learning_rate=learning_rate,\n",
    "      per_device_train_batch_size=batch_size,\n",
    "      per_device_eval_batch_size=batch_size,\n",
    "      num_train_epochs=epoch,\n",
    "      weight_decay=0.01,\n",
    "      load_best_model_at_end=False, # True,\n",
    "      metric_for_best_model=\"f1\",\n",
    "      logging_strategy=\"epoch\",\n",
    "      report_to=\"none\",\n",
    "  )\n",
    "\n",
    "  train_callback = TrainMetricsCallback(\n",
    "      train_dataset=tokenized_datasets[\"train\"],\n",
    "      val_dataset=tokenized_datasets[\"validation\"],\n",
    "      last_epoch=last_epoch,\n",
    "  )\n",
    "\n",
    "  trainer = Trainer(\n",
    "      model=model,\n",
    "      args=training_args,\n",
    "      train_dataset=tokenized_datasets[\"train\"],\n",
    "      eval_dataset=tokenized_datasets[\"validation\"],\n",
    "      tokenizer=tokenizer,\n",
    "      compute_metrics=compute_metrics,\n",
    "      callbacks=[train_callback],\n",
    "  )\n",
    "\n",
    "  train_callback.trainer = trainer\n",
    "\n",
    "  trainer.train()\n",
    "  return trainer\n",
    "\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "def load_and_test_eval(ckpt_dir = GOOGLE_DRIVE_PATH + \"/checkpoint-26733\"):\n",
    "    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\".\", # any\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    eval_trainer = Trainer(\n",
    "        model=model_ckpt,\n",
    "        args=eval_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    eval_results = eval_trainer.evaluate(\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        metric_key_prefix=\"test\",\n",
    "    )\n",
    "    # {'test_loss': 0.4593863785266876, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8740698009806749, 'test_precision': 0.8326252068193959, 'test_recall': 0.8500324417218078, 'test_f1': 0.8369876991837396, 'test_runtime': 123.8232, 'test_samples_per_second': 139.998, 'test_steps_per_second': 2.189}\n",
    "    print(eval_results)\n",
    "    print(f\"[test] acc={eval_results['test_accuracy']}, prec={eval_results['test_precision']}, rec={eval_results['test_recall']}, f1={eval_results['test_f1']}\")\n",
    "    # print(f\"test_loss = {eval_results['test_loss']}\")\n",
    "    # print(f\"test_accuracy = {eval_results['test_accuracy']}\")\n",
    "    # print(f\"test_precision = {eval_results['test_precision']}\")\n",
    "    # print(f\"test_recall = {eval_results['test_recall']}\")\n",
    "    # print(f\"test_f1 = {eval_results['test_f1']}\")\n",
    "    return eval_results\n",
    "\n",
    "def load_and_val_eval(ckpt_dir = \"/checkpoint-26733\"):\n",
    "    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\".\", # any\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    eval_trainer = Trainer(\n",
    "        model=model_ckpt,\n",
    "        args=eval_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    eval_results = eval_trainer.evaluate(\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        metric_key_prefix=\"val\",\n",
    "    )\n",
    "    print(eval_results)\n",
    "    print(f\"[test] acc={eval_results['val_accuracy']}, prec={eval_results['val_precision']}, rec={eval_results['val_recall']}, f1={eval_results['val_f1']}\")\n",
    "    return eval_results['val_f1']\n",
    "\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download everything from https://huggingface.co/microsoft/deberta-v3-base/tree/main\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/deberta-v3-base\", # \"microsoft/deberta-v3-base\"\n",
    "    use_fast=True, # DeBERTa fast tokenizer \n",
    ")\n",
    "\n",
    "max_length = 64 # adjust based on the maximum input size?\n",
    "\n",
    "# 1. Tokenize directly\n",
    "train_encodings = tokenizer(\n",
    "    df[\"train\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    df[\"dev\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "test_encodings = tokenizer(\n",
    "    df[\"test\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "# 2. Build HF Datasets from encoded inputs + labels\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"train\"]['class_label_group_num'],\n",
    "    \"text\": df[\"train\"]['text']\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": val_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": val_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"dev\"]['class_label_group_num'],\n",
    "    \"text\": df[\"dev\"]['text']\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"test\"]['class_label_group_num'],\n",
    "    \"text\": df[\"test\"]['text']\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "# 3. Set format for PyTorch\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\", \"text\"],\n",
    ")\n",
    "\n",
    "# Check appropriate token size\n",
    "tmp_train = tokenizer(df[\"train\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n",
    "lens_train = [len(ids) for ids in tmp_train[\"input_ids\"]]\n",
    "\n",
    "tmp_dev = tokenizer(df[\"dev\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n",
    "lens_dev = [len(ids) for ids in tmp_dev[\"input_ids\"]]\n",
    "\n",
    "lengths = lens_train + lens_dev\n",
    "\n",
    "print(\"median:\", np.median(lengths))\n",
    "print(\"mean:\", np.mean(lengths))\n",
    "print(\"95th percentile:\", np.percentile(lengths, 95))\n",
    "print(\"99th percentile:\", np.percentile(lengths, 99))\n",
    "print(\"max:\", np.max(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "def collect_time_critical_fp_fn(\n",
    "    ckpt_dir,\n",
    "    split=\"test\",                # change to \"validation\" if needed\n",
    "    text_column=\"text\",\n",
    "    labels_column=\"label\",\n",
    "    positive_label_name=\"time_critical\",\n",
    "    output_csv=None,\n",
    "):\n",
    "    # default path for output CSV\n",
    "    if output_csv is None:\n",
    "        output_csv = GOOGLE_DRIVE_PATH + \"/time_critical_fp_fn_test.csv\"\n",
    "\n",
    "    # 1. Load model from checkpoint\n",
    "    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "    # 2. Set up an eval-only Trainer\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\".\",                 # arbitrary temp directory\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    eval_trainer = Trainer(\n",
    "        model=model_ckpt,\n",
    "        args=eval_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # 3. Get test split\n",
    "    test_ds = tokenized_datasets[split]\n",
    "\n",
    "    # 4. Run predictions\n",
    "    pred_output = eval_trainer.predict(test_ds)\n",
    "    logits = pred_output.predictions\n",
    "\n",
    "    # Softmax  probs\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    pred_ids = probs.argmax(axis=-1)\n",
    "\n",
    "    print(test_ds)\n",
    "\n",
    "    # True labels\n",
    "    true_ids = np.array(test_ds[labels_column])\n",
    "\n",
    "    # Map positive class name -> label id\n",
    "    pos_id = label2id[positive_label_name]\n",
    "\n",
    "    # Raw text\n",
    "    texts = test_ds[text_column]\n",
    "\n",
    "    # 5. Collect FP and FN\n",
    "    records = []\n",
    "    for idx, (txt, y_true, y_pred, p_vec) in enumerate(zip(texts, true_ids, pred_ids, probs)):\n",
    "        is_true_pos = (y_true == pos_id)\n",
    "        is_pred_pos = (y_pred == pos_id)\n",
    "\n",
    "        if is_pred_pos and not is_true_pos:\n",
    "            err_type = \"false_positive_time_critical\"\n",
    "        elif is_true_pos and not is_pred_pos:\n",
    "            err_type = \"false_negative_time_critical\"\n",
    "        else:\n",
    "            continue  # skip non-errors\n",
    "\n",
    "        records.append({\n",
    "            \"index\": idx,\n",
    "            \"error_type\": err_type,\n",
    "            \"text\": txt,\n",
    "            \"true_label_id\": int(y_true),\n",
    "            \"true_label\": id2label[int(y_true)],\n",
    "            \"pred_label_id\": int(y_pred),\n",
    "            \"pred_label\": id2label[int(y_pred)],\n",
    "            \"pred_prob_time_critical\": float(p_vec[pos_id]),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved {len(df)} rows to {output_csv}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6fbbe",
   "metadata": {},
   "source": [
    "### Qualitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb2891a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GOOGLE_DRIVE_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m BEST_DEBERTA_MODEL \u001b[38;5;241m=\u001b[39m \u001b[43mGOOGLE_DRIVE_PATH\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/checkpoint-26733\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m df_tc_errors \u001b[38;5;241m=\u001b[39m collect_time_critical_fp_fn(\n\u001b[1;32m      3\u001b[0m     ckpt_dir\u001b[38;5;241m=\u001b[39mBEST_DEBERTA_MODEL,\n\u001b[1;32m      4\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     output_csv \u001b[38;5;241m=\u001b[39m GOOGLE_DRIVE_PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/time_critical_fp_fn_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m df_tc_errors\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GOOGLE_DRIVE_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "BEST_DEBERTA_MODEL = GOOGLE_DRIVE_PATH + \"/checkpoint-26733\"\n",
    "df_tc_errors = collect_time_critical_fp_fn(\n",
    "    ckpt_dir=BEST_DEBERTA_MODEL,\n",
    "    split=\"test\",\n",
    "    output_csv = GOOGLE_DRIVE_PATH + \"/time_critical_fp_fn_test.csv\"\n",
    ")\n",
    "\n",
    "df_tc_errors.head()\n",
    "\n",
    "df_tc_errors = collect_time_critical_fp_fn(\n",
    "    ckpt_dir=BEST_DEBERTA_MODEL,\n",
    "    split=\"test\",\n",
    "    positive_label_name=\"support_and_relief\",\n",
    "    output_csv = GOOGLE_DRIVE_PATH + \"/support_and_relief_fp_fn_test.csv\"\n",
    ")\n",
    "\n",
    "df_tc_errors.head()\n",
    "\n",
    "df_tc_errors = collect_time_critical_fp_fn(\n",
    "    ckpt_dir=BEST_DEBERTA_MODEL,\n",
    "    split=\"test\",\n",
    "    positive_label_name=\"non_informative\",\n",
    "    output_csv = GOOGLE_DRIVE_PATH + \"/non_informative_fp_fn_test.csv\"\n",
    ")\n",
    "\n",
    "df_tc_errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7cb40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V6E1",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "crisisbench-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
