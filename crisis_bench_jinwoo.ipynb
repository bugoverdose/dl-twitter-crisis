{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a9ab23-f031-44a3-88cd-4d08f1f6381c",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ec020-a4bb-430f-b561-1f0367e5f486",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7346fe-d763-4501-9a45-1c4c7a9ab363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <473B02F4-48EA-3880-8B82-14AA228F6939> /Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0869bbce-6ad5-4929-9439-c2f4bc6249f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "generator = torch.Generator()\n",
    "_ = generator.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f2506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_strs = ['time_critical', 'support_and_relief', 'non_informative']\n",
    "label2id = {label: i for i, label in enumerate(all_label_strs)}\n",
    "id2label = {i: label for label, i in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83365a1-379c-4bc6-bbcc-eb8ca273209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./data/crisisbench/preprocessed_data_train.csv\n",
      "Loading: ./data/crisisbench/preprocessed_data_dev.csv\n",
      "Loading: ./data/crisisbench/preprocessed_data_test.csv\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    df = {}\n",
    "    for d in ['train', 'dev', 'test']:\n",
    "        output_path = f\"./data/crisisbench/preprocessed_data_{d}.csv\"\n",
    "        df[d] = pd.read_csv(output_path).loc[:, ['text', 'class_label_group', 'class_label_group_num']]\n",
    "        print(\"Loading:\", output_path)\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43775508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: N=61089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approximately km long firebreaks have been con...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>god bless you</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cracked wine casks damaged historical building...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i m really just excited for new undies and pin...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rescue effort e ands in india pakistan as floo...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class_label_group  \\\n",
       "0  approximately km long firebreaks have been con...     time_critical   \n",
       "1                                      god bless you   non_informative   \n",
       "2  cracked wine casks damaged historical building...     time_critical   \n",
       "3  i m really just excited for new undies and pin...   non_informative   \n",
       "4  rescue effort e ands in india pakistan as floo...     time_critical   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      0  \n",
       "1                      2  \n",
       "2                      0  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_train: N={len(df['train'])}\")\n",
    "df['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ce818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dev: N=8921\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>congrats to all my liverpool supporting fans f...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collapsed buildings in mexico city earthquake ...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>here s your flower</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ready for a relaxing weekend but have too much...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public private information portal developed to...</td>\n",
       "      <td>support_and_relief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   class_label_group  \\\n",
       "0  congrats to all my liverpool supporting fans f...     non_informative   \n",
       "1  collapsed buildings in mexico city earthquake ...       time_critical   \n",
       "2                                 here s your flower     non_informative   \n",
       "3  ready for a relaxing weekend but have too much...     non_informative   \n",
       "4  public private information portal developed to...  support_and_relief   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      2  \n",
       "1                      0  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_dev: N={len(df['dev'])}\")\n",
    "df['dev'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d208947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test: N=17335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staff at our feeding centre say chronic malnou...</td>\n",
       "      <td>support_and_relief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you comin down for the summer semesters right</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yea it s upstate i m like a few hours away</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teach every pakistani that it is not enough to...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stay with for live cvg as typhoon hagupit slam...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   class_label_group  \\\n",
       "0  staff at our feeding centre say chronic malnou...  support_and_relief   \n",
       "1      you comin down for the summer semesters right     non_informative   \n",
       "2         yea it s upstate i m like a few hours away     non_informative   \n",
       "3  teach every pakistani that it is not enough to...     non_informative   \n",
       "4  stay with for live cvg as typhoon hagupit slam...       time_critical   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      1  \n",
       "1                      2  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_test: N={len(df['test'])}\")\n",
    "df['test'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d27fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ea0a0",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a00974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8566f4e",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defa4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "MAX_SEQ_LEN = 64 # depends on tweet length\n",
    "EMBED_DIM = 50\n",
    "FILTER_SIZES = (3, 4, 5)\n",
    "NUM_FILTERS = 100\n",
    "DROPOUT = 0.5 # tune\n",
    "BATCH_SIZE = 64 # tune \n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 10\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "GLOVE_PATH = \"./data/crisisbench/glove_word_embeddings.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb1266",
   "metadata": {},
   "source": [
    "### Tokenizer and Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf53496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits on whitespace\n",
    "    \"\"\"\n",
    "    return text.strip().split()\n",
    "\n",
    "def build_vocab(\n",
    "    texts: List[str],\n",
    "    max_size: int,\n",
    "    min_freq: int = 1\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Build a word -> index vocab from training texts.\n",
    "    Reserves index 0 for PAD and 1 for UNK.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = simple_tokenize(text)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
    "    for word, freq in counter.most_common():\n",
    "        if freq < min_freq:\n",
    "            continue\n",
    "        if len(vocab) >= max_size:\n",
    "            break\n",
    "        vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def encode_text(\n",
    "    text: str,\n",
    "    vocab: Dict[str, int],\n",
    "    max_len: int\n",
    ") -> List[int]:\n",
    "    tokens = simple_tokenize(text)\n",
    "    ids = [vocab.get(tok, vocab[UNK_TOKEN]) for tok in tokens][:max_len]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [vocab[PAD_TOKEN]] * (max_len - len(ids))\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81ae81",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95f7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: List[int],\n",
    "        vocab: Dict[str, int],\n",
    "        max_len: int,\n",
    "    ):\n",
    "        assert len(texts) == len(labels)\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        input_ids = encode_text(text, self.vocab, self.max_len)\n",
    "        return torch.tensor(input_ids, dtype=torch.long), label\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_texts: List[str],\n",
    "    train_labels: List[int],\n",
    "    val_texts: List[str],\n",
    "    val_labels: List[int],\n",
    "    max_vocab_size: int,\n",
    "    max_seq_len: int,\n",
    "    batch_size: int,\n",
    ") -> Tuple[DataLoader, DataLoader, Dict[str, int], int]:\n",
    "    vocab = build_vocab(train_texts, max_vocab_size)\n",
    "    num_classes = len(set(train_labels))\n",
    "\n",
    "    train_dataset = TextDataset(train_texts, train_labels, vocab, max_seq_len)\n",
    "    val_dataset = TextDataset(val_texts, val_labels, vocab, max_seq_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, vocab, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d02775",
   "metadata": {},
   "source": [
    "### Load GloVe & build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1645084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(\n",
    "    glove_path: str,\n",
    "    embed_dim: int,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Load GloVe file into a dict: word -> vector (torch.Tensor).\n",
    "    Expects each line: word val1 val2 ... valD\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != embed_dim + 1:\n",
    "                # ignore malformed lines\n",
    "                continue\n",
    "            word = parts[0]\n",
    "            vec = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float32)\n",
    "            embeddings[word] = vec\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def build_embedding_matrix(\n",
    "    vocab: Dict[str, int],\n",
    "    glove_embeddings: Dict[str, torch.Tensor],\n",
    "    embed_dim: int,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create an embedding matrix of shape [vocab_size, embed_dim]\n",
    "    where row i is the vector for the word with index i.\n",
    "    Words not found in GloVe are randomly initialized (small normal).\n",
    "    \"\"\"\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_matrix = torch.empty(vocab_size, embed_dim, dtype=torch.float32)\n",
    "\n",
    "    # Initialize OOV embeddings to small random values\n",
    "    torch.nn.init.normal_(embedding_matrix, mean=0.0, std=0.05)\n",
    "\n",
    "    # Set PAD embedding to zeros\n",
    "    pad_idx = vocab[PAD_TOKEN]\n",
    "    embedding_matrix[pad_idx] = torch.zeros(embed_dim, dtype=torch.float32)\n",
    "\n",
    "    oov_count = 0\n",
    "    for word, idx in vocab.items():\n",
    "        if word in (PAD_TOKEN, UNK_TOKEN):\n",
    "            continue\n",
    "        vec = glove_embeddings.get(word)\n",
    "        if vec is not None:\n",
    "            embedding_matrix[idx] = vec\n",
    "        else:\n",
    "            oov_count += 1\n",
    "\n",
    "    print(f\"GloVe OOV words: {oov_count}/{vocab_size}\")\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60863f21",
   "metadata": {},
   "source": [
    "### Text CNN model (with optional pretrained embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f94c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        num_classes: int,\n",
    "        pad_idx: int = 0,\n",
    "        num_filters: int = 100,\n",
    "        filter_sizes: Tuple[int, ...] = (3, 4, 5),\n",
    "        dropout: float = 0.5,\n",
    "        pretrained_embeddings: torch.Tensor | None = None,\n",
    "        freeze_embeddings: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embed_dim,\n",
    "            padding_idx=pad_idx,\n",
    "        )\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            if pretrained_embeddings.shape != (vocab_size, embed_dim):\n",
    "                raise ValueError(\n",
    "                    f\"Pretrained embeddings shape {pretrained_embeddings.shape} \"\n",
    "                    f\"does not match (vocab_size, embed_dim)=({vocab_size}, {embed_dim})\"\n",
    "                )\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "            if freeze_embeddings:\n",
    "                self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=embed_dim,\n",
    "                out_channels=num_filters,\n",
    "                kernel_size=fs,\n",
    "            )\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        embedded = self.embedding(input_ids)          # [B, L, D]\n",
    "        embedded = embedded.transpose(1, 2)           # [B, D, L]\n",
    "\n",
    "        conv_outputs = []\n",
    "        for conv in self.convs:\n",
    "            x = conv(embedded)                        # [B, F, L']\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool1d(x, x.size(2)).squeeze(2) # [B, F]\n",
    "            conv_outputs.append(x)\n",
    "\n",
    "        cat = torch.cat(conv_outputs, dim=1)          # [B, F * len(filter_sizes)]\n",
    "        cat = self.dropout(cat)\n",
    "        logits = self.fc(cat)                         # [B, num_classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93543e0d",
   "metadata": {},
   "source": [
    "### Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1baee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for input_ids, labels in dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * input_ids.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(input_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67776a78",
   "metadata": {},
   "source": [
    "### Main CNN Train Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99044bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 20000, Num classes: 3\n",
      "Loading GloVe embeddings...\n",
      "GloVe OOV words: 882/20000\n",
      "Epoch 01 | Train Loss: 0.4595, Train Acc: 0.8258 | Val Loss: 0.3805, Val Acc: 0.8552\n",
      "Epoch 02 | Train Loss: 0.3572, Train Acc: 0.8675 | Val Loss: 0.3513, Val Acc: 0.8696\n",
      "Epoch 03 | Train Loss: 0.3088, Train Acc: 0.8865 | Val Loss: 0.3488, Val Acc: 0.8734\n",
      "Epoch 04 | Train Loss: 0.2718, Train Acc: 0.9027 | Val Loss: 0.3552, Val Acc: 0.8731\n",
      "Epoch 05 | Train Loss: 0.2348, Train Acc: 0.9148 | Val Loss: 0.3815, Val Acc: 0.8666\n",
      "Epoch 06 | Train Loss: 0.2045, Train Acc: 0.9268 | Val Loss: 0.3986, Val Acc: 0.8658\n",
      "Epoch 07 | Train Loss: 0.1774, Train Acc: 0.9370 | Val Loss: 0.4382, Val Acc: 0.8646\n",
      "Epoch 08 | Train Loss: 0.1547, Train Acc: 0.9453 | Val Loss: 0.4868, Val Acc: 0.8606\n",
      "Epoch 09 | Train Loss: 0.1365, Train Acc: 0.9517 | Val Loss: 0.5132, Val Acc: 0.8562\n",
      "Epoch 10 | Train Loss: 0.1208, Train Acc: 0.9579 | Val Loss: 0.5814, Val Acc: 0.8569\n",
      "Best validation accuracy: 0.8734\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_df = df['train'].dropna(subset=['text'])\n",
    "train_texts = train_df['text'].tolist()\n",
    "train_label_strs = train_df['class_label_group']\n",
    "\n",
    "val_df = df['dev'].dropna(subset=['text'])\n",
    "val_texts = val_df['text'].tolist()\n",
    "val_label_strs = val_df['class_label_group']\n",
    "\n",
    "all_label_strs = sorted(set(train_label_strs) | set(val_label_strs))\n",
    "label2id = {label: i for i, label in enumerate(all_label_strs)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "train_labels = [label2id[l] for l in train_label_strs]\n",
    "val_labels   = [label2id[l] for l in val_label_strs]\n",
    "# Create loaders and vocab\n",
    "train_loader, val_loader, vocab, num_classes = create_dataloaders(\n",
    "    train_texts=train_texts,\n",
    "    train_labels=train_labels,\n",
    "    val_texts=val_texts,\n",
    "    val_labels=val_labels,\n",
    "    max_vocab_size=MAX_VOCAB_SIZE,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "print(f\"Vocab size: {len(vocab)}, Num classes: {num_classes}\")\n",
    "\n",
    "# Load GloVe embeddings\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "glove_embeds = load_glove_embeddings(GLOVE_PATH, EMBED_DIM)\n",
    "embedding_matrix = build_embedding_matrix(vocab, glove_embeds, EMBED_DIM)\n",
    "\n",
    "# Initialize model with pretrained embeddings\n",
    "print(\"Model Initialization...\")\n",
    "model = TextCNN(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_classes=num_classes,\n",
    "    pad_idx=vocab[PAD_TOKEN],\n",
    "    num_filters=NUM_FILTERS,\n",
    "    filter_sizes=FILTER_SIZES,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_embeddings=embedding_matrix,\n",
    "    freeze_embeddings=False,   # set True if you want to freeze GloVe\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0.0\n",
    "print(\"Training...\")\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "    val_loss, val_acc = evaluate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_textcnn_glove.pt\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b973a",
   "metadata": {},
   "source": [
    "### Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1fdb0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics:\n",
      "accuracy: 0.8734\n",
      "precision: 0.8467\n",
      "recall: 0.8108\n",
      "f1: 0.8272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Helper to get predictions + labels from a DataLoader\n",
    "def get_all_preds_and_labels(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(input_ids)          # [B, num_classes]\n",
    "            preds = logits.argmax(dim=1)      # [B]\n",
    "\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# compute accuracy, precision, recall, F1 (macro)\n",
    "def compute_classification_metrics(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "    average: str = \"macro\",   # \"macro\", \"micro\", or \"weighted\"\n",
    "):\n",
    "    preds, labels = get_all_preds_and_labels(model, dataloader, device)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=average,\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_textcnn_glove.pt\", map_location=device))\n",
    "\n",
    "# For validation metrics\n",
    "val_metrics = compute_classification_metrics(model, val_loader, device, average=\"macro\")\n",
    "print(\"Validation metrics:\")\n",
    "for k, v in val_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051a548-63f6-4e96-8f3d-fed56f14f42e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b22bed-3c0a-4439-a1a8-7090fa815932",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "032841ea-0f01-437d-aff7-2e43f2d574f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        num_labels = 3,\n",
    "        max_length = 64,\n",
    "        d_model = 256, # hidden size\n",
    "        nhead = 4, # number of attention heads\n",
    "        num_layers = 4, # number of encoder layers\n",
    "        dim_feedforward = 512,  # FFN inner dim\n",
    "        dropout = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Embedding(max_length, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True, # (batch, seq, dim)\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, num_labels),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch_size, seq_len = input_ids.size()\n",
    "        if seq_len > self.max_length:\n",
    "            raise ValueError(f\"seq_len {seq_len} > max_length {self.max_length}\")\n",
    "\n",
    "        token_emb = self.token_embedding(input_ids)  # (B, L, D)\n",
    "\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)  # (1, L)\n",
    "        pos_emb = self.pos_embedding(positions)  # (1, L, D)\n",
    "\n",
    "        x = token_emb + pos_emb  # (B, L, D)\n",
    "\n",
    "        src_key_padding_mask = (attention_mask == 0)  # (B, L), bool\n",
    "\n",
    "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)  # (B, L, D)\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        mask = attention_mask.unsqueeze(-1)  # (B, L, 1)\n",
    "        masked_x = x * mask  # (B, L, D)\n",
    "\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)  # (B, 1)\n",
    "        pooled = masked_x.sum(dim=1) / lengths  # (B, D)\n",
    "\n",
    "        logits = self.classifier(pooled)  # (B, num_labels)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a35066bf-4d49-4551-b3d0-562a55e3f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_preds(all_logits, all_labels):\n",
    "    logits = np.concatenate(all_logits, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc4272-73e0-47e6-a9ea-1a4763bdc1e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "795519ff-4e33-408a-9759-503266752b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_texts = df[\"train\"][\"text\"].tolist()\n",
    "dev_texts   = df[\"dev\"][\"text\"].tolist()\n",
    "test_texts   = df[\"test\"][\"text\"].tolist()\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=30000, # could be adjusted\n",
    "    min_frequency=2,\n",
    "    special_tokens=special_tokens,\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(train_texts, trainer=trainer)\n",
    "\n",
    "max_length = 64\n",
    "pad_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "tokenizer.enable_truncation(max_length=max_length)\n",
    "tokenizer.enable_padding(\n",
    "    length=max_length,\n",
    "    pad_id=pad_id,\n",
    "    pad_token=\"[PAD]\",\n",
    ")\n",
    "\n",
    "def encode_batch(texts):\n",
    "    encodings = tokenizer.encode_batch(texts)\n",
    "    input_ids = [e.ids for e in encodings]\n",
    "    attention_mask = [e.attention_mask for e in encodings]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "train_enc = encode_batch(train_texts)\n",
    "dev_enc   = encode_batch(dev_texts)\n",
    "test_enc   = encode_batch(test_texts)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      train_enc[\"input_ids\"],\n",
    "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"train\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      dev_enc[\"input_ids\"],\n",
    "    \"attention_mask\": dev_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"dev\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      test_enc[\"input_ids\"],\n",
    "    \"attention_mask\": test_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"test\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829ec10-0fca-4019-a3c1-f1e129e0f0ad",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b20bfc4-260d-4557-9450-51fa9d8bcd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluate\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            all_logits.append(logits.detach().cpu().numpy())\n",
    "            all_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(data_loader)\n",
    "    metrics = compute_metrics_from_preds(all_logits, all_labels)\n",
    "    metrics[\"loss\"] = val_loss\n",
    "    return metrics\n",
    "    \n",
    "def train(\n",
    "        d_model=256,\n",
    "        nhead=4,\n",
    "        num_layers=4,\n",
    "        dim_feedforward=512,\n",
    "        dropout=0.1,\n",
    "        lr=1e-4,\n",
    "        batch_size = 32,\n",
    "        weight_decay=0.01,\n",
    "        last_epoch=0,\n",
    "        max_epochs=3,\n",
    "        save_path=\"./transformers/best_transformer_1.pt\"\n",
    "    ):\n",
    "    num_labels = len(label2id)\n",
    "    vocab_size = tokenizer.get_vocab_size()\n",
    "    max_length = 64\n",
    "    \n",
    "    model = TransformerClassifier(\n",
    "        vocab_size=vocab_size,\n",
    "        num_labels=num_labels,\n",
    "        max_length=max_length,\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_layers=num_layers,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        dropout=dropout,\n",
    "    ).to(device)\n",
    "    \n",
    "    # AdamW + weight decay\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        tokenized_datasets[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        tokenized_datasets[\"validation\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        tokenized_datasets[\"test\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        state = torch.load(save_path, map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "    else: # not os.path.exists(save_path) or last_epoch > 0:\n",
    "        logging_steps = 50\n",
    "        best_f1 = 0.0\n",
    "        best_state_dict = None\n",
    "        global_step = 0\n",
    "        \n",
    "        for epoch in range(last_epoch, max_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "        \n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs} [train]\")\n",
    "            for batch in pbar:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(logits, labels)\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                total_loss += loss.item()\n",
    "                global_step += 1\n",
    "        \n",
    "                if global_step % logging_steps == 0:\n",
    "                    avg_loss = total_loss / logging_steps\n",
    "                    pbar.set_postfix({\"loss\": f\"{avg_loss:.4f}\"})\n",
    "                    total_loss = 0.0\n",
    "    \n",
    "            # print performance every epoch\n",
    "            train_metrics = evaluate_model(model, train_loader)\n",
    "            val_metrics   = evaluate_model(model, val_loader)\n",
    "\n",
    "            print(f\"Epoch {epoch+1} train: train_loss  = {train_metrics['loss']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: accuracy    = {train_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: precision   = {train_metrics['precision']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: recall      = {train_metrics['recall']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: f1          = {train_metrics['f1']:.4f}\")\n",
    "\n",
    "            print(f\"Epoch {epoch+1} validation: val_loss    = {val_metrics['loss']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: accuracy    = {val_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: precision   = {val_metrics['precision']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: recall      = {val_metrics['recall']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: f1          = {val_metrics['f1']:.4f}\")\n",
    "\n",
    "            # save best model (highest f1)\n",
    "            if val_metrics[\"f1\"] > best_f1:\n",
    "                best_f1 = val_metrics[\"f1\"]\n",
    "                best_state_dict = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "                torch.save(best_state_dict, save_path)\n",
    "                print(f\"New best model (f1={best_f1:.4f}) saved.\\n\")\n",
    "            \n",
    "        # load best model\n",
    "        if best_state_dict is not None:\n",
    "            model.load_state_dict(best_state_dict)\n",
    "            print(f\"Loaded best model with f1={best_f1:.4f}\")\n",
    "    return model, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e763b1-3338-486c-9aa7-41615300b3de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "272f765d-dbea-4fe1-97cd-d7242e1499f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d98e0fa93940e5be2a9f443d3f67de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8400346120565331, 'precision': 0.7853384733927123, 'recall': 0.791181843157427, 'f1': 0.7880170998346174, 'loss': 0.4298086559805483}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=10, save_path=\"./transformers/best_transformer_1_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   f1          = 0.7790\n",
    "# Epoch 1 validation:\n",
    "#   f1          = 0.7610\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   f1          = 0.8281\n",
    "# Epoch 2 validation:\n",
    "#   f1          = 0.7858\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   f1          = 0.8610\n",
    "# Epoch 3 validation:\n",
    "#   f1          = 0.7978\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   f1          = 0.8896\n",
    "# Epoch 4 validation:\n",
    "#   f1          = 0.8002\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8400346120565331, 'precision': 0.7853384733927123, 'recall': 0.791181843157427, 'f1': 0.7880170998346174, 'loss': 0.4298086559805483}\n",
    "#### Overfitting ######\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   f1          = 0.9136\n",
    "# Epoch 5 validation:\n",
    "#   f1          = 0.7984\n",
    "\n",
    "# Epoch 6 train:\n",
    "#   f1          = 0.9454\n",
    "# Epoch 6 validation:\n",
    "#   f1          = 0.7911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7bf33-240d-48d6-8db9-4a3afe262ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.4335\n",
    "#   accuracy    = 0.8384\n",
    "#   precision   = 0.8024\n",
    "#   recall      = 0.7603\n",
    "#   f1          = 0.7790\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.4582\n",
    "#   accuracy    = 0.8268\n",
    "#   precision   = 0.7841\n",
    "#   recall      = 0.7429\n",
    "#   f1          = 0.7610\n",
    "# New best model (f1=0.7610) saved.\n",
    "\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   train_loss  = 0.3628\n",
    "#   accuracy    = 0.8716\n",
    "#   precision   = 0.8343\n",
    "#   recall      = 0.8230\n",
    "#   f1          = 0.8281\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss    = 0.4280\n",
    "#   accuracy    = 0.8413\n",
    "#   precision   = 0.7921\n",
    "#   recall      = 0.7802\n",
    "#   f1          = 0.7858\n",
    "# New best model (f1=0.7858) saved.\n",
    "\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   train_loss  = 0.2929\n",
    "#   accuracy    = 0.8966\n",
    "#   precision   = 0.8722\n",
    "#   recall      = 0.8507\n",
    "#   f1          = 0.8610\n",
    "\n",
    "# Epoch 3 validation:\n",
    "#   val_loss    = 0.4102\n",
    "#   accuracy    = 0.8530\n",
    "#   precision   = 0.8135\n",
    "#   recall      = 0.7843\n",
    "#   f1          = 0.7978\n",
    "# New best model (f1=0.7978) saved.\n",
    "\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   train_loss  = 0.2442\n",
    "#   accuracy    = 0.9165\n",
    "#   precision   = 0.8866\n",
    "#   recall      = 0.8927\n",
    "#   f1          = 0.8896\n",
    "\n",
    "# Epoch 4 validation:\n",
    "#   val_loss    = 0.4170\n",
    "#   accuracy    = 0.8504\n",
    "#   precision   = 0.8002\n",
    "#   recall      = 0.8006\n",
    "#   f1          = 0.8002\n",
    "# New best model (f1=0.8002) saved.\n",
    "\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   train_loss  = 0.1945\n",
    "#   accuracy    = 0.9336\n",
    "#   precision   = 0.9034\n",
    "#   recall      = 0.9247\n",
    "#   f1          = 0.9136\n",
    "\n",
    "# Epoch 5 validation:\n",
    "#   val_loss    = 0.4526\n",
    "#   accuracy    = 0.8463\n",
    "#   precision   = 0.7909\n",
    "#   recall      = 0.8072\n",
    "#   f1          = 0.7984\n",
    "\n",
    "\n",
    "# Epoch 6 train:\n",
    "#   train_loss  = 0.1474\n",
    "#   accuracy    = 0.9585\n",
    "#   precision   = 0.9492\n",
    "#   recall      = 0.9417\n",
    "#   f1          = 0.9454\n",
    "\n",
    "# Epoch 6 validation:\n",
    "#   val_loss    = 0.4453\n",
    "#   accuracy    = 0.8478\n",
    "#   precision   = 0.8033\n",
    "#   recall      = 0.7803\n",
    "#   f1          = 0.7911\n",
    "\n",
    "\n",
    "# Epoch 7 train:\n",
    "#   train_loss  = 0.1082\n",
    "#   accuracy    = 0.9660\n",
    "#   precision   = 0.9628\n",
    "#   recall      = 0.9469\n",
    "#   f1          = 0.9543\n",
    "\n",
    "# Epoch 7 validation:\n",
    "#   val_loss    = 0.5228\n",
    "#   accuracy    = 0.8459\n",
    "#   precision   = 0.8061\n",
    "#   recall      = 0.7696\n",
    "#   f1          = 0.7849\n",
    "\n",
    "\n",
    "# Epoch 8 train:\n",
    "#   train_loss  = 0.0803\n",
    "#   accuracy    = 0.9758\n",
    "#   precision   = 0.9719\n",
    "#   recall      = 0.9637\n",
    "#   f1          = 0.9677\n",
    "\n",
    "# Epoch 8 validation:\n",
    "#   val_loss    = 0.5808\n",
    "#   accuracy    = 0.8446\n",
    "#   precision   = 0.8029\n",
    "#   recall      = 0.7728\n",
    "#   f1          = 0.7867"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7f725-7ea2-4f1d-96de-d680ac9b89b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbce5ab7-1dbf-4d74-9614-8781b96abd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6387aeb920ac4325a3e90082e3a8502a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30fcbf12aa642c18e2fccb89d23dde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c5d60ced0b47b3b39cf220134b19bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train: train_loss  = 0.5130\n",
      "Epoch 1 train: accuracy    = 0.8026\n",
      "Epoch 1 train: precision   = 0.7595\n",
      "Epoch 1 train: recall      = 0.7103\n",
      "Epoch 1 train: f1          = 0.7275\n",
      "Epoch 1 validation: val_loss    = 0.5323\n",
      "Epoch 1 validation: accuracy    = 0.7972\n",
      "Epoch 1 validation: precision   = 0.7488\n",
      "Epoch 1 validation: recall      = 0.7015\n",
      "Epoch 1 validation: f1          = 0.7189\n",
      "New best model (f1=0.7189) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e066ce449c574414800673366d03c803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3311fcbb2f05407abde1f88f7ad59b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37425a67e685433eae554efae36bd166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train: train_loss  = 0.4540\n",
      "Epoch 2 train: accuracy    = 0.8300\n",
      "Epoch 2 train: precision   = 0.7967\n",
      "Epoch 2 train: recall      = 0.7502\n",
      "Epoch 2 train: f1          = 0.7626\n",
      "Epoch 2 validation: val_loss    = 0.4897\n",
      "Epoch 2 validation: accuracy    = 0.8115\n",
      "Epoch 2 validation: precision   = 0.7644\n",
      "Epoch 2 validation: recall      = 0.7226\n",
      "Epoch 2 validation: f1          = 0.7331\n",
      "New best model (f1=0.7331) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184693d561a94aedb386395c82b7777d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b828be4032e45b9b26f6cc168d03373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aeb1acd54a4990bea5af2c8d1a384b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train: train_loss  = 0.3880\n",
      "Epoch 3 train: accuracy    = 0.8566\n",
      "Epoch 3 train: precision   = 0.8315\n",
      "Epoch 3 train: recall      = 0.7796\n",
      "Epoch 3 train: f1          = 0.8023\n",
      "Epoch 3 validation: val_loss    = 0.4413\n",
      "Epoch 3 validation: accuracy    = 0.8349\n",
      "Epoch 3 validation: precision   = 0.8002\n",
      "Epoch 3 validation: recall      = 0.7471\n",
      "Epoch 3 validation: f1          = 0.7700\n",
      "New best model (f1=0.7700) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64d880b025d4ec8867455d763d629d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc3911432114d40a6eedd5c3477dd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64214bcc38f64804bc459b179b8321a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train: train_loss  = 0.3526\n",
      "Epoch 4 train: accuracy    = 0.8742\n",
      "Epoch 4 train: precision   = 0.8360\n",
      "Epoch 4 train: recall      = 0.8275\n",
      "Epoch 4 train: f1          = 0.8314\n",
      "Epoch 4 validation: val_loss    = 0.4302\n",
      "Epoch 4 validation: accuracy    = 0.8385\n",
      "Epoch 4 validation: precision   = 0.7880\n",
      "Epoch 4 validation: recall      = 0.7778\n",
      "Epoch 4 validation: f1          = 0.7824\n",
      "New best model (f1=0.7824) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da61e4ae3d54b87a29074bb13d66ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3a5688b2574c51beab9d8ed0fed221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d06bc2b234cbc9625af237518a784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train: train_loss  = 0.3248\n",
      "Epoch 5 train: accuracy    = 0.8821\n",
      "Epoch 5 train: precision   = 0.8390\n",
      "Epoch 5 train: recall      = 0.8512\n",
      "Epoch 5 train: f1          = 0.8446\n",
      "Epoch 5 validation: val_loss    = 0.4381\n",
      "Epoch 5 validation: accuracy    = 0.8349\n",
      "Epoch 5 validation: precision   = 0.7781\n",
      "Epoch 5 validation: recall      = 0.7863\n",
      "Epoch 5 validation: f1          = 0.7815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5223c3290754a5283c10295557d3cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeea49fc1d946a8a693bd72ff6b9928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22adda1d841942529b3f8bfac7934000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train: train_loss  = 0.3030\n",
      "Epoch 6 train: accuracy    = 0.8875\n",
      "Epoch 6 train: precision   = 0.8918\n",
      "Epoch 6 train: recall      = 0.8104\n",
      "Epoch 6 train: f1          = 0.8443\n",
      "Epoch 6 validation: val_loss    = 0.4422\n",
      "Epoch 6 validation: accuracy    = 0.8413\n",
      "Epoch 6 validation: precision   = 0.8258\n",
      "Epoch 6 validation: recall      = 0.7434\n",
      "Epoch 6 validation: f1          = 0.7765\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559cef063ba04efcb52ef89af38a04df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623f25210a0847289437c5b956819c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c999f62300c453180149d8e606351ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train: train_loss  = 0.2480\n",
      "Epoch 7 train: accuracy    = 0.9143\n",
      "Epoch 7 train: precision   = 0.9079\n",
      "Epoch 7 train: recall      = 0.8629\n",
      "Epoch 7 train: f1          = 0.8830\n",
      "Epoch 7 validation: val_loss    = 0.4434\n",
      "Epoch 7 validation: accuracy    = 0.8452\n",
      "Epoch 7 validation: precision   = 0.8135\n",
      "Epoch 7 validation: recall      = 0.7608\n",
      "Epoch 7 validation: f1          = 0.7835\n",
      "New best model (f1=0.7835) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724be301a5e14ce5a557ee36fe4e129e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9dc6f57f8a4ca1a1232037ac2777d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116e803f27294a2bb75c9f1d90cb4612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train: train_loss  = 0.2141\n",
      "Epoch 8 train: accuracy    = 0.9270\n",
      "Epoch 8 train: precision   = 0.9154\n",
      "Epoch 8 train: recall      = 0.8900\n",
      "Epoch 8 train: f1          = 0.9017\n",
      "Epoch 8 validation: val_loss    = 0.4528\n",
      "Epoch 8 validation: accuracy    = 0.8452\n",
      "Epoch 8 validation: precision   = 0.8071\n",
      "Epoch 8 validation: recall      = 0.7687\n",
      "Epoch 8 validation: f1          = 0.7856\n",
      "New best model (f1=0.7856) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afff0f572edb47449088cb0fa1e38b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae9d9a7ff5541458812e04c70ac947d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdccdcb663447fbb7962ef837252941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train: train_loss  = 0.1827\n",
      "Epoch 9 train: accuracy    = 0.9407\n",
      "Epoch 9 train: precision   = 0.9337\n",
      "Epoch 9 train: recall      = 0.9081\n",
      "Epoch 9 train: f1          = 0.9199\n",
      "Epoch 9 validation: val_loss    = 0.4592\n",
      "Epoch 9 validation: accuracy    = 0.8447\n",
      "Epoch 9 validation: precision   = 0.8086\n",
      "Epoch 9 validation: recall      = 0.7655\n",
      "Epoch 9 validation: f1          = 0.7844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd38f4d07034d57be814c13f753f27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65903f1c2bc14f51b5cc222826cbe91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/_monitor.py\", line 84, in run\n",
      "    instance.refresh(nolock=True)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/std.py\", line 1347, in refresh\n",
      "    self.display()\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/notebook.py\", line 171, in display\n",
      "    rtext.value = right\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 716, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 706, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 1513, in _notify_trait\n",
      "    self.notify_change(\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 700, in notify_change\n",
      "    self.send_state(key=name)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 586, in send_state\n",
      "    self._send(msg, buffers=buffers)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 825, in _send\n",
      "    self.comm.send(data=msg, buffers=buffers)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/comm/base_comm.py\", line 144, in send\n",
      "    self.publish_msg(\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipykernel/comm/comm.py\", line 42, in publish_msg\n",
      "    parent=self.kernel.get_parent(),\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 797, in get_parent\n",
      "    return self._shell_parent.get()\n",
      "LookupError: <ContextVar name='shell_parent' at 0x1213bd300>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bb4bb7df8043668b65a10cd43afe99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train: train_loss  = 0.1740\n",
      "Epoch 10 train: accuracy    = 0.9423\n",
      "Epoch 10 train: precision   = 0.9192\n",
      "Epoch 10 train: recall      = 0.9270\n",
      "Epoch 10 train: f1          = 0.9217\n",
      "Epoch 10 validation: val_loss    = 0.4961\n",
      "Epoch 10 validation: accuracy    = 0.8335\n",
      "Epoch 10 validation: precision   = 0.7845\n",
      "Epoch 10 validation: recall      = 0.7833\n",
      "Epoch 10 validation: f1          = 0.7799\n",
      "Loaded best model with f1=0.7856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43871e160fe448968b8fa7049a788252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/2167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=10, save_path=\"./transformers/best_transformer_2_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 8 validation: f1          = 0.7856\n",
    "# Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb4d3f-9d18-4709-8a1e-3c03c6a57422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train: train_loss  = 0.5130\n",
    "# Epoch 1 train: accuracy    = 0.8026\n",
    "# Epoch 1 train: precision   = 0.7595\n",
    "# Epoch 1 train: recall      = 0.7103\n",
    "# Epoch 1 train: f1          = 0.7275\n",
    "# Epoch 1 validation: val_loss    = 0.5323\n",
    "# Epoch 1 validation: accuracy    = 0.7972\n",
    "# Epoch 1 validation: precision   = 0.7488\n",
    "# Epoch 1 validation: recall      = 0.7015\n",
    "# Epoch 1 validation: f1          = 0.7189\n",
    "# New best model (f1=0.7189) saved.\n",
    "\n",
    "# Epoch 2 train: train_loss  = 0.4540\n",
    "# Epoch 2 train: accuracy    = 0.8300\n",
    "# Epoch 2 train: precision   = 0.7967\n",
    "# Epoch 2 train: recall      = 0.7502\n",
    "# Epoch 2 train: f1          = 0.7626\n",
    "# Epoch 2 validation: val_loss    = 0.4897\n",
    "# Epoch 2 validation: accuracy    = 0.8115\n",
    "# Epoch 2 validation: precision   = 0.7644\n",
    "# Epoch 2 validation: recall      = 0.7226\n",
    "# Epoch 2 validation: f1          = 0.7331\n",
    "# New best model (f1=0.7331) saved.\n",
    "\n",
    "# Epoch 3 train: train_loss  = 0.3880\n",
    "# Epoch 3 train: accuracy    = 0.8566\n",
    "# Epoch 3 train: precision   = 0.8315\n",
    "# Epoch 3 train: recall      = 0.7796\n",
    "# Epoch 3 train: f1          = 0.8023\n",
    "# Epoch 3 validation: val_loss    = 0.4413\n",
    "# Epoch 3 validation: accuracy    = 0.8349\n",
    "# Epoch 3 validation: precision   = 0.8002\n",
    "# Epoch 3 validation: recall      = 0.7471\n",
    "# Epoch 3 validation: f1          = 0.7700\n",
    "# New best model (f1=0.7700) saved.\n",
    "\n",
    "# Epoch 4 train: train_loss  = 0.3526\n",
    "# Epoch 4 train: accuracy    = 0.8742\n",
    "# Epoch 4 train: precision   = 0.8360\n",
    "# Epoch 4 train: recall      = 0.8275\n",
    "# Epoch 4 train: f1          = 0.8314\n",
    "# Epoch 4 validation: val_loss    = 0.4302\n",
    "# Epoch 4 validation: accuracy    = 0.8385\n",
    "# Epoch 4 validation: precision   = 0.7880\n",
    "# Epoch 4 validation: recall      = 0.7778\n",
    "# Epoch 4 validation: f1          = 0.7824\n",
    "# New best model (f1=0.7824) saved.\n",
    "\n",
    "# Epoch 5 train: train_loss  = 0.3248\n",
    "# Epoch 5 train: accuracy    = 0.8821\n",
    "# Epoch 5 train: precision   = 0.8390\n",
    "# Epoch 5 train: recall      = 0.8512\n",
    "# Epoch 5 train: f1          = 0.8446\n",
    "# Epoch 5 validation: val_loss    = 0.4381\n",
    "# Epoch 5 validation: accuracy    = 0.8349\n",
    "# Epoch 5 validation: precision   = 0.7781\n",
    "# Epoch 5 validation: recall      = 0.7863\n",
    "# Epoch 5 validation: f1          = 0.7815\n",
    "\n",
    "# Epoch 6 train: train_loss  = 0.3030\n",
    "# Epoch 6 train: accuracy    = 0.8875\n",
    "# Epoch 6 train: precision   = 0.8918\n",
    "# Epoch 6 train: recall      = 0.8104\n",
    "# Epoch 6 train: f1          = 0.8443\n",
    "# Epoch 6 validation: val_loss    = 0.4422\n",
    "# Epoch 6 validation: accuracy    = 0.8413\n",
    "# Epoch 6 validation: precision   = 0.8258\n",
    "# Epoch 6 validation: recall      = 0.7434\n",
    "# Epoch 6 validation: f1          = 0.7765\n",
    "\n",
    "# Epoch 7 train: train_loss  = 0.2480\n",
    "# Epoch 7 train: accuracy    = 0.9143\n",
    "# Epoch 7 train: precision   = 0.9079\n",
    "# Epoch 7 train: recall      = 0.8629\n",
    "# Epoch 7 train: f1          = 0.8830\n",
    "# Epoch 7 validation: val_loss    = 0.4434\n",
    "# Epoch 7 validation: accuracy    = 0.8452\n",
    "# Epoch 7 validation: precision   = 0.8135\n",
    "# Epoch 7 validation: recall      = 0.7608\n",
    "# Epoch 7 validation: f1          = 0.7835\n",
    "# New best model (f1=0.7835) saved.\n",
    "\n",
    "# Epoch 8 train: train_loss  = 0.2141\n",
    "# Epoch 8 train: accuracy    = 0.9270\n",
    "# Epoch 8 train: precision   = 0.9154\n",
    "# Epoch 8 train: recall      = 0.8900\n",
    "# Epoch 8 train: f1          = 0.9017\n",
    "# Epoch 8 validation: val_loss    = 0.4528\n",
    "# Epoch 8 validation: accuracy    = 0.8452\n",
    "# Epoch 8 validation: precision   = 0.8071\n",
    "# Epoch 8 validation: recall      = 0.7687\n",
    "# Epoch 8 validation: f1          = 0.7856\n",
    "# New best model (f1=0.7856) saved.\n",
    "\n",
    "# Epoch 9 train: train_loss  = 0.1827\n",
    "# Epoch 9 train: accuracy    = 0.9407\n",
    "# Epoch 9 train: precision   = 0.9337\n",
    "# Epoch 9 train: recall      = 0.9081\n",
    "# Epoch 9 train: f1          = 0.9199\n",
    "# Epoch 9 validation: val_loss    = 0.4592\n",
    "# Epoch 9 validation: accuracy    = 0.8447\n",
    "# Epoch 9 validation: precision   = 0.8086\n",
    "# Epoch 9 validation: recall      = 0.7655\n",
    "# Epoch 9 validation: f1          = 0.7844\n",
    "\n",
    "# Epoch 10 train: train_loss  = 0.1740\n",
    "# Epoch 10 train: accuracy    = 0.9423\n",
    "# Epoch 10 train: precision   = 0.9192\n",
    "# Epoch 10 train: recall      = 0.9270\n",
    "# Epoch 10 train: f1          = 0.9217\n",
    "# Epoch 10 validation: val_loss    = 0.4961\n",
    "# Epoch 10 validation: accuracy    = 0.8335\n",
    "# Epoch 10 validation: precision   = 0.7845\n",
    "# Epoch 10 validation: recall      = 0.7833\n",
    "# Epoch 10 validation: f1          = 0.7799\n",
    "# Loaded best model with f1=0.7856\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1560ac-d830-4f9c-af1d-831caf614038",
   "metadata": {},
   "source": [
    "#### best_transformer_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24663986-5fc7-4f11-80da-72e2cd2bf2eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dcec888c204373805b33c5da8e4322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b79733d05242c78a921989b618d2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9673dbd6727466e9b23e93abe353ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train: train_loss  = 0.5427\n",
      "Epoch 1 train: accuracy    = 0.7908\n",
      "Epoch 1 train: precision   = 0.7750\n",
      "Epoch 1 train: recall      = 0.6531\n",
      "Epoch 1 train: f1          = 0.6932\n",
      "Epoch 1 validation: val_loss    = 0.5459\n",
      "Epoch 1 validation: accuracy    = 0.7876\n",
      "Epoch 1 validation: precision   = 0.7631\n",
      "Epoch 1 validation: recall      = 0.6470\n",
      "Epoch 1 validation: f1          = 0.6848\n",
      "New best model (f1=0.6848) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7679b127de24816a5b21969deb4cfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966d23eda40478e81fd1f0a59fcc6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d34ff15530e422ea044aaac3a7708dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train: train_loss  = 0.4633\n",
      "Epoch 2 train: accuracy    = 0.8244\n",
      "Epoch 2 train: precision   = 0.7907\n",
      "Epoch 2 train: recall      = 0.7311\n",
      "Epoch 2 train: f1          = 0.7563\n",
      "Epoch 2 validation: val_loss    = 0.4769\n",
      "Epoch 2 validation: accuracy    = 0.8165\n",
      "Epoch 2 validation: precision   = 0.7775\n",
      "Epoch 2 validation: recall      = 0.7193\n",
      "Epoch 2 validation: f1          = 0.7439\n",
      "New best model (f1=0.7439) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4973df55f1ff450e8d0518450f24d542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b59e7fbdcb422fbf97f42710936b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f98cc7e0db4db2b596b955f0bb27bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train: train_loss  = 0.4280\n",
      "Epoch 3 train: accuracy    = 0.8397\n",
      "Epoch 3 train: precision   = 0.8104\n",
      "Epoch 3 train: recall      = 0.7568\n",
      "Epoch 3 train: f1          = 0.7788\n",
      "Epoch 3 validation: val_loss    = 0.4552\n",
      "Epoch 3 validation: accuracy    = 0.8291\n",
      "Epoch 3 validation: precision   = 0.7945\n",
      "Epoch 3 validation: recall      = 0.7392\n",
      "Epoch 3 validation: f1          = 0.7618\n",
      "New best model (f1=0.7618) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8845fe7273419a82255ff6ee3a6e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c5b3b2ea7c4c3bac9cc13c25ae1eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5668e50faf485e8f961f2586b7968b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train: train_loss  = 0.3918\n",
      "Epoch 4 train: accuracy    = 0.8547\n",
      "Epoch 4 train: precision   = 0.8102\n",
      "Epoch 4 train: recall      = 0.8011\n",
      "Epoch 4 train: f1          = 0.8055\n",
      "Epoch 4 validation: val_loss    = 0.4373\n",
      "Epoch 4 validation: accuracy    = 0.8350\n",
      "Epoch 4 validation: precision   = 0.7836\n",
      "Epoch 4 validation: recall      = 0.7700\n",
      "Epoch 4 validation: f1          = 0.7765\n",
      "New best model (f1=0.7765) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3caa513ff394c98ab10707aebbdeca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0630c5085f640bd8817aaca144c54ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76486ece0c5544609f40906206daf6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train: train_loss  = 0.3623\n",
      "Epoch 5 train: accuracy    = 0.8659\n",
      "Epoch 5 train: precision   = 0.8320\n",
      "Epoch 5 train: recall      = 0.8071\n",
      "Epoch 5 train: f1          = 0.8181\n",
      "Epoch 5 validation: val_loss    = 0.4230\n",
      "Epoch 5 validation: accuracy    = 0.8440\n",
      "Epoch 5 validation: precision   = 0.8027\n",
      "Epoch 5 validation: recall      = 0.7758\n",
      "Epoch 5 validation: f1          = 0.7876\n",
      "New best model (f1=0.7876) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fc70599a0c4b149c1e62515bcb5534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09b993453a14cb893900bb3ff4357d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b434f477b90493fbe16f8bbd2d79dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train: train_loss  = 0.3344\n",
      "Epoch 6 train: accuracy    = 0.8765\n",
      "Epoch 6 train: precision   = 0.8492\n",
      "Epoch 6 train: recall      = 0.8171\n",
      "Epoch 6 train: f1          = 0.8308\n",
      "Epoch 6 validation: val_loss    = 0.4085\n",
      "Epoch 6 validation: accuracy    = 0.8468\n",
      "Epoch 6 validation: precision   = 0.8068\n",
      "Epoch 6 validation: recall      = 0.7739\n",
      "Epoch 6 validation: f1          = 0.7877\n",
      "New best model (f1=0.7877) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f36b5afae5b4e6eb05ff3965396a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6f3944d55840c7b93b7858ac96cde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d9d0a42bdb4d9eb0cb3aec2ca6ede9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train: train_loss  = 0.3135\n",
      "Epoch 7 train: accuracy    = 0.8857\n",
      "Epoch 7 train: precision   = 0.8603\n",
      "Epoch 7 train: recall      = 0.8300\n",
      "Epoch 7 train: f1          = 0.8441\n",
      "Epoch 7 validation: val_loss    = 0.4137\n",
      "Epoch 7 validation: accuracy    = 0.8537\n",
      "Epoch 7 validation: precision   = 0.8199\n",
      "Epoch 7 validation: recall      = 0.7828\n",
      "Epoch 7 validation: f1          = 0.7996\n",
      "New best model (f1=0.7996) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2611e5fcc334e2eb2acaa9d451f6b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cf0f15021c44bca172a665a8052d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6c9db5cf3a43cfbad6e6a0f291e73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train: train_loss  = 0.2867\n",
      "Epoch 8 train: accuracy    = 0.8962\n",
      "Epoch 8 train: precision   = 0.8761\n",
      "Epoch 8 train: recall      = 0.8443\n",
      "Epoch 8 train: f1          = 0.8590\n",
      "Epoch 8 validation: val_loss    = 0.4044\n",
      "Epoch 8 validation: accuracy    = 0.8523\n",
      "Epoch 8 validation: precision   = 0.8169\n",
      "Epoch 8 validation: recall      = 0.7792\n",
      "Epoch 8 validation: f1          = 0.7963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0f41640fe14cf3a4b114606102e77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0cbea3b34d4711a0478f17f8bbdf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab07d8b1202f4398b8707b7247f5e975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train: train_loss  = 0.2706\n",
      "Epoch 9 train: accuracy    = 0.9026\n",
      "Epoch 9 train: precision   = 0.8843\n",
      "Epoch 9 train: recall      = 0.8545\n",
      "Epoch 9 train: f1          = 0.8674\n",
      "Epoch 9 validation: val_loss    = 0.4110\n",
      "Epoch 9 validation: accuracy    = 0.8528\n",
      "Epoch 9 validation: precision   = 0.8164\n",
      "Epoch 9 validation: recall      = 0.7832\n",
      "Epoch 9 validation: f1          = 0.7972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91da248a5a5c4796a99c15902bec8b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03141e05e69404aa19308077b45ae8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba195f8468c4aa9a1194a28b3b58d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train: train_loss  = 0.2498\n",
      "Epoch 10 train: accuracy    = 0.9113\n",
      "Epoch 10 train: precision   = 0.8779\n",
      "Epoch 10 train: recall      = 0.8867\n",
      "Epoch 10 train: f1          = 0.8822\n",
      "Epoch 10 validation: val_loss    = 0.4073\n",
      "Epoch 10 validation: accuracy    = 0.8541\n",
      "Epoch 10 validation: precision   = 0.8042\n",
      "Epoch 10 validation: recall      = 0.8063\n",
      "Epoch 10 validation: f1          = 0.8052\n",
      "New best model (f1=0.8052) saved.\n",
      "\n",
      "Loaded best model with f1=0.8052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7f2a4d27224028a9e6d6aa103a71d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/2167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8478223247764638, 'precision': 0.7947469165050163, 'recall': 0.803183331774572, 'f1': 0.7988119336768936, 'loss': 0.43349864214906286}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1 => 0.3\n",
    "model, test_loader = train(dropout=0.3, lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=10, save_path=\"./transformers/best_transformer_3.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 10 validation: f1          = 0.8052\n",
    "# Final eval_results: {'accuracy': 0.8478223247764638, 'precision': 0.7947469165050163, 'recall': 0.803183331774572, 'f1': 0.7988119336768936, 'loss': 0.43349864214906286}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2ed1bc9-3e1b-422a-a8c7-0034645c384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train: train_loss  = 0.5427\n",
    "# Epoch 1 train: accuracy    = 0.7908\n",
    "# Epoch 1 train: precision   = 0.7750\n",
    "# Epoch 1 train: recall      = 0.6531\n",
    "# Epoch 1 train: f1          = 0.6932\n",
    "# Epoch 1 validation: val_loss    = 0.5459\n",
    "# Epoch 1 validation: accuracy    = 0.7876\n",
    "# Epoch 1 validation: precision   = 0.7631\n",
    "# Epoch 1 validation: recall      = 0.6470\n",
    "# Epoch 1 validation: f1          = 0.6848\n",
    "# New best model (f1=0.6848) saved.\n",
    "\n",
    "# Epoch 2 train: train_loss  = 0.4633\n",
    "# Epoch 2 train: accuracy    = 0.8244\n",
    "# Epoch 2 train: precision   = 0.7907\n",
    "# Epoch 2 train: recall      = 0.7311\n",
    "# Epoch 2 train: f1          = 0.7563\n",
    "# Epoch 2 validation: val_loss    = 0.4769\n",
    "# Epoch 2 validation: accuracy    = 0.8165\n",
    "# Epoch 2 validation: precision   = 0.7775\n",
    "# Epoch 2 validation: recall      = 0.7193\n",
    "# Epoch 2 validation: f1          = 0.7439\n",
    "# New best model (f1=0.7439) saved.\n",
    "\n",
    "# Epoch 3 train: train_loss  = 0.4280\n",
    "# Epoch 3 train: accuracy    = 0.8397\n",
    "# Epoch 3 train: precision   = 0.8104\n",
    "# Epoch 3 train: recall      = 0.7568\n",
    "# Epoch 3 train: f1          = 0.7788\n",
    "# Epoch 3 validation: val_loss    = 0.4552\n",
    "# Epoch 3 validation: accuracy    = 0.8291\n",
    "# Epoch 3 validation: precision   = 0.7945\n",
    "# Epoch 3 validation: recall      = 0.7392\n",
    "# Epoch 3 validation: f1          = 0.7618\n",
    "# New best model (f1=0.7618) saved.\n",
    "\n",
    "# Epoch 4 train: train_loss  = 0.3918\n",
    "# Epoch 4 train: accuracy    = 0.8547\n",
    "# Epoch 4 train: precision   = 0.8102\n",
    "# Epoch 4 train: recall      = 0.8011\n",
    "# Epoch 4 train: f1          = 0.8055\n",
    "# Epoch 4 validation: val_loss    = 0.4373\n",
    "# Epoch 4 validation: accuracy    = 0.8350\n",
    "# Epoch 4 validation: precision   = 0.7836\n",
    "# Epoch 4 validation: recall      = 0.7700\n",
    "# Epoch 4 validation: f1          = 0.7765\n",
    "# New best model (f1=0.7765) saved.\n",
    "\n",
    "# Epoch 5 train: train_loss  = 0.3623\n",
    "# Epoch 5 train: accuracy    = 0.8659\n",
    "# Epoch 5 train: precision   = 0.8320\n",
    "# Epoch 5 train: recall      = 0.8071\n",
    "# Epoch 5 train: f1          = 0.8181\n",
    "# Epoch 5 validation: val_loss    = 0.4230\n",
    "# Epoch 5 validation: accuracy    = 0.8440\n",
    "# Epoch 5 validation: precision   = 0.8027\n",
    "# Epoch 5 validation: recall      = 0.7758\n",
    "# Epoch 5 validation: f1          = 0.7876\n",
    "# New best model (f1=0.7876) saved.\n",
    "\n",
    "# Epoch 6 train: train_loss  = 0.3344\n",
    "# Epoch 6 train: accuracy    = 0.8765\n",
    "# Epoch 6 train: precision   = 0.8492\n",
    "# Epoch 6 train: recall      = 0.8171\n",
    "# Epoch 6 train: f1          = 0.8308\n",
    "# Epoch 6 validation: val_loss    = 0.4085\n",
    "# Epoch 6 validation: accuracy    = 0.8468\n",
    "# Epoch 6 validation: precision   = 0.8068\n",
    "# Epoch 6 validation: recall      = 0.7739\n",
    "# Epoch 6 validation: f1          = 0.7877\n",
    "# New best model (f1=0.7877) saved.\n",
    "\n",
    "# Epoch 7 train: train_loss  = 0.3135\n",
    "# Epoch 7 train: accuracy    = 0.8857\n",
    "# Epoch 7 train: precision   = 0.8603\n",
    "# Epoch 7 train: recall      = 0.8300\n",
    "# Epoch 7 train: f1          = 0.8441\n",
    "# Epoch 7 validation: val_loss    = 0.4137\n",
    "# Epoch 7 validation: accuracy    = 0.8537\n",
    "# Epoch 7 validation: precision   = 0.8199\n",
    "# Epoch 7 validation: recall      = 0.7828\n",
    "# Epoch 7 validation: f1          = 0.7996\n",
    "# New best model (f1=0.7996) saved.\n",
    "\n",
    "# Epoch 8 train: train_loss  = 0.2867\n",
    "# Epoch 8 train: accuracy    = 0.8962\n",
    "# Epoch 8 train: precision   = 0.8761\n",
    "# Epoch 8 train: recall      = 0.8443\n",
    "# Epoch 8 train: f1          = 0.8590\n",
    "# Epoch 8 validation: val_loss    = 0.4044\n",
    "# Epoch 8 validation: accuracy    = 0.8523\n",
    "# Epoch 8 validation: precision   = 0.8169\n",
    "# Epoch 8 validation: recall      = 0.7792\n",
    "# Epoch 8 validation: f1          = 0.7963\n",
    "\n",
    "# Epoch 9 train: train_loss  = 0.2706\n",
    "# Epoch 9 train: accuracy    = 0.9026\n",
    "# Epoch 9 train: precision   = 0.8843\n",
    "# Epoch 9 train: recall      = 0.8545\n",
    "# Epoch 9 train: f1          = 0.8674\n",
    "# Epoch 9 validation: val_loss    = 0.4110\n",
    "# Epoch 9 validation: accuracy    = 0.8528\n",
    "# Epoch 9 validation: precision   = 0.8164\n",
    "# Epoch 9 validation: recall      = 0.7832\n",
    "# Epoch 9 validation: f1          = 0.7972\n",
    "\n",
    "# Epoch 10 train: train_loss  = 0.2498\n",
    "# Epoch 10 train: accuracy    = 0.9113\n",
    "# Epoch 10 train: precision   = 0.8779\n",
    "# Epoch 10 train: recall      = 0.8867\n",
    "# Epoch 10 train: f1          = 0.8822\n",
    "# Epoch 10 validation: val_loss    = 0.4073\n",
    "# Epoch 10 validation: accuracy    = 0.8541\n",
    "# Epoch 10 validation: precision   = 0.8042\n",
    "# Epoch 10 validation: recall      = 0.8063\n",
    "# Epoch 10 validation: f1          = 0.8052\n",
    "# New best model (f1=0.8052) saved.\n",
    "\n",
    "# Loaded best model with f1=0.8052"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa53ba-8be6-4d60-921e-10ff3e7bbe8e",
   "metadata": {},
   "source": [
    "#### best_transformer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2f534-6150-439d-accc-25d0c4a1cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=3, save_path=\"./transformers/best_transformer_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "# Epoch 1 validation:\n",
    "#   val_loss  = 0.4957\n",
    "#   accuracy  = 0.8108\n",
    "#   precision = 0.7511\n",
    "#   recall    = 0.7480\n",
    "#   f1        = 0.7490\n",
    "#    New best model (f1=0.7490) saved.\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss  = 0.4397\n",
    "#   accuracy  = 0.8314\n",
    "#   precision = 0.7872\n",
    "#   recall    = 0.7633\n",
    "#   f1        = 0.7724\n",
    "#    New best model (f1=0.7724) saved.\n",
    "\n",
    "# Epoch 3 validation:\n",
    "#   val_loss  = 0.4129\n",
    "#   accuracy  = 0.8471\n",
    "#   precision = 0.7982\n",
    "#   recall    = 0.7925\n",
    "#   f1        = 0.7945\n",
    "#    New best model (f1=0.7945) saved.\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8394577444476493, 'precision': 0.7870732957272955, 'recall': 0.7865639150630909, 'f1': 0.7861628773510826, 'loss': 0.4266800470237802}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ace50-196b-422f-9e85-e40009fa500c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef3f4c-320b-4c7d-98b4-17c43888ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=5, save_path=\"./transformers/best_transformer_2.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss  = 0.5102\n",
    "#   accuracy  = 0.8056\n",
    "#   precision = 0.7564\n",
    "#   recall    = 0.7051\n",
    "#   f1        = 0.7269\n",
    "#    New best model (f1=0.7269) saved.\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss  = 0.4723\n",
    "#   accuracy  = 0.8213\n",
    "#   precision = 0.7739\n",
    "#   recall    = 0.7437\n",
    "#   f1        = 0.7558\n",
    "#    New best model (f1=0.7558) saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441298a9-7661-4dc0-ba4c-3923cec091ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=128 <= 256,\n",
    "# nhead=4,\n",
    "# num_layers=2 <= 4,\n",
    "# dim_feedforward=256 <= 512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(d_model=128, num_layers=2, dim_feedforward=256, lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=5, save_path=\"./transformers/best_transformer_3.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.5239\n",
    "#   accuracy    = 0.7990\n",
    "#   precision   = 0.7548\n",
    "#   recall      = 0.6899\n",
    "#   f1          = 0.7164\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.5276\n",
    "#   accuracy    = 0.7989\n",
    "#   precision   = 0.7494\n",
    "#   recall      = 0.6869\n",
    "#   f1          = 0.7125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a847f2e-1488-4b64-bd40-61667954ba75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342536e4a5b24ad6b78c920010143482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98311f72cd524a31a772ecb616b9d684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bba808f4112402f9668d47a395fc166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 train:\n",
      "  train_loss  = 0.4597\n",
      "  accuracy    = 0.8261\n",
      "  precision   = 0.8127\n",
      "  recall      = 0.7218\n",
      "  f1          = 0.7500\n",
      "\n",
      "Epoch 1 validation:\n",
      "  val_loss    = 0.4887\n",
      "  accuracy    = 0.8144\n",
      "  precision   = 0.7946\n",
      "  recall      = 0.7015\n",
      "  f1          = 0.7282\n",
      "New best model (f1=0.7282) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e44998c7a544999de13a6c5c2b8803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe27b80e50b4a42b9223307effeab74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc508d999fc44a188ab6b0fc028c9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 train:\n",
      "  train_loss  = 0.3688\n",
      "  accuracy    = 0.8639\n",
      "  precision   = 0.8235\n",
      "  recall      = 0.8156\n",
      "  f1          = 0.8188\n",
      "\n",
      "Epoch 2 validation:\n",
      "  val_loss    = 0.4365\n",
      "  accuracy    = 0.8378\n",
      "  precision   = 0.7905\n",
      "  recall      = 0.7755\n",
      "  f1          = 0.7823\n",
      "New best model (f1=0.7823) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc435c3b73c54a2480d1ddbd09a03810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f3066eec8d4e7eaef5df3bc715ac22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee883b31d0fe41329319033100cdb61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 train:\n",
      "  train_loss  = 0.3202\n",
      "  accuracy    = 0.8813\n",
      "  precision   = 0.8689\n",
      "  recall      = 0.8117\n",
      "  f1          = 0.8369\n",
      "\n",
      "Epoch 3 validation:\n",
      "  val_loss    = 0.4392\n",
      "  accuracy    = 0.8396\n",
      "  precision   = 0.8122\n",
      "  recall      = 0.7477\n",
      "  f1          = 0.7750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f162af6c9c4c4f34864e9c4d4dab1009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae7b1dd2ad8479f8ea75bd9964a1505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823b20a43ac44949a5fd6ce1f32f5ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 train:\n",
      "  train_loss  = 0.2600\n",
      "  accuracy    = 0.9077\n",
      "  precision   = 0.8946\n",
      "  recall      = 0.8575\n",
      "  f1          = 0.8738\n",
      "\n",
      "Epoch 4 validation:\n",
      "  val_loss    = 0.4221\n",
      "  accuracy    = 0.8499\n",
      "  precision   = 0.8175\n",
      "  recall      = 0.7718\n",
      "  f1          = 0.7914\n",
      "New best model (f1=0.7914) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28479706ac794003b64acfdcc7d86f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11f4bc2e6e442dcaf3b19cd9cc7cbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818b5f0725e84440a7647ee9a48977e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 train:\n",
      "  train_loss  = 0.2058\n",
      "  accuracy    = 0.9299\n",
      "  precision   = 0.9085\n",
      "  recall      = 0.9060\n",
      "  f1          = 0.9066\n",
      "\n",
      "Epoch 5 validation:\n",
      "  val_loss    = 0.4409\n",
      "  accuracy    = 0.8463\n",
      "  precision   = 0.7998\n",
      "  recall      = 0.7894\n",
      "  f1          = 0.7935\n",
      "New best model (f1=0.7935) saved.\n",
      "\n",
      "Loaded best model with f1=0.7935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75067f72aa76493d84d75954fc3a2666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8404384193827517, 'precision': 0.7916469260389406, 'recall': 0.7848264806284927, 'f1': 0.786880109334091, 'loss': 0.4544476669185496}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=3 <= 4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(d_model=256, num_layers=3, dim_feedforward=512, lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=5, save_path=\"./transformers/best_transformer_4.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   f1          = 0.7500\n",
    "# Epoch 1 validation:\n",
    "#   f1          = 0.7282\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   f1          = 0.8188\n",
    "# Epoch 2 validation:\n",
    "#   f1          = 0.7823\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   f1          = 0.8369\n",
    "# Epoch 3 validation:\n",
    "#   f1          = 0.7750 <= first sign of overfitting\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   f1          = 0.8738 <= increasing\n",
    "# Epoch 4 validation:\n",
    "#   f1          = 0.7914\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   f1          = 0.9066 <= increasing\n",
    "# Epoch 5 validation:\n",
    "#   f1          = 0.7935 <= not increasing much. oscilating\n",
    "\n",
    "# test f1 = 0.786880109334091\n",
    "\n",
    "############################################\n",
    "############################################\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.4597\n",
    "#   accuracy    = 0.8261\n",
    "#   precision   = 0.8127\n",
    "#   recall      = 0.7218\n",
    "#   f1          = 0.7500\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.4887\n",
    "#   accuracy    = 0.8144\n",
    "#   precision   = 0.7946\n",
    "#   recall      = 0.7015\n",
    "#   f1          = 0.7282\n",
    "# New best model (f1=0.7282) saved.\n",
    "\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   train_loss  = 0.3688\n",
    "#   accuracy    = 0.8639\n",
    "#   precision   = 0.8235\n",
    "#   recall      = 0.8156\n",
    "#   f1          = 0.8188\n",
    "# Epoch 2 validation:\n",
    "#   val_loss    = 0.4365\n",
    "#   accuracy    = 0.8378\n",
    "#   precision   = 0.7905\n",
    "#   recall      = 0.7755\n",
    "#   f1          = 0.7823\n",
    "# New best model (f1=0.7823) saved.\n",
    "\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   train_loss  = 0.3202\n",
    "#   accuracy    = 0.8813\n",
    "#   precision   = 0.8689\n",
    "#   recall      = 0.8117\n",
    "#   f1          = 0.8369\n",
    "# Epoch 3 validation:\n",
    "#   val_loss    = 0.4392\n",
    "#   accuracy    = 0.8396\n",
    "#   precision   = 0.8122\n",
    "#   recall      = 0.7477\n",
    "#   f1          = 0.7750\n",
    "\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   train_loss  = 0.2600\n",
    "#   accuracy    = 0.9077\n",
    "#   precision   = 0.8946\n",
    "#   recall      = 0.8575\n",
    "#   f1          = 0.8738\n",
    "# Epoch 4 validation:\n",
    "#   val_loss    = 0.4221\n",
    "#   accuracy    = 0.8499\n",
    "#   precision   = 0.8175\n",
    "#   recall      = 0.7718\n",
    "#   f1          = 0.7914\n",
    "# New best model (f1=0.7914) saved.\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   train_loss  = 0.2058\n",
    "#   accuracy    = 0.9299\n",
    "#   precision   = 0.9085\n",
    "#   recall      = 0.9060\n",
    "#   f1          = 0.9066\n",
    "\n",
    "# Epoch 5 validation:\n",
    "#   val_loss    = 0.4409\n",
    "#   accuracy    = 0.8463\n",
    "#   precision   = 0.7998\n",
    "#   recall      = 0.7894\n",
    "#   f1          = 0.7935\n",
    "# New best model (f1=0.7935) saved.\n",
    "\n",
    "# Loaded best model with f1=0.7935\n",
    "# Final eval_results: {'accuracy': 0.8404384193827517, 'precision': 0.7916469260389406, 'recall': 0.7848264806284927, 'f1': 0.786880109334091, 'loss': 0.4544476669185496}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946d83a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transformer (Deberta-V3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a099e1-fd9f-4f7c-be51-2d4991a19dc7",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360f53fd-66c4-468d-9873-9b8bba8750f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ce20be-4d58-4806-851b-833a82b7301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class TrainMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, train_dataset, val_dataset, last_epoch = None):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.trainer = None\n",
    "        self.last_epoch = last_epoch\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.trainer is None:\n",
    "            return control\n",
    "\n",
    "        if self.last_epoch is None:\n",
    "            epoch = state.epoch\n",
    "        else:\n",
    "            self.last_epoch += 1\n",
    "            epoch = self.last_epoch\n",
    "\n",
    "        # --- train metrics ---\n",
    "        train_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.train_dataset,\n",
    "            metric_key_prefix=\"train\",  # train_accuracy, train_f1, ...\n",
    "        )\n",
    "\n",
    "        # --- validation metrics ---\n",
    "        val_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.val_dataset,\n",
    "            metric_key_prefix=\"eval\",   # eval_accuracy, eval_f1, ...\n",
    "        )\n",
    "\n",
    "        val_loss = val_metrics.get(\"eval_loss\")\n",
    "        val_acc  = val_metrics.get(\"eval_accuracy\")\n",
    "        val_prec = val_metrics.get(\"eval_precision\")\n",
    "        val_rec  = val_metrics.get(\"eval_recall\")\n",
    "        val_f1   = val_metrics.get(\"eval_f1\")\n",
    "\n",
    "        train_loss = train_metrics.get(\"train_loss\")\n",
    "        train_acc  = train_metrics.get(\"train_accuracy\")\n",
    "        train_prec = train_metrics.get(\"train_precision\")\n",
    "        train_rec  = train_metrics.get(\"train_recall\")\n",
    "        train_f1   = train_metrics.get(\"train_f1\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[EPOCH {epoch:.0f}]\")\n",
    "        if train_acc is not None:\n",
    "            print(f\"[train] loss={train_loss:.4f}, acc={train_acc:.4f}, prec={train_prec:.4f}, rec={train_rec:.4f}, f1={train_f1:.4f}\")\n",
    "        if val_acc is not None:\n",
    "            print(f\"[valid] loss={val_loss:.4f}, acc={val_acc:.4f}, prec={val_prec:.4f}, rec={val_rec:.4f}, f1={val_f1:.4f}\")\n",
    "        return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ba95a9-9135-42dc-945e-d7ceb7abad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name=\"./deberta\", last_epoch = None, epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\"):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"no\", # \"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epoch,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=False, # True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    train_callback = TrainMetricsCallback(\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        val_dataset=tokenized_datasets[\"validation\"],\n",
    "        last_epoch=last_epoch,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[train_callback],\n",
    "    )\n",
    "\n",
    "    train_callback.trainer = trainer\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b57fb38-6247-4be0-a593-fce04a5191ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <473B02F4-48EA-3880-8B82-14AA228F6939> /Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "def load_and_test_eval(ckpt_dir = \"./deberta-v3-crisis/batchsizeXX/checkpoint-XXXXX\"):\n",
    "    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\".\", # any\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    eval_trainer = Trainer(\n",
    "        model=model_ckpt,\n",
    "        args=eval_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    eval_results = eval_trainer.evaluate(\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        metric_key_prefix=\"test\",\n",
    "    )\n",
    "    # {'test_loss': 0.4593863785266876, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8740698009806749, 'test_precision': 0.8326252068193959, 'test_recall': 0.8500324417218078, 'test_f1': 0.8369876991837396, 'test_runtime': 123.8232, 'test_samples_per_second': 139.998, 'test_steps_per_second': 2.189}\n",
    "    print(eval_results)\n",
    "    print(f\"[test] acc={eval_results['test_accuracy']}, prec={eval_results['test_precision']}, rec={eval_results['test_recall']}, f1={eval_results['test_f1']}\")\n",
    "    # print(f\"test_loss = {eval_results['test_loss']}\")\n",
    "    # print(f\"test_accuracy = {eval_results['test_accuracy']}\")\n",
    "    # print(f\"test_precision = {eval_results['test_precision']}\")\n",
    "    # print(f\"test_recall = {eval_results['test_recall']}\")\n",
    "    # print(f\"test_f1 = {eval_results['test_f1']}\")\n",
    "    return eval_results\n",
    "\n",
    "def load_and_val_eval(ckpt_dir = \"./deberta-v3-crisis/batchsizeXX/checkpoint-XXXXX\"):\n",
    "    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\".\", # any\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    eval_trainer = Trainer(\n",
    "        model=model_ckpt,\n",
    "        args=eval_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    eval_results = eval_trainer.evaluate(\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        metric_key_prefix=\"val\",\n",
    "    )\n",
    "    print(eval_results)\n",
    "    print(f\"[test] acc={eval_results['val_accuracy']}, prec={eval_results['val_precision']}, rec={eval_results['val_recall']}, f1={eval_results['val_f1']}\")\n",
    "    return eval_results['val_f1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657a561",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4996611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 15.0\n",
      "mean: 16.42866733323811\n",
      "95th percentile: 29.0\n",
      "99th percentile: 42.0\n",
      "max: 1126\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download everything from https://huggingface.co/microsoft/deberta-v3-base/tree/main\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"./deberta\", # \"microsoft/deberta-v3-base\"\n",
    "    use_fast=True, # DeBERTa fast tokenizer \n",
    "    local_files_only=True,\n",
    ")\n",
    "\n",
    "max_length = 64 # adjust based on the maximum input size?\n",
    "\n",
    "# 1. Tokenize directly\n",
    "train_encodings = tokenizer(\n",
    "    df[\"train\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    df[\"dev\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "test_encodings = tokenizer(\n",
    "    df[\"test\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "# 2. Build HF Datasets from encoded inputs + labels\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"train\"]['class_label_group_num'],\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": val_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": val_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"dev\"]['class_label_group_num'],\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"test\"]['class_label_group_num'],\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "# 3. Set format for PyTorch\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")\n",
    "\n",
    "# Check appropriate token size\n",
    "tmp_train = tokenizer(df[\"train\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n",
    "lens_train = [len(ids) for ids in tmp_train[\"input_ids\"]]\n",
    "\n",
    "tmp_dev = tokenizer(df[\"dev\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n",
    "lens_dev = [len(ids) for ids in tmp_dev[\"input_ids\"]]\n",
    "\n",
    "lengths = lens_train + lens_dev\n",
    "\n",
    "print(\"median:\", np.median(lengths))\n",
    "print(\"mean:\", np.mean(lengths))\n",
    "print(\"95th percentile:\", np.percentile(lengths, 95))\n",
    "print(\"99th percentile:\", np.percentile(lengths, 99))\n",
    "print(\"max:\", np.max(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058da24c-3882-4647-81db-49bda443f998",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2589f8da-61ae-416a-9ff0-4374a926115a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=1e-6, batch_size=16 (EPOCH 16, val_f1=0.8583, test_f1=0.848050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4d6c967-1608-4294-ac88-970d0d5b6370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.480494886636734, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.8834150562445918, 'test_precision': 0.8357564455145318, 'test_recall': 0.8623533790050426, 'test_f1': 0.8480500870596009, 'test_runtime': 131.5435, 'test_samples_per_second': 131.781, 'test_steps_per_second': 2.06}\n",
      "[test] acc=0.8834150562445918, prec=0.8357564455145318, rec=0.8623533790050426, f1=0.8480500870596009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.480494886636734,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.8834150562445918,\n",
       " 'test_precision': 0.8357564455145318,\n",
       " 'test_recall': 0.8623533790050426,\n",
       " 'test_f1': 0.8480500870596009,\n",
       " 'test_runtime': 131.5435,\n",
       " 'test_samples_per_second': 131.781,\n",
       " 'test_steps_per_second': 2.06}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr1e6_cont_from_13/checkpoint-11457\")\n",
    "# [test] acc=0.8834150562445918, prec=0.8357564455145318, rec=0.8623533790050426, f1=0.8480500870596009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a93d9-339b-4675-a4b6-b33c68b64f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.8767, prec=0.8325, rec=0.8395, f1=0.8359\n",
    "# [valid] acc=0.8722, prec=0.8275, rec=0.8291, f1=0.8283\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.8833, prec=0.8349, rec=0.8651, f1=0.8489\n",
    "# [valid] acc=0.8745, prec=0.8228, rec=0.8486, f1=0.8348\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.8958, prec=0.8568, rec=0.8691, f1=0.8625\n",
    "# [valid] acc=0.8815, prec=0.8382, rec=0.8441, f1=0.8409\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9020, prec=0.8662, rec=0.8761, f1=0.8708\n",
    "# [valid] acc=0.8829, prec=0.8418, rec=0.8448, f1=0.8431\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9039, prec=0.8650, rec=0.8854, f1=0.8744\n",
    "# [valid] acc=0.8834, prec=0.8389, rec=0.8537, f1=0.8456\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9066, prec=0.8676, rec=0.8938, f1=0.8797\n",
    "# [valid] acc=0.8830, prec=0.8375, rec=0.8570, f1=0.8466\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9139, prec=0.8792, rec=0.8964, f1=0.8875\n",
    "# [valid] acc=0.8875, prec=0.8456, rec=0.8559, f1=0.8506\n",
    "# ================================================================================\n",
    "# [EPOCH 8]\n",
    "# [train] acc=0.9181, prec=0.8857, rec=0.8996, f1=0.8923\n",
    "# [valid] acc=0.8872, prec=0.8460, rec=0.8548, f1=0.8501\n",
    "# ================================================================================\n",
    "# [EPOCH 9]\n",
    "# [train] acc=0.9184, prec=0.8835, rec=0.9044, f1=0.8934\n",
    "# [valid] acc=0.8867, prec=0.8431, rec=0.8584, f1=0.8503\n",
    "# ================================================================================\n",
    "# [EPOCH 10]\n",
    "# [train] acc=0.9256, prec=0.8985, rec=0.9054, f1=0.9018\n",
    "# [valid] acc=0.8898, prec=0.8521, rec=0.8544, f1=0.8532\n",
    "# ================================================================================\n",
    "# [EPOCH 11]\n",
    "# [train] acc=0.9236, prec=0.8896, rec=0.9119, f1=0.9001\n",
    "# [valid] acc=0.8884, prec=0.8447, rec=0.8625, f1=0.8530\n",
    "# ================================================================================\n",
    "# [EPOCH 12]\n",
    "# [train] acc=0.9302, prec=0.9042, rec=0.9119, f1=0.9079\n",
    "# [valid] acc=0.8910, prec=0.8532, rec=0.8558, f1=0.8544\n",
    "# ================================================================================\n",
    "# [EPOCH 13]\n",
    "# [train] acc=0.9310, prec=0.9036, rec=0.9149, f1=0.9091\n",
    "# [valid] acc=0.8901, prec=0.8510, rec=0.8569, f1=0.8538\n",
    "# ================================================================================\n",
    "# [EPOCH 14]\n",
    "# [train] loss=0.2028, acc=0.9325, prec=0.9112, rec=0.9126, f1=0.9105\n",
    "# [valid] loss=0.3398, acc=0.8919, prec=0.8602, rec=0.8542, f1=0.8553\n",
    "# ================================================================================\n",
    "# [EPOCH 15]\n",
    "# [train] loss=0.1456, acc=0.9541, prec=0.9361, rec=0.9437, f1=0.9395\n",
    "# [valid] loss=0.3407, acc=0.8885, prec=0.8528, rec=0.8540, f1=0.8524\n",
    "# ================================================================================\n",
    "# [EPOCH 16]\n",
    "# [train] loss=0.1172, acc=0.9672, prec=0.9503, rec=0.9643, f1=0.9570\n",
    "# [valid] loss=0.4375, acc=0.8927, prec=0.8514, rec=0.8660, f1=0.8583\n",
    "# ================================ OVERFITTING ===================================\n",
    "# [EPOCH 17]\n",
    "# [train] loss=0.0874, acc=0.9782, prec=0.9702, rec=0.9718, f1=0.9710\n",
    "# [valid] loss=0.5064, acc=0.8922, prec=0.8592, rec=0.8508, f1=0.8548\n",
    "# ================================================================================\n",
    "# [EPOCH 18]\n",
    "# [train] loss=0.0626, acc=0.9846, prec=0.9825, rec=0.9771, f1=0.9798\n",
    "# [valid] loss=0.5907, acc=0.8882, prec=0.8626, rec=0.8347, f1=0.8473\n",
    "# ================================================================================\n",
    "# [EPOCH 19]\n",
    "# [train] loss=0.0577, acc=0.9866, prec=0.9793, rec=0.9852, f1=0.9822\n",
    "# [valid] loss=0.6760, acc=0.8839, prec=0.8362, rec=0.8612, f1=0.8479\n",
    "# ================================================================================\n",
    "# [EPOCH 20]\n",
    "# [train] loss=0.0370, acc=0.9913, prec=0.9875, rec=0.9893, f1=0.9884\n",
    "# [valid] loss=0.6766, acc=0.8887, prec=0.8456, rec=0.8604, f1=0.8527\n",
    "# ================================================================================\n",
    "# [EPOCH 21]\n",
    "# [train] loss=0.0259, acc=0.9940, prec=0.9914, rec=0.9923, f1=0.9919\n",
    "# [valid] loss=0.7654, acc=0.8873, prec=0.8462, rec=0.8547, f1=0.8504\n",
    "# ================================================================================\n",
    "# [EPOCH 22]\n",
    "# [train] loss=0.0217, acc=0.9950, prec=0.9927, rec=0.9938, f1=0.9932\n",
    "# [valid] loss=0.8305, acc=0.8854, prec=0.8409, rec=0.8579, f1=0.8490\n",
    "# ================================================================================\n",
    "# [EPOCH 23]\n",
    "# [train] loss=0.0176, acc=0.9959, prec=0.9943, rec=0.9945, f1=0.9944\n",
    "# [valid] loss=0.8476, acc=0.8860, prec=0.8447, rec=0.8522, f1=0.8484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26a56375-02e2-4788-af3f-2cc10ecabce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49665' max='76380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49665/76380 12:43:14 < 6:50:34, 1.08 it/s, Epoch 13.00/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.369860</td>\n",
       "      <td>0.872212</td>\n",
       "      <td>0.827513</td>\n",
       "      <td>0.829133</td>\n",
       "      <td>0.828306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.354365</td>\n",
       "      <td>0.874454</td>\n",
       "      <td>0.822754</td>\n",
       "      <td>0.848556</td>\n",
       "      <td>0.834804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.345816</td>\n",
       "      <td>0.881516</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.844074</td>\n",
       "      <td>0.840875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.338899</td>\n",
       "      <td>0.882861</td>\n",
       "      <td>0.841793</td>\n",
       "      <td>0.844776</td>\n",
       "      <td>0.843076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340324</td>\n",
       "      <td>0.883421</td>\n",
       "      <td>0.838853</td>\n",
       "      <td>0.853732</td>\n",
       "      <td>0.845645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346092</td>\n",
       "      <td>0.882973</td>\n",
       "      <td>0.837511</td>\n",
       "      <td>0.857025</td>\n",
       "      <td>0.846615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346158</td>\n",
       "      <td>0.887457</td>\n",
       "      <td>0.845644</td>\n",
       "      <td>0.855859</td>\n",
       "      <td>0.850622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30552</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343148</td>\n",
       "      <td>0.887232</td>\n",
       "      <td>0.845960</td>\n",
       "      <td>0.854781</td>\n",
       "      <td>0.850057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34371</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356693</td>\n",
       "      <td>0.886672</td>\n",
       "      <td>0.843079</td>\n",
       "      <td>0.858372</td>\n",
       "      <td>0.850271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38190</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343051</td>\n",
       "      <td>0.889811</td>\n",
       "      <td>0.852127</td>\n",
       "      <td>0.854418</td>\n",
       "      <td>0.853157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42009</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.360168</td>\n",
       "      <td>0.888353</td>\n",
       "      <td>0.844676</td>\n",
       "      <td>0.862494</td>\n",
       "      <td>0.852971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45828</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356609</td>\n",
       "      <td>0.891044</td>\n",
       "      <td>0.853206</td>\n",
       "      <td>0.855824</td>\n",
       "      <td>0.854363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49647</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.359416</td>\n",
       "      <td>0.890147</td>\n",
       "      <td>0.850972</td>\n",
       "      <td>0.856922</td>\n",
       "      <td>0.853833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.8767, prec=0.8325, rec=0.8395, f1=0.8359\n",
      "[valid] acc=0.8722, prec=0.8275, rec=0.8291, f1=0.8283\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.8833, prec=0.8349, rec=0.8651, f1=0.8489\n",
      "[valid] acc=0.8745, prec=0.8228, rec=0.8486, f1=0.8348\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.8958, prec=0.8568, rec=0.8691, f1=0.8625\n",
      "[valid] acc=0.8815, prec=0.8382, rec=0.8441, f1=0.8409\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9020, prec=0.8662, rec=0.8761, f1=0.8708\n",
      "[valid] acc=0.8829, prec=0.8418, rec=0.8448, f1=0.8431\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9039, prec=0.8650, rec=0.8854, f1=0.8744\n",
      "[valid] acc=0.8834, prec=0.8389, rec=0.8537, f1=0.8456\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9066, prec=0.8676, rec=0.8938, f1=0.8797\n",
      "[valid] acc=0.8830, prec=0.8375, rec=0.8570, f1=0.8466\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 7]\n",
      "[train] acc=0.9139, prec=0.8792, rec=0.8964, f1=0.8875\n",
      "[valid] acc=0.8875, prec=0.8456, rec=0.8559, f1=0.8506\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 8]\n",
      "[train] acc=0.9181, prec=0.8857, rec=0.8996, f1=0.8923\n",
      "[valid] acc=0.8872, prec=0.8460, rec=0.8548, f1=0.8501\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 9]\n",
      "[train] acc=0.9184, prec=0.8835, rec=0.9044, f1=0.8934\n",
      "[valid] acc=0.8867, prec=0.8431, rec=0.8584, f1=0.8503\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 10]\n",
      "[train] acc=0.9256, prec=0.8985, rec=0.9054, f1=0.9018\n",
      "[valid] acc=0.8898, prec=0.8521, rec=0.8544, f1=0.8532\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 11]\n",
      "[train] acc=0.9236, prec=0.8896, rec=0.9119, f1=0.9001\n",
      "[valid] acc=0.8884, prec=0.8447, rec=0.8625, f1=0.8530\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 12]\n",
      "[train] acc=0.9302, prec=0.9042, rec=0.9119, f1=0.9079\n",
      "[valid] acc=0.8910, prec=0.8532, rec=0.8558, f1=0.8544\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 13]\n",
      "[train] acc=0.9310, prec=0.9036, rec=0.9149, f1=0.9091\n",
      "[valid] acc=0.8901, prec=0.8510, rec=0.8569, f1=0.8538\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr1e6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 104\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     93\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     94\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    100\u001b[0m )\n\u001b[1;32m    102\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2740\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2737\u001b[0m     context \u001b[38;5;241m=\u001b[39m implicit_replication\n\u001b[1;32m   2739\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2740\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2742\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;66;03m# get leaning rate before update\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/optimizer.py:179\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/adamw.py:243\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    230\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    232\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    233\u001b[0m         group,\n\u001b[1;32m    234\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m         state_steps,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[0;32m--> 243\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/adamw.py:875\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 875\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/adamw.py:425\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    422\u001b[0m     device_beta1 \u001b[38;5;241m=\u001b[39m beta1\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_beta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=13, learning_rate=1e-6, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6b0dd15-5e9a-4e91-9692-2dda17f89f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38190' max='38190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38190/38190 7:22:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.339816</td>\n",
       "      <td>0.891940</td>\n",
       "      <td>0.860151</td>\n",
       "      <td>0.854168</td>\n",
       "      <td>0.855299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340729</td>\n",
       "      <td>0.888465</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.854037</td>\n",
       "      <td>0.852405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.437489</td>\n",
       "      <td>0.892725</td>\n",
       "      <td>0.851411</td>\n",
       "      <td>0.865999</td>\n",
       "      <td>0.858273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.506365</td>\n",
       "      <td>0.892165</td>\n",
       "      <td>0.859224</td>\n",
       "      <td>0.850820</td>\n",
       "      <td>0.854820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.590669</td>\n",
       "      <td>0.888241</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>0.834667</td>\n",
       "      <td>0.847338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676042</td>\n",
       "      <td>0.883870</td>\n",
       "      <td>0.836201</td>\n",
       "      <td>0.861162</td>\n",
       "      <td>0.847859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676595</td>\n",
       "      <td>0.888690</td>\n",
       "      <td>0.845560</td>\n",
       "      <td>0.860393</td>\n",
       "      <td>0.852680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30552</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.765361</td>\n",
       "      <td>0.887344</td>\n",
       "      <td>0.846230</td>\n",
       "      <td>0.854750</td>\n",
       "      <td>0.850361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34371</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.830512</td>\n",
       "      <td>0.885439</td>\n",
       "      <td>0.840894</td>\n",
       "      <td>0.857950</td>\n",
       "      <td>0.849048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38190</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.847613</td>\n",
       "      <td>0.885999</td>\n",
       "      <td>0.844708</td>\n",
       "      <td>0.852216</td>\n",
       "      <td>0.848392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 14]\n",
      "[train] loss=0.2028, acc=0.9325, prec=0.9112, rec=0.9126, f1=0.9105\n",
      "[valid] loss=0.3398, acc=0.8919, prec=0.8602, rec=0.8542, f1=0.8553\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 15]\n",
      "[train] loss=0.1456, acc=0.9541, prec=0.9361, rec=0.9437, f1=0.9395\n",
      "[valid] loss=0.3407, acc=0.8885, prec=0.8528, rec=0.8540, f1=0.8524\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 16]\n",
      "[train] loss=0.1172, acc=0.9672, prec=0.9503, rec=0.9643, f1=0.9570\n",
      "[valid] loss=0.4375, acc=0.8927, prec=0.8514, rec=0.8660, f1=0.8583\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 17]\n",
      "[train] loss=0.0874, acc=0.9782, prec=0.9702, rec=0.9718, f1=0.9710\n",
      "[valid] loss=0.5064, acc=0.8922, prec=0.8592, rec=0.8508, f1=0.8548\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 18]\n",
      "[train] loss=0.0626, acc=0.9846, prec=0.9825, rec=0.9771, f1=0.9798\n",
      "[valid] loss=0.5907, acc=0.8882, prec=0.8626, rec=0.8347, f1=0.8473\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 19]\n",
      "[train] loss=0.0577, acc=0.9866, prec=0.9793, rec=0.9852, f1=0.9822\n",
      "[valid] loss=0.6760, acc=0.8839, prec=0.8362, rec=0.8612, f1=0.8479\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 20]\n",
      "[train] loss=0.0370, acc=0.9913, prec=0.9875, rec=0.9893, f1=0.9884\n",
      "[valid] loss=0.6766, acc=0.8887, prec=0.8456, rec=0.8604, f1=0.8527\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 21]\n",
      "[train] loss=0.0259, acc=0.9940, prec=0.9914, rec=0.9923, f1=0.9919\n",
      "[valid] loss=0.7654, acc=0.8873, prec=0.8462, rec=0.8547, f1=0.8504\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 22]\n",
      "[train] loss=0.0217, acc=0.9950, prec=0.9927, rec=0.9938, f1=0.9932\n",
      "[valid] loss=0.8305, acc=0.8854, prec=0.8409, rec=0.8579, f1=0.8490\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 23]\n",
      "[train] loss=0.0176, acc=0.9959, prec=0.9943, rec=0.9945, f1=0.9944\n",
      "[valid] loss=0.8476, acc=0.8860, prec=0.8447, rec=0.8522, f1=0.8484\n"
     ]
    }
   ],
   "source": [
    "trainer = train(model_name=\"./deberta-v3-crisis/batchsize16_lr1e6/checkpoint-49647\",\n",
    "                last_epoch=13, epoch=10, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e6_cont_from_13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d1baab-ce2e-48c2-84b0-fbff5f56c716",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=5e-6, batch_size=16 (EPOCH 7, val_f1=0.8603, test_f1=0.85244) => BEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e0cff26-9d86-4b26-af93-d86b3f5b944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.44441157579421997, 'test_model_preparation_time': 0.0016, 'test_accuracy': 0.8876261897894433, 'test_precision': 0.8431801450425511, 'test_recall': 0.8625945973329592, 'test_f1': 0.8524425110946661, 'test_runtime': 130.2498, 'test_samples_per_second': 133.09, 'test_steps_per_second': 2.081}\n",
      "[test] acc=0.8876261897894433, prec=0.8431801450425511, rec=0.8625945973329592, f1=0.8524425110946661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.44441157579421997,\n",
       " 'test_model_preparation_time': 0.0016,\n",
       " 'test_accuracy': 0.8876261897894433,\n",
       " 'test_precision': 0.8431801450425511,\n",
       " 'test_recall': 0.8625945973329592,\n",
       " 'test_f1': 0.8524425110946661,\n",
       " 'test_runtime': 130.2498,\n",
       " 'test_samples_per_second': 133.09,\n",
       " 'test_steps_per_second': 2.081}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32815efa-a78f-4c8e-b826-778d114323b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.8983, prec=0.8618, rec=0.8756, f1=0.8673\n",
    "# [valid] acc=0.8816, prec=0.8414, rec=0.8494, f1=0.8440\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9174, prec=0.8843, rec=0.9019, f1=0.8927\n",
    "# [valid] acc=0.8908, prec=0.8504, rec=0.8638, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9314, prec=0.9065, rec=0.9128, f1=0.9095\n",
    "# [valid] acc=0.8935, prec=0.8584, rec=0.8579, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9448, prec=0.9269, rec=0.9279, f1=0.9274\n",
    "# [valid] acc=0.8927, prec=0.8597, rec=0.8541, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9510, prec=0.9316, rec=0.9389, f1=0.9351\n",
    "# [valid] acc=0.8936, prec=0.8566, rec=0.8598, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9532, prec=0.9325, rec=0.9467, f1=0.9393\n",
    "# [valid] acc=0.8924, prec=0.8516, rec=0.8659, f1=0.8584\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9569, prec=0.9386, rec=0.9489, f1=0.9436\n",
    "# [valid] acc=0.8942, prec=0.8557, rec=0.8651, f1=0.8603\n",
    "# ============================= OVERFITTING ======================================\n",
    "# [EPOCH 8]\n",
    "# [train] loss=0.1480, acc=0.9574, prec=0.9391, rec=0.9508, f1=0.9444\n",
    "# [valid] loss=0.4439, acc=0.8864, prec=0.8488, rec=0.8546, f1=0.8505\n",
    "# ================================================================================\n",
    "# [EPOCH 9]\n",
    "# [train] loss=0.1104, acc=0.9689, prec=0.9530, rec=0.9652, f1=0.9589\n",
    "# [valid] loss=0.4663, acc=0.8887, prec=0.8475, rec=0.8598, f1=0.8533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47629d0e-9806-4a75-96eb-d924def9b554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26733' max='26733' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26733/26733 5:00:09, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.332313</td>\n",
       "      <td>0.881628</td>\n",
       "      <td>0.841446</td>\n",
       "      <td>0.849445</td>\n",
       "      <td>0.844033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306507</td>\n",
       "      <td>0.890819</td>\n",
       "      <td>0.850377</td>\n",
       "      <td>0.863838</td>\n",
       "      <td>0.856841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.329520</td>\n",
       "      <td>0.893510</td>\n",
       "      <td>0.858364</td>\n",
       "      <td>0.857872</td>\n",
       "      <td>0.857992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343858</td>\n",
       "      <td>0.892725</td>\n",
       "      <td>0.859702</td>\n",
       "      <td>0.854125</td>\n",
       "      <td>0.856828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.361830</td>\n",
       "      <td>0.893622</td>\n",
       "      <td>0.856642</td>\n",
       "      <td>0.859780</td>\n",
       "      <td>0.857983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.397974</td>\n",
       "      <td>0.892389</td>\n",
       "      <td>0.851599</td>\n",
       "      <td>0.865910</td>\n",
       "      <td>0.858416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.413612</td>\n",
       "      <td>0.894182</td>\n",
       "      <td>0.855740</td>\n",
       "      <td>0.865078</td>\n",
       "      <td>0.860305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.8983, prec=0.8618, rec=0.8756, f1=0.8673\n",
      "[valid] acc=0.8816, prec=0.8414, rec=0.8494, f1=0.8440\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9174, prec=0.8843, rec=0.9019, f1=0.8927\n",
      "[valid] acc=0.8908, prec=0.8504, rec=0.8638, f1=0.8568\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9314, prec=0.9065, rec=0.9128, f1=0.9095\n",
      "[valid] acc=0.8935, prec=0.8584, rec=0.8579, f1=0.8580\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9448, prec=0.9269, rec=0.9279, f1=0.9274\n",
      "[valid] acc=0.8927, prec=0.8597, rec=0.8541, f1=0.8568\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9510, prec=0.9316, rec=0.9389, f1=0.9351\n",
      "[valid] acc=0.8936, prec=0.8566, rec=0.8598, f1=0.8580\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9532, prec=0.9325, rec=0.9467, f1=0.9393\n",
      "[valid] acc=0.8924, prec=0.8516, rec=0.8659, f1=0.8584\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 7]\n",
      "[train] acc=0.9569, prec=0.9386, rec=0.9489, f1=0.9436\n",
      "[valid] acc=0.8942, prec=0.8557, rec=0.8651, f1=0.8603\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=7, learning_rate=5e-6, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr5e6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4823d845-8fa2-4ca6-bb2a-f1bc079c2a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8148' max='38190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8148/38190 1:34:59 < 5:50:19, 1.43 it/s, Epoch 2.13/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.443878</td>\n",
       "      <td>0.886448</td>\n",
       "      <td>0.848826</td>\n",
       "      <td>0.854559</td>\n",
       "      <td>0.850476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466330</td>\n",
       "      <td>0.888690</td>\n",
       "      <td>0.847531</td>\n",
       "      <td>0.859838</td>\n",
       "      <td>0.853341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 8]\n",
      "[train] loss=0.1480, acc=0.9574, prec=0.9391, rec=0.9508, f1=0.9444\n",
      "[valid] loss=0.4439, acc=0.8864, prec=0.8488, rec=0.8546, f1=0.8505\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 9]\n",
      "[train] loss=0.1104, acc=0.9689, prec=0.9530, rec=0.9652, f1=0.9589\n",
      "[valid] loss=0.4663, acc=0.8887, prec=0.8475, rec=0.8598, f1=0.8533\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlast_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e6_cont_after_7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 112\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_name, last_epoch, epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    101\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    102\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 112\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2618\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2616\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2617\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2618\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[38;5;66;03m# Store the number of batches for current gradient accumulation\u001b[39;00m\n\u001b[1;32m   2620\u001b[0m \u001b[38;5;66;03m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001b[39;00m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_gradient_accumulation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:5654\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5652\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5653\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5654\u001b[0m         batch_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   5655\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5656\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/data_loader.py:577\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[1;32m    579\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/utils/operations.py:154\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    152\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:837\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    838\u001b[0m         k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(v\u001b[38;5;241m.\u001b[39mto) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    840\u001b[0m     }\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    842\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:838\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 838\u001b[0m         k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(v\u001b[38;5;241m.\u001b[39mto) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    840\u001b[0m     }\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    842\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(model_name=\"./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\",\n",
    "                last_epoch=7, epoch=10, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr5e6_cont_after_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d8086-7cd1-4e04-9835-2ec31ef799e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=1e-5, batch_size=16 (EPOCH 5, val_f1=0.8584, test_f1=0.85042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a24e793-165c-48ef-a869-6ba71041e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.4733332693576813, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.8879146235938852, 'test_precision': 0.8480751638235061, 'test_recall': 0.8532187935966081, 'test_f1': 0.8504206093957811, 'test_runtime': 131.1168, 'test_samples_per_second': 132.21, 'test_steps_per_second': 2.067}\n",
      "[test] acc=0.8879146235938852, prec=0.8480751638235061, rec=0.8532187935966081, f1=0.8504206093957811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.4733332693576813,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.8879146235938852,\n",
       " 'test_precision': 0.8480751638235061,\n",
       " 'test_recall': 0.8532187935966081,\n",
       " 'test_f1': 0.8504206093957811,\n",
       " 'test_runtime': 131.1168,\n",
       " 'test_samples_per_second': 132.21,\n",
       " 'test_steps_per_second': 2.067}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr1e5/checkpoint-19095\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2df7826b-e72b-45ce-a4d4-b5ee2615252f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26733' max='26733' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26733/26733 5:55:23, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.325811</td>\n",
       "      <td>0.884206</td>\n",
       "      <td>0.841713</td>\n",
       "      <td>0.857896</td>\n",
       "      <td>0.848201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302651</td>\n",
       "      <td>0.889698</td>\n",
       "      <td>0.848987</td>\n",
       "      <td>0.863118</td>\n",
       "      <td>0.855654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.351273</td>\n",
       "      <td>0.894519</td>\n",
       "      <td>0.856339</td>\n",
       "      <td>0.863506</td>\n",
       "      <td>0.859627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.387684</td>\n",
       "      <td>0.892949</td>\n",
       "      <td>0.859153</td>\n",
       "      <td>0.854211</td>\n",
       "      <td>0.856652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.444698</td>\n",
       "      <td>0.894743</td>\n",
       "      <td>0.860771</td>\n",
       "      <td>0.856631</td>\n",
       "      <td>0.858374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.518066</td>\n",
       "      <td>0.888129</td>\n",
       "      <td>0.842856</td>\n",
       "      <td>0.867592</td>\n",
       "      <td>0.854441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.558347</td>\n",
       "      <td>0.891604</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.860968</td>\n",
       "      <td>0.856229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.9042, prec=0.8665, rec=0.8892, f1=0.8762\n",
      "[valid] acc=0.8842, prec=0.8417, rec=0.8579, f1=0.8482\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9313, prec=0.9018, rec=0.9200, f1=0.9105\n",
      "[valid] acc=0.8897, prec=0.8490, rec=0.8631, f1=0.8557\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9497, prec=0.9291, rec=0.9388, f1=0.9338\n",
      "[valid] acc=0.8945, prec=0.8563, rec=0.8635, f1=0.8596\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9668, prec=0.9558, rec=0.9571, f1=0.9564\n",
      "[valid] acc=0.8929, prec=0.8592, rec=0.8542, f1=0.8567\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9753, prec=0.9674, rec=0.9678, f1=0.9675\n",
      "[valid] acc=0.8947, prec=0.8608, rec=0.8566, f1=0.8584\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9757, prec=0.9628, rec=0.9745, f1=0.9685\n",
      "[valid] acc=0.8881, prec=0.8429, rec=0.8676, f1=0.8544\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 7]\n",
      "[train] acc=0.9813, prec=0.9730, rec=0.9777, f1=0.9753\n",
      "[valid] acc=0.8916, prec=0.8517, rec=0.8610, f1=0.8562\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=7, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e5\")\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.9042, prec=0.8665, rec=0.8892, f1=0.8762\n",
    "# [valid] acc=0.8842, prec=0.8417, rec=0.8579, f1=0.8482\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9313, prec=0.9018, rec=0.9200, f1=0.9105\n",
    "# [valid] acc=0.8897, prec=0.8490, rec=0.8631, f1=0.8557\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9497, prec=0.9291, rec=0.9388, f1=0.9338\n",
    "# [valid] acc=0.8945, prec=0.8563, rec=0.8635, f1=0.8596\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9668, prec=0.9558, rec=0.9571, f1=0.9564\n",
    "# [valid] acc=0.8929, prec=0.8592, rec=0.8542, f1=0.8567\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9753, prec=0.9674, rec=0.9678, f1=0.9675\n",
    "# [valid] acc=0.8947, prec=0.8608, rec=0.8566, f1=0.8584\n",
    "# =============================== OVERFITTING ====================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9757, prec=0.9628, rec=0.9745, f1=0.9685\n",
    "# [valid] acc=0.8881, prec=0.8429, rec=0.8676, f1=0.8544\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9813, prec=0.9730, rec=0.9777, f1=0.9753\n",
    "# [valid] acc=0.8916, prec=0.8517, rec=0.8610, f1=0.8562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc52583-12a9-423a-b001-575ef67d1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = train(model_name=\"./deberta-v3-crisis/batchsize16_lr1e5/checkpoint-26733\",\n",
    "#                 last_epoch = None, epoch=10, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e5_epoch7_cont\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8386e4f-958e-4525-a9cd-4de5c00f85e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=2e-5, batch_size=16 (EPOCH 3, val_f1=0.8579, test_f1=0.85392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adf0cb55-a32f-4106-a411-de4b135e84fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/2837947494.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19095' max='19095' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19095/19095 3:36:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346062</td>\n",
       "      <td>0.884542</td>\n",
       "      <td>0.843709</td>\n",
       "      <td>0.856845</td>\n",
       "      <td>0.848527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312487</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.847801</td>\n",
       "      <td>0.863210</td>\n",
       "      <td>0.855002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.415822</td>\n",
       "      <td>0.893622</td>\n",
       "      <td>0.855097</td>\n",
       "      <td>0.860775</td>\n",
       "      <td>0.857898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.430682</td>\n",
       "      <td>0.892837</td>\n",
       "      <td>0.856731</td>\n",
       "      <td>0.856669</td>\n",
       "      <td>0.856693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.889698</td>\n",
       "      <td>0.847530</td>\n",
       "      <td>0.860315</td>\n",
       "      <td>0.853732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.9095, prec=0.8759, rec=0.8929, f1=0.8827\n",
      "[valid] acc=0.8845, prec=0.8437, rec=0.8568, f1=0.8485\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9421, prec=0.9170, rec=0.9328, f1=0.9245\n",
      "[valid] acc=0.8893, prec=0.8478, rec=0.8632, f1=0.8550\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9647, prec=0.9501, rec=0.9570, f1=0.9535\n",
      "[valid] acc=0.8936, prec=0.8551, rec=0.8608, f1=0.8579\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9771, prec=0.9689, rec=0.9711, f1=0.9700\n",
      "[valid] acc=0.8928, prec=0.8567, rec=0.8567, f1=0.8567\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9802, prec=0.9714, rec=0.9770, f1=0.9742\n",
      "[valid] acc=0.8897, prec=0.8475, rec=0.8603, f1=0.8537\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=5, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16\")\n",
    "\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.9095, prec=0.8759, rec=0.8929, f1=0.8827\n",
    "# [valid] acc=0.8845, prec=0.8437, rec=0.8568, f1=0.8485\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9421, prec=0.9170, rec=0.9328, f1=0.9245\n",
    "# [valid] acc=0.8893, prec=0.8478, rec=0.8632, f1=0.8550\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9647, prec=0.9501, rec=0.9570, f1=0.9535\n",
    "# [valid] acc=0.8936, prec=0.8551, rec=0.8608, f1=0.8579\n",
    "# ================================= OVERFITTING ===================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9771, prec=0.9689, rec=0.9711, f1=0.9700\n",
    "# [valid] acc=0.8928, prec=0.8567, rec=0.8567, f1=0.8567\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9802, prec=0.9714, rec=0.9770, f1=0.9742\n",
    "# [valid] acc=0.8897, prec=0.8475, rec=0.8603, f1=0.8537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3644d122-eb2f-475d-9429-d8984aefcd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:121: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 14:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.4428344666957855, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8888952985289876, 'test_precision': 0.8469517407076887, 'test_recall': 0.8614854411684476, 'test_f1': 0.8539233722507791, 'test_runtime': 843.0977, 'test_samples_per_second': 20.561, 'test_steps_per_second': 0.321}\n",
      "[test] acc=0.8888952985289876, prec=0.8469517407076887, rec=0.8614854411684476, f1=0.8539233722507791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.4428344666957855,\n",
       " 'test_model_preparation_time': 0.0011,\n",
       " 'test_accuracy': 0.8888952985289876,\n",
       " 'test_precision': 0.8469517407076887,\n",
       " 'test_recall': 0.8614854411684476,\n",
       " 'test_f1': 0.8539233722507791,\n",
       " 'test_runtime': 843.0977,\n",
       " 'test_samples_per_second': 20.561,\n",
       " 'test_steps_per_second': 0.321}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16/checkpoint-11457\")\n",
    "# [test] acc=0.8888952985289876, prec=0.8469517407076887, rec=0.8614854411684476, f1=0.8539233722507791"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7f6657-99ae-42da-9502-bf3603eccd10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=5e-5, batch_size=16 (EPOCH 2, val_f1=0.8363, test_f1=0.836272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "718415df-f7ce-47bd-b48a-0c456e05c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1381527606.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 01:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.3785085082054138, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.873893061315996, 'test_precision': 0.8232246134894181, 'test_recall': 0.8519248854229843, 'test_f1': 0.8362720804971207, 'test_runtime': 65.9497, 'test_samples_per_second': 135.27, 'test_steps_per_second': 2.123}\n",
      "[test] acc=0.873893061315996, prec=0.8232246134894181, rec=0.8519248854229843, f1=0.8362720804971207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.3785085082054138,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.873893061315996,\n",
       " 'test_precision': 0.8232246134894181,\n",
       " 'test_recall': 0.8519248854229843,\n",
       " 'test_f1': 0.8362720804971207,\n",
       " 'test_runtime': 65.9497,\n",
       " 'test_samples_per_second': 135.27,\n",
       " 'test_steps_per_second': 2.123}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr5e5/checkpoint-7638\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89465347-8a07-4e53-8f31-2b419364f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] loss=0.3701, acc=0.8898, prec=0.8705, rec=0.8344, f1=0.8504\n",
    "# [valid] loss=0.4345, acc=0.8714, prec=0.8502, rec=0.8026, f1=0.8232\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] loss=0.2995, acc=0.9050, prec=0.8625, rec=0.8906, f1=0.8756\n",
    "# [valid] loss=0.3785, acc=0.8739, prec=0.8232, rec=0.8519, f1=0.8363\n",
    "# ============================= OVERFITTING =====================================\n",
    "# [EPOCH 3]\n",
    "# [train] loss=0.3244, acc=0.9158, prec=0.8993, rec=0.8725, f1=0.8826\n",
    "# [valid] loss=0.4700, acc=0.8808, prec=0.8584, rec=0.8188, f1=0.8324\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] loss=0.3399, acc=0.9151, prec=0.8885, rec=0.8804, f1=0.8835\n",
    "# [valid] loss=0.4732, acc=0.8783, prec=0.8438, rec=0.8265, f1=0.8335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81cd60c9-60db-4492-9ce4-fcd2bbe518f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15483' max='38190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15483/38190 2:57:41 < 4:20:38, 1.45 it/s, Epoch 4.05/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434464</td>\n",
       "      <td>0.871427</td>\n",
       "      <td>0.850153</td>\n",
       "      <td>0.802633</td>\n",
       "      <td>0.823238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.873893</td>\n",
       "      <td>0.823225</td>\n",
       "      <td>0.851925</td>\n",
       "      <td>0.836272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.880843</td>\n",
       "      <td>0.858400</td>\n",
       "      <td>0.818754</td>\n",
       "      <td>0.832363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.473155</td>\n",
       "      <td>0.878265</td>\n",
       "      <td>0.843796</td>\n",
       "      <td>0.826548</td>\n",
       "      <td>0.833529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] loss=0.3701, acc=0.8898, prec=0.8705, rec=0.8344, f1=0.8504\n",
      "[valid] loss=0.4345, acc=0.8714, prec=0.8502, rec=0.8026, f1=0.8232\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] loss=0.2995, acc=0.9050, prec=0.8625, rec=0.8906, f1=0.8756\n",
      "[valid] loss=0.3785, acc=0.8739, prec=0.8232, rec=0.8519, f1=0.8363\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] loss=0.3244, acc=0.9158, prec=0.8993, rec=0.8725, f1=0.8826\n",
      "[valid] loss=0.4700, acc=0.8808, prec=0.8584, rec=0.8188, f1=0.8324\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] loss=0.3399, acc=0.9151, prec=0.8885, rec=0.8804, f1=0.8835\n",
      "[valid] loss=0.4732, acc=0.8783, prec=0.8438, rec=0.8265, f1=0.8335\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 112\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_name, last_epoch, epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    101\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    102\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 112\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=10, learning_rate=5e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr5e5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc44e0-edaa-4231-9f1f-d84caf01e592",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=1e-4, batch_size=16 (EPOCH 1, val_f1=0.2623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdbffa6e-f9c4-44fb-a28b-31bd5ecc5f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19095' max='19095' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19095/19095 3:50:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.901548</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.908638</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.957057</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.923322</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.934442</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=5, learning_rate=1e-4, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e4\")\n",
    "\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fff49-1ba1-4642-a1b1-51f366e31e9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=2e-5, batch_size=8 (EPOCH 3, val_f1=0.8575, test_f1=0.85072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4692839d-ee61-4ebb-9999-7eb5b5fa21f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/2837947494.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50505' max='76370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50505/76370 11:58:42 < 6:08:05, 1.17 it/s, Epoch 6.61/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7637</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.438154</td>\n",
       "      <td>0.878713</td>\n",
       "      <td>0.838978</td>\n",
       "      <td>0.848959</td>\n",
       "      <td>0.840268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15274</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357016</td>\n",
       "      <td>0.891044</td>\n",
       "      <td>0.853015</td>\n",
       "      <td>0.857961</td>\n",
       "      <td>0.855069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22911</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.542490</td>\n",
       "      <td>0.893510</td>\n",
       "      <td>0.857933</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.857463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30548</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.478209</td>\n",
       "      <td>0.887905</td>\n",
       "      <td>0.848656</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>0.851310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38185</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.670134</td>\n",
       "      <td>0.885999</td>\n",
       "      <td>0.849009</td>\n",
       "      <td>0.845102</td>\n",
       "      <td>0.846945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45822</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.671519</td>\n",
       "      <td>0.888017</td>\n",
       "      <td>0.847992</td>\n",
       "      <td>0.854826</td>\n",
       "      <td>0.851258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.9054, prec=0.8719, rec=0.8880, f1=0.8770\n",
      "[valid] acc=0.8787, prec=0.8390, rec=0.8490, f1=0.8403\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9380, prec=0.9154, rec=0.9203, f1=0.9176\n",
      "[valid] acc=0.8910, prec=0.8530, rec=0.8580, f1=0.8551\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9611, prec=0.9465, rec=0.9496, f1=0.9480\n",
      "[valid] acc=0.8935, prec=0.8579, rec=0.8575, f1=0.8575\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9740, prec=0.9634, rec=0.9674, f1=0.9654\n",
      "[valid] acc=0.8879, prec=0.8487, rec=0.8541, f1=0.8513\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9843, prec=0.9790, rec=0.9786, f1=0.9788\n",
      "[valid] acc=0.8860, prec=0.8490, rec=0.8451, f1=0.8469\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9898, prec=0.9853, rec=0.9868, f1=0.9861\n",
      "[valid] acc=0.8880, prec=0.8480, rec=0.8548, f1=0.8513\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 104\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     93\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     94\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    100\u001b[0m )\n\u001b[1;32m    102\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=10, learning_rate=2e-5, batch_size=8, output_dir=\"./deberta-v3-crisis/batchsize8\")\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.9054, prec=0.8719, rec=0.8880, f1=0.8770\n",
    "# [valid] acc=0.8787, prec=0.8390, rec=0.8490, f1=0.8403\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9380, prec=0.9154, rec=0.9203, f1=0.9176\n",
    "# [valid] acc=0.8910, prec=0.8530, rec=0.8580, f1=0.8551\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9611, prec=0.9465, rec=0.9496, f1=0.9480\n",
    "# [valid] acc=0.8935, prec=0.8579, rec=0.8575, f1=0.8575\n",
    "\n",
    "# test_loss = 0.577634871006012\n",
    "# test_accuracy = 0.8872800692241131\n",
    "# test_precision = 0.8469312572131958\n",
    "# test_recall = 0.855374024799894\n",
    "# test_f1 = 0.8507208362474484\n",
    "# ============================= OVERFITTING =====================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9740, prec=0.9634, rec=0.9674, f1=0.9654\n",
    "# [valid] acc=0.8879, prec=0.8487, rec=0.8541, f1=0.8513\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9843, prec=0.9790, rec=0.9786, f1=0.9788\n",
    "# [valid] acc=0.8860, prec=0.8490, rec=0.8451, f1=0.8469\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9898, prec=0.9853, rec=0.9868, f1=0.9861\n",
    "# [valid] acc=0.8880, prec=0.8480, rec=0.8548, f1=0.8513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "818e1317-f3df-4e54-8a22-b99b795abba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:121: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0023, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 124.2977, 'test_samples_per_second': 139.464, 'test_steps_per_second': 2.18}\n",
      "[test] acc=0.8872800692241131, prec=0.8469312572131958, rec=0.855374024799894, f1=0.8507208362474484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.577634871006012,\n",
       " 'test_model_preparation_time': 0.0023,\n",
       " 'test_accuracy': 0.8872800692241131,\n",
       " 'test_precision': 0.8469312572131958,\n",
       " 'test_recall': 0.855374024799894,\n",
       " 'test_f1': 0.8507208362474484,\n",
       " 'test_runtime': 124.2977,\n",
       " 'test_samples_per_second': 139.464,\n",
       " 'test_steps_per_second': 2.18}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-22911\")\n",
    "# [test] acc=0.8872800692241131, prec=0.8469312572131958, rec=0.855374024799894, f1=0.8507208362474484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0685b9f-94a6-49ba-9847-d5d27c436e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.37746426463127136, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8849149120276897, 'test_precision': 0.8430869630919547, 'test_recall': 0.8545599129431753, 'test_f1': 0.8482132493443325, 'test_runtime': 125.0236, 'test_samples_per_second': 138.654, 'test_steps_per_second': 2.168}\n",
      "test_loss = 0.37746426463127136\n",
      "test_accuracy = 0.8849149120276897\n",
      "test_precision = 0.8430869630919547\n",
      "test_recall = 0.8545599129431753\n",
      "test_f1 = 0.8482132493443325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 125.0976, 'test_samples_per_second': 138.572, 'test_steps_per_second': 2.166}\n",
      "test_loss = 0.577634871006012\n",
      "test_accuracy = 0.8872800692241131\n",
      "test_precision = 0.8469312572131958\n",
      "test_recall = 0.855374024799894\n",
      "test_f1 = 0.8507208362474484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.49717429280281067, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8831843092010384, 'test_precision': 0.8392270903901514, 'test_recall': 0.8564725619023125, 'test_f1': 0.8473071372190685, 'test_runtime': 125.1699, 'test_samples_per_second': 138.492, 'test_steps_per_second': 2.165}\n",
      "test_loss = 0.49717429280281067\n",
      "test_accuracy = 0.8831843092010384\n",
      "test_precision = 0.8392270903901514\n",
      "test_recall = 0.8564725619023125\n",
      "test_f1 = 0.8473071372190685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.6949165463447571, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8830689356792616, 'test_precision': 0.842145954123632, 'test_recall': 0.8472896061789302, 'test_f1': 0.8445861775113469, 'test_runtime': 128.6307, 'test_samples_per_second': 134.766, 'test_steps_per_second': 2.107}\n",
      "test_loss = 0.6949165463447571\n",
      "test_accuracy = 0.8830689356792616\n",
      "test_precision = 0.842145954123632\n",
      "test_recall = 0.8472896061789302\n",
      "test_f1 = 0.8445861775113469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.715135395526886, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8819728872223824, 'test_precision': 0.836460218016704, 'test_recall': 0.8544100282915196, 'test_f1': 0.8450040779020537, 'test_runtime': 125.2994, 'test_samples_per_second': 138.349, 'test_steps_per_second': 2.163}\n",
      "test_loss = 0.715135395526886\n",
      "test_accuracy = 0.8819728872223824\n",
      "test_precision = 0.836460218016704\n",
      "test_recall = 0.8544100282915196\n",
      "test_f1 = 0.8450040779020537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.715135395526886,\n",
       " 'test_model_preparation_time': 0.0013,\n",
       " 'test_accuracy': 0.8819728872223824,\n",
       " 'test_precision': 0.836460218016704,\n",
       " 'test_recall': 0.8544100282915196,\n",
       " 'test_f1': 0.8450040779020537,\n",
       " 'test_runtime': 125.2994,\n",
       " 'test_samples_per_second': 138.349,\n",
       " 'test_steps_per_second': 2.163}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-7637\")\n",
    "# {'test_loss': 0.4593863785266876, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8740698009806749, 'test_precision': 0.8326252068193959, 'test_recall': 0.8500324417218078, 'test_f1': 0.8369876991837396, 'test_runtime': 123.8232, 'test_samples_per_second': 139.998, 'test_steps_per_second': 2.189}\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-15274\")\n",
    "# {'test_loss': 0.37746426463127136, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8849149120276897, 'test_precision': 0.8430869630919547, 'test_recall': 0.8545599129431753, 'test_f1': 0.8482132493443325, 'test_runtime': 125.0236, 'test_samples_per_second': 138.654, 'test_steps_per_second': 2.168}\n",
    "# test_loss = 0.37746426463127136\n",
    "# test_accuracy = 0.8849149120276897\n",
    "# test_precision = 0.8430869630919547\n",
    "# test_recall = 0.8545599129431753\n",
    "# test_f1 = 0.8482132493443325\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-22911\")\n",
    "# {'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 125.0976, 'test_samples_per_second': 138.572, 'test_steps_per_second': 2.166}\n",
    "# test_loss = 0.577634871006012\n",
    "# test_accuracy = 0.8872800692241131\n",
    "# test_precision = 0.8469312572131958\n",
    "# test_recall = 0.855374024799894\n",
    "# test_f1 = 0.8507208362474484\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-30548\")\n",
    "# {'test_loss': 0.49717429280281067, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8831843092010384, 'test_precision': 0.8392270903901514, 'test_recall': 0.8564725619023125, 'test_f1': 0.8473071372190685, 'test_runtime': 125.1699, 'test_samples_per_second': 138.492, 'test_steps_per_second': 2.165}\n",
    "# test_loss = 0.49717429280281067\n",
    "# test_accuracy = 0.8831843092010384\n",
    "# test_precision = 0.8392270903901514\n",
    "# test_recall = 0.8564725619023125\n",
    "# test_f1 = 0.8473071372190685\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-38185\")\n",
    "# {'test_loss': 0.6949165463447571, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8830689356792616, 'test_precision': 0.842145954123632, 'test_recall': 0.8472896061789302, 'test_f1': 0.8445861775113469, 'test_runtime': 128.6307, 'test_samples_per_second': 134.766, 'test_steps_per_second': 2.107}\n",
    "# test_loss = 0.6949165463447571\n",
    "# test_accuracy = 0.8830689356792616\n",
    "# test_precision = 0.842145954123632\n",
    "# test_recall = 0.8472896061789302\n",
    "# test_f1 = 0.8445861775113469\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-45822\")\n",
    "# {'test_loss': 0.715135395526886, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8819728872223824, 'test_precision': 0.836460218016704, 'test_recall': 0.8544100282915196, 'test_f1': 0.8450040779020537, 'test_runtime': 125.2994, 'test_samples_per_second': 138.349, 'test_steps_per_second': 2.163}\n",
    "# test_loss = 0.715135395526886\n",
    "# test_accuracy = 0.8819728872223824\n",
    "# test_precision = 0.836460218016704\n",
    "# test_recall = 0.8544100282915196\n",
    "# test_f1 = 0.8450040779020537"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fae6d-678a-45ed-b0c7-d1b8ab081f2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Learning and Validation Curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3306b97e-c319-4e42-94eb-c2ed962a53e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.44441157579421997, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.8876261897894433, 'test_precision': 0.8431801450425511, 'test_recall': 0.8625945973329592, 'test_f1': 0.8524425110946661, 'test_runtime': 126.022, 'test_samples_per_second': 137.555, 'test_steps_per_second': 2.15}\n",
      "[test] acc=0.8876261897894433, prec=0.8431801450425511, rec=0.8625945973329592, f1=0.8524425110946661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.44441157579421997,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.8876261897894433,\n",
       " 'test_precision': 0.8431801450425511,\n",
       " 'test_recall': 0.8625945973329592,\n",
       " 'test_f1': 0.8524425110946661,\n",
       " 'test_runtime': 126.022,\n",
       " 'test_samples_per_second': 137.555,\n",
       " 'test_steps_per_second': 2.15}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model\n",
    "# learning_rate=5e-6, batch_size=16 (EPOCH 7, val_f1=0.8603, test_f1=0.85244) => BEST\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f05f654d-04d8-4061-9a6b-c06908ef9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = [0.8673, 0.8927, 0.9095, 0.9274, 0.9351, 0.9393, 0.9436,\n",
    "            0.9444, 0.9589]\n",
    "best_model_val_f1 = [0.8440, 0.8568, 0.8580, 0.8568, 0.8580, 0.8584, 0.8603,\n",
    "          0.8505, 0.8533]\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.8983, prec=0.8618, rec=0.8756, f1=0.8673\n",
    "# [valid] acc=0.8816, prec=0.8414, rec=0.8494, f1=0.8440\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9174, prec=0.8843, rec=0.9019, f1=0.8927\n",
    "# [valid] acc=0.8908, prec=0.8504, rec=0.8638, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9314, prec=0.9065, rec=0.9128, f1=0.9095\n",
    "# [valid] acc=0.8935, prec=0.8584, rec=0.8579, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9448, prec=0.9269, rec=0.9279, f1=0.9274\n",
    "# [valid] acc=0.8927, prec=0.8597, rec=0.8541, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9510, prec=0.9316, rec=0.9389, f1=0.9351\n",
    "# [valid] acc=0.8936, prec=0.8566, rec=0.8598, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9532, prec=0.9325, rec=0.9467, f1=0.9393\n",
    "# [valid] acc=0.8924, prec=0.8516, rec=0.8659, f1=0.8584\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9569, prec=0.9386, rec=0.9489, f1=0.9436\n",
    "# [valid] acc=0.8942, prec=0.8557, rec=0.8651, f1=0.8603\n",
    "# ============================= OVERFITTING ======================================\n",
    "# [EPOCH 8]\n",
    "# [train] loss=0.1480, acc=0.9574, prec=0.9391, rec=0.9508, f1=0.9444\n",
    "# [valid] loss=0.4439, acc=0.8864, prec=0.8488, rec=0.8546, f1=0.8505\n",
    "# ================================================================================\n",
    "# [EPOCH 9]\n",
    "# [train] loss=0.1104, acc=0.9689, prec=0.9530, rec=0.9652, f1=0.9589\n",
    "# [valid] loss=0.4663, acc=0.8887, prec=0.8475, rec=0.8598, f1=0.8533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e5bd818-577e-44d9-9fec-4d5cad0c8b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(train_f1s, val_f1s):\n",
    "    N = len(train_f1s)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(train_f1s, label=\"Train\")\n",
    "    # plt.plot(val_f1s, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\", fontsize=16)\n",
    "    plt.plot(range(1, N+1), train_f1s, label=\"Train\")\n",
    "    plt.plot(range(1, N+1), val_f1s, label=\"Validation\")\n",
    "    plt.axvline(x=7, color='red', linestyle='--', linewidth=1.5) # , label=\"overfitting threshold\")\n",
    "    plt.xticks([i for i in range(1, N+1)], fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n",
    "    plt.title(\"Transformer (Deberta-V3) Learning Curve\", fontsize=18)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.savefig(\"pretrained_transformer_f1_score_curve.png\")\n",
    "\n",
    "plot_learning_curve(best_model_train_f1, best_model_val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07447846-6f37-4387-9a74-ca0066315c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_validation_curve(xticks, log_scale, val_f1s, filename):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    if log_scale:\n",
    "        # Log-scale line plot\n",
    "        plt.semilogx(xticks, val_f1s, marker=\"o\") # , label=\"Validation\")\n",
    "        plt.xticks(xticks, [f\"{x:.0e}\" for x in xticks], fontsize=14)\n",
    "    else:\n",
    "        plt.plot(xticks, val_f1s) # , label=\"Validation\")\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel(\"Learning Rate (log scale)\" if log_scale else \"Learning Rate\", fontsize=16)\n",
    "    plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n",
    "    plt.title(\"Transformer (DeBERTa-V3) Validation Curve\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "\n",
    "# learning_rate=1e-6, batch_size=16 (EPOCH 16, val_f1=0.8583, test_f1=0.848050)\n",
    "# learning_rate=5e-6, batch_size=16 (EPOCH 7, val_f1=0.8603, test_f1=0.85244) => BEST\n",
    "# learning_rate=1e-5, batch_size=16 (EPOCH 5, val_f1=0.8584, test_f1=0.85042)\n",
    "# learning_rate=2e-5, batch_size=16 (EPOCH 3, val_f1=0.8579, test_f1=0.85392)\n",
    "# learning_rate=5e-5, batch_size=16 (EPOCH 2, val_f1=0.8363, test_f1=0.836272)\n",
    "\n",
    "# learning_rate=1e-4, batch_size=16 (EPOCH 1~3, val_f1=0.2623)\n",
    "\n",
    "val_f1_scores = [0.8583, 0.8603, 0.8584, 0.8579] # , 0.2623]\n",
    "learning_rates = [1e-6, 5e-6, 1e-5, 2e-5]\n",
    "plot_validation_curve(learning_rates, True, val_f1_scores, \"pretrained_transformer_f1_score_val_curve1.png\")\n",
    "# learning_rates = [\"1e-6\\n(epoch=16)\", \"5e-6\\n(epoch=7)\", \"1e-5\\n(epoch=5)\", \"2e-5\\n(epoch=3)\"]\n",
    "# plot_validation_curve(learning_rates, False, val_f1_scores, \"pretrained_transformer_f1_score_val_curve_epoch1.png\")\n",
    "\n",
    "val_f1_scores = [0.8583, 0.8603, 0.8584, 0.8579, 0.8363] # , 0.2623]\n",
    "learning_rates = [1e-6, 5e-6, 1e-5, 2e-5, 5e-5]\n",
    "plot_validation_curve(learning_rates, True, val_f1_scores, \"pretrained_transformer_f1_score_val_curve2.png\")\n",
    "# learning_rates = [\"1e-6\\n(epoch=16)\", \"5e-6\\n(epoch=7)\", \"1e-5\\n(epoch=5)\", \"2e-5\\n(epoch=3)\", \"5e-5\\n(epoch=2)\"]\n",
    "# plot_validation_curve(learning_rates, False, val_f1_scores, \"pretrained_transformer_f1_score_val_curve_epoch2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ab5e3-0e5d-4942-bc60-b7f9bf723604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a809155e-ab79-411a-a178-8a504ee294af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_95996/312600777.py:44: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38236' max='76370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38236/76370 4:44:25 < 4:43:40, 2.24 it/s, Epoch 5.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341084</td>\n",
       "      <td>0.901881</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.888816</td>\n",
       "      <td>0.873895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.218777</td>\n",
       "      <td>0.935504</td>\n",
       "      <td>0.909765</td>\n",
       "      <td>0.919633</td>\n",
       "      <td>0.913919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.164746</td>\n",
       "      <td>0.959142</td>\n",
       "      <td>0.939431</td>\n",
       "      <td>0.952655</td>\n",
       "      <td>0.945791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.973907</td>\n",
       "      <td>0.963635</td>\n",
       "      <td>0.966295</td>\n",
       "      <td>0.964884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.087381</td>\n",
       "      <td>0.982927</td>\n",
       "      <td>0.976098</td>\n",
       "      <td>0.977472</td>\n",
       "      <td>0.976734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[60], line 56\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     45\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     46\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 56\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=10, learning_rate=2e-5, batch_size=8, output_dir=\"./deberta-v3-crisis/2\")\n",
    "# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# print(eval_results)\n",
    "\n",
    "#  # [38186/76370 4:35:02 < 4:35:02, 2.31 it/s, Epoch 5/10]\n",
    "# # Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# # 1\tNo log\t0.341084\t0.901881\t0.866828\t0.888816\t0.873895\n",
    "# # 2\tNo log\t0.218777\t0.935504\t0.909765\t0.919633\t0.913919\n",
    "# # 3\tNo log\t0.164746\t0.959142\t0.939431\t0.952655\t0.945791\n",
    "# # 4\tNo log\t0.109434\t0.973907\t0.963635\t0.966295\t0.964884\n",
    "# # 5\tNo log\t0.087381\t0.982927\t0.976098\t0.977472\t0.976734\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73ddf31d-8048-40dc-8c6b-a97d893d5872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/281152571.py:115: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='276' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 276/2710 10:21 < 1:31:57, 0.44 it/s, Epoch 1.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319999</td>\n",
       "      <td>0.888491</td>\n",
       "      <td>0.851906</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.849046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.8885, prec=0.8519, rec=0.8495, f1=0.8490\n",
      "[valid] acc=0.8709, prec=0.8351, rec=0.8190, f1=0.8247\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(eval_results)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 127\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    115\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    116\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    117\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 127\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4020\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   4019\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4020\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4022\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   4023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4024\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4025\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   4026\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4110\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4108\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   4109\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 4110\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   4112\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   4113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1102\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1102\u001b[0m     label_index \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=10, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/batchsize64\")\n",
    "# # eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# # print(eval_results)\n",
    "\n",
    "# #  [ 272/2710 07:04 < 1:03:52, 0.64 it/s, Epoch 1/10]\n",
    "# # Step\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# # 271\tNo log\t0.360962\t0.870866\t0.835089\t0.818979\t0.824688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a2faa6-fd37-4f29-ad7a-6a952b848fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/3149821493.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1014' max='9550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1014/9550 1:00:22 < 8:29:14, 0.28 it/s, Epoch 1.06/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262881</td>\n",
       "      <td>0.903174</td>\n",
       "      <td>0.863936</td>\n",
       "      <td>0.888640</td>\n",
       "      <td>0.874394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "  [train] acc=0.9032, prec=0.8639, rec=0.8886, f1=0.8744  (n=None)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[12], line 120\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    108\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    109\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    110\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 120\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=10, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/batchsize64_1\")\n",
    "# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# print(eval_results)\n",
    "# #  [1014/9550 1:00:22 < 8:29:14, 0.28 it/s, Epoch 1.06/10]\n",
    "# # Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# # 1\tNo log\t0.262881\t0.903174\t0.863936\t0.888640\t0.874394\n",
    "\n",
    "# # ================================================================================\n",
    "# # [EPOCH 1]\n",
    "# #   [train] acc=0.9032, prec=0.8639, rec=0.8886, f1=0.8744  (n=None)\n",
    "\n",
    "# # Batch size can't be as high as 256?\n",
    "# # RuntimeError: MPS backend out of memory (MPS allocated: 27.10 GB, other allocations: 832.00 KB, max allowed: 27.20 GB). Tried to allocate 375.29 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5675a2b6-2ca4-4ccf-a66a-1a82c8139042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class TrainMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, train_dataset):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.trainer = None\n",
    "        self.last_eval_metrics = None\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        if any(k.startswith(\"eval_\") for k in metrics.keys()):\n",
    "            self.last_eval_metrics = metrics\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.trainer is None:\n",
    "            return control\n",
    "\n",
    "        train_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.train_dataset,\n",
    "            metric_key_prefix=\"train\", # train_accuracy, train_f1, ...\n",
    "        )\n",
    "\n",
    "        epoch = state.epoch\n",
    "        train_acc = train_metrics.get(\"train_accuracy\", None)\n",
    "        train_f1  = train_metrics.get(\"train_f1\", None)\n",
    "\n",
    "        val_acc = None\n",
    "        val_f1  = None\n",
    "        if self.last_eval_metrics is not None:\n",
    "            val_acc = self.last_eval_metrics.get(\"eval_accuracy\", None)\n",
    "            val_f1  = self.last_eval_metrics.get(\"eval_f1\", None)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[EPOCH {epoch:.0f}]\")\n",
    "        if train_acc is not None and train_f1 is not None:\n",
    "            print(f\"  train_acc = {train_acc:.4f}, train_f1 = {train_f1:.4f}\")\n",
    "        if val_acc is not None and val_f1 is not None:\n",
    "            print(f\"  val_acc   = {val_acc:.4f}, val_f1   = {val_f1:.4f}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        return control\n",
    "\n",
    "\n",
    "def train(epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\"):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epoch,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    train_callback = TrainMetricsCallback(tokenized_datasets[\"train\"])\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[train_callback],\n",
    "    )\n",
    "\n",
    "    train_callback.trainer = trainer\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7e8d34-f563-4067-8dae-d3726081c67f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/2795326635.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2716' max='2865' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2716/2865 1:24:08 < 04:37, 0.54 it/s, Epoch 2.84/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265105</td>\n",
       "      <td>0.901373</td>\n",
       "      <td>0.860023</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.873302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.204079</td>\n",
       "      <td>0.928432</td>\n",
       "      <td>0.897973</td>\n",
       "      <td>0.917152</td>\n",
       "      <td>0.907176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "  train_acc = 0.9014, train_f1 = 0.8733\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "  train_acc = 0.9284, train_f1 = 0.9072\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/test2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[10], line 87\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     75\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     76\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     77\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 87\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=3, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/test2\")\n",
    "# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# print(eval_results)\n",
    "\n",
    "# # Batch size can't be as high as 256?\n",
    "# # RuntimeError: MPS backend out of memory (MPS allocated: 27.10 GB, other allocations: 832.00 KB, max allowed: 27.20 GB). Tried to allocate 375.29 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc0f71a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_84643/3190309381.py:41: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7802' max='11457' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7802/11457 1:12:17 < 33:52, 1.80 it/s, Epoch 2.04/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.322661</td>\n",
       "      <td>0.888241</td>\n",
       "      <td>0.851410</td>\n",
       "      <td>0.855949</td>\n",
       "      <td>0.852308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.300615</td>\n",
       "      <td>0.893398</td>\n",
       "      <td>0.853491</td>\n",
       "      <td>0.866558</td>\n",
       "      <td>0.859771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 50\u001b[0m\n\u001b[1;32m     26\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     27\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./deberta-v3-crisis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     42\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     43\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\")\n",
    "\n",
    "# # Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall  \tF1\n",
    "# # 1\t    0.311500\t    0.322661\t    0.888241\t0.851410\t0.855949\t0.852308\n",
    "# # 2\t    0.239700\t    0.300615\t    0.893398\t0.853491\t0.866558\t0.859771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09147530-f5a5-4c5a-8a5f-e8d56169444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c2942-0c4a-430e-889f-c765fa6daab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V6E1",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
