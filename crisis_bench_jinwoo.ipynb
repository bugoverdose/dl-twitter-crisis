{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a9ab23-f031-44a3-88cd-4d08f1f6381c",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ec020-a4bb-430f-b561-1f0367e5f486",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7346fe-d763-4501-9a45-1c4c7a9ab363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <473B02F4-48EA-3880-8B82-14AA228F6939> /Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0869bbce-6ad5-4929-9439-c2f4bc6249f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "generator = torch.Generator()\n",
    "_ = generator.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f2506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_strs = ['time_critical', 'support_and_relief', 'non_informative']\n",
    "label2id = {label: i for i, label in enumerate(all_label_strs)}\n",
    "id2label = {i: label for label, i in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83365a1-379c-4bc6-bbcc-eb8ca273209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./data/crisisbench/preprocessed_data_train.csv\n",
      "Loading: ./data/crisisbench/preprocessed_data_dev.csv\n",
      "Loading: ./data/crisisbench/preprocessed_data_test.csv\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    df = {}\n",
    "    for d in ['train', 'dev', 'test']:\n",
    "        output_path = f\"./data/crisisbench/preprocessed_data_{d}.csv\"\n",
    "        df[d] = pd.read_csv(output_path).loc[:, ['text', 'class_label_group', 'class_label_group_num']]\n",
    "        print(\"Loading:\", output_path)\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43775508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: N=61089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approximately km long firebreaks have been con...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>god bless you</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cracked wine casks damaged historical building...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i m really just excited for new undies and pin...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rescue effort e ands in india pakistan as floo...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class_label_group  \\\n",
       "0  approximately km long firebreaks have been con...     time_critical   \n",
       "1                                      god bless you   non_informative   \n",
       "2  cracked wine casks damaged historical building...     time_critical   \n",
       "3  i m really just excited for new undies and pin...   non_informative   \n",
       "4  rescue effort e ands in india pakistan as floo...     time_critical   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      0  \n",
       "1                      2  \n",
       "2                      0  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_train: N={len(df['train'])}\")\n",
    "df['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ce818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dev: N=8921\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>congrats to all my liverpool supporting fans f...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collapsed buildings in mexico city earthquake ...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>here s your flower</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ready for a relaxing weekend but have too much...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public private information portal developed to...</td>\n",
       "      <td>support_and_relief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   class_label_group  \\\n",
       "0  congrats to all my liverpool supporting fans f...     non_informative   \n",
       "1  collapsed buildings in mexico city earthquake ...       time_critical   \n",
       "2                                 here s your flower     non_informative   \n",
       "3  ready for a relaxing weekend but have too much...     non_informative   \n",
       "4  public private information portal developed to...  support_and_relief   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      2  \n",
       "1                      0  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_dev: N={len(df['dev'])}\")\n",
    "df['dev'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d208947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test: N=17335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staff at our feeding centre say chronic malnou...</td>\n",
       "      <td>support_and_relief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you comin down for the summer semesters right</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yea it s upstate i m like a few hours away</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teach every pakistani that it is not enough to...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stay with for live cvg as typhoon hagupit slam...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   class_label_group  \\\n",
       "0  staff at our feeding centre say chronic malnou...  support_and_relief   \n",
       "1      you comin down for the summer semesters right     non_informative   \n",
       "2         yea it s upstate i m like a few hours away     non_informative   \n",
       "3  teach every pakistani that it is not enough to...     non_informative   \n",
       "4  stay with for live cvg as typhoon hagupit slam...       time_critical   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      1  \n",
       "1                      2  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_test: N={len(df['test'])}\")\n",
    "df['test'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d27fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ea0a0",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a00974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8566f4e",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defa4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "MAX_SEQ_LEN = 64 # depends on tweet length\n",
    "EMBED_DIM = 50\n",
    "FILTER_SIZES = (3, 4, 5)\n",
    "NUM_FILTERS = 100\n",
    "DROPOUT = 0.5 # tune\n",
    "BATCH_SIZE = 64 # tune \n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 10\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "GLOVE_PATH = \"./data/crisisbench/glove_word_embeddings.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb1266",
   "metadata": {},
   "source": [
    "### Tokenizer and Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf53496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits on whitespace\n",
    "    \"\"\"\n",
    "    return text.strip().split()\n",
    "\n",
    "def build_vocab(\n",
    "    texts: List[str],\n",
    "    max_size: int,\n",
    "    min_freq: int = 1\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Build a word -> index vocab from training texts.\n",
    "    Reserves index 0 for PAD and 1 for UNK.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = simple_tokenize(text)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
    "    for word, freq in counter.most_common():\n",
    "        if freq < min_freq:\n",
    "            continue\n",
    "        if len(vocab) >= max_size:\n",
    "            break\n",
    "        vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def encode_text(\n",
    "    text: str,\n",
    "    vocab: Dict[str, int],\n",
    "    max_len: int\n",
    ") -> List[int]:\n",
    "    tokens = simple_tokenize(text)\n",
    "    ids = [vocab.get(tok, vocab[UNK_TOKEN]) for tok in tokens][:max_len]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [vocab[PAD_TOKEN]] * (max_len - len(ids))\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81ae81",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95f7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: List[int],\n",
    "        vocab: Dict[str, int],\n",
    "        max_len: int,\n",
    "    ):\n",
    "        assert len(texts) == len(labels)\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        input_ids = encode_text(text, self.vocab, self.max_len)\n",
    "        return torch.tensor(input_ids, dtype=torch.long), label\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_texts: List[str],\n",
    "    train_labels: List[int],\n",
    "    val_texts: List[str],\n",
    "    val_labels: List[int],\n",
    "    max_vocab_size: int,\n",
    "    max_seq_len: int,\n",
    "    batch_size: int,\n",
    ") -> Tuple[DataLoader, DataLoader, Dict[str, int], int]:\n",
    "    vocab = build_vocab(train_texts, max_vocab_size)\n",
    "    num_classes = len(set(train_labels))\n",
    "\n",
    "    train_dataset = TextDataset(train_texts, train_labels, vocab, max_seq_len)\n",
    "    val_dataset = TextDataset(val_texts, val_labels, vocab, max_seq_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, vocab, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d02775",
   "metadata": {},
   "source": [
    "### Load GloVe & build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1645084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(\n",
    "    glove_path: str,\n",
    "    embed_dim: int,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Load GloVe file into a dict: word -> vector (torch.Tensor).\n",
    "    Expects each line: word val1 val2 ... valD\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != embed_dim + 1:\n",
    "                # ignore malformed lines\n",
    "                continue\n",
    "            word = parts[0]\n",
    "            vec = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float32)\n",
    "            embeddings[word] = vec\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def build_embedding_matrix(\n",
    "    vocab: Dict[str, int],\n",
    "    glove_embeddings: Dict[str, torch.Tensor],\n",
    "    embed_dim: int,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create an embedding matrix of shape [vocab_size, embed_dim]\n",
    "    where row i is the vector for the word with index i.\n",
    "    Words not found in GloVe are randomly initialized (small normal).\n",
    "    \"\"\"\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_matrix = torch.empty(vocab_size, embed_dim, dtype=torch.float32)\n",
    "\n",
    "    # Initialize OOV embeddings to small random values\n",
    "    torch.nn.init.normal_(embedding_matrix, mean=0.0, std=0.05)\n",
    "\n",
    "    # Set PAD embedding to zeros\n",
    "    pad_idx = vocab[PAD_TOKEN]\n",
    "    embedding_matrix[pad_idx] = torch.zeros(embed_dim, dtype=torch.float32)\n",
    "\n",
    "    oov_count = 0\n",
    "    for word, idx in vocab.items():\n",
    "        if word in (PAD_TOKEN, UNK_TOKEN):\n",
    "            continue\n",
    "        vec = glove_embeddings.get(word)\n",
    "        if vec is not None:\n",
    "            embedding_matrix[idx] = vec\n",
    "        else:\n",
    "            oov_count += 1\n",
    "\n",
    "    print(f\"GloVe OOV words: {oov_count}/{vocab_size}\")\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60863f21",
   "metadata": {},
   "source": [
    "### Text CNN model (with optional pretrained embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f94c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        num_classes: int,\n",
    "        pad_idx: int = 0,\n",
    "        num_filters: int = 100,\n",
    "        filter_sizes: Tuple[int, ...] = (3, 4, 5),\n",
    "        dropout: float = 0.5,\n",
    "        pretrained_embeddings: torch.Tensor | None = None,\n",
    "        freeze_embeddings: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embed_dim,\n",
    "            padding_idx=pad_idx,\n",
    "        )\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            if pretrained_embeddings.shape != (vocab_size, embed_dim):\n",
    "                raise ValueError(\n",
    "                    f\"Pretrained embeddings shape {pretrained_embeddings.shape} \"\n",
    "                    f\"does not match (vocab_size, embed_dim)=({vocab_size}, {embed_dim})\"\n",
    "                )\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "            if freeze_embeddings:\n",
    "                self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=embed_dim,\n",
    "                out_channels=num_filters,\n",
    "                kernel_size=fs,\n",
    "            )\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        embedded = self.embedding(input_ids)          # [B, L, D]\n",
    "        embedded = embedded.transpose(1, 2)           # [B, D, L]\n",
    "\n",
    "        conv_outputs = []\n",
    "        for conv in self.convs:\n",
    "            x = conv(embedded)                        # [B, F, L']\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool1d(x, x.size(2)).squeeze(2) # [B, F]\n",
    "            conv_outputs.append(x)\n",
    "\n",
    "        cat = torch.cat(conv_outputs, dim=1)          # [B, F * len(filter_sizes)]\n",
    "        cat = self.dropout(cat)\n",
    "        logits = self.fc(cat)                         # [B, num_classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93543e0d",
   "metadata": {},
   "source": [
    "### Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1baee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for input_ids, labels in dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * input_ids.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(input_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67776a78",
   "metadata": {},
   "source": [
    "### Main CNN Train Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99044bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 20000, Num classes: 3\n",
      "Loading GloVe embeddings...\n",
      "GloVe OOV words: 882/20000\n",
      "Epoch 01 | Train Loss: 0.4595, Train Acc: 0.8258 | Val Loss: 0.3805, Val Acc: 0.8552\n",
      "Epoch 02 | Train Loss: 0.3572, Train Acc: 0.8675 | Val Loss: 0.3513, Val Acc: 0.8696\n",
      "Epoch 03 | Train Loss: 0.3088, Train Acc: 0.8865 | Val Loss: 0.3488, Val Acc: 0.8734\n",
      "Epoch 04 | Train Loss: 0.2718, Train Acc: 0.9027 | Val Loss: 0.3552, Val Acc: 0.8731\n",
      "Epoch 05 | Train Loss: 0.2348, Train Acc: 0.9148 | Val Loss: 0.3815, Val Acc: 0.8666\n",
      "Epoch 06 | Train Loss: 0.2045, Train Acc: 0.9268 | Val Loss: 0.3986, Val Acc: 0.8658\n",
      "Epoch 07 | Train Loss: 0.1774, Train Acc: 0.9370 | Val Loss: 0.4382, Val Acc: 0.8646\n",
      "Epoch 08 | Train Loss: 0.1547, Train Acc: 0.9453 | Val Loss: 0.4868, Val Acc: 0.8606\n",
      "Epoch 09 | Train Loss: 0.1365, Train Acc: 0.9517 | Val Loss: 0.5132, Val Acc: 0.8562\n",
      "Epoch 10 | Train Loss: 0.1208, Train Acc: 0.9579 | Val Loss: 0.5814, Val Acc: 0.8569\n",
      "Best validation accuracy: 0.8734\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_df = df['train'].dropna(subset=['text'])\n",
    "train_texts = train_df['text'].tolist()\n",
    "train_label_strs = train_df['class_label_group']\n",
    "\n",
    "val_df = df['dev'].dropna(subset=['text'])\n",
    "val_texts = val_df['text'].tolist()\n",
    "val_label_strs = val_df['class_label_group']\n",
    "\n",
    "all_label_strs = sorted(set(train_label_strs) | set(val_label_strs))\n",
    "label2id = {label: i for i, label in enumerate(all_label_strs)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "train_labels = [label2id[l] for l in train_label_strs]\n",
    "val_labels   = [label2id[l] for l in val_label_strs]\n",
    "# Create loaders and vocab\n",
    "train_loader, val_loader, vocab, num_classes = create_dataloaders(\n",
    "    train_texts=train_texts,\n",
    "    train_labels=train_labels,\n",
    "    val_texts=val_texts,\n",
    "    val_labels=val_labels,\n",
    "    max_vocab_size=MAX_VOCAB_SIZE,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "print(f\"Vocab size: {len(vocab)}, Num classes: {num_classes}\")\n",
    "\n",
    "# Load GloVe embeddings\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "glove_embeds = load_glove_embeddings(GLOVE_PATH, EMBED_DIM)\n",
    "embedding_matrix = build_embedding_matrix(vocab, glove_embeds, EMBED_DIM)\n",
    "\n",
    "# Initialize model with pretrained embeddings\n",
    "print(\"Model Initialization...\")\n",
    "model = TextCNN(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_classes=num_classes,\n",
    "    pad_idx=vocab[PAD_TOKEN],\n",
    "    num_filters=NUM_FILTERS,\n",
    "    filter_sizes=FILTER_SIZES,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_embeddings=embedding_matrix,\n",
    "    freeze_embeddings=False,   # set True if you want to freeze GloVe\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0.0\n",
    "print(\"Training...\")\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "    val_loss, val_acc = evaluate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_textcnn_glove.pt\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b973a",
   "metadata": {},
   "source": [
    "### Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1fdb0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics:\n",
      "accuracy: 0.8734\n",
      "precision: 0.8467\n",
      "recall: 0.8108\n",
      "f1: 0.8272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Helper to get predictions + labels from a DataLoader\n",
    "def get_all_preds_and_labels(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(input_ids)          # [B, num_classes]\n",
    "            preds = logits.argmax(dim=1)      # [B]\n",
    "\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# compute accuracy, precision, recall, F1 (macro)\n",
    "def compute_classification_metrics(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "    average: str = \"macro\",   # \"macro\", \"micro\", or \"weighted\"\n",
    "):\n",
    "    preds, labels = get_all_preds_and_labels(model, dataloader, device)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=average,\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_textcnn_glove.pt\", map_location=device))\n",
    "\n",
    "# For validation metrics\n",
    "val_metrics = compute_classification_metrics(model, val_loader, device, average=\"macro\")\n",
    "print(\"Validation metrics:\")\n",
    "for k, v in val_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051a548-63f6-4e96-8f3d-fed56f14f42e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b22bed-3c0a-4439-a1a8-7090fa815932",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "032841ea-0f01-437d-aff7-2e43f2d574f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        num_labels = 3,\n",
    "        max_length = 64,\n",
    "        d_model = 256, # hidden size\n",
    "        nhead = 4, # number of attention heads\n",
    "        num_layers = 4, # number of encoder layers\n",
    "        dim_feedforward = 512,  # FFN inner dim\n",
    "        dropout = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Embedding(max_length, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True, # (batch, seq, dim)\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, num_labels),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch_size, seq_len = input_ids.size()\n",
    "        if seq_len > self.max_length:\n",
    "            raise ValueError(f\"seq_len {seq_len} > max_length {self.max_length}\")\n",
    "\n",
    "        token_emb = self.token_embedding(input_ids)  # (B, L, D)\n",
    "\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)  # (1, L)\n",
    "        pos_emb = self.pos_embedding(positions)  # (1, L, D)\n",
    "\n",
    "        x = token_emb + pos_emb  # (B, L, D)\n",
    "\n",
    "        src_key_padding_mask = (attention_mask == 0)  # (B, L), bool\n",
    "\n",
    "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)  # (B, L, D)\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        mask = attention_mask.unsqueeze(-1)  # (B, L, 1)\n",
    "        masked_x = x * mask  # (B, L, D)\n",
    "\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)  # (B, 1)\n",
    "        pooled = masked_x.sum(dim=1) / lengths  # (B, D)\n",
    "\n",
    "        logits = self.classifier(pooled)  # (B, num_labels)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a35066bf-4d49-4551-b3d0-562a55e3f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_preds(all_logits, all_labels):\n",
    "    logits = np.concatenate(all_logits, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc4272-73e0-47e6-a9ea-1a4763bdc1e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "795519ff-4e33-408a-9759-503266752b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_texts = df[\"train\"][\"text\"].tolist()\n",
    "dev_texts   = df[\"dev\"][\"text\"].tolist()\n",
    "test_texts   = df[\"test\"][\"text\"].tolist()\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=30000, # could be adjusted\n",
    "    min_frequency=2,\n",
    "    special_tokens=special_tokens,\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(train_texts, trainer=trainer)\n",
    "\n",
    "max_length = 64\n",
    "pad_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "tokenizer.enable_truncation(max_length=max_length)\n",
    "tokenizer.enable_padding(\n",
    "    length=max_length,\n",
    "    pad_id=pad_id,\n",
    "    pad_token=\"[PAD]\",\n",
    ")\n",
    "\n",
    "def encode_batch(texts):\n",
    "    encodings = tokenizer.encode_batch(texts)\n",
    "    input_ids = [e.ids for e in encodings]\n",
    "    attention_mask = [e.attention_mask for e in encodings]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "train_enc = encode_batch(train_texts)\n",
    "dev_enc   = encode_batch(dev_texts)\n",
    "test_enc   = encode_batch(test_texts)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      train_enc[\"input_ids\"],\n",
    "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"train\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      dev_enc[\"input_ids\"],\n",
    "    \"attention_mask\": dev_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"dev\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      test_enc[\"input_ids\"],\n",
    "    \"attention_mask\": test_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"test\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829ec10-0fca-4019-a3c1-f1e129e0f0ad",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b20bfc4-260d-4557-9450-51fa9d8bcd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluate\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            all_logits.append(logits.detach().cpu().numpy())\n",
    "            all_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(data_loader)\n",
    "    metrics = compute_metrics_from_preds(all_logits, all_labels)\n",
    "    metrics[\"loss\"] = val_loss\n",
    "    return metrics\n",
    "    \n",
    "def train(\n",
    "        d_model=256,\n",
    "        nhead=4,\n",
    "        num_layers=4,\n",
    "        dim_feedforward=512,\n",
    "        dropout=0.1,\n",
    "        lr=1e-4,\n",
    "        batch_size = 32,\n",
    "        weight_decay=0.01,\n",
    "        last_epoch=0,\n",
    "        max_epochs=3,\n",
    "        save_path=\"./transformers/best_transformer_1.pt\"\n",
    "    ):\n",
    "    num_labels = len(label2id)\n",
    "    vocab_size = tokenizer.get_vocab_size()\n",
    "    max_length = 64\n",
    "    \n",
    "    model = TransformerClassifier(\n",
    "        vocab_size=vocab_size,\n",
    "        num_labels=num_labels,\n",
    "        max_length=max_length,\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_layers=num_layers,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        dropout=dropout,\n",
    "    ).to(device)\n",
    "    \n",
    "    # AdamW + weight decay\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        tokenized_datasets[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        tokenized_datasets[\"validation\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        tokenized_datasets[\"test\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        state = torch.load(save_path, map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "    else: # not os.path.exists(save_path) or last_epoch > 0:\n",
    "        logging_steps = 50\n",
    "        best_f1 = 0.0\n",
    "        best_state_dict = None\n",
    "        global_step = 0\n",
    "        \n",
    "        for epoch in range(last_epoch, max_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "        \n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs} [train]\")\n",
    "            for batch in pbar:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(logits, labels)\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                total_loss += loss.item()\n",
    "                global_step += 1\n",
    "        \n",
    "                if global_step % logging_steps == 0:\n",
    "                    avg_loss = total_loss / logging_steps\n",
    "                    pbar.set_postfix({\"loss\": f\"{avg_loss:.4f}\"})\n",
    "                    total_loss = 0.0\n",
    "    \n",
    "            # print performance every epoch\n",
    "            train_metrics = evaluate_model(model, train_loader)\n",
    "            val_metrics   = evaluate_model(model, val_loader)\n",
    "\n",
    "            print(f\"Epoch {epoch+1} train: train_loss  = {train_metrics['loss']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: accuracy    = {train_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: precision   = {train_metrics['precision']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: recall      = {train_metrics['recall']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: f1          = {train_metrics['f1']:.4f}\")\n",
    "\n",
    "            print(f\"Epoch {epoch+1} validation: val_loss    = {val_metrics['loss']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: accuracy    = {val_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: precision   = {val_metrics['precision']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: recall      = {val_metrics['recall']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: f1          = {val_metrics['f1']:.4f}\")\n",
    "\n",
    "            # save best model (highest f1)\n",
    "            if val_metrics[\"f1\"] > best_f1:\n",
    "                best_f1 = val_metrics[\"f1\"]\n",
    "                best_state_dict = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "                torch.save(best_state_dict, save_path)\n",
    "                print(f\"New best model (f1={best_f1:.4f}) saved.\\n\")\n",
    "            \n",
    "        # load best model\n",
    "        if best_state_dict is not None:\n",
    "            model.load_state_dict(best_state_dict)\n",
    "            print(f\"Loaded best model with f1={best_f1:.4f}\")\n",
    "    return model, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e763b1-3338-486c-9aa7-41615300b3de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "272f765d-dbea-4fe1-97cd-d7242e1499f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d98e0fa93940e5be2a9f443d3f67de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8400346120565331, 'precision': 0.7853384733927123, 'recall': 0.791181843157427, 'f1': 0.7880170998346174, 'loss': 0.4298086559805483}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=10, save_path=\"./transformers/best_transformer_1_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   f1          = 0.7790\n",
    "# Epoch 1 validation:\n",
    "#   f1          = 0.7610\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   f1          = 0.8281\n",
    "# Epoch 2 validation:\n",
    "#   f1          = 0.7858\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   f1          = 0.8610\n",
    "# Epoch 3 validation:\n",
    "#   f1          = 0.7978\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   f1          = 0.8896\n",
    "# Epoch 4 validation:\n",
    "#   f1          = 0.8002\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8400346120565331, 'precision': 0.7853384733927123, 'recall': 0.791181843157427, 'f1': 0.7880170998346174, 'loss': 0.4298086559805483}\n",
    "#### Overfitting ######\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   f1          = 0.9136\n",
    "# Epoch 5 validation:\n",
    "#   f1          = 0.7984\n",
    "\n",
    "# Epoch 6 train:\n",
    "#   f1          = 0.9454\n",
    "# Epoch 6 validation:\n",
    "#   f1          = 0.7911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7bf33-240d-48d6-8db9-4a3afe262ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.4335\n",
    "#   accuracy    = 0.8384\n",
    "#   precision   = 0.8024\n",
    "#   recall      = 0.7603\n",
    "#   f1          = 0.7790\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.4582\n",
    "#   accuracy    = 0.8268\n",
    "#   precision   = 0.7841\n",
    "#   recall      = 0.7429\n",
    "#   f1          = 0.7610\n",
    "# New best model (f1=0.7610) saved.\n",
    "\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   train_loss  = 0.3628\n",
    "#   accuracy    = 0.8716\n",
    "#   precision   = 0.8343\n",
    "#   recall      = 0.8230\n",
    "#   f1          = 0.8281\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss    = 0.4280\n",
    "#   accuracy    = 0.8413\n",
    "#   precision   = 0.7921\n",
    "#   recall      = 0.7802\n",
    "#   f1          = 0.7858\n",
    "# New best model (f1=0.7858) saved.\n",
    "\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   train_loss  = 0.2929\n",
    "#   accuracy    = 0.8966\n",
    "#   precision   = 0.8722\n",
    "#   recall      = 0.8507\n",
    "#   f1          = 0.8610\n",
    "\n",
    "# Epoch 3 validation:\n",
    "#   val_loss    = 0.4102\n",
    "#   accuracy    = 0.8530\n",
    "#   precision   = 0.8135\n",
    "#   recall      = 0.7843\n",
    "#   f1          = 0.7978\n",
    "# New best model (f1=0.7978) saved.\n",
    "\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   train_loss  = 0.2442\n",
    "#   accuracy    = 0.9165\n",
    "#   precision   = 0.8866\n",
    "#   recall      = 0.8927\n",
    "#   f1          = 0.8896\n",
    "\n",
    "# Epoch 4 validation:\n",
    "#   val_loss    = 0.4170\n",
    "#   accuracy    = 0.8504\n",
    "#   precision   = 0.8002\n",
    "#   recall      = 0.8006\n",
    "#   f1          = 0.8002\n",
    "# New best model (f1=0.8002) saved.\n",
    "\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   train_loss  = 0.1945\n",
    "#   accuracy    = 0.9336\n",
    "#   precision   = 0.9034\n",
    "#   recall      = 0.9247\n",
    "#   f1          = 0.9136\n",
    "\n",
    "# Epoch 5 validation:\n",
    "#   val_loss    = 0.4526\n",
    "#   accuracy    = 0.8463\n",
    "#   precision   = 0.7909\n",
    "#   recall      = 0.8072\n",
    "#   f1          = 0.7984\n",
    "\n",
    "\n",
    "# Epoch 6 train:\n",
    "#   train_loss  = 0.1474\n",
    "#   accuracy    = 0.9585\n",
    "#   precision   = 0.9492\n",
    "#   recall      = 0.9417\n",
    "#   f1          = 0.9454\n",
    "\n",
    "# Epoch 6 validation:\n",
    "#   val_loss    = 0.4453\n",
    "#   accuracy    = 0.8478\n",
    "#   precision   = 0.8033\n",
    "#   recall      = 0.7803\n",
    "#   f1          = 0.7911\n",
    "\n",
    "\n",
    "# Epoch 7 train:\n",
    "#   train_loss  = 0.1082\n",
    "#   accuracy    = 0.9660\n",
    "#   precision   = 0.9628\n",
    "#   recall      = 0.9469\n",
    "#   f1          = 0.9543\n",
    "\n",
    "# Epoch 7 validation:\n",
    "#   val_loss    = 0.5228\n",
    "#   accuracy    = 0.8459\n",
    "#   precision   = 0.8061\n",
    "#   recall      = 0.7696\n",
    "#   f1          = 0.7849\n",
    "\n",
    "\n",
    "# Epoch 8 train:\n",
    "#   train_loss  = 0.0803\n",
    "#   accuracy    = 0.9758\n",
    "#   precision   = 0.9719\n",
    "#   recall      = 0.9637\n",
    "#   f1          = 0.9677\n",
    "\n",
    "# Epoch 8 validation:\n",
    "#   val_loss    = 0.5808\n",
    "#   accuracy    = 0.8446\n",
    "#   precision   = 0.8029\n",
    "#   recall      = 0.7728\n",
    "#   f1          = 0.7867"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7f725-7ea2-4f1d-96de-d680ac9b89b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbce5ab7-1dbf-4d74-9614-8781b96abd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6387aeb920ac4325a3e90082e3a8502a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30fcbf12aa642c18e2fccb89d23dde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c5d60ced0b47b3b39cf220134b19bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train: train_loss  = 0.5130\n",
      "Epoch 1 train: accuracy    = 0.8026\n",
      "Epoch 1 train: precision   = 0.7595\n",
      "Epoch 1 train: recall      = 0.7103\n",
      "Epoch 1 train: f1          = 0.7275\n",
      "Epoch 1 validation: val_loss    = 0.5323\n",
      "Epoch 1 validation: accuracy    = 0.7972\n",
      "Epoch 1 validation: precision   = 0.7488\n",
      "Epoch 1 validation: recall      = 0.7015\n",
      "Epoch 1 validation: f1          = 0.7189\n",
      "New best model (f1=0.7189) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e066ce449c574414800673366d03c803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3311fcbb2f05407abde1f88f7ad59b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37425a67e685433eae554efae36bd166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train: train_loss  = 0.4540\n",
      "Epoch 2 train: accuracy    = 0.8300\n",
      "Epoch 2 train: precision   = 0.7967\n",
      "Epoch 2 train: recall      = 0.7502\n",
      "Epoch 2 train: f1          = 0.7626\n",
      "Epoch 2 validation: val_loss    = 0.4897\n",
      "Epoch 2 validation: accuracy    = 0.8115\n",
      "Epoch 2 validation: precision   = 0.7644\n",
      "Epoch 2 validation: recall      = 0.7226\n",
      "Epoch 2 validation: f1          = 0.7331\n",
      "New best model (f1=0.7331) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184693d561a94aedb386395c82b7777d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b828be4032e45b9b26f6cc168d03373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aeb1acd54a4990bea5af2c8d1a384b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train: train_loss  = 0.3880\n",
      "Epoch 3 train: accuracy    = 0.8566\n",
      "Epoch 3 train: precision   = 0.8315\n",
      "Epoch 3 train: recall      = 0.7796\n",
      "Epoch 3 train: f1          = 0.8023\n",
      "Epoch 3 validation: val_loss    = 0.4413\n",
      "Epoch 3 validation: accuracy    = 0.8349\n",
      "Epoch 3 validation: precision   = 0.8002\n",
      "Epoch 3 validation: recall      = 0.7471\n",
      "Epoch 3 validation: f1          = 0.7700\n",
      "New best model (f1=0.7700) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64d880b025d4ec8867455d763d629d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc3911432114d40a6eedd5c3477dd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64214bcc38f64804bc459b179b8321a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train: train_loss  = 0.3526\n",
      "Epoch 4 train: accuracy    = 0.8742\n",
      "Epoch 4 train: precision   = 0.8360\n",
      "Epoch 4 train: recall      = 0.8275\n",
      "Epoch 4 train: f1          = 0.8314\n",
      "Epoch 4 validation: val_loss    = 0.4302\n",
      "Epoch 4 validation: accuracy    = 0.8385\n",
      "Epoch 4 validation: precision   = 0.7880\n",
      "Epoch 4 validation: recall      = 0.7778\n",
      "Epoch 4 validation: f1          = 0.7824\n",
      "New best model (f1=0.7824) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da61e4ae3d54b87a29074bb13d66ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3a5688b2574c51beab9d8ed0fed221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d06bc2b234cbc9625af237518a784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train: train_loss  = 0.3248\n",
      "Epoch 5 train: accuracy    = 0.8821\n",
      "Epoch 5 train: precision   = 0.8390\n",
      "Epoch 5 train: recall      = 0.8512\n",
      "Epoch 5 train: f1          = 0.8446\n",
      "Epoch 5 validation: val_loss    = 0.4381\n",
      "Epoch 5 validation: accuracy    = 0.8349\n",
      "Epoch 5 validation: precision   = 0.7781\n",
      "Epoch 5 validation: recall      = 0.7863\n",
      "Epoch 5 validation: f1          = 0.7815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5223c3290754a5283c10295557d3cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeea49fc1d946a8a693bd72ff6b9928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22adda1d841942529b3f8bfac7934000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train: train_loss  = 0.3030\n",
      "Epoch 6 train: accuracy    = 0.8875\n",
      "Epoch 6 train: precision   = 0.8918\n",
      "Epoch 6 train: recall      = 0.8104\n",
      "Epoch 6 train: f1          = 0.8443\n",
      "Epoch 6 validation: val_loss    = 0.4422\n",
      "Epoch 6 validation: accuracy    = 0.8413\n",
      "Epoch 6 validation: precision   = 0.8258\n",
      "Epoch 6 validation: recall      = 0.7434\n",
      "Epoch 6 validation: f1          = 0.7765\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559cef063ba04efcb52ef89af38a04df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623f25210a0847289437c5b956819c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c999f62300c453180149d8e606351ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train: train_loss  = 0.2480\n",
      "Epoch 7 train: accuracy    = 0.9143\n",
      "Epoch 7 train: precision   = 0.9079\n",
      "Epoch 7 train: recall      = 0.8629\n",
      "Epoch 7 train: f1          = 0.8830\n",
      "Epoch 7 validation: val_loss    = 0.4434\n",
      "Epoch 7 validation: accuracy    = 0.8452\n",
      "Epoch 7 validation: precision   = 0.8135\n",
      "Epoch 7 validation: recall      = 0.7608\n",
      "Epoch 7 validation: f1          = 0.7835\n",
      "New best model (f1=0.7835) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724be301a5e14ce5a557ee36fe4e129e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9dc6f57f8a4ca1a1232037ac2777d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116e803f27294a2bb75c9f1d90cb4612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train: train_loss  = 0.2141\n",
      "Epoch 8 train: accuracy    = 0.9270\n",
      "Epoch 8 train: precision   = 0.9154\n",
      "Epoch 8 train: recall      = 0.8900\n",
      "Epoch 8 train: f1          = 0.9017\n",
      "Epoch 8 validation: val_loss    = 0.4528\n",
      "Epoch 8 validation: accuracy    = 0.8452\n",
      "Epoch 8 validation: precision   = 0.8071\n",
      "Epoch 8 validation: recall      = 0.7687\n",
      "Epoch 8 validation: f1          = 0.7856\n",
      "New best model (f1=0.7856) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afff0f572edb47449088cb0fa1e38b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae9d9a7ff5541458812e04c70ac947d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdccdcb663447fbb7962ef837252941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train: train_loss  = 0.1827\n",
      "Epoch 9 train: accuracy    = 0.9407\n",
      "Epoch 9 train: precision   = 0.9337\n",
      "Epoch 9 train: recall      = 0.9081\n",
      "Epoch 9 train: f1          = 0.9199\n",
      "Epoch 9 validation: val_loss    = 0.4592\n",
      "Epoch 9 validation: accuracy    = 0.8447\n",
      "Epoch 9 validation: precision   = 0.8086\n",
      "Epoch 9 validation: recall      = 0.7655\n",
      "Epoch 9 validation: f1          = 0.7844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd38f4d07034d57be814c13f753f27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65903f1c2bc14f51b5cc222826cbe91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/_monitor.py\", line 84, in run\n",
      "    instance.refresh(nolock=True)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/std.py\", line 1347, in refresh\n",
      "    self.display()\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/notebook.py\", line 171, in display\n",
      "    rtext.value = right\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 716, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 706, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 1513, in _notify_trait\n",
      "    self.notify_change(\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 700, in notify_change\n",
      "    self.send_state(key=name)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 586, in send_state\n",
      "    self._send(msg, buffers=buffers)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 825, in _send\n",
      "    self.comm.send(data=msg, buffers=buffers)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/comm/base_comm.py\", line 144, in send\n",
      "    self.publish_msg(\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipykernel/comm/comm.py\", line 42, in publish_msg\n",
      "    parent=self.kernel.get_parent(),\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 797, in get_parent\n",
      "    return self._shell_parent.get()\n",
      "LookupError: <ContextVar name='shell_parent' at 0x1213bd300>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bb4bb7df8043668b65a10cd43afe99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train: train_loss  = 0.1740\n",
      "Epoch 10 train: accuracy    = 0.9423\n",
      "Epoch 10 train: precision   = 0.9192\n",
      "Epoch 10 train: recall      = 0.9270\n",
      "Epoch 10 train: f1          = 0.9217\n",
      "Epoch 10 validation: val_loss    = 0.4961\n",
      "Epoch 10 validation: accuracy    = 0.8335\n",
      "Epoch 10 validation: precision   = 0.7845\n",
      "Epoch 10 validation: recall      = 0.7833\n",
      "Epoch 10 validation: f1          = 0.7799\n",
      "Loaded best model with f1=0.7856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43871e160fe448968b8fa7049a788252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/2167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=10, save_path=\"./transformers/best_transformer_2_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 8 validation: f1          = 0.7856\n",
    "# Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb4d3f-9d18-4709-8a1e-3c03c6a57422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train: train_loss  = 0.5130\n",
    "# Epoch 1 train: accuracy    = 0.8026\n",
    "# Epoch 1 train: precision   = 0.7595\n",
    "# Epoch 1 train: recall      = 0.7103\n",
    "# Epoch 1 train: f1          = 0.7275\n",
    "# Epoch 1 validation: val_loss    = 0.5323\n",
    "# Epoch 1 validation: accuracy    = 0.7972\n",
    "# Epoch 1 validation: precision   = 0.7488\n",
    "# Epoch 1 validation: recall      = 0.7015\n",
    "# Epoch 1 validation: f1          = 0.7189\n",
    "# New best model (f1=0.7189) saved.\n",
    "\n",
    "# Epoch 2 train: train_loss  = 0.4540\n",
    "# Epoch 2 train: accuracy    = 0.8300\n",
    "# Epoch 2 train: precision   = 0.7967\n",
    "# Epoch 2 train: recall      = 0.7502\n",
    "# Epoch 2 train: f1          = 0.7626\n",
    "# Epoch 2 validation: val_loss    = 0.4897\n",
    "# Epoch 2 validation: accuracy    = 0.8115\n",
    "# Epoch 2 validation: precision   = 0.7644\n",
    "# Epoch 2 validation: recall      = 0.7226\n",
    "# Epoch 2 validation: f1          = 0.7331\n",
    "# New best model (f1=0.7331) saved.\n",
    "\n",
    "# Epoch 3 train: train_loss  = 0.3880\n",
    "# Epoch 3 train: accuracy    = 0.8566\n",
    "# Epoch 3 train: precision   = 0.8315\n",
    "# Epoch 3 train: recall      = 0.7796\n",
    "# Epoch 3 train: f1          = 0.8023\n",
    "# Epoch 3 validation: val_loss    = 0.4413\n",
    "# Epoch 3 validation: accuracy    = 0.8349\n",
    "# Epoch 3 validation: precision   = 0.8002\n",
    "# Epoch 3 validation: recall      = 0.7471\n",
    "# Epoch 3 validation: f1          = 0.7700\n",
    "# New best model (f1=0.7700) saved.\n",
    "\n",
    "# Epoch 4 train: train_loss  = 0.3526\n",
    "# Epoch 4 train: accuracy    = 0.8742\n",
    "# Epoch 4 train: precision   = 0.8360\n",
    "# Epoch 4 train: recall      = 0.8275\n",
    "# Epoch 4 train: f1          = 0.8314\n",
    "# Epoch 4 validation: val_loss    = 0.4302\n",
    "# Epoch 4 validation: accuracy    = 0.8385\n",
    "# Epoch 4 validation: precision   = 0.7880\n",
    "# Epoch 4 validation: recall      = 0.7778\n",
    "# Epoch 4 validation: f1          = 0.7824\n",
    "# New best model (f1=0.7824) saved.\n",
    "\n",
    "# Epoch 5 train: train_loss  = 0.3248\n",
    "# Epoch 5 train: accuracy    = 0.8821\n",
    "# Epoch 5 train: precision   = 0.8390\n",
    "# Epoch 5 train: recall      = 0.8512\n",
    "# Epoch 5 train: f1          = 0.8446\n",
    "# Epoch 5 validation: val_loss    = 0.4381\n",
    "# Epoch 5 validation: accuracy    = 0.8349\n",
    "# Epoch 5 validation: precision   = 0.7781\n",
    "# Epoch 5 validation: recall      = 0.7863\n",
    "# Epoch 5 validation: f1          = 0.7815\n",
    "\n",
    "# Epoch 6 train: train_loss  = 0.3030\n",
    "# Epoch 6 train: accuracy    = 0.8875\n",
    "# Epoch 6 train: precision   = 0.8918\n",
    "# Epoch 6 train: recall      = 0.8104\n",
    "# Epoch 6 train: f1          = 0.8443\n",
    "# Epoch 6 validation: val_loss    = 0.4422\n",
    "# Epoch 6 validation: accuracy    = 0.8413\n",
    "# Epoch 6 validation: precision   = 0.8258\n",
    "# Epoch 6 validation: recall      = 0.7434\n",
    "# Epoch 6 validation: f1          = 0.7765\n",
    "\n",
    "# Epoch 7 train: train_loss  = 0.2480\n",
    "# Epoch 7 train: accuracy    = 0.9143\n",
    "# Epoch 7 train: precision   = 0.9079\n",
    "# Epoch 7 train: recall      = 0.8629\n",
    "# Epoch 7 train: f1          = 0.8830\n",
    "# Epoch 7 validation: val_loss    = 0.4434\n",
    "# Epoch 7 validation: accuracy    = 0.8452\n",
    "# Epoch 7 validation: precision   = 0.8135\n",
    "# Epoch 7 validation: recall      = 0.7608\n",
    "# Epoch 7 validation: f1          = 0.7835\n",
    "# New best model (f1=0.7835) saved.\n",
    "\n",
    "# Epoch 8 train: train_loss  = 0.2141\n",
    "# Epoch 8 train: accuracy    = 0.9270\n",
    "# Epoch 8 train: precision   = 0.9154\n",
    "# Epoch 8 train: recall      = 0.8900\n",
    "# Epoch 8 train: f1          = 0.9017\n",
    "# Epoch 8 validation: val_loss    = 0.4528\n",
    "# Epoch 8 validation: accuracy    = 0.8452\n",
    "# Epoch 8 validation: precision   = 0.8071\n",
    "# Epoch 8 validation: recall      = 0.7687\n",
    "# Epoch 8 validation: f1          = 0.7856\n",
    "# New best model (f1=0.7856) saved.\n",
    "\n",
    "# Epoch 9 train: train_loss  = 0.1827\n",
    "# Epoch 9 train: accuracy    = 0.9407\n",
    "# Epoch 9 train: precision   = 0.9337\n",
    "# Epoch 9 train: recall      = 0.9081\n",
    "# Epoch 9 train: f1          = 0.9199\n",
    "# Epoch 9 validation: val_loss    = 0.4592\n",
    "# Epoch 9 validation: accuracy    = 0.8447\n",
    "# Epoch 9 validation: precision   = 0.8086\n",
    "# Epoch 9 validation: recall      = 0.7655\n",
    "# Epoch 9 validation: f1          = 0.7844\n",
    "\n",
    "# Epoch 10 train: train_loss  = 0.1740\n",
    "# Epoch 10 train: accuracy    = 0.9423\n",
    "# Epoch 10 train: precision   = 0.9192\n",
    "# Epoch 10 train: recall      = 0.9270\n",
    "# Epoch 10 train: f1          = 0.9217\n",
    "# Epoch 10 validation: val_loss    = 0.4961\n",
    "# Epoch 10 validation: accuracy    = 0.8335\n",
    "# Epoch 10 validation: precision   = 0.7845\n",
    "# Epoch 10 validation: recall      = 0.7833\n",
    "# Epoch 10 validation: f1          = 0.7799\n",
    "# Loaded best model with f1=0.7856\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1560ac-d830-4f9c-af1d-831caf614038",
   "metadata": {},
   "source": [
    "#### best_transformer_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24663986-5fc7-4f11-80da-72e2cd2bf2eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dcec888c204373805b33c5da8e4322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b79733d05242c78a921989b618d2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9673dbd6727466e9b23e93abe353ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train: train_loss  = 0.5427\n",
      "Epoch 1 train: accuracy    = 0.7908\n",
      "Epoch 1 train: precision   = 0.7750\n",
      "Epoch 1 train: recall      = 0.6531\n",
      "Epoch 1 train: f1          = 0.6932\n",
      "Epoch 1 validation: val_loss    = 0.5459\n",
      "Epoch 1 validation: accuracy    = 0.7876\n",
      "Epoch 1 validation: precision   = 0.7631\n",
      "Epoch 1 validation: recall      = 0.6470\n",
      "Epoch 1 validation: f1          = 0.6848\n",
      "New best model (f1=0.6848) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7679b127de24816a5b21969deb4cfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966d23eda40478e81fd1f0a59fcc6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d34ff15530e422ea044aaac3a7708dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train: train_loss  = 0.4633\n",
      "Epoch 2 train: accuracy    = 0.8244\n",
      "Epoch 2 train: precision   = 0.7907\n",
      "Epoch 2 train: recall      = 0.7311\n",
      "Epoch 2 train: f1          = 0.7563\n",
      "Epoch 2 validation: val_loss    = 0.4769\n",
      "Epoch 2 validation: accuracy    = 0.8165\n",
      "Epoch 2 validation: precision   = 0.7775\n",
      "Epoch 2 validation: recall      = 0.7193\n",
      "Epoch 2 validation: f1          = 0.7439\n",
      "New best model (f1=0.7439) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4973df55f1ff450e8d0518450f24d542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b59e7fbdcb422fbf97f42710936b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f98cc7e0db4db2b596b955f0bb27bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train: train_loss  = 0.4280\n",
      "Epoch 3 train: accuracy    = 0.8397\n",
      "Epoch 3 train: precision   = 0.8104\n",
      "Epoch 3 train: recall      = 0.7568\n",
      "Epoch 3 train: f1          = 0.7788\n",
      "Epoch 3 validation: val_loss    = 0.4552\n",
      "Epoch 3 validation: accuracy    = 0.8291\n",
      "Epoch 3 validation: precision   = 0.7945\n",
      "Epoch 3 validation: recall      = 0.7392\n",
      "Epoch 3 validation: f1          = 0.7618\n",
      "New best model (f1=0.7618) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8845fe7273419a82255ff6ee3a6e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c5b3b2ea7c4c3bac9cc13c25ae1eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5668e50faf485e8f961f2586b7968b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train: train_loss  = 0.3918\n",
      "Epoch 4 train: accuracy    = 0.8547\n",
      "Epoch 4 train: precision   = 0.8102\n",
      "Epoch 4 train: recall      = 0.8011\n",
      "Epoch 4 train: f1          = 0.8055\n",
      "Epoch 4 validation: val_loss    = 0.4373\n",
      "Epoch 4 validation: accuracy    = 0.8350\n",
      "Epoch 4 validation: precision   = 0.7836\n",
      "Epoch 4 validation: recall      = 0.7700\n",
      "Epoch 4 validation: f1          = 0.7765\n",
      "New best model (f1=0.7765) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3caa513ff394c98ab10707aebbdeca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0630c5085f640bd8817aaca144c54ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76486ece0c5544609f40906206daf6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train: train_loss  = 0.3623\n",
      "Epoch 5 train: accuracy    = 0.8659\n",
      "Epoch 5 train: precision   = 0.8320\n",
      "Epoch 5 train: recall      = 0.8071\n",
      "Epoch 5 train: f1          = 0.8181\n",
      "Epoch 5 validation: val_loss    = 0.4230\n",
      "Epoch 5 validation: accuracy    = 0.8440\n",
      "Epoch 5 validation: precision   = 0.8027\n",
      "Epoch 5 validation: recall      = 0.7758\n",
      "Epoch 5 validation: f1          = 0.7876\n",
      "New best model (f1=0.7876) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fc70599a0c4b149c1e62515bcb5534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09b993453a14cb893900bb3ff4357d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b434f477b90493fbe16f8bbd2d79dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train: train_loss  = 0.3344\n",
      "Epoch 6 train: accuracy    = 0.8765\n",
      "Epoch 6 train: precision   = 0.8492\n",
      "Epoch 6 train: recall      = 0.8171\n",
      "Epoch 6 train: f1          = 0.8308\n",
      "Epoch 6 validation: val_loss    = 0.4085\n",
      "Epoch 6 validation: accuracy    = 0.8468\n",
      "Epoch 6 validation: precision   = 0.8068\n",
      "Epoch 6 validation: recall      = 0.7739\n",
      "Epoch 6 validation: f1          = 0.7877\n",
      "New best model (f1=0.7877) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f36b5afae5b4e6eb05ff3965396a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6f3944d55840c7b93b7858ac96cde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d9d0a42bdb4d9eb0cb3aec2ca6ede9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train: train_loss  = 0.3135\n",
      "Epoch 7 train: accuracy    = 0.8857\n",
      "Epoch 7 train: precision   = 0.8603\n",
      "Epoch 7 train: recall      = 0.8300\n",
      "Epoch 7 train: f1          = 0.8441\n",
      "Epoch 7 validation: val_loss    = 0.4137\n",
      "Epoch 7 validation: accuracy    = 0.8537\n",
      "Epoch 7 validation: precision   = 0.8199\n",
      "Epoch 7 validation: recall      = 0.7828\n",
      "Epoch 7 validation: f1          = 0.7996\n",
      "New best model (f1=0.7996) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2611e5fcc334e2eb2acaa9d451f6b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cf0f15021c44bca172a665a8052d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6c9db5cf3a43cfbad6e6a0f291e73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train: train_loss  = 0.2867\n",
      "Epoch 8 train: accuracy    = 0.8962\n",
      "Epoch 8 train: precision   = 0.8761\n",
      "Epoch 8 train: recall      = 0.8443\n",
      "Epoch 8 train: f1          = 0.8590\n",
      "Epoch 8 validation: val_loss    = 0.4044\n",
      "Epoch 8 validation: accuracy    = 0.8523\n",
      "Epoch 8 validation: precision   = 0.8169\n",
      "Epoch 8 validation: recall      = 0.7792\n",
      "Epoch 8 validation: f1          = 0.7963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0f41640fe14cf3a4b114606102e77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0cbea3b34d4711a0478f17f8bbdf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab07d8b1202f4398b8707b7247f5e975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train: train_loss  = 0.2706\n",
      "Epoch 9 train: accuracy    = 0.9026\n",
      "Epoch 9 train: precision   = 0.8843\n",
      "Epoch 9 train: recall      = 0.8545\n",
      "Epoch 9 train: f1          = 0.8674\n",
      "Epoch 9 validation: val_loss    = 0.4110\n",
      "Epoch 9 validation: accuracy    = 0.8528\n",
      "Epoch 9 validation: precision   = 0.8164\n",
      "Epoch 9 validation: recall      = 0.7832\n",
      "Epoch 9 validation: f1          = 0.7972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91da248a5a5c4796a99c15902bec8b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03141e05e69404aa19308077b45ae8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba195f8468c4aa9a1194a28b3b58d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train: train_loss  = 0.2498\n",
      "Epoch 10 train: accuracy    = 0.9113\n",
      "Epoch 10 train: precision   = 0.8779\n",
      "Epoch 10 train: recall      = 0.8867\n",
      "Epoch 10 train: f1          = 0.8822\n",
      "Epoch 10 validation: val_loss    = 0.4073\n",
      "Epoch 10 validation: accuracy    = 0.8541\n",
      "Epoch 10 validation: precision   = 0.8042\n",
      "Epoch 10 validation: recall      = 0.8063\n",
      "Epoch 10 validation: f1          = 0.8052\n",
      "New best model (f1=0.8052) saved.\n",
      "\n",
      "Loaded best model with f1=0.8052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7f2a4d27224028a9e6d6aa103a71d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/2167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8478223247764638, 'precision': 0.7947469165050163, 'recall': 0.803183331774572, 'f1': 0.7988119336768936, 'loss': 0.43349864214906286}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1 => 0.3\n",
    "model, test_loader = train(dropout=0.3, lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=10, save_path=\"./transformers/best_transformer_3.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 10 validation: f1          = 0.8052\n",
    "# Final eval_results: {'accuracy': 0.8478223247764638, 'precision': 0.7947469165050163, 'recall': 0.803183331774572, 'f1': 0.7988119336768936, 'loss': 0.43349864214906286}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2ed1bc9-3e1b-422a-a8c7-0034645c384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train: train_loss  = 0.5427\n",
    "# Epoch 1 train: accuracy    = 0.7908\n",
    "# Epoch 1 train: precision   = 0.7750\n",
    "# Epoch 1 train: recall      = 0.6531\n",
    "# Epoch 1 train: f1          = 0.6932\n",
    "# Epoch 1 validation: val_loss    = 0.5459\n",
    "# Epoch 1 validation: accuracy    = 0.7876\n",
    "# Epoch 1 validation: precision   = 0.7631\n",
    "# Epoch 1 validation: recall      = 0.6470\n",
    "# Epoch 1 validation: f1          = 0.6848\n",
    "# New best model (f1=0.6848) saved.\n",
    "\n",
    "# Epoch 2 train: train_loss  = 0.4633\n",
    "# Epoch 2 train: accuracy    = 0.8244\n",
    "# Epoch 2 train: precision   = 0.7907\n",
    "# Epoch 2 train: recall      = 0.7311\n",
    "# Epoch 2 train: f1          = 0.7563\n",
    "# Epoch 2 validation: val_loss    = 0.4769\n",
    "# Epoch 2 validation: accuracy    = 0.8165\n",
    "# Epoch 2 validation: precision   = 0.7775\n",
    "# Epoch 2 validation: recall      = 0.7193\n",
    "# Epoch 2 validation: f1          = 0.7439\n",
    "# New best model (f1=0.7439) saved.\n",
    "\n",
    "# Epoch 3 train: train_loss  = 0.4280\n",
    "# Epoch 3 train: accuracy    = 0.8397\n",
    "# Epoch 3 train: precision   = 0.8104\n",
    "# Epoch 3 train: recall      = 0.7568\n",
    "# Epoch 3 train: f1          = 0.7788\n",
    "# Epoch 3 validation: val_loss    = 0.4552\n",
    "# Epoch 3 validation: accuracy    = 0.8291\n",
    "# Epoch 3 validation: precision   = 0.7945\n",
    "# Epoch 3 validation: recall      = 0.7392\n",
    "# Epoch 3 validation: f1          = 0.7618\n",
    "# New best model (f1=0.7618) saved.\n",
    "\n",
    "# Epoch 4 train: train_loss  = 0.3918\n",
    "# Epoch 4 train: accuracy    = 0.8547\n",
    "# Epoch 4 train: precision   = 0.8102\n",
    "# Epoch 4 train: recall      = 0.8011\n",
    "# Epoch 4 train: f1          = 0.8055\n",
    "# Epoch 4 validation: val_loss    = 0.4373\n",
    "# Epoch 4 validation: accuracy    = 0.8350\n",
    "# Epoch 4 validation: precision   = 0.7836\n",
    "# Epoch 4 validation: recall      = 0.7700\n",
    "# Epoch 4 validation: f1          = 0.7765\n",
    "# New best model (f1=0.7765) saved.\n",
    "\n",
    "# Epoch 5 train: train_loss  = 0.3623\n",
    "# Epoch 5 train: accuracy    = 0.8659\n",
    "# Epoch 5 train: precision   = 0.8320\n",
    "# Epoch 5 train: recall      = 0.8071\n",
    "# Epoch 5 train: f1          = 0.8181\n",
    "# Epoch 5 validation: val_loss    = 0.4230\n",
    "# Epoch 5 validation: accuracy    = 0.8440\n",
    "# Epoch 5 validation: precision   = 0.8027\n",
    "# Epoch 5 validation: recall      = 0.7758\n",
    "# Epoch 5 validation: f1          = 0.7876\n",
    "# New best model (f1=0.7876) saved.\n",
    "\n",
    "# Epoch 6 train: train_loss  = 0.3344\n",
    "# Epoch 6 train: accuracy    = 0.8765\n",
    "# Epoch 6 train: precision   = 0.8492\n",
    "# Epoch 6 train: recall      = 0.8171\n",
    "# Epoch 6 train: f1          = 0.8308\n",
    "# Epoch 6 validation: val_loss    = 0.4085\n",
    "# Epoch 6 validation: accuracy    = 0.8468\n",
    "# Epoch 6 validation: precision   = 0.8068\n",
    "# Epoch 6 validation: recall      = 0.7739\n",
    "# Epoch 6 validation: f1          = 0.7877\n",
    "# New best model (f1=0.7877) saved.\n",
    "\n",
    "# Epoch 7 train: train_loss  = 0.3135\n",
    "# Epoch 7 train: accuracy    = 0.8857\n",
    "# Epoch 7 train: precision   = 0.8603\n",
    "# Epoch 7 train: recall      = 0.8300\n",
    "# Epoch 7 train: f1          = 0.8441\n",
    "# Epoch 7 validation: val_loss    = 0.4137\n",
    "# Epoch 7 validation: accuracy    = 0.8537\n",
    "# Epoch 7 validation: precision   = 0.8199\n",
    "# Epoch 7 validation: recall      = 0.7828\n",
    "# Epoch 7 validation: f1          = 0.7996\n",
    "# New best model (f1=0.7996) saved.\n",
    "\n",
    "# Epoch 8 train: train_loss  = 0.2867\n",
    "# Epoch 8 train: accuracy    = 0.8962\n",
    "# Epoch 8 train: precision   = 0.8761\n",
    "# Epoch 8 train: recall      = 0.8443\n",
    "# Epoch 8 train: f1          = 0.8590\n",
    "# Epoch 8 validation: val_loss    = 0.4044\n",
    "# Epoch 8 validation: accuracy    = 0.8523\n",
    "# Epoch 8 validation: precision   = 0.8169\n",
    "# Epoch 8 validation: recall      = 0.7792\n",
    "# Epoch 8 validation: f1          = 0.7963\n",
    "\n",
    "# Epoch 9 train: train_loss  = 0.2706\n",
    "# Epoch 9 train: accuracy    = 0.9026\n",
    "# Epoch 9 train: precision   = 0.8843\n",
    "# Epoch 9 train: recall      = 0.8545\n",
    "# Epoch 9 train: f1          = 0.8674\n",
    "# Epoch 9 validation: val_loss    = 0.4110\n",
    "# Epoch 9 validation: accuracy    = 0.8528\n",
    "# Epoch 9 validation: precision   = 0.8164\n",
    "# Epoch 9 validation: recall      = 0.7832\n",
    "# Epoch 9 validation: f1          = 0.7972\n",
    "\n",
    "# Epoch 10 train: train_loss  = 0.2498\n",
    "# Epoch 10 train: accuracy    = 0.9113\n",
    "# Epoch 10 train: precision   = 0.8779\n",
    "# Epoch 10 train: recall      = 0.8867\n",
    "# Epoch 10 train: f1          = 0.8822\n",
    "# Epoch 10 validation: val_loss    = 0.4073\n",
    "# Epoch 10 validation: accuracy    = 0.8541\n",
    "# Epoch 10 validation: precision   = 0.8042\n",
    "# Epoch 10 validation: recall      = 0.8063\n",
    "# Epoch 10 validation: f1          = 0.8052\n",
    "# New best model (f1=0.8052) saved.\n",
    "\n",
    "# Loaded best model with f1=0.8052"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa53ba-8be6-4d60-921e-10ff3e7bbe8e",
   "metadata": {},
   "source": [
    "#### best_transformer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2f534-6150-439d-accc-25d0c4a1cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=3, save_path=\"./transformers/best_transformer_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "# Epoch 1 validation:\n",
    "#   val_loss  = 0.4957\n",
    "#   accuracy  = 0.8108\n",
    "#   precision = 0.7511\n",
    "#   recall    = 0.7480\n",
    "#   f1        = 0.7490\n",
    "#    New best model (f1=0.7490) saved.\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss  = 0.4397\n",
    "#   accuracy  = 0.8314\n",
    "#   precision = 0.7872\n",
    "#   recall    = 0.7633\n",
    "#   f1        = 0.7724\n",
    "#    New best model (f1=0.7724) saved.\n",
    "\n",
    "# Epoch 3 validation:\n",
    "#   val_loss  = 0.4129\n",
    "#   accuracy  = 0.8471\n",
    "#   precision = 0.7982\n",
    "#   recall    = 0.7925\n",
    "#   f1        = 0.7945\n",
    "#    New best model (f1=0.7945) saved.\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8394577444476493, 'precision': 0.7870732957272955, 'recall': 0.7865639150630909, 'f1': 0.7861628773510826, 'loss': 0.4266800470237802}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ace50-196b-422f-9e85-e40009fa500c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef3f4c-320b-4c7d-98b4-17c43888ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=5, save_path=\"./transformers/best_transformer_2.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss  = 0.5102\n",
    "#   accuracy  = 0.8056\n",
    "#   precision = 0.7564\n",
    "#   recall    = 0.7051\n",
    "#   f1        = 0.7269\n",
    "#    New best model (f1=0.7269) saved.\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss  = 0.4723\n",
    "#   accuracy  = 0.8213\n",
    "#   precision = 0.7739\n",
    "#   recall    = 0.7437\n",
    "#   f1        = 0.7558\n",
    "#    New best model (f1=0.7558) saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441298a9-7661-4dc0-ba4c-3923cec091ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=128 <= 256,\n",
    "# nhead=4,\n",
    "# num_layers=2 <= 4,\n",
    "# dim_feedforward=256 <= 512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(d_model=128, num_layers=2, dim_feedforward=256, lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=5, save_path=\"./transformers/best_transformer_3.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.5239\n",
    "#   accuracy    = 0.7990\n",
    "#   precision   = 0.7548\n",
    "#   recall      = 0.6899\n",
    "#   f1          = 0.7164\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.5276\n",
    "#   accuracy    = 0.7989\n",
    "#   precision   = 0.7494\n",
    "#   recall      = 0.6869\n",
    "#   f1          = 0.7125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a847f2e-1488-4b64-bd40-61667954ba75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342536e4a5b24ad6b78c920010143482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98311f72cd524a31a772ecb616b9d684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bba808f4112402f9668d47a395fc166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 train:\n",
      "  train_loss  = 0.4597\n",
      "  accuracy    = 0.8261\n",
      "  precision   = 0.8127\n",
      "  recall      = 0.7218\n",
      "  f1          = 0.7500\n",
      "\n",
      "Epoch 1 validation:\n",
      "  val_loss    = 0.4887\n",
      "  accuracy    = 0.8144\n",
      "  precision   = 0.7946\n",
      "  recall      = 0.7015\n",
      "  f1          = 0.7282\n",
      "New best model (f1=0.7282) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e44998c7a544999de13a6c5c2b8803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe27b80e50b4a42b9223307effeab74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc508d999fc44a188ab6b0fc028c9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 train:\n",
      "  train_loss  = 0.3688\n",
      "  accuracy    = 0.8639\n",
      "  precision   = 0.8235\n",
      "  recall      = 0.8156\n",
      "  f1          = 0.8188\n",
      "\n",
      "Epoch 2 validation:\n",
      "  val_loss    = 0.4365\n",
      "  accuracy    = 0.8378\n",
      "  precision   = 0.7905\n",
      "  recall      = 0.7755\n",
      "  f1          = 0.7823\n",
      "New best model (f1=0.7823) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc435c3b73c54a2480d1ddbd09a03810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f3066eec8d4e7eaef5df3bc715ac22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee883b31d0fe41329319033100cdb61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 train:\n",
      "  train_loss  = 0.3202\n",
      "  accuracy    = 0.8813\n",
      "  precision   = 0.8689\n",
      "  recall      = 0.8117\n",
      "  f1          = 0.8369\n",
      "\n",
      "Epoch 3 validation:\n",
      "  val_loss    = 0.4392\n",
      "  accuracy    = 0.8396\n",
      "  precision   = 0.8122\n",
      "  recall      = 0.7477\n",
      "  f1          = 0.7750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f162af6c9c4c4f34864e9c4d4dab1009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae7b1dd2ad8479f8ea75bd9964a1505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823b20a43ac44949a5fd6ce1f32f5ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 train:\n",
      "  train_loss  = 0.2600\n",
      "  accuracy    = 0.9077\n",
      "  precision   = 0.8946\n",
      "  recall      = 0.8575\n",
      "  f1          = 0.8738\n",
      "\n",
      "Epoch 4 validation:\n",
      "  val_loss    = 0.4221\n",
      "  accuracy    = 0.8499\n",
      "  precision   = 0.8175\n",
      "  recall      = 0.7718\n",
      "  f1          = 0.7914\n",
      "New best model (f1=0.7914) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28479706ac794003b64acfdcc7d86f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11f4bc2e6e442dcaf3b19cd9cc7cbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818b5f0725e84440a7647ee9a48977e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 train:\n",
      "  train_loss  = 0.2058\n",
      "  accuracy    = 0.9299\n",
      "  precision   = 0.9085\n",
      "  recall      = 0.9060\n",
      "  f1          = 0.9066\n",
      "\n",
      "Epoch 5 validation:\n",
      "  val_loss    = 0.4409\n",
      "  accuracy    = 0.8463\n",
      "  precision   = 0.7998\n",
      "  recall      = 0.7894\n",
      "  f1          = 0.7935\n",
      "New best model (f1=0.7935) saved.\n",
      "\n",
      "Loaded best model with f1=0.7935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75067f72aa76493d84d75954fc3a2666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8404384193827517, 'precision': 0.7916469260389406, 'recall': 0.7848264806284927, 'f1': 0.786880109334091, 'loss': 0.4544476669185496}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=3 <= 4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(d_model=256, num_layers=3, dim_feedforward=512, lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=5, save_path=\"./transformers/best_transformer_4.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   f1          = 0.7500\n",
    "# Epoch 1 validation:\n",
    "#   f1          = 0.7282\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   f1          = 0.8188\n",
    "# Epoch 2 validation:\n",
    "#   f1          = 0.7823\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   f1          = 0.8369\n",
    "# Epoch 3 validation:\n",
    "#   f1          = 0.7750 <= first sign of overfitting\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   f1          = 0.8738 <= increasing\n",
    "# Epoch 4 validation:\n",
    "#   f1          = 0.7914\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   f1          = 0.9066 <= increasing\n",
    "# Epoch 5 validation:\n",
    "#   f1          = 0.7935 <= not increasing much. oscilating\n",
    "\n",
    "# test f1 = 0.786880109334091\n",
    "\n",
    "############################################\n",
    "############################################\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.4597\n",
    "#   accuracy    = 0.8261\n",
    "#   precision   = 0.8127\n",
    "#   recall      = 0.7218\n",
    "#   f1          = 0.7500\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.4887\n",
    "#   accuracy    = 0.8144\n",
    "#   precision   = 0.7946\n",
    "#   recall      = 0.7015\n",
    "#   f1          = 0.7282\n",
    "# New best model (f1=0.7282) saved.\n",
    "\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   train_loss  = 0.3688\n",
    "#   accuracy    = 0.8639\n",
    "#   precision   = 0.8235\n",
    "#   recall      = 0.8156\n",
    "#   f1          = 0.8188\n",
    "# Epoch 2 validation:\n",
    "#   val_loss    = 0.4365\n",
    "#   accuracy    = 0.8378\n",
    "#   precision   = 0.7905\n",
    "#   recall      = 0.7755\n",
    "#   f1          = 0.7823\n",
    "# New best model (f1=0.7823) saved.\n",
    "\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   train_loss  = 0.3202\n",
    "#   accuracy    = 0.8813\n",
    "#   precision   = 0.8689\n",
    "#   recall      = 0.8117\n",
    "#   f1          = 0.8369\n",
    "# Epoch 3 validation:\n",
    "#   val_loss    = 0.4392\n",
    "#   accuracy    = 0.8396\n",
    "#   precision   = 0.8122\n",
    "#   recall      = 0.7477\n",
    "#   f1          = 0.7750\n",
    "\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   train_loss  = 0.2600\n",
    "#   accuracy    = 0.9077\n",
    "#   precision   = 0.8946\n",
    "#   recall      = 0.8575\n",
    "#   f1          = 0.8738\n",
    "# Epoch 4 validation:\n",
    "#   val_loss    = 0.4221\n",
    "#   accuracy    = 0.8499\n",
    "#   precision   = 0.8175\n",
    "#   recall      = 0.7718\n",
    "#   f1          = 0.7914\n",
    "# New best model (f1=0.7914) saved.\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   train_loss  = 0.2058\n",
    "#   accuracy    = 0.9299\n",
    "#   precision   = 0.9085\n",
    "#   recall      = 0.9060\n",
    "#   f1          = 0.9066\n",
    "\n",
    "# Epoch 5 validation:\n",
    "#   val_loss    = 0.4409\n",
    "#   accuracy    = 0.8463\n",
    "#   precision   = 0.7998\n",
    "#   recall      = 0.7894\n",
    "#   f1          = 0.7935\n",
    "# New best model (f1=0.7935) saved.\n",
    "\n",
    "# Loaded best model with f1=0.7935\n",
    "# Final eval_results: {'accuracy': 0.8404384193827517, 'precision': 0.7916469260389406, 'recall': 0.7848264806284927, 'f1': 0.786880109334091, 'loss': 0.4544476669185496}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946d83a",
   "metadata": {},
   "source": [
    "## Transformer (Deberta-V3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657a561",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4996611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 15.0\n",
      "mean: 16.42866733323811\n",
      "95th percentile: 29.0\n",
      "99th percentile: 42.0\n",
      "max: 1126\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download everything from https://huggingface.co/microsoft/deberta-v3-base/tree/main\n",
    "model_name = \"./deberta\" # \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast=True, # DeBERTa fast tokenizer \n",
    "    local_files_only=True,\n",
    ")\n",
    "\n",
    "max_length = 64 # adjust based on the maximum input size?\n",
    "\n",
    "# 1. Tokenize directly\n",
    "train_encodings = tokenizer(\n",
    "    df[\"train\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    df[\"dev\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "test_encodings = tokenizer(\n",
    "    df[\"test\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "# 2. Build HF Datasets from encoded inputs + labels\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"train\"]['class_label_group_num'],\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": val_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": val_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"dev\"]['class_label_group_num'],\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"test\"]['class_label_group_num'],\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "# 3. Set format for PyTorch\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")\n",
    "\n",
    "# Check appropriate token size\n",
    "tmp_train = tokenizer(df[\"train\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n",
    "lens_train = [len(ids) for ids in tmp_train[\"input_ids\"]]\n",
    "\n",
    "tmp_dev = tokenizer(df[\"dev\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n",
    "lens_dev = [len(ids) for ids in tmp_dev[\"input_ids\"]]\n",
    "\n",
    "lengths = lens_train + lens_dev\n",
    "\n",
    "print(\"median:\", np.median(lengths))\n",
    "print(\"mean:\", np.mean(lengths))\n",
    "print(\"95th percentile:\", np.percentile(lengths, 95))\n",
    "print(\"99th percentile:\", np.percentile(lengths, 99))\n",
    "print(\"max:\", np.max(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058da24c-3882-4647-81db-49bda443f998",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ba95a9-9135-42dc-945e-d7ceb7abad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class TrainMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, train_dataset, val_dataset):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.trainer = None\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.trainer is None:\n",
    "            return control\n",
    "\n",
    "        epoch = state.epoch\n",
    "\n",
    "        # --- train metrics ---\n",
    "        train_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.train_dataset,\n",
    "            metric_key_prefix=\"train\",  # train_accuracy, train_f1, ...\n",
    "        )\n",
    "\n",
    "        # --- validation metrics ---\n",
    "        val_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.val_dataset,\n",
    "            metric_key_prefix=\"eval\",   # eval_accuracy, eval_f1, ...\n",
    "        )\n",
    "\n",
    "        val_acc  = val_metrics.get(\"eval_accuracy\")\n",
    "        val_prec = val_metrics.get(\"eval_precision\")\n",
    "        val_rec  = val_metrics.get(\"eval_recall\")\n",
    "        val_f1   = val_metrics.get(\"eval_f1\")\n",
    "\n",
    "        train_acc  = train_metrics.get(\"train_accuracy\")\n",
    "        train_prec = train_metrics.get(\"train_precision\")\n",
    "        train_rec  = train_metrics.get(\"train_recall\")\n",
    "        train_f1   = train_metrics.get(\"train_f1\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[EPOCH {epoch:.0f}]\")\n",
    "        if train_acc is not None:\n",
    "            print(f\"[train] acc={train_acc:.4f}, prec={train_prec:.4f}, rec={train_rec:.4f}, f1={train_f1:.4f}\")\n",
    "        if val_acc is not None:\n",
    "            print(f\"[valid] acc={val_acc:.4f}, prec={val_prec:.4f}, rec={val_rec:.4f}, f1={val_f1:.4f}\")\n",
    "        return control\n",
    "\n",
    "def train(epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\"):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"no\", # \"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epoch,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=False, # True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    train_callback = TrainMetricsCallback(\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        val_dataset=tokenized_datasets[\"validation\"],\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[train_callback],\n",
    "    )\n",
    "\n",
    "    train_callback.trainer = trainer\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "def load_and_test_eval(ckpt_dir = \"./deberta-v3-crisis/batchsize64/checkpoint-30548\"):\n",
    "    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\".\", # any\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    eval_trainer = Trainer(\n",
    "        model=model_ckpt,\n",
    "        args=eval_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    eval_results = eval_trainer.evaluate(\n",
    "        eval_dataset=tokenized_datasets[\"test\"],\n",
    "        metric_key_prefix=\"test\",\n",
    "    )\n",
    "    # {'test_loss': 0.4593863785266876, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8740698009806749, 'test_precision': 0.8326252068193959, 'test_recall': 0.8500324417218078, 'test_f1': 0.8369876991837396, 'test_runtime': 123.8232, 'test_samples_per_second': 139.998, 'test_steps_per_second': 2.189}\n",
    "    print(eval_results)\n",
    "    print(f\"test_loss = {eval_results['test_loss']}\")\n",
    "    print(f\"test_accuracy = {eval_results['test_accuracy']}\")\n",
    "    print(f\"test_precision = {eval_results['test_precision']}\")\n",
    "    print(f\"test_recall = {eval_results['test_recall']}\")\n",
    "    print(f\"test_f1 = {eval_results['test_f1']}\")\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fff49-1ba1-4642-a1b1-51f366e31e9c",
   "metadata": {},
   "source": [
    "#### learning_rate=2e-5, batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4692839d-ee61-4ebb-9999-7eb5b5fa21f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/2837947494.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50505' max='76370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50505/76370 11:58:42 < 6:08:05, 1.17 it/s, Epoch 6.61/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7637</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.438154</td>\n",
       "      <td>0.878713</td>\n",
       "      <td>0.838978</td>\n",
       "      <td>0.848959</td>\n",
       "      <td>0.840268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15274</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357016</td>\n",
       "      <td>0.891044</td>\n",
       "      <td>0.853015</td>\n",
       "      <td>0.857961</td>\n",
       "      <td>0.855069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22911</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.542490</td>\n",
       "      <td>0.893510</td>\n",
       "      <td>0.857933</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.857463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30548</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.478209</td>\n",
       "      <td>0.887905</td>\n",
       "      <td>0.848656</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>0.851310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38185</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.670134</td>\n",
       "      <td>0.885999</td>\n",
       "      <td>0.849009</td>\n",
       "      <td>0.845102</td>\n",
       "      <td>0.846945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45822</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.671519</td>\n",
       "      <td>0.888017</td>\n",
       "      <td>0.847992</td>\n",
       "      <td>0.854826</td>\n",
       "      <td>0.851258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.9054, prec=0.8719, rec=0.8880, f1=0.8770\n",
      "[valid] acc=0.8787, prec=0.8390, rec=0.8490, f1=0.8403\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9380, prec=0.9154, rec=0.9203, f1=0.9176\n",
      "[valid] acc=0.8910, prec=0.8530, rec=0.8580, f1=0.8551\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9611, prec=0.9465, rec=0.9496, f1=0.9480\n",
      "[valid] acc=0.8935, prec=0.8579, rec=0.8575, f1=0.8575\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9740, prec=0.9634, rec=0.9674, f1=0.9654\n",
      "[valid] acc=0.8879, prec=0.8487, rec=0.8541, f1=0.8513\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9843, prec=0.9790, rec=0.9786, f1=0.9788\n",
      "[valid] acc=0.8860, prec=0.8490, rec=0.8451, f1=0.8469\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9898, prec=0.9853, rec=0.9868, f1=0.9861\n",
      "[valid] acc=0.8880, prec=0.8480, rec=0.8548, f1=0.8513\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 104\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     93\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     94\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    100\u001b[0m )\n\u001b[1;32m    102\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=10, learning_rate=2e-5, batch_size=8, output_dir=\"./deberta-v3-crisis/batchsize8\")\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.9054, prec=0.8719, rec=0.8880, f1=0.8770\n",
    "# [valid] acc=0.8787, prec=0.8390, rec=0.8490, f1=0.8403\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9380, prec=0.9154, rec=0.9203, f1=0.9176\n",
    "# [valid] acc=0.8910, prec=0.8530, rec=0.8580, f1=0.8551\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9611, prec=0.9465, rec=0.9496, f1=0.9480\n",
    "# [valid] acc=0.8935, prec=0.8579, rec=0.8575, f1=0.8575\n",
    "# ============================= OVERFITTING =====================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9740, prec=0.9634, rec=0.9674, f1=0.9654\n",
    "# [valid] acc=0.8879, prec=0.8487, rec=0.8541, f1=0.8513\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9843, prec=0.9790, rec=0.9786, f1=0.9788\n",
    "# [valid] acc=0.8860, prec=0.8490, rec=0.8451, f1=0.8469\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9898, prec=0.9853, rec=0.9868, f1=0.9861\n",
    "# [valid] acc=0.8880, prec=0.8480, rec=0.8548, f1=0.8513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0685b9f-94a6-49ba-9847-d5d27c436e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.37746426463127136, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8849149120276897, 'test_precision': 0.8430869630919547, 'test_recall': 0.8545599129431753, 'test_f1': 0.8482132493443325, 'test_runtime': 125.0236, 'test_samples_per_second': 138.654, 'test_steps_per_second': 2.168}\n",
      "test_loss = 0.37746426463127136\n",
      "test_accuracy = 0.8849149120276897\n",
      "test_precision = 0.8430869630919547\n",
      "test_recall = 0.8545599129431753\n",
      "test_f1 = 0.8482132493443325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 125.0976, 'test_samples_per_second': 138.572, 'test_steps_per_second': 2.166}\n",
      "test_loss = 0.577634871006012\n",
      "test_accuracy = 0.8872800692241131\n",
      "test_precision = 0.8469312572131958\n",
      "test_recall = 0.855374024799894\n",
      "test_f1 = 0.8507208362474484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.49717429280281067, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8831843092010384, 'test_precision': 0.8392270903901514, 'test_recall': 0.8564725619023125, 'test_f1': 0.8473071372190685, 'test_runtime': 125.1699, 'test_samples_per_second': 138.492, 'test_steps_per_second': 2.165}\n",
      "test_loss = 0.49717429280281067\n",
      "test_accuracy = 0.8831843092010384\n",
      "test_precision = 0.8392270903901514\n",
      "test_recall = 0.8564725619023125\n",
      "test_f1 = 0.8473071372190685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.6949165463447571, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8830689356792616, 'test_precision': 0.842145954123632, 'test_recall': 0.8472896061789302, 'test_f1': 0.8445861775113469, 'test_runtime': 128.6307, 'test_samples_per_second': 134.766, 'test_steps_per_second': 2.107}\n",
      "test_loss = 0.6949165463447571\n",
      "test_accuracy = 0.8830689356792616\n",
      "test_precision = 0.842145954123632\n",
      "test_recall = 0.8472896061789302\n",
      "test_f1 = 0.8445861775113469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.715135395526886, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8819728872223824, 'test_precision': 0.836460218016704, 'test_recall': 0.8544100282915196, 'test_f1': 0.8450040779020537, 'test_runtime': 125.2994, 'test_samples_per_second': 138.349, 'test_steps_per_second': 2.163}\n",
      "test_loss = 0.715135395526886\n",
      "test_accuracy = 0.8819728872223824\n",
      "test_precision = 0.836460218016704\n",
      "test_recall = 0.8544100282915196\n",
      "test_f1 = 0.8450040779020537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.715135395526886,\n",
       " 'test_model_preparation_time': 0.0013,\n",
       " 'test_accuracy': 0.8819728872223824,\n",
       " 'test_precision': 0.836460218016704,\n",
       " 'test_recall': 0.8544100282915196,\n",
       " 'test_f1': 0.8450040779020537,\n",
       " 'test_runtime': 125.2994,\n",
       " 'test_samples_per_second': 138.349,\n",
       " 'test_steps_per_second': 2.163}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-7637\")\n",
    "# {'test_loss': 0.4593863785266876, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8740698009806749, 'test_precision': 0.8326252068193959, 'test_recall': 0.8500324417218078, 'test_f1': 0.8369876991837396, 'test_runtime': 123.8232, 'test_samples_per_second': 139.998, 'test_steps_per_second': 2.189}\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-15274\")\n",
    "# {'test_loss': 0.37746426463127136, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8849149120276897, 'test_precision': 0.8430869630919547, 'test_recall': 0.8545599129431753, 'test_f1': 0.8482132493443325, 'test_runtime': 125.0236, 'test_samples_per_second': 138.654, 'test_steps_per_second': 2.168}\n",
    "# test_loss = 0.37746426463127136\n",
    "# test_accuracy = 0.8849149120276897\n",
    "# test_precision = 0.8430869630919547\n",
    "# test_recall = 0.8545599129431753\n",
    "# test_f1 = 0.8482132493443325\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-22911\")\n",
    "# {'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 125.0976, 'test_samples_per_second': 138.572, 'test_steps_per_second': 2.166}\n",
    "# test_loss = 0.577634871006012\n",
    "# test_accuracy = 0.8872800692241131\n",
    "# test_precision = 0.8469312572131958\n",
    "# test_recall = 0.855374024799894\n",
    "# test_f1 = 0.8507208362474484\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-30548\")\n",
    "# {'test_loss': 0.49717429280281067, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8831843092010384, 'test_precision': 0.8392270903901514, 'test_recall': 0.8564725619023125, 'test_f1': 0.8473071372190685, 'test_runtime': 125.1699, 'test_samples_per_second': 138.492, 'test_steps_per_second': 2.165}\n",
    "# test_loss = 0.49717429280281067\n",
    "# test_accuracy = 0.8831843092010384\n",
    "# test_precision = 0.8392270903901514\n",
    "# test_recall = 0.8564725619023125\n",
    "# test_f1 = 0.8473071372190685\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-38185\")\n",
    "# {'test_loss': 0.6949165463447571, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8830689356792616, 'test_precision': 0.842145954123632, 'test_recall': 0.8472896061789302, 'test_f1': 0.8445861775113469, 'test_runtime': 128.6307, 'test_samples_per_second': 134.766, 'test_steps_per_second': 2.107}\n",
    "# test_loss = 0.6949165463447571\n",
    "# test_accuracy = 0.8830689356792616\n",
    "# test_precision = 0.842145954123632\n",
    "# test_recall = 0.8472896061789302\n",
    "# test_f1 = 0.8445861775113469\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-45822\")\n",
    "# {'test_loss': 0.715135395526886, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8819728872223824, 'test_precision': 0.836460218016704, 'test_recall': 0.8544100282915196, 'test_f1': 0.8450040779020537, 'test_runtime': 125.2994, 'test_samples_per_second': 138.349, 'test_steps_per_second': 2.163}\n",
    "# test_loss = 0.715135395526886\n",
    "# test_accuracy = 0.8819728872223824\n",
    "# test_precision = 0.836460218016704\n",
    "# test_recall = 0.8544100282915196\n",
    "# test_f1 = 0.8450040779020537"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8386e4f-958e-4525-a9cd-4de5c00f85e5",
   "metadata": {},
   "source": [
    "#### learning_rate=2e-5, batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0cb55-a32f-4106-a411-de4b135e84fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/2837947494.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='19095' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  135/19095 01:11 < 2:49:47, 1.86 it/s, Epoch 0.04/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = train(epoch=5, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ab5e3-0e5d-4942-bc60-b7f9bf723604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a809155e-ab79-411a-a178-8a504ee294af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_95996/312600777.py:44: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38236' max='76370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38236/76370 4:44:25 < 4:43:40, 2.24 it/s, Epoch 5.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341084</td>\n",
       "      <td>0.901881</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.888816</td>\n",
       "      <td>0.873895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.218777</td>\n",
       "      <td>0.935504</td>\n",
       "      <td>0.909765</td>\n",
       "      <td>0.919633</td>\n",
       "      <td>0.913919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.164746</td>\n",
       "      <td>0.959142</td>\n",
       "      <td>0.939431</td>\n",
       "      <td>0.952655</td>\n",
       "      <td>0.945791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.973907</td>\n",
       "      <td>0.963635</td>\n",
       "      <td>0.966295</td>\n",
       "      <td>0.964884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.087381</td>\n",
       "      <td>0.982927</td>\n",
       "      <td>0.976098</td>\n",
       "      <td>0.977472</td>\n",
       "      <td>0.976734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[60], line 56\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     45\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     46\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 56\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=10, learning_rate=2e-5, batch_size=8, output_dir=\"./deberta-v3-crisis/2\")\n",
    "eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(eval_results)\n",
    "\n",
    " # [38186/76370 4:35:02 < 4:35:02, 2.31 it/s, Epoch 5/10]\n",
    "# Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# 1\tNo log\t0.341084\t0.901881\t0.866828\t0.888816\t0.873895\n",
    "# 2\tNo log\t0.218777\t0.935504\t0.909765\t0.919633\t0.913919\n",
    "# 3\tNo log\t0.164746\t0.959142\t0.939431\t0.952655\t0.945791\n",
    "# 4\tNo log\t0.109434\t0.973907\t0.963635\t0.966295\t0.964884\n",
    "# 5\tNo log\t0.087381\t0.982927\t0.976098\t0.977472\t0.976734\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73ddf31d-8048-40dc-8c6b-a97d893d5872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/281152571.py:115: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='276' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 276/2710 10:21 < 1:31:57, 0.44 it/s, Epoch 1.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319999</td>\n",
       "      <td>0.888491</td>\n",
       "      <td>0.851906</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.849046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.8885, prec=0.8519, rec=0.8495, f1=0.8490\n",
      "[valid] acc=0.8709, prec=0.8351, rec=0.8190, f1=0.8247\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(eval_results)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 127\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    115\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    116\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    117\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 127\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4020\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   4019\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4020\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4022\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   4023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4024\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4025\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   4026\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4110\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4108\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   4109\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 4110\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   4112\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   4113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1102\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1102\u001b[0m     label_index \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=10, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/batchsize64\")\n",
    "# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# print(eval_results)\n",
    "\n",
    "#  [ 272/2710 07:04 < 1:03:52, 0.64 it/s, Epoch 1/10]\n",
    "# Step\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# 271\tNo log\t0.360962\t0.870866\t0.835089\t0.818979\t0.824688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a2faa6-fd37-4f29-ad7a-6a952b848fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/3149821493.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1014' max='9550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1014/9550 1:00:22 < 8:29:14, 0.28 it/s, Epoch 1.06/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262881</td>\n",
       "      <td>0.903174</td>\n",
       "      <td>0.863936</td>\n",
       "      <td>0.888640</td>\n",
       "      <td>0.874394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "  [train] acc=0.9032, prec=0.8639, rec=0.8886, f1=0.8744  (n=None)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[12], line 120\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    108\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    109\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    110\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 120\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=10, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/batchsize64_1\")\n",
    "eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(eval_results)\n",
    "#  [1014/9550 1:00:22 < 8:29:14, 0.28 it/s, Epoch 1.06/10]\n",
    "# Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# 1\tNo log\t0.262881\t0.903174\t0.863936\t0.888640\t0.874394\n",
    "\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "#   [train] acc=0.9032, prec=0.8639, rec=0.8886, f1=0.8744  (n=None)\n",
    "\n",
    "# Batch size can't be as high as 256?\n",
    "# RuntimeError: MPS backend out of memory (MPS allocated: 27.10 GB, other allocations: 832.00 KB, max allowed: 27.20 GB). Tried to allocate 375.29 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5675a2b6-2ca4-4ccf-a66a-1a82c8139042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class TrainMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, train_dataset):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.trainer = None\n",
    "        self.last_eval_metrics = None\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        if any(k.startswith(\"eval_\") for k in metrics.keys()):\n",
    "            self.last_eval_metrics = metrics\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.trainer is None:\n",
    "            return control\n",
    "\n",
    "        train_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.train_dataset,\n",
    "            metric_key_prefix=\"train\", # train_accuracy, train_f1, ...\n",
    "        )\n",
    "\n",
    "        epoch = state.epoch\n",
    "        train_acc = train_metrics.get(\"train_accuracy\", None)\n",
    "        train_f1  = train_metrics.get(\"train_f1\", None)\n",
    "\n",
    "        val_acc = None\n",
    "        val_f1  = None\n",
    "        if self.last_eval_metrics is not None:\n",
    "            val_acc = self.last_eval_metrics.get(\"eval_accuracy\", None)\n",
    "            val_f1  = self.last_eval_metrics.get(\"eval_f1\", None)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[EPOCH {epoch:.0f}]\")\n",
    "        if train_acc is not None and train_f1 is not None:\n",
    "            print(f\"  train_acc = {train_acc:.4f}, train_f1 = {train_f1:.4f}\")\n",
    "        if val_acc is not None and val_f1 is not None:\n",
    "            print(f\"  val_acc   = {val_acc:.4f}, val_f1   = {val_f1:.4f}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        return control\n",
    "\n",
    "\n",
    "def train(epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\"):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epoch,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    train_callback = TrainMetricsCallback(tokenized_datasets[\"train\"])\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[train_callback],\n",
    "    )\n",
    "\n",
    "    train_callback.trainer = trainer\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7e8d34-f563-4067-8dae-d3726081c67f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/2795326635.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2716' max='2865' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2716/2865 1:24:08 < 04:37, 0.54 it/s, Epoch 2.84/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265105</td>\n",
       "      <td>0.901373</td>\n",
       "      <td>0.860023</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.873302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.204079</td>\n",
       "      <td>0.928432</td>\n",
       "      <td>0.897973</td>\n",
       "      <td>0.917152</td>\n",
       "      <td>0.907176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "  train_acc = 0.9014, train_f1 = 0.8733\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "  train_acc = 0.9284, train_f1 = 0.9072\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/test2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[10], line 87\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     75\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     76\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     77\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 87\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=3, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/test2\")\n",
    "eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(eval_results)\n",
    "\n",
    "# Batch size can't be as high as 256?\n",
    "# RuntimeError: MPS backend out of memory (MPS allocated: 27.10 GB, other allocations: 832.00 KB, max allowed: 27.20 GB). Tried to allocate 375.29 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc0f71a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_84643/3190309381.py:41: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7802' max='11457' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7802/11457 1:12:17 < 33:52, 1.80 it/s, Epoch 2.04/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.322661</td>\n",
       "      <td>0.888241</td>\n",
       "      <td>0.851410</td>\n",
       "      <td>0.855949</td>\n",
       "      <td>0.852308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.300615</td>\n",
       "      <td>0.893398</td>\n",
       "      <td>0.853491</td>\n",
       "      <td>0.866558</td>\n",
       "      <td>0.859771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 50\u001b[0m\n\u001b[1;32m     26\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     27\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./deberta-v3-crisis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     42\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     43\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\")\n",
    "\n",
    "# Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall  \tF1\n",
    "# 1\t    0.311500\t    0.322661\t    0.888241\t0.851410\t0.855949\t0.852308\n",
    "# 2\t    0.239700\t    0.300615\t    0.893398\t0.853491\t0.866558\t0.859771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09147530-f5a5-4c5a-8a5f-e8d56169444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c2942-0c4a-430e-889f-c765fa6daab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V6E1",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
