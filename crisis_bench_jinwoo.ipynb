{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a9ab23-f031-44a3-88cd-4d08f1f6381c",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ec020-a4bb-430f-b561-1f0367e5f486",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7346fe-d763-4501-9a45-1c4c7a9ab363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <473B02F4-48EA-3880-8B82-14AA228F6939> /Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0869bbce-6ad5-4929-9439-c2f4bc6249f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "generator = torch.Generator()\n",
    "_ = generator.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f2506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_strs = ['time_critical', 'support_and_relief', 'non_informative']\n",
    "label2id = {label: i for i, label in enumerate(all_label_strs)}\n",
    "id2label = {i: label for label, i in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83365a1-379c-4bc6-bbcc-eb8ca273209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./data/crisisbench/preprocessed_data_train.csv\n",
      "Loading: ./data/crisisbench/preprocessed_data_dev.csv\n",
      "Loading: ./data/crisisbench/preprocessed_data_test.csv\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    df = {}\n",
    "    for d in ['train', 'dev', 'test']:\n",
    "        output_path = f\"./data/crisisbench/preprocessed_data_{d}.csv\"\n",
    "        df[d] = pd.read_csv(output_path).loc[:, ['text', 'class_label_group', 'class_label_group_num']]\n",
    "        print(\"Loading:\", output_path)\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43775508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: N=61089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approximately km long firebreaks have been con...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>god bless you</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cracked wine casks damaged historical building...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i m really just excited for new undies and pin...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rescue effort e ands in india pakistan as floo...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class_label_group  \\\n",
       "0  approximately km long firebreaks have been con...     time_critical   \n",
       "1                                      god bless you   non_informative   \n",
       "2  cracked wine casks damaged historical building...     time_critical   \n",
       "3  i m really just excited for new undies and pin...   non_informative   \n",
       "4  rescue effort e ands in india pakistan as floo...     time_critical   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      0  \n",
       "1                      2  \n",
       "2                      0  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_train: N={len(df['train'])}\")\n",
    "df['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ce818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dev: N=8921\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>congrats to all my liverpool supporting fans f...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collapsed buildings in mexico city earthquake ...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>here s your flower</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ready for a relaxing weekend but have too much...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public private information portal developed to...</td>\n",
       "      <td>support_and_relief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   class_label_group  \\\n",
       "0  congrats to all my liverpool supporting fans f...     non_informative   \n",
       "1  collapsed buildings in mexico city earthquake ...       time_critical   \n",
       "2                                 here s your flower     non_informative   \n",
       "3  ready for a relaxing weekend but have too much...     non_informative   \n",
       "4  public private information portal developed to...  support_and_relief   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      2  \n",
       "1                      0  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_dev: N={len(df['dev'])}\")\n",
    "df['dev'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d208947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test: N=17335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staff at our feeding centre say chronic malnou...</td>\n",
       "      <td>support_and_relief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you comin down for the summer semesters right</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yea it s upstate i m like a few hours away</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teach every pakistani that it is not enough to...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stay with for live cvg as typhoon hagupit slam...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   class_label_group  \\\n",
       "0  staff at our feeding centre say chronic malnou...  support_and_relief   \n",
       "1      you comin down for the summer semesters right     non_informative   \n",
       "2         yea it s upstate i m like a few hours away     non_informative   \n",
       "3  teach every pakistani that it is not enough to...     non_informative   \n",
       "4  stay with for live cvg as typhoon hagupit slam...       time_critical   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      1  \n",
       "1                      2  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_test: N={len(df['test'])}\")\n",
    "df['test'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a053846-ee59-4798-875c-cb482edaeb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total N =87345\n"
     ]
    }
   ],
   "source": [
    "print(f\"total N ={len(df['train']) + len(df['dev']) + len(df['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d27fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ea0a0",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a00974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8566f4e",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defa4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "MAX_SEQ_LEN = 64 # depends on tweet length\n",
    "EMBED_DIM = 50\n",
    "FILTER_SIZES = (3, 4, 5)\n",
    "NUM_FILTERS = 100\n",
    "DROPOUT = 0.5 # tune\n",
    "BATCH_SIZE = 64 # tune \n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 10\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "GLOVE_PATH = \"./data/crisisbench/glove_word_embeddings.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb1266",
   "metadata": {},
   "source": [
    "### Tokenizer and Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf53496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits on whitespace\n",
    "    \"\"\"\n",
    "    return text.strip().split()\n",
    "\n",
    "def build_vocab(\n",
    "    texts: List[str],\n",
    "    max_size: int,\n",
    "    min_freq: int = 1\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Build a word -> index vocab from training texts.\n",
    "    Reserves index 0 for PAD and 1 for UNK.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = simple_tokenize(text)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
    "    for word, freq in counter.most_common():\n",
    "        if freq < min_freq:\n",
    "            continue\n",
    "        if len(vocab) >= max_size:\n",
    "            break\n",
    "        vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def encode_text(\n",
    "    text: str,\n",
    "    vocab: Dict[str, int],\n",
    "    max_len: int\n",
    ") -> List[int]:\n",
    "    tokens = simple_tokenize(text)\n",
    "    ids = [vocab.get(tok, vocab[UNK_TOKEN]) for tok in tokens][:max_len]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [vocab[PAD_TOKEN]] * (max_len - len(ids))\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81ae81",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95f7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: List[int],\n",
    "        vocab: Dict[str, int],\n",
    "        max_len: int,\n",
    "    ):\n",
    "        assert len(texts) == len(labels)\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        input_ids = encode_text(text, self.vocab, self.max_len)\n",
    "        return torch.tensor(input_ids, dtype=torch.long), label\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_texts: List[str],\n",
    "    train_labels: List[int],\n",
    "    val_texts: List[str],\n",
    "    val_labels: List[int],\n",
    "    max_vocab_size: int,\n",
    "    max_seq_len: int,\n",
    "    batch_size: int,\n",
    ") -> Tuple[DataLoader, DataLoader, Dict[str, int], int]:\n",
    "    vocab = build_vocab(train_texts, max_vocab_size)\n",
    "    num_classes = len(set(train_labels))\n",
    "\n",
    "    train_dataset = TextDataset(train_texts, train_labels, vocab, max_seq_len)\n",
    "    val_dataset = TextDataset(val_texts, val_labels, vocab, max_seq_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, vocab, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d02775",
   "metadata": {},
   "source": [
    "### Load GloVe & build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1645084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(\n",
    "    glove_path: str,\n",
    "    embed_dim: int,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Load GloVe file into a dict: word -> vector (torch.Tensor).\n",
    "    Expects each line: word val1 val2 ... valD\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != embed_dim + 1:\n",
    "                # ignore malformed lines\n",
    "                continue\n",
    "            word = parts[0]\n",
    "            vec = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float32)\n",
    "            embeddings[word] = vec\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def build_embedding_matrix(\n",
    "    vocab: Dict[str, int],\n",
    "    glove_embeddings: Dict[str, torch.Tensor],\n",
    "    embed_dim: int,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create an embedding matrix of shape [vocab_size, embed_dim]\n",
    "    where row i is the vector for the word with index i.\n",
    "    Words not found in GloVe are randomly initialized (small normal).\n",
    "    \"\"\"\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_matrix = torch.empty(vocab_size, embed_dim, dtype=torch.float32)\n",
    "\n",
    "    # Initialize OOV embeddings to small random values\n",
    "    torch.nn.init.normal_(embedding_matrix, mean=0.0, std=0.05)\n",
    "\n",
    "    # Set PAD embedding to zeros\n",
    "    pad_idx = vocab[PAD_TOKEN]\n",
    "    embedding_matrix[pad_idx] = torch.zeros(embed_dim, dtype=torch.float32)\n",
    "\n",
    "    oov_count = 0\n",
    "    for word, idx in vocab.items():\n",
    "        if word in (PAD_TOKEN, UNK_TOKEN):\n",
    "            continue\n",
    "        vec = glove_embeddings.get(word)\n",
    "        if vec is not None:\n",
    "            embedding_matrix[idx] = vec\n",
    "        else:\n",
    "            oov_count += 1\n",
    "\n",
    "    print(f\"GloVe OOV words: {oov_count}/{vocab_size}\")\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60863f21",
   "metadata": {},
   "source": [
    "### Text CNN model (with optional pretrained embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f94c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        num_classes: int,\n",
    "        pad_idx: int = 0,\n",
    "        num_filters: int = 100,\n",
    "        filter_sizes: Tuple[int, ...] = (3, 4, 5),\n",
    "        dropout: float = 0.5,\n",
    "        pretrained_embeddings: torch.Tensor | None = None,\n",
    "        freeze_embeddings: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embed_dim,\n",
    "            padding_idx=pad_idx,\n",
    "        )\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            if pretrained_embeddings.shape != (vocab_size, embed_dim):\n",
    "                raise ValueError(\n",
    "                    f\"Pretrained embeddings shape {pretrained_embeddings.shape} \"\n",
    "                    f\"does not match (vocab_size, embed_dim)=({vocab_size}, {embed_dim})\"\n",
    "                )\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "            if freeze_embeddings:\n",
    "                self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=embed_dim,\n",
    "                out_channels=num_filters,\n",
    "                kernel_size=fs,\n",
    "            )\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        embedded = self.embedding(input_ids)          # [B, L, D]\n",
    "        embedded = embedded.transpose(1, 2)           # [B, D, L]\n",
    "\n",
    "        conv_outputs = []\n",
    "        for conv in self.convs:\n",
    "            x = conv(embedded)                        # [B, F, L']\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool1d(x, x.size(2)).squeeze(2) # [B, F]\n",
    "            conv_outputs.append(x)\n",
    "\n",
    "        cat = torch.cat(conv_outputs, dim=1)          # [B, F * len(filter_sizes)]\n",
    "        cat = self.dropout(cat)\n",
    "        logits = self.fc(cat)                         # [B, num_classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93543e0d",
   "metadata": {},
   "source": [
    "### Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1baee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for input_ids, labels in dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * input_ids.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(input_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67776a78",
   "metadata": {},
   "source": [
    "### Main CNN Train Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99044bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 20000, Num classes: 3\n",
      "Loading GloVe embeddings...\n",
      "GloVe OOV words: 882/20000\n",
      "Epoch 01 | Train Loss: 0.4595, Train Acc: 0.8258 | Val Loss: 0.3805, Val Acc: 0.8552\n",
      "Epoch 02 | Train Loss: 0.3572, Train Acc: 0.8675 | Val Loss: 0.3513, Val Acc: 0.8696\n",
      "Epoch 03 | Train Loss: 0.3088, Train Acc: 0.8865 | Val Loss: 0.3488, Val Acc: 0.8734\n",
      "Epoch 04 | Train Loss: 0.2718, Train Acc: 0.9027 | Val Loss: 0.3552, Val Acc: 0.8731\n",
      "Epoch 05 | Train Loss: 0.2348, Train Acc: 0.9148 | Val Loss: 0.3815, Val Acc: 0.8666\n",
      "Epoch 06 | Train Loss: 0.2045, Train Acc: 0.9268 | Val Loss: 0.3986, Val Acc: 0.8658\n",
      "Epoch 07 | Train Loss: 0.1774, Train Acc: 0.9370 | Val Loss: 0.4382, Val Acc: 0.8646\n",
      "Epoch 08 | Train Loss: 0.1547, Train Acc: 0.9453 | Val Loss: 0.4868, Val Acc: 0.8606\n",
      "Epoch 09 | Train Loss: 0.1365, Train Acc: 0.9517 | Val Loss: 0.5132, Val Acc: 0.8562\n",
      "Epoch 10 | Train Loss: 0.1208, Train Acc: 0.9579 | Val Loss: 0.5814, Val Acc: 0.8569\n",
      "Best validation accuracy: 0.8734\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_df = df['train'].dropna(subset=['text'])\n",
    "train_texts = train_df['text'].tolist()\n",
    "train_label_strs = train_df['class_label_group']\n",
    "\n",
    "val_df = df['dev'].dropna(subset=['text'])\n",
    "val_texts = val_df['text'].tolist()\n",
    "val_label_strs = val_df['class_label_group']\n",
    "\n",
    "all_label_strs = sorted(set(train_label_strs) | set(val_label_strs))\n",
    "label2id = {label: i for i, label in enumerate(all_label_strs)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "train_labels = [label2id[l] for l in train_label_strs]\n",
    "val_labels   = [label2id[l] for l in val_label_strs]\n",
    "# Create loaders and vocab\n",
    "train_loader, val_loader, vocab, num_classes = create_dataloaders(\n",
    "    train_texts=train_texts,\n",
    "    train_labels=train_labels,\n",
    "    val_texts=val_texts,\n",
    "    val_labels=val_labels,\n",
    "    max_vocab_size=MAX_VOCAB_SIZE,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "print(f\"Vocab size: {len(vocab)}, Num classes: {num_classes}\")\n",
    "\n",
    "# Load GloVe embeddings\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "glove_embeds = load_glove_embeddings(GLOVE_PATH, EMBED_DIM)\n",
    "embedding_matrix = build_embedding_matrix(vocab, glove_embeds, EMBED_DIM)\n",
    "\n",
    "# Initialize model with pretrained embeddings\n",
    "print(\"Model Initialization...\")\n",
    "model = TextCNN(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_classes=num_classes,\n",
    "    pad_idx=vocab[PAD_TOKEN],\n",
    "    num_filters=NUM_FILTERS,\n",
    "    filter_sizes=FILTER_SIZES,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_embeddings=embedding_matrix,\n",
    "    freeze_embeddings=False,   # set True if you want to freeze GloVe\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0.0\n",
    "print(\"Training...\")\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "    val_loss, val_acc = evaluate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_textcnn_glove.pt\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b973a",
   "metadata": {},
   "source": [
    "### Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1fdb0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics:\n",
      "accuracy: 0.8734\n",
      "precision: 0.8467\n",
      "recall: 0.8108\n",
      "f1: 0.8272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Helper to get predictions + labels from a DataLoader\n",
    "def get_all_preds_and_labels(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(input_ids)          # [B, num_classes]\n",
    "            preds = logits.argmax(dim=1)      # [B]\n",
    "\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# compute accuracy, precision, recall, F1 (macro)\n",
    "def compute_classification_metrics(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "    average: str = \"macro\",   # \"macro\", \"micro\", or \"weighted\"\n",
    "):\n",
    "    preds, labels = get_all_preds_and_labels(model, dataloader, device)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=average,\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_textcnn_glove.pt\", map_location=device))\n",
    "\n",
    "# For validation metrics\n",
    "val_metrics = compute_classification_metrics(model, val_loader, device, average=\"macro\")\n",
    "print(\"Validation metrics:\")\n",
    "for k, v in val_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051a548-63f6-4e96-8f3d-fed56f14f42e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b22bed-3c0a-4439-a1a8-7090fa815932",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "032841ea-0f01-437d-aff7-2e43f2d574f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        num_labels = 3,\n",
    "        max_length = 64,\n",
    "        d_model = 256, # hidden size\n",
    "        nhead = 4, # number of attention heads\n",
    "        num_layers = 4, # number of encoder layers\n",
    "        dim_feedforward = 512,  # FFN inner dim\n",
    "        dropout = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Embedding(max_length, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True, # (batch, seq, dim)\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, num_labels),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch_size, seq_len = input_ids.size()\n",
    "        if seq_len > self.max_length:\n",
    "            raise ValueError(f\"seq_len {seq_len} > max_length {self.max_length}\")\n",
    "\n",
    "        token_emb = self.token_embedding(input_ids)  # (B, L, D)\n",
    "\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)  # (1, L)\n",
    "        pos_emb = self.pos_embedding(positions)  # (1, L, D)\n",
    "\n",
    "        x = token_emb + pos_emb  # (B, L, D)\n",
    "\n",
    "        src_key_padding_mask = (attention_mask == 0)  # (B, L), bool\n",
    "\n",
    "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)  # (B, L, D)\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        mask = attention_mask.unsqueeze(-1)  # (B, L, 1)\n",
    "        masked_x = x * mask  # (B, L, D)\n",
    "\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)  # (B, 1)\n",
    "        pooled = masked_x.sum(dim=1) / lengths  # (B, D)\n",
    "\n",
    "        logits = self.classifier(pooled)  # (B, num_labels)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a35066bf-4d49-4551-b3d0-562a55e3f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_preds(all_logits, all_labels):\n",
    "    logits = np.concatenate(all_logits, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc4272-73e0-47e6-a9ea-1a4763bdc1e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "795519ff-4e33-408a-9759-503266752b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_texts = df[\"train\"][\"text\"].tolist()\n",
    "dev_texts   = df[\"dev\"][\"text\"].tolist()\n",
    "test_texts   = df[\"test\"][\"text\"].tolist()\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=30000, # could be adjusted\n",
    "    min_frequency=2,\n",
    "    special_tokens=special_tokens,\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(train_texts, trainer=trainer)\n",
    "\n",
    "max_length = 64\n",
    "pad_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "tokenizer.enable_truncation(max_length=max_length)\n",
    "tokenizer.enable_padding(\n",
    "    length=max_length,\n",
    "    pad_id=pad_id,\n",
    "    pad_token=\"[PAD]\",\n",
    ")\n",
    "\n",
    "def encode_batch(texts):\n",
    "    encodings = tokenizer.encode_batch(texts)\n",
    "    input_ids = [e.ids for e in encodings]\n",
    "    attention_mask = [e.attention_mask for e in encodings]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "train_enc = encode_batch(train_texts)\n",
    "dev_enc   = encode_batch(dev_texts)\n",
    "test_enc   = encode_batch(test_texts)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      train_enc[\"input_ids\"],\n",
    "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"train\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      dev_enc[\"input_ids\"],\n",
    "    \"attention_mask\": dev_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"dev\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      test_enc[\"input_ids\"],\n",
    "    \"attention_mask\": test_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"test\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829ec10-0fca-4019-a3c1-f1e129e0f0ad",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b20bfc4-260d-4557-9450-51fa9d8bcd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluate\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            all_logits.append(logits.detach().cpu().numpy())\n",
    "            all_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(data_loader)\n",
    "    metrics = compute_metrics_from_preds(all_logits, all_labels)\n",
    "    metrics[\"loss\"] = val_loss\n",
    "    return metrics\n",
    "    \n",
    "def train(\n",
    "        d_model=256,\n",
    "        nhead=4,\n",
    "        num_layers=4,\n",
    "        dim_feedforward=512,\n",
    "        dropout=0.1,\n",
    "        lr=1e-4,\n",
    "        batch_size = 32,\n",
    "        weight_decay=0.01,\n",
    "        last_epoch=0,\n",
    "        max_epochs=3,\n",
    "        save_path=\"./transformers/best_transformer_1.pt\"\n",
    "    ):\n",
    "    num_labels = len(label2id)\n",
    "    vocab_size = tokenizer.get_vocab_size()\n",
    "    max_length = 64\n",
    "    \n",
    "    model = TransformerClassifier(\n",
    "        vocab_size=vocab_size,\n",
    "        num_labels=num_labels,\n",
    "        max_length=max_length,\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_layers=num_layers,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        dropout=dropout,\n",
    "    ).to(device)\n",
    "    \n",
    "    # AdamW + weight decay\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        tokenized_datasets[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        tokenized_datasets[\"validation\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        tokenized_datasets[\"test\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        state = torch.load(save_path, map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "    else: # not os.path.exists(save_path) or last_epoch > 0:\n",
    "        logging_steps = 50\n",
    "        best_f1 = 0.0\n",
    "        best_state_dict = None\n",
    "        global_step = 0\n",
    "        \n",
    "        for epoch in range(last_epoch, max_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "        \n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs} [train]\")\n",
    "            for batch in pbar:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(logits, labels)\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                total_loss += loss.item()\n",
    "                global_step += 1\n",
    "        \n",
    "                if global_step % logging_steps == 0:\n",
    "                    avg_loss = total_loss / logging_steps\n",
    "                    pbar.set_postfix({\"loss\": f\"{avg_loss:.4f}\"})\n",
    "                    total_loss = 0.0\n",
    "    \n",
    "            # print performance every epoch\n",
    "            train_metrics = evaluate_model(model, train_loader)\n",
    "            val_metrics   = evaluate_model(model, val_loader)\n",
    "\n",
    "            print(f\"Epoch {epoch+1} train: train_loss  = {train_metrics['loss']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: accuracy    = {train_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: precision   = {train_metrics['precision']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: recall      = {train_metrics['recall']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: f1          = {train_metrics['f1']:.4f}\")\n",
    "\n",
    "            print(f\"Epoch {epoch+1} validation: val_loss    = {val_metrics['loss']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: accuracy    = {val_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: precision   = {val_metrics['precision']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: recall      = {val_metrics['recall']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: f1          = {val_metrics['f1']:.4f}\")\n",
    "\n",
    "            # save best model (highest f1)\n",
    "            if val_metrics[\"f1\"] > best_f1:\n",
    "                best_f1 = val_metrics[\"f1\"]\n",
    "                best_state_dict = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "                torch.save(best_state_dict, save_path)\n",
    "                print(f\"New best model (f1={best_f1:.4f}) saved.\\n\")\n",
    "            \n",
    "        # load best model\n",
    "        if best_state_dict is not None:\n",
    "            model.load_state_dict(best_state_dict)\n",
    "            print(f\"Loaded best model with f1={best_f1:.4f}\")\n",
    "    return model, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e763b1-3338-486c-9aa7-41615300b3de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "272f765d-dbea-4fe1-97cd-d7242e1499f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d98e0fa93940e5be2a9f443d3f67de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8400346120565331, 'precision': 0.7853384733927123, 'recall': 0.791181843157427, 'f1': 0.7880170998346174, 'loss': 0.4298086559805483}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=10, save_path=\"./transformers/best_transformer_1_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   f1          = 0.7790\n",
    "# Epoch 1 validation:\n",
    "#   f1          = 0.7610\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   f1          = 0.8281\n",
    "# Epoch 2 validation:\n",
    "#   f1          = 0.7858\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   f1          = 0.8610\n",
    "# Epoch 3 validation:\n",
    "#   f1          = 0.7978\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   f1          = 0.8896\n",
    "# Epoch 4 validation:\n",
    "#   f1          = 0.8002\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8400346120565331, 'precision': 0.7853384733927123, 'recall': 0.791181843157427, 'f1': 0.7880170998346174, 'loss': 0.4298086559805483}\n",
    "#### Overfitting ######\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   f1          = 0.9136\n",
    "# Epoch 5 validation:\n",
    "#   f1          = 0.7984\n",
    "\n",
    "# Epoch 6 train:\n",
    "#   f1          = 0.9454\n",
    "# Epoch 6 validation:\n",
    "#   f1          = 0.7911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7bf33-240d-48d6-8db9-4a3afe262ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.4335\n",
    "#   accuracy    = 0.8384\n",
    "#   precision   = 0.8024\n",
    "#   recall      = 0.7603\n",
    "#   f1          = 0.7790\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.4582\n",
    "#   accuracy    = 0.8268\n",
    "#   precision   = 0.7841\n",
    "#   recall      = 0.7429\n",
    "#   f1          = 0.7610\n",
    "# New best model (f1=0.7610) saved.\n",
    "\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   train_loss  = 0.3628\n",
    "#   accuracy    = 0.8716\n",
    "#   precision   = 0.8343\n",
    "#   recall      = 0.8230\n",
    "#   f1          = 0.8281\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss    = 0.4280\n",
    "#   accuracy    = 0.8413\n",
    "#   precision   = 0.7921\n",
    "#   recall      = 0.7802\n",
    "#   f1          = 0.7858\n",
    "# New best model (f1=0.7858) saved.\n",
    "\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   train_loss  = 0.2929\n",
    "#   accuracy    = 0.8966\n",
    "#   precision   = 0.8722\n",
    "#   recall      = 0.8507\n",
    "#   f1          = 0.8610\n",
    "\n",
    "# Epoch 3 validation:\n",
    "#   val_loss    = 0.4102\n",
    "#   accuracy    = 0.8530\n",
    "#   precision   = 0.8135\n",
    "#   recall      = 0.7843\n",
    "#   f1          = 0.7978\n",
    "# New best model (f1=0.7978) saved.\n",
    "\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   train_loss  = 0.2442\n",
    "#   accuracy    = 0.9165\n",
    "#   precision   = 0.8866\n",
    "#   recall      = 0.8927\n",
    "#   f1          = 0.8896\n",
    "\n",
    "# Epoch 4 validation:\n",
    "#   val_loss    = 0.4170\n",
    "#   accuracy    = 0.8504\n",
    "#   precision   = 0.8002\n",
    "#   recall      = 0.8006\n",
    "#   f1          = 0.8002\n",
    "# New best model (f1=0.8002) saved.\n",
    "\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   train_loss  = 0.1945\n",
    "#   accuracy    = 0.9336\n",
    "#   precision   = 0.9034\n",
    "#   recall      = 0.9247\n",
    "#   f1          = 0.9136\n",
    "\n",
    "# Epoch 5 validation:\n",
    "#   val_loss    = 0.4526\n",
    "#   accuracy    = 0.8463\n",
    "#   precision   = 0.7909\n",
    "#   recall      = 0.8072\n",
    "#   f1          = 0.7984\n",
    "\n",
    "\n",
    "# Epoch 6 train:\n",
    "#   train_loss  = 0.1474\n",
    "#   accuracy    = 0.9585\n",
    "#   precision   = 0.9492\n",
    "#   recall      = 0.9417\n",
    "#   f1          = 0.9454\n",
    "\n",
    "# Epoch 6 validation:\n",
    "#   val_loss    = 0.4453\n",
    "#   accuracy    = 0.8478\n",
    "#   precision   = 0.8033\n",
    "#   recall      = 0.7803\n",
    "#   f1          = 0.7911\n",
    "\n",
    "\n",
    "# Epoch 7 train:\n",
    "#   train_loss  = 0.1082\n",
    "#   accuracy    = 0.9660\n",
    "#   precision   = 0.9628\n",
    "#   recall      = 0.9469\n",
    "#   f1          = 0.9543\n",
    "\n",
    "# Epoch 7 validation:\n",
    "#   val_loss    = 0.5228\n",
    "#   accuracy    = 0.8459\n",
    "#   precision   = 0.8061\n",
    "#   recall      = 0.7696\n",
    "#   f1          = 0.7849\n",
    "\n",
    "\n",
    "# Epoch 8 train:\n",
    "#   train_loss  = 0.0803\n",
    "#   accuracy    = 0.9758\n",
    "#   precision   = 0.9719\n",
    "#   recall      = 0.9637\n",
    "#   f1          = 0.9677\n",
    "\n",
    "# Epoch 8 validation:\n",
    "#   val_loss    = 0.5808\n",
    "#   accuracy    = 0.8446\n",
    "#   precision   = 0.8029\n",
    "#   recall      = 0.7728\n",
    "#   f1          = 0.7867"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7f725-7ea2-4f1d-96de-d680ac9b89b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbce5ab7-1dbf-4d74-9614-8781b96abd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6387aeb920ac4325a3e90082e3a8502a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30fcbf12aa642c18e2fccb89d23dde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c5d60ced0b47b3b39cf220134b19bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train: train_loss  = 0.5130\n",
      "Epoch 1 train: accuracy    = 0.8026\n",
      "Epoch 1 train: precision   = 0.7595\n",
      "Epoch 1 train: recall      = 0.7103\n",
      "Epoch 1 train: f1          = 0.7275\n",
      "Epoch 1 validation: val_loss    = 0.5323\n",
      "Epoch 1 validation: accuracy    = 0.7972\n",
      "Epoch 1 validation: precision   = 0.7488\n",
      "Epoch 1 validation: recall      = 0.7015\n",
      "Epoch 1 validation: f1          = 0.7189\n",
      "New best model (f1=0.7189) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e066ce449c574414800673366d03c803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3311fcbb2f05407abde1f88f7ad59b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37425a67e685433eae554efae36bd166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train: train_loss  = 0.4540\n",
      "Epoch 2 train: accuracy    = 0.8300\n",
      "Epoch 2 train: precision   = 0.7967\n",
      "Epoch 2 train: recall      = 0.7502\n",
      "Epoch 2 train: f1          = 0.7626\n",
      "Epoch 2 validation: val_loss    = 0.4897\n",
      "Epoch 2 validation: accuracy    = 0.8115\n",
      "Epoch 2 validation: precision   = 0.7644\n",
      "Epoch 2 validation: recall      = 0.7226\n",
      "Epoch 2 validation: f1          = 0.7331\n",
      "New best model (f1=0.7331) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184693d561a94aedb386395c82b7777d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b828be4032e45b9b26f6cc168d03373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aeb1acd54a4990bea5af2c8d1a384b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train: train_loss  = 0.3880\n",
      "Epoch 3 train: accuracy    = 0.8566\n",
      "Epoch 3 train: precision   = 0.8315\n",
      "Epoch 3 train: recall      = 0.7796\n",
      "Epoch 3 train: f1          = 0.8023\n",
      "Epoch 3 validation: val_loss    = 0.4413\n",
      "Epoch 3 validation: accuracy    = 0.8349\n",
      "Epoch 3 validation: precision   = 0.8002\n",
      "Epoch 3 validation: recall      = 0.7471\n",
      "Epoch 3 validation: f1          = 0.7700\n",
      "New best model (f1=0.7700) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64d880b025d4ec8867455d763d629d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc3911432114d40a6eedd5c3477dd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64214bcc38f64804bc459b179b8321a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train: train_loss  = 0.3526\n",
      "Epoch 4 train: accuracy    = 0.8742\n",
      "Epoch 4 train: precision   = 0.8360\n",
      "Epoch 4 train: recall      = 0.8275\n",
      "Epoch 4 train: f1          = 0.8314\n",
      "Epoch 4 validation: val_loss    = 0.4302\n",
      "Epoch 4 validation: accuracy    = 0.8385\n",
      "Epoch 4 validation: precision   = 0.7880\n",
      "Epoch 4 validation: recall      = 0.7778\n",
      "Epoch 4 validation: f1          = 0.7824\n",
      "New best model (f1=0.7824) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da61e4ae3d54b87a29074bb13d66ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3a5688b2574c51beab9d8ed0fed221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d06bc2b234cbc9625af237518a784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train: train_loss  = 0.3248\n",
      "Epoch 5 train: accuracy    = 0.8821\n",
      "Epoch 5 train: precision   = 0.8390\n",
      "Epoch 5 train: recall      = 0.8512\n",
      "Epoch 5 train: f1          = 0.8446\n",
      "Epoch 5 validation: val_loss    = 0.4381\n",
      "Epoch 5 validation: accuracy    = 0.8349\n",
      "Epoch 5 validation: precision   = 0.7781\n",
      "Epoch 5 validation: recall      = 0.7863\n",
      "Epoch 5 validation: f1          = 0.7815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5223c3290754a5283c10295557d3cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeea49fc1d946a8a693bd72ff6b9928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22adda1d841942529b3f8bfac7934000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train: train_loss  = 0.3030\n",
      "Epoch 6 train: accuracy    = 0.8875\n",
      "Epoch 6 train: precision   = 0.8918\n",
      "Epoch 6 train: recall      = 0.8104\n",
      "Epoch 6 train: f1          = 0.8443\n",
      "Epoch 6 validation: val_loss    = 0.4422\n",
      "Epoch 6 validation: accuracy    = 0.8413\n",
      "Epoch 6 validation: precision   = 0.8258\n",
      "Epoch 6 validation: recall      = 0.7434\n",
      "Epoch 6 validation: f1          = 0.7765\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559cef063ba04efcb52ef89af38a04df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623f25210a0847289437c5b956819c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c999f62300c453180149d8e606351ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train: train_loss  = 0.2480\n",
      "Epoch 7 train: accuracy    = 0.9143\n",
      "Epoch 7 train: precision   = 0.9079\n",
      "Epoch 7 train: recall      = 0.8629\n",
      "Epoch 7 train: f1          = 0.8830\n",
      "Epoch 7 validation: val_loss    = 0.4434\n",
      "Epoch 7 validation: accuracy    = 0.8452\n",
      "Epoch 7 validation: precision   = 0.8135\n",
      "Epoch 7 validation: recall      = 0.7608\n",
      "Epoch 7 validation: f1          = 0.7835\n",
      "New best model (f1=0.7835) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724be301a5e14ce5a557ee36fe4e129e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9dc6f57f8a4ca1a1232037ac2777d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116e803f27294a2bb75c9f1d90cb4612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train: train_loss  = 0.2141\n",
      "Epoch 8 train: accuracy    = 0.9270\n",
      "Epoch 8 train: precision   = 0.9154\n",
      "Epoch 8 train: recall      = 0.8900\n",
      "Epoch 8 train: f1          = 0.9017\n",
      "Epoch 8 validation: val_loss    = 0.4528\n",
      "Epoch 8 validation: accuracy    = 0.8452\n",
      "Epoch 8 validation: precision   = 0.8071\n",
      "Epoch 8 validation: recall      = 0.7687\n",
      "Epoch 8 validation: f1          = 0.7856\n",
      "New best model (f1=0.7856) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afff0f572edb47449088cb0fa1e38b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae9d9a7ff5541458812e04c70ac947d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdccdcb663447fbb7962ef837252941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train: train_loss  = 0.1827\n",
      "Epoch 9 train: accuracy    = 0.9407\n",
      "Epoch 9 train: precision   = 0.9337\n",
      "Epoch 9 train: recall      = 0.9081\n",
      "Epoch 9 train: f1          = 0.9199\n",
      "Epoch 9 validation: val_loss    = 0.4592\n",
      "Epoch 9 validation: accuracy    = 0.8447\n",
      "Epoch 9 validation: precision   = 0.8086\n",
      "Epoch 9 validation: recall      = 0.7655\n",
      "Epoch 9 validation: f1          = 0.7844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd38f4d07034d57be814c13f753f27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65903f1c2bc14f51b5cc222826cbe91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/_monitor.py\", line 84, in run\n",
      "    instance.refresh(nolock=True)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/std.py\", line 1347, in refresh\n",
      "    self.display()\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/notebook.py\", line 171, in display\n",
      "    rtext.value = right\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 716, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 706, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 1513, in _notify_trait\n",
      "    self.notify_change(\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 700, in notify_change\n",
      "    self.send_state(key=name)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 586, in send_state\n",
      "    self._send(msg, buffers=buffers)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 825, in _send\n",
      "    self.comm.send(data=msg, buffers=buffers)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/comm/base_comm.py\", line 144, in send\n",
      "    self.publish_msg(\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipykernel/comm/comm.py\", line 42, in publish_msg\n",
      "    parent=self.kernel.get_parent(),\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 797, in get_parent\n",
      "    return self._shell_parent.get()\n",
      "LookupError: <ContextVar name='shell_parent' at 0x1213bd300>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bb4bb7df8043668b65a10cd43afe99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train: train_loss  = 0.1740\n",
      "Epoch 10 train: accuracy    = 0.9423\n",
      "Epoch 10 train: precision   = 0.9192\n",
      "Epoch 10 train: recall      = 0.9270\n",
      "Epoch 10 train: f1          = 0.9217\n",
      "Epoch 10 validation: val_loss    = 0.4961\n",
      "Epoch 10 validation: accuracy    = 0.8335\n",
      "Epoch 10 validation: precision   = 0.7845\n",
      "Epoch 10 validation: recall      = 0.7833\n",
      "Epoch 10 validation: f1          = 0.7799\n",
      "Loaded best model with f1=0.7856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43871e160fe448968b8fa7049a788252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/2167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=10, save_path=\"./transformers/best_transformer_2_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 8 validation: f1          = 0.7856\n",
    "# Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb4d3f-9d18-4709-8a1e-3c03c6a57422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train: train_loss  = 0.5130\n",
    "# Epoch 1 train: accuracy    = 0.8026\n",
    "# Epoch 1 train: precision   = 0.7595\n",
    "# Epoch 1 train: recall      = 0.7103\n",
    "# Epoch 1 train: f1          = 0.7275\n",
    "# Epoch 1 validation: val_loss    = 0.5323\n",
    "# Epoch 1 validation: accuracy    = 0.7972\n",
    "# Epoch 1 validation: precision   = 0.7488\n",
    "# Epoch 1 validation: recall      = 0.7015\n",
    "# Epoch 1 validation: f1          = 0.7189\n",
    "# New best model (f1=0.7189) saved.\n",
    "\n",
    "# Epoch 2 train: train_loss  = 0.4540\n",
    "# Epoch 2 train: accuracy    = 0.8300\n",
    "# Epoch 2 train: precision   = 0.7967\n",
    "# Epoch 2 train: recall      = 0.7502\n",
    "# Epoch 2 train: f1          = 0.7626\n",
    "# Epoch 2 validation: val_loss    = 0.4897\n",
    "# Epoch 2 validation: accuracy    = 0.8115\n",
    "# Epoch 2 validation: precision   = 0.7644\n",
    "# Epoch 2 validation: recall      = 0.7226\n",
    "# Epoch 2 validation: f1          = 0.7331\n",
    "# New best model (f1=0.7331) saved.\n",
    "\n",
    "# Epoch 3 train: train_loss  = 0.3880\n",
    "# Epoch 3 train: accuracy    = 0.8566\n",
    "# Epoch 3 train: precision   = 0.8315\n",
    "# Epoch 3 train: recall      = 0.7796\n",
    "# Epoch 3 train: f1          = 0.8023\n",
    "# Epoch 3 validation: val_loss    = 0.4413\n",
    "# Epoch 3 validation: accuracy    = 0.8349\n",
    "# Epoch 3 validation: precision   = 0.8002\n",
    "# Epoch 3 validation: recall      = 0.7471\n",
    "# Epoch 3 validation: f1          = 0.7700\n",
    "# New best model (f1=0.7700) saved.\n",
    "\n",
    "# Epoch 4 train: train_loss  = 0.3526\n",
    "# Epoch 4 train: accuracy    = 0.8742\n",
    "# Epoch 4 train: precision   = 0.8360\n",
    "# Epoch 4 train: recall      = 0.8275\n",
    "# Epoch 4 train: f1          = 0.8314\n",
    "# Epoch 4 validation: val_loss    = 0.4302\n",
    "# Epoch 4 validation: accuracy    = 0.8385\n",
    "# Epoch 4 validation: precision   = 0.7880\n",
    "# Epoch 4 validation: recall      = 0.7778\n",
    "# Epoch 4 validation: f1          = 0.7824\n",
    "# New best model (f1=0.7824) saved.\n",
    "\n",
    "# Epoch 5 train: train_loss  = 0.3248\n",
    "# Epoch 5 train: accuracy    = 0.8821\n",
    "# Epoch 5 train: precision   = 0.8390\n",
    "# Epoch 5 train: recall      = 0.8512\n",
    "# Epoch 5 train: f1          = 0.8446\n",
    "# Epoch 5 validation: val_loss    = 0.4381\n",
    "# Epoch 5 validation: accuracy    = 0.8349\n",
    "# Epoch 5 validation: precision   = 0.7781\n",
    "# Epoch 5 validation: recall      = 0.7863\n",
    "# Epoch 5 validation: f1          = 0.7815\n",
    "\n",
    "# Epoch 6 train: train_loss  = 0.3030\n",
    "# Epoch 6 train: accuracy    = 0.8875\n",
    "# Epoch 6 train: precision   = 0.8918\n",
    "# Epoch 6 train: recall      = 0.8104\n",
    "# Epoch 6 train: f1          = 0.8443\n",
    "# Epoch 6 validation: val_loss    = 0.4422\n",
    "# Epoch 6 validation: accuracy    = 0.8413\n",
    "# Epoch 6 validation: precision   = 0.8258\n",
    "# Epoch 6 validation: recall      = 0.7434\n",
    "# Epoch 6 validation: f1          = 0.7765\n",
    "\n",
    "# Epoch 7 train: train_loss  = 0.2480\n",
    "# Epoch 7 train: accuracy    = 0.9143\n",
    "# Epoch 7 train: precision   = 0.9079\n",
    "# Epoch 7 train: recall      = 0.8629\n",
    "# Epoch 7 train: f1          = 0.8830\n",
    "# Epoch 7 validation: val_loss    = 0.4434\n",
    "# Epoch 7 validation: accuracy    = 0.8452\n",
    "# Epoch 7 validation: precision   = 0.8135\n",
    "# Epoch 7 validation: recall      = 0.7608\n",
    "# Epoch 7 validation: f1          = 0.7835\n",
    "# New best model (f1=0.7835) saved.\n",
    "\n",
    "# Epoch 8 train: train_loss  = 0.2141\n",
    "# Epoch 8 train: accuracy    = 0.9270\n",
    "# Epoch 8 train: precision   = 0.9154\n",
    "# Epoch 8 train: recall      = 0.8900\n",
    "# Epoch 8 train: f1          = 0.9017\n",
    "# Epoch 8 validation: val_loss    = 0.4528\n",
    "# Epoch 8 validation: accuracy    = 0.8452\n",
    "# Epoch 8 validation: precision   = 0.8071\n",
    "# Epoch 8 validation: recall      = 0.7687\n",
    "# Epoch 8 validation: f1          = 0.7856\n",
    "# New best model (f1=0.7856) saved.\n",
    "\n",
    "# Epoch 9 train: train_loss  = 0.1827\n",
    "# Epoch 9 train: accuracy    = 0.9407\n",
    "# Epoch 9 train: precision   = 0.9337\n",
    "# Epoch 9 train: recall      = 0.9081\n",
    "# Epoch 9 train: f1          = 0.9199\n",
    "# Epoch 9 validation: val_loss    = 0.4592\n",
    "# Epoch 9 validation: accuracy    = 0.8447\n",
    "# Epoch 9 validation: precision   = 0.8086\n",
    "# Epoch 9 validation: recall      = 0.7655\n",
    "# Epoch 9 validation: f1          = 0.7844\n",
    "\n",
    "# Epoch 10 train: train_loss  = 0.1740\n",
    "# Epoch 10 train: accuracy    = 0.9423\n",
    "# Epoch 10 train: precision   = 0.9192\n",
    "# Epoch 10 train: recall      = 0.9270\n",
    "# Epoch 10 train: f1          = 0.9217\n",
    "# Epoch 10 validation: val_loss    = 0.4961\n",
    "# Epoch 10 validation: accuracy    = 0.8335\n",
    "# Epoch 10 validation: precision   = 0.7845\n",
    "# Epoch 10 validation: recall      = 0.7833\n",
    "# Epoch 10 validation: f1          = 0.7799\n",
    "# Loaded best model with f1=0.7856\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1560ac-d830-4f9c-af1d-831caf614038",
   "metadata": {},
   "source": [
    "#### best_transformer_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24663986-5fc7-4f11-80da-72e2cd2bf2eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dcec888c204373805b33c5da8e4322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b79733d05242c78a921989b618d2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9673dbd6727466e9b23e93abe353ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train: train_loss  = 0.5427\n",
      "Epoch 1 train: accuracy    = 0.7908\n",
      "Epoch 1 train: precision   = 0.7750\n",
      "Epoch 1 train: recall      = 0.6531\n",
      "Epoch 1 train: f1          = 0.6932\n",
      "Epoch 1 validation: val_loss    = 0.5459\n",
      "Epoch 1 validation: accuracy    = 0.7876\n",
      "Epoch 1 validation: precision   = 0.7631\n",
      "Epoch 1 validation: recall      = 0.6470\n",
      "Epoch 1 validation: f1          = 0.6848\n",
      "New best model (f1=0.6848) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7679b127de24816a5b21969deb4cfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966d23eda40478e81fd1f0a59fcc6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d34ff15530e422ea044aaac3a7708dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train: train_loss  = 0.4633\n",
      "Epoch 2 train: accuracy    = 0.8244\n",
      "Epoch 2 train: precision   = 0.7907\n",
      "Epoch 2 train: recall      = 0.7311\n",
      "Epoch 2 train: f1          = 0.7563\n",
      "Epoch 2 validation: val_loss    = 0.4769\n",
      "Epoch 2 validation: accuracy    = 0.8165\n",
      "Epoch 2 validation: precision   = 0.7775\n",
      "Epoch 2 validation: recall      = 0.7193\n",
      "Epoch 2 validation: f1          = 0.7439\n",
      "New best model (f1=0.7439) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4973df55f1ff450e8d0518450f24d542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b59e7fbdcb422fbf97f42710936b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f98cc7e0db4db2b596b955f0bb27bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train: train_loss  = 0.4280\n",
      "Epoch 3 train: accuracy    = 0.8397\n",
      "Epoch 3 train: precision   = 0.8104\n",
      "Epoch 3 train: recall      = 0.7568\n",
      "Epoch 3 train: f1          = 0.7788\n",
      "Epoch 3 validation: val_loss    = 0.4552\n",
      "Epoch 3 validation: accuracy    = 0.8291\n",
      "Epoch 3 validation: precision   = 0.7945\n",
      "Epoch 3 validation: recall      = 0.7392\n",
      "Epoch 3 validation: f1          = 0.7618\n",
      "New best model (f1=0.7618) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8845fe7273419a82255ff6ee3a6e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c5b3b2ea7c4c3bac9cc13c25ae1eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5668e50faf485e8f961f2586b7968b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train: train_loss  = 0.3918\n",
      "Epoch 4 train: accuracy    = 0.8547\n",
      "Epoch 4 train: precision   = 0.8102\n",
      "Epoch 4 train: recall      = 0.8011\n",
      "Epoch 4 train: f1          = 0.8055\n",
      "Epoch 4 validation: val_loss    = 0.4373\n",
      "Epoch 4 validation: accuracy    = 0.8350\n",
      "Epoch 4 validation: precision   = 0.7836\n",
      "Epoch 4 validation: recall      = 0.7700\n",
      "Epoch 4 validation: f1          = 0.7765\n",
      "New best model (f1=0.7765) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3caa513ff394c98ab10707aebbdeca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0630c5085f640bd8817aaca144c54ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76486ece0c5544609f40906206daf6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train: train_loss  = 0.3623\n",
      "Epoch 5 train: accuracy    = 0.8659\n",
      "Epoch 5 train: precision   = 0.8320\n",
      "Epoch 5 train: recall      = 0.8071\n",
      "Epoch 5 train: f1          = 0.8181\n",
      "Epoch 5 validation: val_loss    = 0.4230\n",
      "Epoch 5 validation: accuracy    = 0.8440\n",
      "Epoch 5 validation: precision   = 0.8027\n",
      "Epoch 5 validation: recall      = 0.7758\n",
      "Epoch 5 validation: f1          = 0.7876\n",
      "New best model (f1=0.7876) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fc70599a0c4b149c1e62515bcb5534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09b993453a14cb893900bb3ff4357d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b434f477b90493fbe16f8bbd2d79dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train: train_loss  = 0.3344\n",
      "Epoch 6 train: accuracy    = 0.8765\n",
      "Epoch 6 train: precision   = 0.8492\n",
      "Epoch 6 train: recall      = 0.8171\n",
      "Epoch 6 train: f1          = 0.8308\n",
      "Epoch 6 validation: val_loss    = 0.4085\n",
      "Epoch 6 validation: accuracy    = 0.8468\n",
      "Epoch 6 validation: precision   = 0.8068\n",
      "Epoch 6 validation: recall      = 0.7739\n",
      "Epoch 6 validation: f1          = 0.7877\n",
      "New best model (f1=0.7877) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f36b5afae5b4e6eb05ff3965396a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6f3944d55840c7b93b7858ac96cde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d9d0a42bdb4d9eb0cb3aec2ca6ede9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train: train_loss  = 0.3135\n",
      "Epoch 7 train: accuracy    = 0.8857\n",
      "Epoch 7 train: precision   = 0.8603\n",
      "Epoch 7 train: recall      = 0.8300\n",
      "Epoch 7 train: f1          = 0.8441\n",
      "Epoch 7 validation: val_loss    = 0.4137\n",
      "Epoch 7 validation: accuracy    = 0.8537\n",
      "Epoch 7 validation: precision   = 0.8199\n",
      "Epoch 7 validation: recall      = 0.7828\n",
      "Epoch 7 validation: f1          = 0.7996\n",
      "New best model (f1=0.7996) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2611e5fcc334e2eb2acaa9d451f6b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cf0f15021c44bca172a665a8052d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6c9db5cf3a43cfbad6e6a0f291e73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train: train_loss  = 0.2867\n",
      "Epoch 8 train: accuracy    = 0.8962\n",
      "Epoch 8 train: precision   = 0.8761\n",
      "Epoch 8 train: recall      = 0.8443\n",
      "Epoch 8 train: f1          = 0.8590\n",
      "Epoch 8 validation: val_loss    = 0.4044\n",
      "Epoch 8 validation: accuracy    = 0.8523\n",
      "Epoch 8 validation: precision   = 0.8169\n",
      "Epoch 8 validation: recall      = 0.7792\n",
      "Epoch 8 validation: f1          = 0.7963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0f41640fe14cf3a4b114606102e77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0cbea3b34d4711a0478f17f8bbdf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab07d8b1202f4398b8707b7247f5e975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train: train_loss  = 0.2706\n",
      "Epoch 9 train: accuracy    = 0.9026\n",
      "Epoch 9 train: precision   = 0.8843\n",
      "Epoch 9 train: recall      = 0.8545\n",
      "Epoch 9 train: f1          = 0.8674\n",
      "Epoch 9 validation: val_loss    = 0.4110\n",
      "Epoch 9 validation: accuracy    = 0.8528\n",
      "Epoch 9 validation: precision   = 0.8164\n",
      "Epoch 9 validation: recall      = 0.7832\n",
      "Epoch 9 validation: f1          = 0.7972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91da248a5a5c4796a99c15902bec8b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03141e05e69404aa19308077b45ae8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba195f8468c4aa9a1194a28b3b58d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train: train_loss  = 0.2498\n",
      "Epoch 10 train: accuracy    = 0.9113\n",
      "Epoch 10 train: precision   = 0.8779\n",
      "Epoch 10 train: recall      = 0.8867\n",
      "Epoch 10 train: f1          = 0.8822\n",
      "Epoch 10 validation: val_loss    = 0.4073\n",
      "Epoch 10 validation: accuracy    = 0.8541\n",
      "Epoch 10 validation: precision   = 0.8042\n",
      "Epoch 10 validation: recall      = 0.8063\n",
      "Epoch 10 validation: f1          = 0.8052\n",
      "New best model (f1=0.8052) saved.\n",
      "\n",
      "Loaded best model with f1=0.8052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7f2a4d27224028a9e6d6aa103a71d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/2167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8478223247764638, 'precision': 0.7947469165050163, 'recall': 0.803183331774572, 'f1': 0.7988119336768936, 'loss': 0.43349864214906286}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1 => 0.3\n",
    "model, test_loader = train(dropout=0.3, lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=10, save_path=\"./transformers/best_transformer_3.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 10 validation: f1          = 0.8052\n",
    "# Final eval_results: {'accuracy': 0.8478223247764638, 'precision': 0.7947469165050163, 'recall': 0.803183331774572, 'f1': 0.7988119336768936, 'loss': 0.43349864214906286}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2ed1bc9-3e1b-422a-a8c7-0034645c384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train: train_loss  = 0.5427\n",
    "# Epoch 1 train: accuracy    = 0.7908\n",
    "# Epoch 1 train: precision   = 0.7750\n",
    "# Epoch 1 train: recall      = 0.6531\n",
    "# Epoch 1 train: f1          = 0.6932\n",
    "# Epoch 1 validation: val_loss    = 0.5459\n",
    "# Epoch 1 validation: accuracy    = 0.7876\n",
    "# Epoch 1 validation: precision   = 0.7631\n",
    "# Epoch 1 validation: recall      = 0.6470\n",
    "# Epoch 1 validation: f1          = 0.6848\n",
    "# New best model (f1=0.6848) saved.\n",
    "\n",
    "# Epoch 2 train: train_loss  = 0.4633\n",
    "# Epoch 2 train: accuracy    = 0.8244\n",
    "# Epoch 2 train: precision   = 0.7907\n",
    "# Epoch 2 train: recall      = 0.7311\n",
    "# Epoch 2 train: f1          = 0.7563\n",
    "# Epoch 2 validation: val_loss    = 0.4769\n",
    "# Epoch 2 validation: accuracy    = 0.8165\n",
    "# Epoch 2 validation: precision   = 0.7775\n",
    "# Epoch 2 validation: recall      = 0.7193\n",
    "# Epoch 2 validation: f1          = 0.7439\n",
    "# New best model (f1=0.7439) saved.\n",
    "\n",
    "# Epoch 3 train: train_loss  = 0.4280\n",
    "# Epoch 3 train: accuracy    = 0.8397\n",
    "# Epoch 3 train: precision   = 0.8104\n",
    "# Epoch 3 train: recall      = 0.7568\n",
    "# Epoch 3 train: f1          = 0.7788\n",
    "# Epoch 3 validation: val_loss    = 0.4552\n",
    "# Epoch 3 validation: accuracy    = 0.8291\n",
    "# Epoch 3 validation: precision   = 0.7945\n",
    "# Epoch 3 validation: recall      = 0.7392\n",
    "# Epoch 3 validation: f1          = 0.7618\n",
    "# New best model (f1=0.7618) saved.\n",
    "\n",
    "# Epoch 4 train: train_loss  = 0.3918\n",
    "# Epoch 4 train: accuracy    = 0.8547\n",
    "# Epoch 4 train: precision   = 0.8102\n",
    "# Epoch 4 train: recall      = 0.8011\n",
    "# Epoch 4 train: f1          = 0.8055\n",
    "# Epoch 4 validation: val_loss    = 0.4373\n",
    "# Epoch 4 validation: accuracy    = 0.8350\n",
    "# Epoch 4 validation: precision   = 0.7836\n",
    "# Epoch 4 validation: recall      = 0.7700\n",
    "# Epoch 4 validation: f1          = 0.7765\n",
    "# New best model (f1=0.7765) saved.\n",
    "\n",
    "# Epoch 5 train: train_loss  = 0.3623\n",
    "# Epoch 5 train: accuracy    = 0.8659\n",
    "# Epoch 5 train: precision   = 0.8320\n",
    "# Epoch 5 train: recall      = 0.8071\n",
    "# Epoch 5 train: f1          = 0.8181\n",
    "# Epoch 5 validation: val_loss    = 0.4230\n",
    "# Epoch 5 validation: accuracy    = 0.8440\n",
    "# Epoch 5 validation: precision   = 0.8027\n",
    "# Epoch 5 validation: recall      = 0.7758\n",
    "# Epoch 5 validation: f1          = 0.7876\n",
    "# New best model (f1=0.7876) saved.\n",
    "\n",
    "# Epoch 6 train: train_loss  = 0.3344\n",
    "# Epoch 6 train: accuracy    = 0.8765\n",
    "# Epoch 6 train: precision   = 0.8492\n",
    "# Epoch 6 train: recall      = 0.8171\n",
    "# Epoch 6 train: f1          = 0.8308\n",
    "# Epoch 6 validation: val_loss    = 0.4085\n",
    "# Epoch 6 validation: accuracy    = 0.8468\n",
    "# Epoch 6 validation: precision   = 0.8068\n",
    "# Epoch 6 validation: recall      = 0.7739\n",
    "# Epoch 6 validation: f1          = 0.7877\n",
    "# New best model (f1=0.7877) saved.\n",
    "\n",
    "# Epoch 7 train: train_loss  = 0.3135\n",
    "# Epoch 7 train: accuracy    = 0.8857\n",
    "# Epoch 7 train: precision   = 0.8603\n",
    "# Epoch 7 train: recall      = 0.8300\n",
    "# Epoch 7 train: f1          = 0.8441\n",
    "# Epoch 7 validation: val_loss    = 0.4137\n",
    "# Epoch 7 validation: accuracy    = 0.8537\n",
    "# Epoch 7 validation: precision   = 0.8199\n",
    "# Epoch 7 validation: recall      = 0.7828\n",
    "# Epoch 7 validation: f1          = 0.7996\n",
    "# New best model (f1=0.7996) saved.\n",
    "\n",
    "# Epoch 8 train: train_loss  = 0.2867\n",
    "# Epoch 8 train: accuracy    = 0.8962\n",
    "# Epoch 8 train: precision   = 0.8761\n",
    "# Epoch 8 train: recall      = 0.8443\n",
    "# Epoch 8 train: f1          = 0.8590\n",
    "# Epoch 8 validation: val_loss    = 0.4044\n",
    "# Epoch 8 validation: accuracy    = 0.8523\n",
    "# Epoch 8 validation: precision   = 0.8169\n",
    "# Epoch 8 validation: recall      = 0.7792\n",
    "# Epoch 8 validation: f1          = 0.7963\n",
    "\n",
    "# Epoch 9 train: train_loss  = 0.2706\n",
    "# Epoch 9 train: accuracy    = 0.9026\n",
    "# Epoch 9 train: precision   = 0.8843\n",
    "# Epoch 9 train: recall      = 0.8545\n",
    "# Epoch 9 train: f1          = 0.8674\n",
    "# Epoch 9 validation: val_loss    = 0.4110\n",
    "# Epoch 9 validation: accuracy    = 0.8528\n",
    "# Epoch 9 validation: precision   = 0.8164\n",
    "# Epoch 9 validation: recall      = 0.7832\n",
    "# Epoch 9 validation: f1          = 0.7972\n",
    "\n",
    "# Epoch 10 train: train_loss  = 0.2498\n",
    "# Epoch 10 train: accuracy    = 0.9113\n",
    "# Epoch 10 train: precision   = 0.8779\n",
    "# Epoch 10 train: recall      = 0.8867\n",
    "# Epoch 10 train: f1          = 0.8822\n",
    "# Epoch 10 validation: val_loss    = 0.4073\n",
    "# Epoch 10 validation: accuracy    = 0.8541\n",
    "# Epoch 10 validation: precision   = 0.8042\n",
    "# Epoch 10 validation: recall      = 0.8063\n",
    "# Epoch 10 validation: f1          = 0.8052\n",
    "# New best model (f1=0.8052) saved.\n",
    "\n",
    "# Loaded best model with f1=0.8052"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa53ba-8be6-4d60-921e-10ff3e7bbe8e",
   "metadata": {},
   "source": [
    "#### best_transformer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2f534-6150-439d-accc-25d0c4a1cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=3, save_path=\"./transformers/best_transformer_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "# Epoch 1 validation:\n",
    "#   val_loss  = 0.4957\n",
    "#   accuracy  = 0.8108\n",
    "#   precision = 0.7511\n",
    "#   recall    = 0.7480\n",
    "#   f1        = 0.7490\n",
    "#    New best model (f1=0.7490) saved.\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss  = 0.4397\n",
    "#   accuracy  = 0.8314\n",
    "#   precision = 0.7872\n",
    "#   recall    = 0.7633\n",
    "#   f1        = 0.7724\n",
    "#    New best model (f1=0.7724) saved.\n",
    "\n",
    "# Epoch 3 validation:\n",
    "#   val_loss  = 0.4129\n",
    "#   accuracy  = 0.8471\n",
    "#   precision = 0.7982\n",
    "#   recall    = 0.7925\n",
    "#   f1        = 0.7945\n",
    "#    New best model (f1=0.7945) saved.\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8394577444476493, 'precision': 0.7870732957272955, 'recall': 0.7865639150630909, 'f1': 0.7861628773510826, 'loss': 0.4266800470237802}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ace50-196b-422f-9e85-e40009fa500c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef3f4c-320b-4c7d-98b4-17c43888ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=5, save_path=\"./transformers/best_transformer_2.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss  = 0.5102\n",
    "#   accuracy  = 0.8056\n",
    "#   precision = 0.7564\n",
    "#   recall    = 0.7051\n",
    "#   f1        = 0.7269\n",
    "#    New best model (f1=0.7269) saved.\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss  = 0.4723\n",
    "#   accuracy  = 0.8213\n",
    "#   precision = 0.7739\n",
    "#   recall    = 0.7437\n",
    "#   f1        = 0.7558\n",
    "#    New best model (f1=0.7558) saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441298a9-7661-4dc0-ba4c-3923cec091ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=128 <= 256,\n",
    "# nhead=4,\n",
    "# num_layers=2 <= 4,\n",
    "# dim_feedforward=256 <= 512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(d_model=128, num_layers=2, dim_feedforward=256, lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=5, save_path=\"./transformers/best_transformer_3.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.5239\n",
    "#   accuracy    = 0.7990\n",
    "#   precision   = 0.7548\n",
    "#   recall      = 0.6899\n",
    "#   f1          = 0.7164\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.5276\n",
    "#   accuracy    = 0.7989\n",
    "#   precision   = 0.7494\n",
    "#   recall      = 0.6869\n",
    "#   f1          = 0.7125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a847f2e-1488-4b64-bd40-61667954ba75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342536e4a5b24ad6b78c920010143482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98311f72cd524a31a772ecb616b9d684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bba808f4112402f9668d47a395fc166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 train:\n",
      "  train_loss  = 0.4597\n",
      "  accuracy    = 0.8261\n",
      "  precision   = 0.8127\n",
      "  recall      = 0.7218\n",
      "  f1          = 0.7500\n",
      "\n",
      "Epoch 1 validation:\n",
      "  val_loss    = 0.4887\n",
      "  accuracy    = 0.8144\n",
      "  precision   = 0.7946\n",
      "  recall      = 0.7015\n",
      "  f1          = 0.7282\n",
      "New best model (f1=0.7282) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e44998c7a544999de13a6c5c2b8803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe27b80e50b4a42b9223307effeab74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc508d999fc44a188ab6b0fc028c9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 train:\n",
      "  train_loss  = 0.3688\n",
      "  accuracy    = 0.8639\n",
      "  precision   = 0.8235\n",
      "  recall      = 0.8156\n",
      "  f1          = 0.8188\n",
      "\n",
      "Epoch 2 validation:\n",
      "  val_loss    = 0.4365\n",
      "  accuracy    = 0.8378\n",
      "  precision   = 0.7905\n",
      "  recall      = 0.7755\n",
      "  f1          = 0.7823\n",
      "New best model (f1=0.7823) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc435c3b73c54a2480d1ddbd09a03810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f3066eec8d4e7eaef5df3bc715ac22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee883b31d0fe41329319033100cdb61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 train:\n",
      "  train_loss  = 0.3202\n",
      "  accuracy    = 0.8813\n",
      "  precision   = 0.8689\n",
      "  recall      = 0.8117\n",
      "  f1          = 0.8369\n",
      "\n",
      "Epoch 3 validation:\n",
      "  val_loss    = 0.4392\n",
      "  accuracy    = 0.8396\n",
      "  precision   = 0.8122\n",
      "  recall      = 0.7477\n",
      "  f1          = 0.7750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f162af6c9c4c4f34864e9c4d4dab1009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae7b1dd2ad8479f8ea75bd9964a1505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823b20a43ac44949a5fd6ce1f32f5ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 train:\n",
      "  train_loss  = 0.2600\n",
      "  accuracy    = 0.9077\n",
      "  precision   = 0.8946\n",
      "  recall      = 0.8575\n",
      "  f1          = 0.8738\n",
      "\n",
      "Epoch 4 validation:\n",
      "  val_loss    = 0.4221\n",
      "  accuracy    = 0.8499\n",
      "  precision   = 0.8175\n",
      "  recall      = 0.7718\n",
      "  f1          = 0.7914\n",
      "New best model (f1=0.7914) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28479706ac794003b64acfdcc7d86f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11f4bc2e6e442dcaf3b19cd9cc7cbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818b5f0725e84440a7647ee9a48977e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 train:\n",
      "  train_loss  = 0.2058\n",
      "  accuracy    = 0.9299\n",
      "  precision   = 0.9085\n",
      "  recall      = 0.9060\n",
      "  f1          = 0.9066\n",
      "\n",
      "Epoch 5 validation:\n",
      "  val_loss    = 0.4409\n",
      "  accuracy    = 0.8463\n",
      "  precision   = 0.7998\n",
      "  recall      = 0.7894\n",
      "  f1          = 0.7935\n",
      "New best model (f1=0.7935) saved.\n",
      "\n",
      "Loaded best model with f1=0.7935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75067f72aa76493d84d75954fc3a2666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8404384193827517, 'precision': 0.7916469260389406, 'recall': 0.7848264806284927, 'f1': 0.786880109334091, 'loss': 0.4544476669185496}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=3 <= 4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(d_model=256, num_layers=3, dim_feedforward=512, lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=5, save_path=\"./transformers/best_transformer_4.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   f1          = 0.7500\n",
    "# Epoch 1 validation:\n",
    "#   f1          = 0.7282\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   f1          = 0.8188\n",
    "# Epoch 2 validation:\n",
    "#   f1          = 0.7823\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   f1          = 0.8369\n",
    "# Epoch 3 validation:\n",
    "#   f1          = 0.7750 <= first sign of overfitting\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   f1          = 0.8738 <= increasing\n",
    "# Epoch 4 validation:\n",
    "#   f1          = 0.7914\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   f1          = 0.9066 <= increasing\n",
    "# Epoch 5 validation:\n",
    "#   f1          = 0.7935 <= not increasing much. oscilating\n",
    "\n",
    "# test f1 = 0.786880109334091\n",
    "\n",
    "############################################\n",
    "############################################\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.4597\n",
    "#   accuracy    = 0.8261\n",
    "#   precision   = 0.8127\n",
    "#   recall      = 0.7218\n",
    "#   f1          = 0.7500\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.4887\n",
    "#   accuracy    = 0.8144\n",
    "#   precision   = 0.7946\n",
    "#   recall      = 0.7015\n",
    "#   f1          = 0.7282\n",
    "# New best model (f1=0.7282) saved.\n",
    "\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   train_loss  = 0.3688\n",
    "#   accuracy    = 0.8639\n",
    "#   precision   = 0.8235\n",
    "#   recall      = 0.8156\n",
    "#   f1          = 0.8188\n",
    "# Epoch 2 validation:\n",
    "#   val_loss    = 0.4365\n",
    "#   accuracy    = 0.8378\n",
    "#   precision   = 0.7905\n",
    "#   recall      = 0.7755\n",
    "#   f1          = 0.7823\n",
    "# New best model (f1=0.7823) saved.\n",
    "\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   train_loss  = 0.3202\n",
    "#   accuracy    = 0.8813\n",
    "#   precision   = 0.8689\n",
    "#   recall      = 0.8117\n",
    "#   f1          = 0.8369\n",
    "# Epoch 3 validation:\n",
    "#   val_loss    = 0.4392\n",
    "#   accuracy    = 0.8396\n",
    "#   precision   = 0.8122\n",
    "#   recall      = 0.7477\n",
    "#   f1          = 0.7750\n",
    "\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   train_loss  = 0.2600\n",
    "#   accuracy    = 0.9077\n",
    "#   precision   = 0.8946\n",
    "#   recall      = 0.8575\n",
    "#   f1          = 0.8738\n",
    "# Epoch 4 validation:\n",
    "#   val_loss    = 0.4221\n",
    "#   accuracy    = 0.8499\n",
    "#   precision   = 0.8175\n",
    "#   recall      = 0.7718\n",
    "#   f1          = 0.7914\n",
    "# New best model (f1=0.7914) saved.\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   train_loss  = 0.2058\n",
    "#   accuracy    = 0.9299\n",
    "#   precision   = 0.9085\n",
    "#   recall      = 0.9060\n",
    "#   f1          = 0.9066\n",
    "\n",
    "# Epoch 5 validation:\n",
    "#   val_loss    = 0.4409\n",
    "#   accuracy    = 0.8463\n",
    "#   precision   = 0.7998\n",
    "#   recall      = 0.7894\n",
    "#   f1          = 0.7935\n",
    "# New best model (f1=0.7935) saved.\n",
    "\n",
    "# Loaded best model with f1=0.7935\n",
    "# Final eval_results: {'accuracy': 0.8404384193827517, 'precision': 0.7916469260389406, 'recall': 0.7848264806284927, 'f1': 0.786880109334091, 'loss': 0.4544476669185496}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946d83a",
   "metadata": {},
   "source": [
    "## Transformer (Deberta-V3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a099e1-fd9f-4f7c-be51-2d4991a19dc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360f53fd-66c4-468d-9873-9b8bba8750f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ce20be-4d58-4806-851b-833a82b7301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class TrainMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, train_dataset, val_dataset, last_epoch = None):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.trainer = None\n",
    "        self.last_epoch = last_epoch\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.trainer is None:\n",
    "            return control\n",
    "\n",
    "        if self.last_epoch is None:\n",
    "            epoch = state.epoch\n",
    "        else:\n",
    "            self.last_epoch += 1\n",
    "            epoch = self.last_epoch\n",
    "\n",
    "        # --- train metrics ---\n",
    "        train_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.train_dataset,\n",
    "            metric_key_prefix=\"train\",  # train_accuracy, train_f1, ...\n",
    "        )\n",
    "\n",
    "        # --- validation metrics ---\n",
    "        val_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.val_dataset,\n",
    "            metric_key_prefix=\"eval\",   # eval_accuracy, eval_f1, ...\n",
    "        )\n",
    "\n",
    "        val_loss = val_metrics.get(\"eval_loss\")\n",
    "        val_acc  = val_metrics.get(\"eval_accuracy\")\n",
    "        val_prec = val_metrics.get(\"eval_precision\")\n",
    "        val_rec  = val_metrics.get(\"eval_recall\")\n",
    "        val_f1   = val_metrics.get(\"eval_f1\")\n",
    "\n",
    "        train_loss = train_metrics.get(\"train_loss\")\n",
    "        train_acc  = train_metrics.get(\"train_accuracy\")\n",
    "        train_prec = train_metrics.get(\"train_precision\")\n",
    "        train_rec  = train_metrics.get(\"train_recall\")\n",
    "        train_f1   = train_metrics.get(\"train_f1\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[EPOCH {epoch:.0f}]\")\n",
    "        if train_acc is not None:\n",
    "            print(f\"[train] loss={train_loss:.4f}, acc={train_acc:.4f}, prec={train_prec:.4f}, rec={train_rec:.4f}, f1={train_f1:.4f}\")\n",
    "        if val_acc is not None:\n",
    "            print(f\"[valid] loss={val_loss:.4f}, acc={val_acc:.4f}, prec={val_prec:.4f}, rec={val_rec:.4f}, f1={val_f1:.4f}\")\n",
    "        return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1ba95a9-9135-42dc-945e-d7ceb7abad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name=\"./deberta\", last_epoch = None, epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\"):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"no\", # \"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epoch,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=False, # True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    train_callback = TrainMetricsCallback(\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        val_dataset=tokenized_datasets[\"validation\"],\n",
    "        last_epoch=last_epoch,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[train_callback],\n",
    "    )\n",
    "\n",
    "    train_callback.trainer = trainer\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b57fb38-6247-4be0-a593-fce04a5191ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "def load_and_test_eval(ckpt_dir = \"./deberta-v3-crisis/batchsizeXX/checkpoint-XXXXX\"):\n",
    "    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\".\", # any\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    eval_trainer = Trainer(\n",
    "        model=model_ckpt,\n",
    "        args=eval_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    eval_results = eval_trainer.evaluate(\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        metric_key_prefix=\"test\",\n",
    "    )\n",
    "    # {'test_loss': 0.4593863785266876, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8740698009806749, 'test_precision': 0.8326252068193959, 'test_recall': 0.8500324417218078, 'test_f1': 0.8369876991837396, 'test_runtime': 123.8232, 'test_samples_per_second': 139.998, 'test_steps_per_second': 2.189}\n",
    "    print(eval_results)\n",
    "    print(f\"[test] acc={eval_results['test_accuracy']}, prec={eval_results['test_precision']}, rec={eval_results['test_recall']}, f1={eval_results['test_f1']}\")\n",
    "    # print(f\"test_loss = {eval_results['test_loss']}\")\n",
    "    # print(f\"test_accuracy = {eval_results['test_accuracy']}\")\n",
    "    # print(f\"test_precision = {eval_results['test_precision']}\")\n",
    "    # print(f\"test_recall = {eval_results['test_recall']}\")\n",
    "    # print(f\"test_f1 = {eval_results['test_f1']}\")\n",
    "    return eval_results\n",
    "\n",
    "def load_and_val_eval(ckpt_dir = \"./deberta-v3-crisis/batchsizeXX/checkpoint-XXXXX\"):\n",
    "    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\".\", # any\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    eval_trainer = Trainer(\n",
    "        model=model_ckpt,\n",
    "        args=eval_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    eval_results = eval_trainer.evaluate(\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        metric_key_prefix=\"val\",\n",
    "    )\n",
    "    print(eval_results)\n",
    "    print(f\"[test] acc={eval_results['val_accuracy']}, prec={eval_results['val_precision']}, rec={eval_results['val_recall']}, f1={eval_results['val_f1']}\")\n",
    "    return eval_results['val_f1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657a561",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4996611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 15.0\n",
      "mean: 16.42866733323811\n",
      "95th percentile: 29.0\n",
      "99th percentile: 42.0\n",
      "max: 1126\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download everything from https://huggingface.co/microsoft/deberta-v3-base/tree/main\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"./deberta\", # \"microsoft/deberta-v3-base\"\n",
    "    use_fast=True, # DeBERTa fast tokenizer \n",
    "    local_files_only=True,\n",
    ")\n",
    "\n",
    "max_length = 64 # adjust based on the maximum input size?\n",
    "\n",
    "# 1. Tokenize directly\n",
    "train_encodings = tokenizer(\n",
    "    df[\"train\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    df[\"dev\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "test_encodings = tokenizer(\n",
    "    df[\"test\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "# 2. Build HF Datasets from encoded inputs + labels\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"train\"]['class_label_group_num'],\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": val_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": val_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"dev\"]['class_label_group_num'],\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"test\"]['class_label_group_num'],\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "# 3. Set format for PyTorch\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")\n",
    "\n",
    "# Check appropriate token size\n",
    "tmp_train = tokenizer(df[\"train\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n",
    "lens_train = [len(ids) for ids in tmp_train[\"input_ids\"]]\n",
    "\n",
    "tmp_dev = tokenizer(df[\"dev\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n",
    "lens_dev = [len(ids) for ids in tmp_dev[\"input_ids\"]]\n",
    "\n",
    "lengths = lens_train + lens_dev\n",
    "\n",
    "print(\"median:\", np.median(lengths))\n",
    "print(\"mean:\", np.mean(lengths))\n",
    "print(\"95th percentile:\", np.percentile(lengths, 95))\n",
    "print(\"99th percentile:\", np.percentile(lengths, 99))\n",
    "print(\"max:\", np.max(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058da24c-3882-4647-81db-49bda443f998",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2589f8da-61ae-416a-9ff0-4374a926115a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=1e-6, batch_size=16 (EPOCH 16, val_f1=0.8583, test_f1=0.848050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4d6c967-1608-4294-ac88-970d0d5b6370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.480494886636734, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.8834150562445918, 'test_precision': 0.8357564455145318, 'test_recall': 0.8623533790050426, 'test_f1': 0.8480500870596009, 'test_runtime': 131.5435, 'test_samples_per_second': 131.781, 'test_steps_per_second': 2.06}\n",
      "[test] acc=0.8834150562445918, prec=0.8357564455145318, rec=0.8623533790050426, f1=0.8480500870596009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.480494886636734,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.8834150562445918,\n",
       " 'test_precision': 0.8357564455145318,\n",
       " 'test_recall': 0.8623533790050426,\n",
       " 'test_f1': 0.8480500870596009,\n",
       " 'test_runtime': 131.5435,\n",
       " 'test_samples_per_second': 131.781,\n",
       " 'test_steps_per_second': 2.06}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr1e6_cont_from_13/checkpoint-11457\")\n",
    "# [test] acc=0.8834150562445918, prec=0.8357564455145318, rec=0.8623533790050426, f1=0.8480500870596009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a93d9-339b-4675-a4b6-b33c68b64f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.8767, prec=0.8325, rec=0.8395, f1=0.8359\n",
    "# [valid] acc=0.8722, prec=0.8275, rec=0.8291, f1=0.8283\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.8833, prec=0.8349, rec=0.8651, f1=0.8489\n",
    "# [valid] acc=0.8745, prec=0.8228, rec=0.8486, f1=0.8348\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.8958, prec=0.8568, rec=0.8691, f1=0.8625\n",
    "# [valid] acc=0.8815, prec=0.8382, rec=0.8441, f1=0.8409\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9020, prec=0.8662, rec=0.8761, f1=0.8708\n",
    "# [valid] acc=0.8829, prec=0.8418, rec=0.8448, f1=0.8431\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9039, prec=0.8650, rec=0.8854, f1=0.8744\n",
    "# [valid] acc=0.8834, prec=0.8389, rec=0.8537, f1=0.8456\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9066, prec=0.8676, rec=0.8938, f1=0.8797\n",
    "# [valid] acc=0.8830, prec=0.8375, rec=0.8570, f1=0.8466\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9139, prec=0.8792, rec=0.8964, f1=0.8875\n",
    "# [valid] acc=0.8875, prec=0.8456, rec=0.8559, f1=0.8506\n",
    "# ================================================================================\n",
    "# [EPOCH 8]\n",
    "# [train] acc=0.9181, prec=0.8857, rec=0.8996, f1=0.8923\n",
    "# [valid] acc=0.8872, prec=0.8460, rec=0.8548, f1=0.8501\n",
    "# ================================================================================\n",
    "# [EPOCH 9]\n",
    "# [train] acc=0.9184, prec=0.8835, rec=0.9044, f1=0.8934\n",
    "# [valid] acc=0.8867, prec=0.8431, rec=0.8584, f1=0.8503\n",
    "# ================================================================================\n",
    "# [EPOCH 10]\n",
    "# [train] acc=0.9256, prec=0.8985, rec=0.9054, f1=0.9018\n",
    "# [valid] acc=0.8898, prec=0.8521, rec=0.8544, f1=0.8532\n",
    "# ================================================================================\n",
    "# [EPOCH 11]\n",
    "# [train] acc=0.9236, prec=0.8896, rec=0.9119, f1=0.9001\n",
    "# [valid] acc=0.8884, prec=0.8447, rec=0.8625, f1=0.8530\n",
    "# ================================================================================\n",
    "# [EPOCH 12]\n",
    "# [train] acc=0.9302, prec=0.9042, rec=0.9119, f1=0.9079\n",
    "# [valid] acc=0.8910, prec=0.8532, rec=0.8558, f1=0.8544\n",
    "# ================================================================================\n",
    "# [EPOCH 13]\n",
    "# [train] acc=0.9310, prec=0.9036, rec=0.9149, f1=0.9091\n",
    "# [valid] acc=0.8901, prec=0.8510, rec=0.8569, f1=0.8538\n",
    "# ================================================================================\n",
    "# [EPOCH 14]\n",
    "# [train] loss=0.2028, acc=0.9325, prec=0.9112, rec=0.9126, f1=0.9105\n",
    "# [valid] loss=0.3398, acc=0.8919, prec=0.8602, rec=0.8542, f1=0.8553\n",
    "# ================================================================================\n",
    "# [EPOCH 15]\n",
    "# [train] loss=0.1456, acc=0.9541, prec=0.9361, rec=0.9437, f1=0.9395\n",
    "# [valid] loss=0.3407, acc=0.8885, prec=0.8528, rec=0.8540, f1=0.8524\n",
    "# ================================================================================\n",
    "# [EPOCH 16]\n",
    "# [train] loss=0.1172, acc=0.9672, prec=0.9503, rec=0.9643, f1=0.9570\n",
    "# [valid] loss=0.4375, acc=0.8927, prec=0.8514, rec=0.8660, f1=0.8583\n",
    "# ================================ OVERFITTING ===================================\n",
    "# [EPOCH 17]\n",
    "# [train] loss=0.0874, acc=0.9782, prec=0.9702, rec=0.9718, f1=0.9710\n",
    "# [valid] loss=0.5064, acc=0.8922, prec=0.8592, rec=0.8508, f1=0.8548\n",
    "# ================================================================================\n",
    "# [EPOCH 18]\n",
    "# [train] loss=0.0626, acc=0.9846, prec=0.9825, rec=0.9771, f1=0.9798\n",
    "# [valid] loss=0.5907, acc=0.8882, prec=0.8626, rec=0.8347, f1=0.8473\n",
    "# ================================================================================\n",
    "# [EPOCH 19]\n",
    "# [train] loss=0.0577, acc=0.9866, prec=0.9793, rec=0.9852, f1=0.9822\n",
    "# [valid] loss=0.6760, acc=0.8839, prec=0.8362, rec=0.8612, f1=0.8479\n",
    "# ================================================================================\n",
    "# [EPOCH 20]\n",
    "# [train] loss=0.0370, acc=0.9913, prec=0.9875, rec=0.9893, f1=0.9884\n",
    "# [valid] loss=0.6766, acc=0.8887, prec=0.8456, rec=0.8604, f1=0.8527\n",
    "# ================================================================================\n",
    "# [EPOCH 21]\n",
    "# [train] loss=0.0259, acc=0.9940, prec=0.9914, rec=0.9923, f1=0.9919\n",
    "# [valid] loss=0.7654, acc=0.8873, prec=0.8462, rec=0.8547, f1=0.8504\n",
    "# ================================================================================\n",
    "# [EPOCH 22]\n",
    "# [train] loss=0.0217, acc=0.9950, prec=0.9927, rec=0.9938, f1=0.9932\n",
    "# [valid] loss=0.8305, acc=0.8854, prec=0.8409, rec=0.8579, f1=0.8490\n",
    "# ================================================================================\n",
    "# [EPOCH 23]\n",
    "# [train] loss=0.0176, acc=0.9959, prec=0.9943, rec=0.9945, f1=0.9944\n",
    "# [valid] loss=0.8476, acc=0.8860, prec=0.8447, rec=0.8522, f1=0.8484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26a56375-02e2-4788-af3f-2cc10ecabce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49665' max='76380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49665/76380 12:43:14 < 6:50:34, 1.08 it/s, Epoch 13.00/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.369860</td>\n",
       "      <td>0.872212</td>\n",
       "      <td>0.827513</td>\n",
       "      <td>0.829133</td>\n",
       "      <td>0.828306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.354365</td>\n",
       "      <td>0.874454</td>\n",
       "      <td>0.822754</td>\n",
       "      <td>0.848556</td>\n",
       "      <td>0.834804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.345816</td>\n",
       "      <td>0.881516</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.844074</td>\n",
       "      <td>0.840875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.338899</td>\n",
       "      <td>0.882861</td>\n",
       "      <td>0.841793</td>\n",
       "      <td>0.844776</td>\n",
       "      <td>0.843076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340324</td>\n",
       "      <td>0.883421</td>\n",
       "      <td>0.838853</td>\n",
       "      <td>0.853732</td>\n",
       "      <td>0.845645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346092</td>\n",
       "      <td>0.882973</td>\n",
       "      <td>0.837511</td>\n",
       "      <td>0.857025</td>\n",
       "      <td>0.846615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346158</td>\n",
       "      <td>0.887457</td>\n",
       "      <td>0.845644</td>\n",
       "      <td>0.855859</td>\n",
       "      <td>0.850622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30552</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343148</td>\n",
       "      <td>0.887232</td>\n",
       "      <td>0.845960</td>\n",
       "      <td>0.854781</td>\n",
       "      <td>0.850057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34371</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356693</td>\n",
       "      <td>0.886672</td>\n",
       "      <td>0.843079</td>\n",
       "      <td>0.858372</td>\n",
       "      <td>0.850271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38190</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343051</td>\n",
       "      <td>0.889811</td>\n",
       "      <td>0.852127</td>\n",
       "      <td>0.854418</td>\n",
       "      <td>0.853157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42009</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.360168</td>\n",
       "      <td>0.888353</td>\n",
       "      <td>0.844676</td>\n",
       "      <td>0.862494</td>\n",
       "      <td>0.852971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45828</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356609</td>\n",
       "      <td>0.891044</td>\n",
       "      <td>0.853206</td>\n",
       "      <td>0.855824</td>\n",
       "      <td>0.854363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49647</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.359416</td>\n",
       "      <td>0.890147</td>\n",
       "      <td>0.850972</td>\n",
       "      <td>0.856922</td>\n",
       "      <td>0.853833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.8767, prec=0.8325, rec=0.8395, f1=0.8359\n",
      "[valid] acc=0.8722, prec=0.8275, rec=0.8291, f1=0.8283\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.8833, prec=0.8349, rec=0.8651, f1=0.8489\n",
      "[valid] acc=0.8745, prec=0.8228, rec=0.8486, f1=0.8348\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.8958, prec=0.8568, rec=0.8691, f1=0.8625\n",
      "[valid] acc=0.8815, prec=0.8382, rec=0.8441, f1=0.8409\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9020, prec=0.8662, rec=0.8761, f1=0.8708\n",
      "[valid] acc=0.8829, prec=0.8418, rec=0.8448, f1=0.8431\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9039, prec=0.8650, rec=0.8854, f1=0.8744\n",
      "[valid] acc=0.8834, prec=0.8389, rec=0.8537, f1=0.8456\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9066, prec=0.8676, rec=0.8938, f1=0.8797\n",
      "[valid] acc=0.8830, prec=0.8375, rec=0.8570, f1=0.8466\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 7]\n",
      "[train] acc=0.9139, prec=0.8792, rec=0.8964, f1=0.8875\n",
      "[valid] acc=0.8875, prec=0.8456, rec=0.8559, f1=0.8506\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 8]\n",
      "[train] acc=0.9181, prec=0.8857, rec=0.8996, f1=0.8923\n",
      "[valid] acc=0.8872, prec=0.8460, rec=0.8548, f1=0.8501\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 9]\n",
      "[train] acc=0.9184, prec=0.8835, rec=0.9044, f1=0.8934\n",
      "[valid] acc=0.8867, prec=0.8431, rec=0.8584, f1=0.8503\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 10]\n",
      "[train] acc=0.9256, prec=0.8985, rec=0.9054, f1=0.9018\n",
      "[valid] acc=0.8898, prec=0.8521, rec=0.8544, f1=0.8532\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 11]\n",
      "[train] acc=0.9236, prec=0.8896, rec=0.9119, f1=0.9001\n",
      "[valid] acc=0.8884, prec=0.8447, rec=0.8625, f1=0.8530\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 12]\n",
      "[train] acc=0.9302, prec=0.9042, rec=0.9119, f1=0.9079\n",
      "[valid] acc=0.8910, prec=0.8532, rec=0.8558, f1=0.8544\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 13]\n",
      "[train] acc=0.9310, prec=0.9036, rec=0.9149, f1=0.9091\n",
      "[valid] acc=0.8901, prec=0.8510, rec=0.8569, f1=0.8538\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr1e6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 104\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     93\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     94\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    100\u001b[0m )\n\u001b[1;32m    102\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2740\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2737\u001b[0m     context \u001b[38;5;241m=\u001b[39m implicit_replication\n\u001b[1;32m   2739\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2740\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2742\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;66;03m# get leaning rate before update\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/optimizer.py:179\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/adamw.py:243\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    230\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    232\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    233\u001b[0m         group,\n\u001b[1;32m    234\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m         state_steps,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[0;32m--> 243\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/adamw.py:875\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 875\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/adamw.py:425\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    422\u001b[0m     device_beta1 \u001b[38;5;241m=\u001b[39m beta1\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_beta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=13, learning_rate=1e-6, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6b0dd15-5e9a-4e91-9692-2dda17f89f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38190' max='38190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38190/38190 7:22:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.339816</td>\n",
       "      <td>0.891940</td>\n",
       "      <td>0.860151</td>\n",
       "      <td>0.854168</td>\n",
       "      <td>0.855299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340729</td>\n",
       "      <td>0.888465</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.854037</td>\n",
       "      <td>0.852405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.437489</td>\n",
       "      <td>0.892725</td>\n",
       "      <td>0.851411</td>\n",
       "      <td>0.865999</td>\n",
       "      <td>0.858273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.506365</td>\n",
       "      <td>0.892165</td>\n",
       "      <td>0.859224</td>\n",
       "      <td>0.850820</td>\n",
       "      <td>0.854820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.590669</td>\n",
       "      <td>0.888241</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>0.834667</td>\n",
       "      <td>0.847338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676042</td>\n",
       "      <td>0.883870</td>\n",
       "      <td>0.836201</td>\n",
       "      <td>0.861162</td>\n",
       "      <td>0.847859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676595</td>\n",
       "      <td>0.888690</td>\n",
       "      <td>0.845560</td>\n",
       "      <td>0.860393</td>\n",
       "      <td>0.852680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30552</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.765361</td>\n",
       "      <td>0.887344</td>\n",
       "      <td>0.846230</td>\n",
       "      <td>0.854750</td>\n",
       "      <td>0.850361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34371</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.830512</td>\n",
       "      <td>0.885439</td>\n",
       "      <td>0.840894</td>\n",
       "      <td>0.857950</td>\n",
       "      <td>0.849048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38190</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.847613</td>\n",
       "      <td>0.885999</td>\n",
       "      <td>0.844708</td>\n",
       "      <td>0.852216</td>\n",
       "      <td>0.848392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 14]\n",
      "[train] loss=0.2028, acc=0.9325, prec=0.9112, rec=0.9126, f1=0.9105\n",
      "[valid] loss=0.3398, acc=0.8919, prec=0.8602, rec=0.8542, f1=0.8553\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 15]\n",
      "[train] loss=0.1456, acc=0.9541, prec=0.9361, rec=0.9437, f1=0.9395\n",
      "[valid] loss=0.3407, acc=0.8885, prec=0.8528, rec=0.8540, f1=0.8524\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 16]\n",
      "[train] loss=0.1172, acc=0.9672, prec=0.9503, rec=0.9643, f1=0.9570\n",
      "[valid] loss=0.4375, acc=0.8927, prec=0.8514, rec=0.8660, f1=0.8583\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 17]\n",
      "[train] loss=0.0874, acc=0.9782, prec=0.9702, rec=0.9718, f1=0.9710\n",
      "[valid] loss=0.5064, acc=0.8922, prec=0.8592, rec=0.8508, f1=0.8548\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 18]\n",
      "[train] loss=0.0626, acc=0.9846, prec=0.9825, rec=0.9771, f1=0.9798\n",
      "[valid] loss=0.5907, acc=0.8882, prec=0.8626, rec=0.8347, f1=0.8473\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 19]\n",
      "[train] loss=0.0577, acc=0.9866, prec=0.9793, rec=0.9852, f1=0.9822\n",
      "[valid] loss=0.6760, acc=0.8839, prec=0.8362, rec=0.8612, f1=0.8479\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 20]\n",
      "[train] loss=0.0370, acc=0.9913, prec=0.9875, rec=0.9893, f1=0.9884\n",
      "[valid] loss=0.6766, acc=0.8887, prec=0.8456, rec=0.8604, f1=0.8527\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 21]\n",
      "[train] loss=0.0259, acc=0.9940, prec=0.9914, rec=0.9923, f1=0.9919\n",
      "[valid] loss=0.7654, acc=0.8873, prec=0.8462, rec=0.8547, f1=0.8504\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 22]\n",
      "[train] loss=0.0217, acc=0.9950, prec=0.9927, rec=0.9938, f1=0.9932\n",
      "[valid] loss=0.8305, acc=0.8854, prec=0.8409, rec=0.8579, f1=0.8490\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 23]\n",
      "[train] loss=0.0176, acc=0.9959, prec=0.9943, rec=0.9945, f1=0.9944\n",
      "[valid] loss=0.8476, acc=0.8860, prec=0.8447, rec=0.8522, f1=0.8484\n"
     ]
    }
   ],
   "source": [
    "trainer = train(model_name=\"./deberta-v3-crisis/batchsize16_lr1e6/checkpoint-49647\",\n",
    "                last_epoch=13, epoch=10, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e6_cont_from_13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d1baab-ce2e-48c2-84b0-fbff5f56c716",
   "metadata": {},
   "source": [
    "#### learning_rate=5e-6, batch_size=16 (EPOCH 7, val_f1=0.8603, test_f1=0.85244) => BEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e0cff26-9d86-4b26-af93-d86b3f5b944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.44441157579421997, 'test_model_preparation_time': 0.0016, 'test_accuracy': 0.8876261897894433, 'test_precision': 0.8431801450425511, 'test_recall': 0.8625945973329592, 'test_f1': 0.8524425110946661, 'test_runtime': 130.2498, 'test_samples_per_second': 133.09, 'test_steps_per_second': 2.081}\n",
      "[test] acc=0.8876261897894433, prec=0.8431801450425511, rec=0.8625945973329592, f1=0.8524425110946661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.44441157579421997,\n",
       " 'test_model_preparation_time': 0.0016,\n",
       " 'test_accuracy': 0.8876261897894433,\n",
       " 'test_precision': 0.8431801450425511,\n",
       " 'test_recall': 0.8625945973329592,\n",
       " 'test_f1': 0.8524425110946661,\n",
       " 'test_runtime': 130.2498,\n",
       " 'test_samples_per_second': 133.09,\n",
       " 'test_steps_per_second': 2.081}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32815efa-a78f-4c8e-b826-778d114323b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.8983, prec=0.8618, rec=0.8756, f1=0.8673\n",
    "# [valid] acc=0.8816, prec=0.8414, rec=0.8494, f1=0.8440\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9174, prec=0.8843, rec=0.9019, f1=0.8927\n",
    "# [valid] acc=0.8908, prec=0.8504, rec=0.8638, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9314, prec=0.9065, rec=0.9128, f1=0.9095\n",
    "# [valid] acc=0.8935, prec=0.8584, rec=0.8579, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9448, prec=0.9269, rec=0.9279, f1=0.9274\n",
    "# [valid] acc=0.8927, prec=0.8597, rec=0.8541, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9510, prec=0.9316, rec=0.9389, f1=0.9351\n",
    "# [valid] acc=0.8936, prec=0.8566, rec=0.8598, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9532, prec=0.9325, rec=0.9467, f1=0.9393\n",
    "# [valid] acc=0.8924, prec=0.8516, rec=0.8659, f1=0.8584\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9569, prec=0.9386, rec=0.9489, f1=0.9436\n",
    "# [valid] acc=0.8942, prec=0.8557, rec=0.8651, f1=0.8603\n",
    "# ============================= OVERFITTING ======================================\n",
    "# [EPOCH 8]\n",
    "# [train] loss=0.1480, acc=0.9574, prec=0.9391, rec=0.9508, f1=0.9444\n",
    "# [valid] loss=0.4439, acc=0.8864, prec=0.8488, rec=0.8546, f1=0.8505\n",
    "# ================================================================================\n",
    "# [EPOCH 9]\n",
    "# [train] loss=0.1104, acc=0.9689, prec=0.9530, rec=0.9652, f1=0.9589\n",
    "# [valid] loss=0.4663, acc=0.8887, prec=0.8475, rec=0.8598, f1=0.8533\n",
    "# ================================================================================\n",
    "# [EPOCH 10]\n",
    "# [train] loss=0.0928, acc=0.9791, prec=0.9701, rec=0.9744, f1=0.9723\n",
    "# [valid] loss=0.6590, acc=0.8893, prec=0.8514, rec=0.8523, f1=0.8518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47629d0e-9806-4a75-96eb-d924def9b554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26733' max='26733' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26733/26733 5:00:09, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.332313</td>\n",
       "      <td>0.881628</td>\n",
       "      <td>0.841446</td>\n",
       "      <td>0.849445</td>\n",
       "      <td>0.844033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306507</td>\n",
       "      <td>0.890819</td>\n",
       "      <td>0.850377</td>\n",
       "      <td>0.863838</td>\n",
       "      <td>0.856841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.329520</td>\n",
       "      <td>0.893510</td>\n",
       "      <td>0.858364</td>\n",
       "      <td>0.857872</td>\n",
       "      <td>0.857992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343858</td>\n",
       "      <td>0.892725</td>\n",
       "      <td>0.859702</td>\n",
       "      <td>0.854125</td>\n",
       "      <td>0.856828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.361830</td>\n",
       "      <td>0.893622</td>\n",
       "      <td>0.856642</td>\n",
       "      <td>0.859780</td>\n",
       "      <td>0.857983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.397974</td>\n",
       "      <td>0.892389</td>\n",
       "      <td>0.851599</td>\n",
       "      <td>0.865910</td>\n",
       "      <td>0.858416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.413612</td>\n",
       "      <td>0.894182</td>\n",
       "      <td>0.855740</td>\n",
       "      <td>0.865078</td>\n",
       "      <td>0.860305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.8983, prec=0.8618, rec=0.8756, f1=0.8673\n",
      "[valid] acc=0.8816, prec=0.8414, rec=0.8494, f1=0.8440\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9174, prec=0.8843, rec=0.9019, f1=0.8927\n",
      "[valid] acc=0.8908, prec=0.8504, rec=0.8638, f1=0.8568\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9314, prec=0.9065, rec=0.9128, f1=0.9095\n",
      "[valid] acc=0.8935, prec=0.8584, rec=0.8579, f1=0.8580\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9448, prec=0.9269, rec=0.9279, f1=0.9274\n",
      "[valid] acc=0.8927, prec=0.8597, rec=0.8541, f1=0.8568\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9510, prec=0.9316, rec=0.9389, f1=0.9351\n",
      "[valid] acc=0.8936, prec=0.8566, rec=0.8598, f1=0.8580\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9532, prec=0.9325, rec=0.9467, f1=0.9393\n",
      "[valid] acc=0.8924, prec=0.8516, rec=0.8659, f1=0.8584\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 7]\n",
      "[train] acc=0.9569, prec=0.9386, rec=0.9489, f1=0.9436\n",
      "[valid] acc=0.8942, prec=0.8557, rec=0.8651, f1=0.8603\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=7, learning_rate=5e-6, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr5e6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4823d845-8fa2-4ca6-bb2a-f1bc079c2a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8148' max='38190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8148/38190 1:34:59 < 5:50:19, 1.43 it/s, Epoch 2.13/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.443878</td>\n",
       "      <td>0.886448</td>\n",
       "      <td>0.848826</td>\n",
       "      <td>0.854559</td>\n",
       "      <td>0.850476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466330</td>\n",
       "      <td>0.888690</td>\n",
       "      <td>0.847531</td>\n",
       "      <td>0.859838</td>\n",
       "      <td>0.853341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 8]\n",
      "[train] loss=0.1480, acc=0.9574, prec=0.9391, rec=0.9508, f1=0.9444\n",
      "[valid] loss=0.4439, acc=0.8864, prec=0.8488, rec=0.8546, f1=0.8505\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 9]\n",
      "[train] loss=0.1104, acc=0.9689, prec=0.9530, rec=0.9652, f1=0.9589\n",
      "[valid] loss=0.4663, acc=0.8887, prec=0.8475, rec=0.8598, f1=0.8533\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlast_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e6_cont_after_7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 112\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_name, last_epoch, epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    101\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    102\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 112\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2618\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2616\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2617\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2618\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[38;5;66;03m# Store the number of batches for current gradient accumulation\u001b[39;00m\n\u001b[1;32m   2620\u001b[0m \u001b[38;5;66;03m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001b[39;00m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_gradient_accumulation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:5654\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5652\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5653\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5654\u001b[0m         batch_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   5655\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5656\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/data_loader.py:577\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[1;32m    579\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/utils/operations.py:154\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    152\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:837\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    838\u001b[0m         k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(v\u001b[38;5;241m.\u001b[39mto) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    840\u001b[0m     }\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    842\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:838\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 838\u001b[0m         k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(v\u001b[38;5;241m.\u001b[39mto) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    840\u001b[0m     }\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    842\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(model_name=\"./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\",\n",
    "                last_epoch=7, epoch=10, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr5e6_cont_after_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da30c65b-901e-43ae-bf7b-0e15a55b1253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_79218/1544260634.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9489' max='11457' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9489/11457 1:44:06 < 21:35, 1.52 it/s, Epoch 2.48/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.659025</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.851387</td>\n",
       "      <td>0.852298</td>\n",
       "      <td>0.851787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.778568</td>\n",
       "      <td>0.880170</td>\n",
       "      <td>0.830401</td>\n",
       "      <td>0.860368</td>\n",
       "      <td>0.844266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 10]\n",
      "[train] loss=0.0928, acc=0.9791, prec=0.9701, rec=0.9744, f1=0.9723\n",
      "[valid] loss=0.6590, acc=0.8893, prec=0.8514, rec=0.8523, f1=0.8518\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 11]\n",
      "[train] loss=0.0924, acc=0.9799, prec=0.9666, rec=0.9824, f1=0.9742\n",
      "[valid] loss=0.7786, acc=0.8802, prec=0.8304, rec=0.8604, f1=0.8443\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e6_cont_after_7/checkpoint-7638\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlast_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e6_cont_after_9\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 42\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_name, last_epoch, epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     30\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     31\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     32\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 42\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2715\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2713\u001b[0m         grad_norm_context \u001b[38;5;241m=\u001b[39m implicit_replication\n\u001b[1;32m   2714\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m grad_norm_context():\n\u001b[0;32m-> 2715\u001b[0m         _grad_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2716\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2717\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2718\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2721\u001b[0m     is_accelerate_available()\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2723\u001b[0m ):\n\u001b[1;32m   2724\u001b[0m     grad_norm \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_global_grad_norm()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:3009\u001b[0m, in \u001b[0;36mAccelerator.clip_grad_norm_\u001b[0;34m(self, parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m   3007\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mclip_grad_norm_(max_norm, norm_type)\n\u001b[1;32m   3008\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_gradients()\n\u001b[0;32m-> 3009\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:34\u001b[0m, in \u001b[0;36m_no_grad.<locals>._no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_no_grad_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:215\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m    213\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(parameters)\n\u001b[1;32m    214\u001b[0m grads \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m--> 215\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[43m_get_total_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_if_nonfinite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m _clip_grads_with_norm_(parameters, max_norm, total_norm, foreach)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:34\u001b[0m, in \u001b[0;36m_no_grad.<locals>._no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_no_grad_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:94\u001b[0m, in \u001b[0;36m_get_total_norm\u001b[0;34m(tensors, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     90\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m         norms\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m---> 94\u001b[0m             [torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(g, norm_type) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m device_tensors]\n\u001b[1;32m     95\u001b[0m         )\n\u001b[1;32m     97\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\n\u001b[1;32m     98\u001b[0m     torch\u001b[38;5;241m.\u001b[39mstack([norm\u001b[38;5;241m.\u001b[39mto(first_device) \u001b[38;5;28;01mfor\u001b[39;00m norm \u001b[38;5;129;01min\u001b[39;00m norms]), norm_type\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:94\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     90\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m         norms\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m---> 94\u001b[0m             [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m device_tensors]\n\u001b[1;32m     95\u001b[0m         )\n\u001b[1;32m     97\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\n\u001b[1;32m     98\u001b[0m     torch\u001b[38;5;241m.\u001b[39mstack([norm\u001b[38;5;241m.\u001b[39mto(first_device) \u001b[38;5;28;01mfor\u001b[39;00m norm \u001b[38;5;129;01min\u001b[39;00m norms]), norm_type\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(model_name=\"./deberta-v3-crisis/batchsize16_lr5e6_cont_after_7/checkpoint-7638\",\n",
    "                last_epoch=9, epoch=3, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr5e6_cont_after_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d8086-7cd1-4e04-9835-2ec31ef799e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=1e-5, batch_size=16 (EPOCH 5, val_f1=0.8584, test_f1=0.85042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a24e793-165c-48ef-a869-6ba71041e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.4733332693576813, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.8879146235938852, 'test_precision': 0.8480751638235061, 'test_recall': 0.8532187935966081, 'test_f1': 0.8504206093957811, 'test_runtime': 131.1168, 'test_samples_per_second': 132.21, 'test_steps_per_second': 2.067}\n",
      "[test] acc=0.8879146235938852, prec=0.8480751638235061, rec=0.8532187935966081, f1=0.8504206093957811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.4733332693576813,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.8879146235938852,\n",
       " 'test_precision': 0.8480751638235061,\n",
       " 'test_recall': 0.8532187935966081,\n",
       " 'test_f1': 0.8504206093957811,\n",
       " 'test_runtime': 131.1168,\n",
       " 'test_samples_per_second': 132.21,\n",
       " 'test_steps_per_second': 2.067}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr1e5/checkpoint-19095\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2df7826b-e72b-45ce-a4d4-b5ee2615252f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26733' max='26733' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26733/26733 5:55:23, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.325811</td>\n",
       "      <td>0.884206</td>\n",
       "      <td>0.841713</td>\n",
       "      <td>0.857896</td>\n",
       "      <td>0.848201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302651</td>\n",
       "      <td>0.889698</td>\n",
       "      <td>0.848987</td>\n",
       "      <td>0.863118</td>\n",
       "      <td>0.855654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.351273</td>\n",
       "      <td>0.894519</td>\n",
       "      <td>0.856339</td>\n",
       "      <td>0.863506</td>\n",
       "      <td>0.859627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.387684</td>\n",
       "      <td>0.892949</td>\n",
       "      <td>0.859153</td>\n",
       "      <td>0.854211</td>\n",
       "      <td>0.856652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.444698</td>\n",
       "      <td>0.894743</td>\n",
       "      <td>0.860771</td>\n",
       "      <td>0.856631</td>\n",
       "      <td>0.858374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.518066</td>\n",
       "      <td>0.888129</td>\n",
       "      <td>0.842856</td>\n",
       "      <td>0.867592</td>\n",
       "      <td>0.854441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.558347</td>\n",
       "      <td>0.891604</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.860968</td>\n",
       "      <td>0.856229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.9042, prec=0.8665, rec=0.8892, f1=0.8762\n",
      "[valid] acc=0.8842, prec=0.8417, rec=0.8579, f1=0.8482\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9313, prec=0.9018, rec=0.9200, f1=0.9105\n",
      "[valid] acc=0.8897, prec=0.8490, rec=0.8631, f1=0.8557\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9497, prec=0.9291, rec=0.9388, f1=0.9338\n",
      "[valid] acc=0.8945, prec=0.8563, rec=0.8635, f1=0.8596\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9668, prec=0.9558, rec=0.9571, f1=0.9564\n",
      "[valid] acc=0.8929, prec=0.8592, rec=0.8542, f1=0.8567\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9753, prec=0.9674, rec=0.9678, f1=0.9675\n",
      "[valid] acc=0.8947, prec=0.8608, rec=0.8566, f1=0.8584\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9757, prec=0.9628, rec=0.9745, f1=0.9685\n",
      "[valid] acc=0.8881, prec=0.8429, rec=0.8676, f1=0.8544\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 7]\n",
      "[train] acc=0.9813, prec=0.9730, rec=0.9777, f1=0.9753\n",
      "[valid] acc=0.8916, prec=0.8517, rec=0.8610, f1=0.8562\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=7, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e5\")\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.9042, prec=0.8665, rec=0.8892, f1=0.8762\n",
    "# [valid] acc=0.8842, prec=0.8417, rec=0.8579, f1=0.8482\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9313, prec=0.9018, rec=0.9200, f1=0.9105\n",
    "# [valid] acc=0.8897, prec=0.8490, rec=0.8631, f1=0.8557\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9497, prec=0.9291, rec=0.9388, f1=0.9338\n",
    "# [valid] acc=0.8945, prec=0.8563, rec=0.8635, f1=0.8596\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9668, prec=0.9558, rec=0.9571, f1=0.9564\n",
    "# [valid] acc=0.8929, prec=0.8592, rec=0.8542, f1=0.8567\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9753, prec=0.9674, rec=0.9678, f1=0.9675\n",
    "# [valid] acc=0.8947, prec=0.8608, rec=0.8566, f1=0.8584\n",
    "# =============================== OVERFITTING ====================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9757, prec=0.9628, rec=0.9745, f1=0.9685\n",
    "# [valid] acc=0.8881, prec=0.8429, rec=0.8676, f1=0.8544\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9813, prec=0.9730, rec=0.9777, f1=0.9753\n",
    "# [valid] acc=0.8916, prec=0.8517, rec=0.8610, f1=0.8562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc52583-12a9-423a-b001-575ef67d1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = train(model_name=\"./deberta-v3-crisis/batchsize16_lr1e5/checkpoint-26733\",\n",
    "#                 last_epoch = None, epoch=10, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e5_epoch7_cont\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8386e4f-958e-4525-a9cd-4de5c00f85e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=2e-5, batch_size=16 (EPOCH 3, val_f1=0.8579, test_f1=0.85392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adf0cb55-a32f-4106-a411-de4b135e84fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/2837947494.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19095' max='19095' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19095/19095 3:36:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346062</td>\n",
       "      <td>0.884542</td>\n",
       "      <td>0.843709</td>\n",
       "      <td>0.856845</td>\n",
       "      <td>0.848527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312487</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.847801</td>\n",
       "      <td>0.863210</td>\n",
       "      <td>0.855002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.415822</td>\n",
       "      <td>0.893622</td>\n",
       "      <td>0.855097</td>\n",
       "      <td>0.860775</td>\n",
       "      <td>0.857898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.430682</td>\n",
       "      <td>0.892837</td>\n",
       "      <td>0.856731</td>\n",
       "      <td>0.856669</td>\n",
       "      <td>0.856693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.889698</td>\n",
       "      <td>0.847530</td>\n",
       "      <td>0.860315</td>\n",
       "      <td>0.853732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.9095, prec=0.8759, rec=0.8929, f1=0.8827\n",
      "[valid] acc=0.8845, prec=0.8437, rec=0.8568, f1=0.8485\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9421, prec=0.9170, rec=0.9328, f1=0.9245\n",
      "[valid] acc=0.8893, prec=0.8478, rec=0.8632, f1=0.8550\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9647, prec=0.9501, rec=0.9570, f1=0.9535\n",
      "[valid] acc=0.8936, prec=0.8551, rec=0.8608, f1=0.8579\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9771, prec=0.9689, rec=0.9711, f1=0.9700\n",
      "[valid] acc=0.8928, prec=0.8567, rec=0.8567, f1=0.8567\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9802, prec=0.9714, rec=0.9770, f1=0.9742\n",
      "[valid] acc=0.8897, prec=0.8475, rec=0.8603, f1=0.8537\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=5, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16\")\n",
    "\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.9095, prec=0.8759, rec=0.8929, f1=0.8827\n",
    "# [valid] acc=0.8845, prec=0.8437, rec=0.8568, f1=0.8485\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9421, prec=0.9170, rec=0.9328, f1=0.9245\n",
    "# [valid] acc=0.8893, prec=0.8478, rec=0.8632, f1=0.8550\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9647, prec=0.9501, rec=0.9570, f1=0.9535\n",
    "# [valid] acc=0.8936, prec=0.8551, rec=0.8608, f1=0.8579\n",
    "# ================================= OVERFITTING ===================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9771, prec=0.9689, rec=0.9711, f1=0.9700\n",
    "# [valid] acc=0.8928, prec=0.8567, rec=0.8567, f1=0.8567\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9802, prec=0.9714, rec=0.9770, f1=0.9742\n",
    "# [valid] acc=0.8897, prec=0.8475, rec=0.8603, f1=0.8537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3644d122-eb2f-475d-9429-d8984aefcd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:121: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 14:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.4428344666957855, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8888952985289876, 'test_precision': 0.8469517407076887, 'test_recall': 0.8614854411684476, 'test_f1': 0.8539233722507791, 'test_runtime': 843.0977, 'test_samples_per_second': 20.561, 'test_steps_per_second': 0.321}\n",
      "[test] acc=0.8888952985289876, prec=0.8469517407076887, rec=0.8614854411684476, f1=0.8539233722507791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.4428344666957855,\n",
       " 'test_model_preparation_time': 0.0011,\n",
       " 'test_accuracy': 0.8888952985289876,\n",
       " 'test_precision': 0.8469517407076887,\n",
       " 'test_recall': 0.8614854411684476,\n",
       " 'test_f1': 0.8539233722507791,\n",
       " 'test_runtime': 843.0977,\n",
       " 'test_samples_per_second': 20.561,\n",
       " 'test_steps_per_second': 0.321}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16/checkpoint-11457\")\n",
    "# [test] acc=0.8888952985289876, prec=0.8469517407076887, rec=0.8614854411684476, f1=0.8539233722507791"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7f6657-99ae-42da-9502-bf3603eccd10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=5e-5, batch_size=16 (EPOCH 2, val_f1=0.8363, test_f1=0.836272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "718415df-f7ce-47bd-b48a-0c456e05c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1381527606.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 01:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.3785085082054138, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.873893061315996, 'test_precision': 0.8232246134894181, 'test_recall': 0.8519248854229843, 'test_f1': 0.8362720804971207, 'test_runtime': 65.9497, 'test_samples_per_second': 135.27, 'test_steps_per_second': 2.123}\n",
      "[test] acc=0.873893061315996, prec=0.8232246134894181, rec=0.8519248854229843, f1=0.8362720804971207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.3785085082054138,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.873893061315996,\n",
       " 'test_precision': 0.8232246134894181,\n",
       " 'test_recall': 0.8519248854229843,\n",
       " 'test_f1': 0.8362720804971207,\n",
       " 'test_runtime': 65.9497,\n",
       " 'test_samples_per_second': 135.27,\n",
       " 'test_steps_per_second': 2.123}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr5e5/checkpoint-7638\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89465347-8a07-4e53-8f31-2b419364f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] loss=0.3701, acc=0.8898, prec=0.8705, rec=0.8344, f1=0.8504\n",
    "# [valid] loss=0.4345, acc=0.8714, prec=0.8502, rec=0.8026, f1=0.8232\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] loss=0.2995, acc=0.9050, prec=0.8625, rec=0.8906, f1=0.8756\n",
    "# [valid] loss=0.3785, acc=0.8739, prec=0.8232, rec=0.8519, f1=0.8363\n",
    "# ============================= OVERFITTING =====================================\n",
    "# [EPOCH 3]\n",
    "# [train] loss=0.3244, acc=0.9158, prec=0.8993, rec=0.8725, f1=0.8826\n",
    "# [valid] loss=0.4700, acc=0.8808, prec=0.8584, rec=0.8188, f1=0.8324\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] loss=0.3399, acc=0.9151, prec=0.8885, rec=0.8804, f1=0.8835\n",
    "# [valid] loss=0.4732, acc=0.8783, prec=0.8438, rec=0.8265, f1=0.8335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81cd60c9-60db-4492-9ce4-fcd2bbe518f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15483' max='38190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15483/38190 2:57:41 < 4:20:38, 1.45 it/s, Epoch 4.05/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434464</td>\n",
       "      <td>0.871427</td>\n",
       "      <td>0.850153</td>\n",
       "      <td>0.802633</td>\n",
       "      <td>0.823238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.873893</td>\n",
       "      <td>0.823225</td>\n",
       "      <td>0.851925</td>\n",
       "      <td>0.836272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.880843</td>\n",
       "      <td>0.858400</td>\n",
       "      <td>0.818754</td>\n",
       "      <td>0.832363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.473155</td>\n",
       "      <td>0.878265</td>\n",
       "      <td>0.843796</td>\n",
       "      <td>0.826548</td>\n",
       "      <td>0.833529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] loss=0.3701, acc=0.8898, prec=0.8705, rec=0.8344, f1=0.8504\n",
      "[valid] loss=0.4345, acc=0.8714, prec=0.8502, rec=0.8026, f1=0.8232\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] loss=0.2995, acc=0.9050, prec=0.8625, rec=0.8906, f1=0.8756\n",
      "[valid] loss=0.3785, acc=0.8739, prec=0.8232, rec=0.8519, f1=0.8363\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] loss=0.3244, acc=0.9158, prec=0.8993, rec=0.8725, f1=0.8826\n",
      "[valid] loss=0.4700, acc=0.8808, prec=0.8584, rec=0.8188, f1=0.8324\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] loss=0.3399, acc=0.9151, prec=0.8885, rec=0.8804, f1=0.8835\n",
      "[valid] loss=0.4732, acc=0.8783, prec=0.8438, rec=0.8265, f1=0.8335\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 112\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_name, last_epoch, epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    101\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    102\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 112\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=10, learning_rate=5e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr5e5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc44e0-edaa-4231-9f1f-d84caf01e592",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=1e-4, batch_size=16 (EPOCH 1, val_f1=0.2623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdbffa6e-f9c4-44fb-a28b-31bd5ecc5f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19095' max='19095' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19095/19095 3:50:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.901548</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.908638</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.957057</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.923322</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.934442</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=5, learning_rate=1e-4, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e4\")\n",
    "\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fff49-1ba1-4642-a1b1-51f366e31e9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=2e-5, batch_size=8 (EPOCH 3, val_f1=0.8575, test_f1=0.85072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4692839d-ee61-4ebb-9999-7eb5b5fa21f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/2837947494.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50505' max='76370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50505/76370 11:58:42 < 6:08:05, 1.17 it/s, Epoch 6.61/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7637</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.438154</td>\n",
       "      <td>0.878713</td>\n",
       "      <td>0.838978</td>\n",
       "      <td>0.848959</td>\n",
       "      <td>0.840268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15274</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357016</td>\n",
       "      <td>0.891044</td>\n",
       "      <td>0.853015</td>\n",
       "      <td>0.857961</td>\n",
       "      <td>0.855069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22911</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.542490</td>\n",
       "      <td>0.893510</td>\n",
       "      <td>0.857933</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.857463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30548</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.478209</td>\n",
       "      <td>0.887905</td>\n",
       "      <td>0.848656</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>0.851310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38185</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.670134</td>\n",
       "      <td>0.885999</td>\n",
       "      <td>0.849009</td>\n",
       "      <td>0.845102</td>\n",
       "      <td>0.846945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45822</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.671519</td>\n",
       "      <td>0.888017</td>\n",
       "      <td>0.847992</td>\n",
       "      <td>0.854826</td>\n",
       "      <td>0.851258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.9054, prec=0.8719, rec=0.8880, f1=0.8770\n",
      "[valid] acc=0.8787, prec=0.8390, rec=0.8490, f1=0.8403\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9380, prec=0.9154, rec=0.9203, f1=0.9176\n",
      "[valid] acc=0.8910, prec=0.8530, rec=0.8580, f1=0.8551\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9611, prec=0.9465, rec=0.9496, f1=0.9480\n",
      "[valid] acc=0.8935, prec=0.8579, rec=0.8575, f1=0.8575\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9740, prec=0.9634, rec=0.9674, f1=0.9654\n",
      "[valid] acc=0.8879, prec=0.8487, rec=0.8541, f1=0.8513\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9843, prec=0.9790, rec=0.9786, f1=0.9788\n",
      "[valid] acc=0.8860, prec=0.8490, rec=0.8451, f1=0.8469\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9898, prec=0.9853, rec=0.9868, f1=0.9861\n",
      "[valid] acc=0.8880, prec=0.8480, rec=0.8548, f1=0.8513\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 104\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     93\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     94\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    100\u001b[0m )\n\u001b[1;32m    102\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=10, learning_rate=2e-5, batch_size=8, output_dir=\"./deberta-v3-crisis/batchsize8\")\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.9054, prec=0.8719, rec=0.8880, f1=0.8770\n",
    "# [valid] acc=0.8787, prec=0.8390, rec=0.8490, f1=0.8403\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9380, prec=0.9154, rec=0.9203, f1=0.9176\n",
    "# [valid] acc=0.8910, prec=0.8530, rec=0.8580, f1=0.8551\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9611, prec=0.9465, rec=0.9496, f1=0.9480\n",
    "# [valid] acc=0.8935, prec=0.8579, rec=0.8575, f1=0.8575\n",
    "\n",
    "# test_loss = 0.577634871006012\n",
    "# test_accuracy = 0.8872800692241131\n",
    "# test_precision = 0.8469312572131958\n",
    "# test_recall = 0.855374024799894\n",
    "# test_f1 = 0.8507208362474484\n",
    "# ============================= OVERFITTING =====================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9740, prec=0.9634, rec=0.9674, f1=0.9654\n",
    "# [valid] acc=0.8879, prec=0.8487, rec=0.8541, f1=0.8513\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9843, prec=0.9790, rec=0.9786, f1=0.9788\n",
    "# [valid] acc=0.8860, prec=0.8490, rec=0.8451, f1=0.8469\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9898, prec=0.9853, rec=0.9868, f1=0.9861\n",
    "# [valid] acc=0.8880, prec=0.8480, rec=0.8548, f1=0.8513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "818e1317-f3df-4e54-8a22-b99b795abba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:121: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0023, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 124.2977, 'test_samples_per_second': 139.464, 'test_steps_per_second': 2.18}\n",
      "[test] acc=0.8872800692241131, prec=0.8469312572131958, rec=0.855374024799894, f1=0.8507208362474484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.577634871006012,\n",
       " 'test_model_preparation_time': 0.0023,\n",
       " 'test_accuracy': 0.8872800692241131,\n",
       " 'test_precision': 0.8469312572131958,\n",
       " 'test_recall': 0.855374024799894,\n",
       " 'test_f1': 0.8507208362474484,\n",
       " 'test_runtime': 124.2977,\n",
       " 'test_samples_per_second': 139.464,\n",
       " 'test_steps_per_second': 2.18}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-22911\")\n",
    "# [test] acc=0.8872800692241131, prec=0.8469312572131958, rec=0.855374024799894, f1=0.8507208362474484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0685b9f-94a6-49ba-9847-d5d27c436e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.37746426463127136, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8849149120276897, 'test_precision': 0.8430869630919547, 'test_recall': 0.8545599129431753, 'test_f1': 0.8482132493443325, 'test_runtime': 125.0236, 'test_samples_per_second': 138.654, 'test_steps_per_second': 2.168}\n",
      "test_loss = 0.37746426463127136\n",
      "test_accuracy = 0.8849149120276897\n",
      "test_precision = 0.8430869630919547\n",
      "test_recall = 0.8545599129431753\n",
      "test_f1 = 0.8482132493443325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 125.0976, 'test_samples_per_second': 138.572, 'test_steps_per_second': 2.166}\n",
      "test_loss = 0.577634871006012\n",
      "test_accuracy = 0.8872800692241131\n",
      "test_precision = 0.8469312572131958\n",
      "test_recall = 0.855374024799894\n",
      "test_f1 = 0.8507208362474484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.49717429280281067, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8831843092010384, 'test_precision': 0.8392270903901514, 'test_recall': 0.8564725619023125, 'test_f1': 0.8473071372190685, 'test_runtime': 125.1699, 'test_samples_per_second': 138.492, 'test_steps_per_second': 2.165}\n",
      "test_loss = 0.49717429280281067\n",
      "test_accuracy = 0.8831843092010384\n",
      "test_precision = 0.8392270903901514\n",
      "test_recall = 0.8564725619023125\n",
      "test_f1 = 0.8473071372190685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.6949165463447571, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8830689356792616, 'test_precision': 0.842145954123632, 'test_recall': 0.8472896061789302, 'test_f1': 0.8445861775113469, 'test_runtime': 128.6307, 'test_samples_per_second': 134.766, 'test_steps_per_second': 2.107}\n",
      "test_loss = 0.6949165463447571\n",
      "test_accuracy = 0.8830689356792616\n",
      "test_precision = 0.842145954123632\n",
      "test_recall = 0.8472896061789302\n",
      "test_f1 = 0.8445861775113469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.715135395526886, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8819728872223824, 'test_precision': 0.836460218016704, 'test_recall': 0.8544100282915196, 'test_f1': 0.8450040779020537, 'test_runtime': 125.2994, 'test_samples_per_second': 138.349, 'test_steps_per_second': 2.163}\n",
      "test_loss = 0.715135395526886\n",
      "test_accuracy = 0.8819728872223824\n",
      "test_precision = 0.836460218016704\n",
      "test_recall = 0.8544100282915196\n",
      "test_f1 = 0.8450040779020537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.715135395526886,\n",
       " 'test_model_preparation_time': 0.0013,\n",
       " 'test_accuracy': 0.8819728872223824,\n",
       " 'test_precision': 0.836460218016704,\n",
       " 'test_recall': 0.8544100282915196,\n",
       " 'test_f1': 0.8450040779020537,\n",
       " 'test_runtime': 125.2994,\n",
       " 'test_samples_per_second': 138.349,\n",
       " 'test_steps_per_second': 2.163}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-7637\")\n",
    "# {'test_loss': 0.4593863785266876, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8740698009806749, 'test_precision': 0.8326252068193959, 'test_recall': 0.8500324417218078, 'test_f1': 0.8369876991837396, 'test_runtime': 123.8232, 'test_samples_per_second': 139.998, 'test_steps_per_second': 2.189}\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-15274\")\n",
    "# {'test_loss': 0.37746426463127136, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8849149120276897, 'test_precision': 0.8430869630919547, 'test_recall': 0.8545599129431753, 'test_f1': 0.8482132493443325, 'test_runtime': 125.0236, 'test_samples_per_second': 138.654, 'test_steps_per_second': 2.168}\n",
    "# test_loss = 0.37746426463127136\n",
    "# test_accuracy = 0.8849149120276897\n",
    "# test_precision = 0.8430869630919547\n",
    "# test_recall = 0.8545599129431753\n",
    "# test_f1 = 0.8482132493443325\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-22911\")\n",
    "# {'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 125.0976, 'test_samples_per_second': 138.572, 'test_steps_per_second': 2.166}\n",
    "# test_loss = 0.577634871006012\n",
    "# test_accuracy = 0.8872800692241131\n",
    "# test_precision = 0.8469312572131958\n",
    "# test_recall = 0.855374024799894\n",
    "# test_f1 = 0.8507208362474484\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-30548\")\n",
    "# {'test_loss': 0.49717429280281067, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8831843092010384, 'test_precision': 0.8392270903901514, 'test_recall': 0.8564725619023125, 'test_f1': 0.8473071372190685, 'test_runtime': 125.1699, 'test_samples_per_second': 138.492, 'test_steps_per_second': 2.165}\n",
    "# test_loss = 0.49717429280281067\n",
    "# test_accuracy = 0.8831843092010384\n",
    "# test_precision = 0.8392270903901514\n",
    "# test_recall = 0.8564725619023125\n",
    "# test_f1 = 0.8473071372190685\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-38185\")\n",
    "# {'test_loss': 0.6949165463447571, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8830689356792616, 'test_precision': 0.842145954123632, 'test_recall': 0.8472896061789302, 'test_f1': 0.8445861775113469, 'test_runtime': 128.6307, 'test_samples_per_second': 134.766, 'test_steps_per_second': 2.107}\n",
    "# test_loss = 0.6949165463447571\n",
    "# test_accuracy = 0.8830689356792616\n",
    "# test_precision = 0.842145954123632\n",
    "# test_recall = 0.8472896061789302\n",
    "# test_f1 = 0.8445861775113469\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-45822\")\n",
    "# {'test_loss': 0.715135395526886, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8819728872223824, 'test_precision': 0.836460218016704, 'test_recall': 0.8544100282915196, 'test_f1': 0.8450040779020537, 'test_runtime': 125.2994, 'test_samples_per_second': 138.349, 'test_steps_per_second': 2.163}\n",
    "# test_loss = 0.715135395526886\n",
    "# test_accuracy = 0.8819728872223824\n",
    "# test_precision = 0.836460218016704\n",
    "# test_recall = 0.8544100282915196\n",
    "# test_f1 = 0.8450040779020537"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fae6d-678a-45ed-b0c7-d1b8ab081f2f",
   "metadata": {},
   "source": [
    "### Learning and Validation Curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3306b97e-c319-4e42-94eb-c2ed962a53e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.44441157579421997, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.8876261897894433, 'test_precision': 0.8431801450425511, 'test_recall': 0.8625945973329592, 'test_f1': 0.8524425110946661, 'test_runtime': 126.022, 'test_samples_per_second': 137.555, 'test_steps_per_second': 2.15}\n",
      "[test] acc=0.8876261897894433, prec=0.8431801450425511, rec=0.8625945973329592, f1=0.8524425110946661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.44441157579421997,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.8876261897894433,\n",
       " 'test_precision': 0.8431801450425511,\n",
       " 'test_recall': 0.8625945973329592,\n",
       " 'test_f1': 0.8524425110946661,\n",
       " 'test_runtime': 126.022,\n",
       " 'test_samples_per_second': 137.555,\n",
       " 'test_steps_per_second': 2.15}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model\n",
    "# learning_rate=5e-6, batch_size=16 (EPOCH 7, val_f1=0.8603, test_f1=0.85244) => BEST\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f05f654d-04d8-4061-9a6b-c06908ef9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = [0.8673, 0.8927, 0.9095, 0.9274, 0.9351, 0.9393, 0.9436,\n",
    "            0.9444, 0.9589, 0.9723]\n",
    "best_model_val_f1 = [0.8440, 0.8568, 0.8580, 0.8568, 0.8580, 0.8584, 0.8603,\n",
    "          0.8505, 0.8533, 0.8518]\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.8983, prec=0.8618, rec=0.8756, f1=0.8673\n",
    "# [valid] acc=0.8816, prec=0.8414, rec=0.8494, f1=0.8440\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9174, prec=0.8843, rec=0.9019, f1=0.8927\n",
    "# [valid] acc=0.8908, prec=0.8504, rec=0.8638, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9314, prec=0.9065, rec=0.9128, f1=0.9095\n",
    "# [valid] acc=0.8935, prec=0.8584, rec=0.8579, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9448, prec=0.9269, rec=0.9279, f1=0.9274\n",
    "# [valid] acc=0.8927, prec=0.8597, rec=0.8541, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9510, prec=0.9316, rec=0.9389, f1=0.9351\n",
    "# [valid] acc=0.8936, prec=0.8566, rec=0.8598, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9532, prec=0.9325, rec=0.9467, f1=0.9393\n",
    "# [valid] acc=0.8924, prec=0.8516, rec=0.8659, f1=0.8584\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9569, prec=0.9386, rec=0.9489, f1=0.9436\n",
    "# [valid] acc=0.8942, prec=0.8557, rec=0.8651, f1=0.8603\n",
    "# ============================= OVERFITTING ======================================\n",
    "# [EPOCH 8]\n",
    "# [train] loss=0.1480, acc=0.9574, prec=0.9391, rec=0.9508, f1=0.9444\n",
    "# [valid] loss=0.4439, acc=0.8864, prec=0.8488, rec=0.8546, f1=0.8505\n",
    "# ================================================================================\n",
    "# [EPOCH 9]\n",
    "# [train] loss=0.1104, acc=0.9689, prec=0.9530, rec=0.9652, f1=0.9589\n",
    "# [valid] loss=0.4663, acc=0.8887, prec=0.8475, rec=0.8598, f1=0.8533\n",
    "# ================================================================================\n",
    "# [EPOCH 10]\n",
    "# [train] loss=0.0928, acc=0.9791, prec=0.9701, rec=0.9744, f1=0.9723\n",
    "# [valid] loss=0.6590, acc=0.8893, prec=0.8514, rec=0.8523, f1=0.8518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e5bd818-577e-44d9-9fec-4d5cad0c8b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(train_f1s, val_f1s):\n",
    "    N = len(train_f1s)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(train_f1s, label=\"Train\")\n",
    "    # plt.plot(val_f1s, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\", fontsize=16)\n",
    "    plt.plot(range(1, N+1), train_f1s, label=\"Train\")\n",
    "    plt.plot(range(1, N+1), val_f1s, label=\"Validation\")\n",
    "    plt.axvline(x=7, color='red', linestyle='--', linewidth=1.5) # , label=\"overfitting threshold\")\n",
    "    plt.xticks([i for i in range(1, N+1)], fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n",
    "    plt.title(\"Transformer (Deberta-V3) Learning Curve\", fontsize=18)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"pretrained_transformer_f1_score_curve.png\")\n",
    "\n",
    "plot_learning_curve(best_model_train_f1, best_model_val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07447846-6f37-4387-9a74-ca0066315c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAqE9JREFUeJzs3XlYVOXbB/DvmRlmWGfYBAEVFDfELXcTxSWXtMw209S0UtsXzSyzWMQ0Lc3S96eVaaaZZVrua4r7blKCC4o7Ivu+Dpz3D5wjI+swwAzw/VwXl3DOc57nPuPMwD3PJoiiKIKIiIiIiIiIqpzM1AEQERERERER1VVMuomIiIiIiIiqCZNuIiIiIiIiomrCpJuIiIiIiIiomjDpJiIiIiIiIqomTLqJiIiIiIiIqgmTbiIiIiIiIqJqwqSbiIiIiIiIqJow6SYiIiIiIiKqJky6iYiIiIiIiKoJk24ioip06NAhDBs2DA0aNIBcLocgCBgxYoSpw6rTcnNz4e3tDZVKhVu3bpk6HKonhgwZAkEQsG/fPlOHUilBQUEQBAF9+/Y16JyxddeECRMmQBAETJgwwSTtExE9jEk3EVWKIAiV/vrpp59MHX61OH78OPr374/t27cjISEBjo6OcHV1hYODg6lDq9MWL16MqKgoTJw4EY0bN9Y7d/369RKfg5aWlnBxcUGbNm0watQoLFy4EHfu3KnWOENDQ0t9TahUKjRq1AhPPPEE1q1bB1EUS63HkNdaUFBQhR4PuVwOe3t7dOnSBR999BFu3rxZ7jUV/QoNDa2yx3DSpEkQBAFOTk7Iycmp8HXNmzeHIAgYPny4dCwyMhJffPEFnnvuOfj6+sLFxQUWFhbS4zBjxgzcvn271Dp1j+20adNQUFBg8L20bNkSgiDgiSeeqPA1N2/ehEwmgyAIWLhwocFt1nahoaEICgqqs79DHrZjxw5MnjwZvr6+cHR0hIWFBZycnNCtWze8//77OHHihKlDJKIKUpg6ACKqnVxdXUs8np6ejoyMjDLLWFlZVVtcprRo0SJotVr06tULmzdvhqOjo6lDqvMSExMxe/ZsqFQqzJgxo8yyarVaeu7l5+cjOTkZcXFxuHDhAn777TdMnz4dL7zwAr755hs4OztXa9wODg5QKpXSz0lJSbhz5w7u3LmDbdu24aeffsKmTZugUqlKrcPGxga2trZltlPW+aKPR15eHhITE3HmzBmcOXMG//d//4f169fj8ccfh1wuL/W1nJKSguzsbMhkMjRo0KDEMkXv01ivvvoqli9fjsTERGzatAkjR44s95oDBw7g6tWr0vU6mzZt0nvOKJVK2NraIjk5WXocFi9ejDVr1pQ4WqVHjx4YPHgwdu3ahTVr1uCll14y6F5eeeUVzJgxAzt37sTdu3fh5uZW7jUrV66EKIqwsLDAuHHjDGrPEM7OzmjVqhWaNGlSbW1URmhoKIKDg+Hv719mL7abmxtatWpVocfUHF2+fBljxozB6dOnpWNyuRwajQYpKSk4deoUTp06hW+++Qb9+vXD77//Xu3vWURkJJGIqAoFBgaKAMT6+PbSpk0bEYC4ePFiU4dSb8ydO1cEID733HMlnr927Zr0fFy5cmWx89HR0eKGDRvExx9/XCrn7u4uXrt2rcpj3b9/v9TG/v379c4VFBSIkZGR4osvviiVmTNnTon16M4HBgYaHENZj0dGRoa4cuVK0d7eXgQgajQaMSEhocz6xo8fLwIQPT09DY6lsnSvsyFDhlSovC5GV1dXMS8vTzq+detWcfbs2eL+/fv17jMrK0vcuHGj6O3tLQIQraysxKioqBLr/vPPP0UAoq+vr8H3ER0dLSoUChGA+MUXX5RbvqCgQGzatKkIQHz22WcNbu9huvdqf39/o+uqqbqrM2ZzcfLkSek1aGNjI86YMUMMCwsTCwoKRFEUxfz8fDE8PFz8/PPPRVdXVxGA+M8//5g2aCIqF4eXExFVkczMTABl9y5S1RFFET/88AMAYOzYsZWqw83NDc888wy2b9+O3377DRYWFoiOjsawYcOg1WqrMtwyCYKA5s2b4+eff0bLli0BAH/99VeNtQ8A1tbWmDBhAr799lsAhb3Yf/zxR43GUBG63urdu3eXOfwbANLS0qR7eOmll6BQPBjgN2zYMMycORN9+/bVG5ViaWmJp59+Gtu3bwcAZGVlYe3atSXWP3ToUDg6OiI8PBxHjhwx6D7c3Nzw+OOPAyjswS7P/v37ce3aNQCFveRU9yQkJOCZZ55BcnIy3N3dceLECcyZMwft27eHIAgAAJlMhjZt2uCTTz5BVFQUJk+eLJ0jIvPFpJuIalTReZ6xsbGYOnUqWrZsCWtra70/HLKysrB582ZMmjQJHTt2RIMGDaBSqeDu7o4RI0Zgx44dpbbx008/QRAEeHl5AQDOnDmDkSNHws3NDSqVCs2aNcPUqVORlJRUah0nTpzAmDFj0LRpU1haWsLGxgaenp7w9/dHSEiI3h/7unu6fv06AODll1/Wm9OqO65z9epVvPHGG2jRogWsrKygVqvRqVMnzJo1C6mpqSXGU3Q+MAD8888/GDNmDBo1agQLCwtpwaKH7/3QoUN48skn4eLiAhsbGzzyyCP48ccf9eretm0bBg4ciAYNGsDa2hpdu3bFb7/9Vupjo/PPP//glVdegbe3N6ytrWFra4sOHTrg008/RXx8fInXPLzA0oYNGzBo0CC4uLhAJpMVm4Nclr179yIqKgr29vZS8mKMkSNHYs6cOQCAiIgIrFq1qtSylbn3ipDL5WjXrh2AwqkapjBkyBDp+/Dw8ErXY8xruCzjxo2DhYUFCgoKyvw/AoDffvtNmu5iaKLasmVLaT2G0pJ7pVKJZ599FgDw/fffG1Q/8OADhEuXLpWbtK9YsQIA4OHhgcGDBwMAYmNjsWLFCjzzzDPw8fGBRqOBlZUVmjdvjokTJ1b6/68iC6Ht2LEDAwcOhL29vfT8nz9/PvLy8sqsOyUlBevWrcOYMWPQrl07ODo6wtLSEp6ennjxxRdx/PjxYtfo1hUIDg4GUDhloKy1QiqykFpoaCief/55eHh4QKVSwdnZGQMGDMDKlSuRn59focfl77//lhbOtLS0hI+PD4KDg5GdnV3mY1Ca+fPnS8+1X3/9Fb6+vmWWt7a2xnfffSe9ZwDFfweUpOg6DQ//fnr4+v3792PEiBFwc3ODXC7HhAkTsHHjRgiCAKVSWe77Xe/evSEIAiZOnFji+b/++gsjRoyAu7s7lEolHBwc0KdPHyxbtqzc5xJRrWLqrnYiqlvKG16uO/fDDz9IQ+MsLS1FOzs7vWtWrlwplcX9IZ7W1tZ6xz744IMS29Bd6+npKf7yyy+ihYWFNFxWJpNJ1/v6+oppaWnFrv/pp59EQRCkciqVSlSr1XptFx2a6+rqKrq6ukp1q9Vq6Zirq6t48+ZNqexvv/0mqlQqqR47Ozu9nxs3bixGREQUi6no0OQ//vhDuie1Wi1aWlpKwy2L3vsPP/wgymQyURAEUaPR6MX/8ccfi6IoigEBASIAUSaTFSuzdOnSUv+fAwIC9B4ja2trUalUSj+7ubmJZ8+eLXZd0eGhU6dOFQGIgiCIDg4OolwuN2jItO76wYMHl1qmvOHlD8vKyhKdnZ1FAGLv3r1LLFPZey9reLlOfn6+2KpVKxGA+PTTT5dYRldHVQ8v14mNjZXKvPXWW2XWV9bwcmNew+V59tlnRQBi8+bNyyz36KOPigDEXr16GdzG+fPnpTi//PLLUsutXr1aBCC6uLgY3EZeXp7YsGFDEYD46quvllouJSVFtLKyEgGIM2fOlI7rHn/dl1qtloas6967/vjjjxLrLGuodnnDuIu+zwMQ7e3tpXb79Okjzpgxo9y6dV+2trZ674GCIIjffPON3jU3b94UXV1dRRsbGxGAaGFhofce6+rqKq5bt67Y4zJ+/PgS458yZYpee/b29qJcLpeO9e/fX0xNTS3zcZk/f74oCIJ0fdH3hH79+olarbbEtkuTl5cnvQcPGDDAoGuLKvo7oDRF3wcenkpT9PpvvvlGui+NRiNaWFiI48ePF3NyckRHR0cRgLhkyZIy29FdHxoaqncuLS1NfOKJJ4o9f4s+jj179hQTExMr/VgQmRMm3URUpSqadNva2oqtWrUS//77bzE/P18URVG8dOmSVO7PP/8UJ0+eLO7fv1+Mj4+XjkdHR4vBwcFS0rlp06Zibej+aLC2thZVKpU4ceJEKfHNyMgQlyxZIl3/2Wef6V2bkZEhfQAwduxY8cqVK9K59PR08fTp0+KHH34obtu2rVi7np6eZSYzZ86ckdrt1auXGBYWJopiYaK1efNm0c3NTQQgent7F/swoGjCZmtrKw4dOlS8cOGCdP7y5cvF7l2pVIrvvvuuGBsbK4qiKCYkJEh/jMpkMnHevHmiXC4XZ8+eLSYnJ0uP75AhQ0SgcD6h7nhRX3/9tfSBwdy5c8W7d++KoiiKWq1WPH36tNi/f38RgNioUaNi96F7ftja2ooAxOnTp0vxZWdni9evXy/xsStJly5dSvw/LMrQpFsURXHkyJEiAFGpVIpZWVlVdu/lJd1Xr14Vx40bJwIQ5XK5ePDgwRLjq+6ke9WqVVKZBQsWlFlfWUm3Ma/h8mzfvl2K8cCBAyWWuXjxolTmxx9/rFC9eXl54q1bt8SffvpJbNKkiQhAdHBwEOPi4kq95vLly1I7RV+TFTV9+nTpOZWenl5imWXLlkkJYtH3pKCgIPHTTz8V//nnH+na/Px88fz58+KYMWOk1/GdO3eK1VnZpHvTpk3S/T7//PPSe2tmZqb4f//3f6JSqZTmJJd0/dKlS8UpU6aIx48fF5OSkkRRLJyvHhUVJb733nuiIAiiXC4v90O7spSVdC9evFiKf/LkydJrOD09Xfz666+lDw9eeOGFUtu3t7cXZTKZOGPGDOm5kZKSIn2IachzTufYsWPStWUlsuWpqqTb0tJSlMvl4oQJE6T/Y61WKz3/3njjDRGA2L1791LbCQkJkWLRzUnXGTFihPTB2dq1a6UPObKyssRNmzaJzZo1EwGII0aMqMSjQGR+mHQTUZWqaNKtVqvFW7duVbqdL7/8stQegaI9bKX1dOh6SR/uKTtx4oT0h2rRRZcqorykW5fMNm/eXMzIyCh2/uzZs9IffA/3rBVN2Lp161ZqL0rRe584cWKx81qtVlqMCYA4e/bsYmVSUlKkHqXVq1frnYuLixOtra1FQRDEvXv3lhhDXl6e2LlzZxGA+PXXX+udK/r8mDp1aonXV0ROTo7UM1VaT54oVi7p/vzzz6VrIiMjpePG3nvR/0MHBwe9XjpdT59cLhcHDRpUak+4KD54DdnY2BTr7Xv4q+goi/Iej4yMDPGnn36SEiaVSiVGR0eX+VgZs5BaWa/h8uTn54uNGjUq8zWuS2ZtbW1LHNFSlG50wcNfbdq0kT4cK4vuQ6QVK1YYfC9FPxwo7TnarVs3EYDYt29fg+oeNmyYCEAMCQkpdq6ySbduITt/f3/pA9OidB8QVCQ5Lslbb70lAiX3/BubdGdmZko9tKNHjy7x2m+//VaK/9SpUyW2X9aHXs8884wIQHzsscfKjPFhy5cvl+o+cuSIQdcWVVVJNwDxmWeeKbWOoh8SFP3AvCjd6+rTTz/VO75161YRgNiwYUPx9u3bJV5769Yt6fcQF4qjuoBzuonIJMaNG4dGjRpV+vphw4YBAI4dO1bq/DsA+PTTT0s8/tRTTwEArly5Ii2ABgD29vYAgNzcXCQkJFQ6voclJydj165dAIAPP/wQ1tbWxco88sgjeOaZZwAUzucrzYcffgi5XF5umx9//HGxY3K5HAMGDABQuGDU+++/X6yMWq1Gz549AQD//vuv3rlffvkFmZmZ6NKli1TPwxQKBUaPHg0A0j0/TCaT4aOPPir3HkoTGxsr/b+XtlVVZRVdVCsxMVH6vqruHSjcIuzevXvSl27P6fz8fCQmJlZoz/CMjAy9Okr6Kuu18d5776Fhw4Zo2LAhnJycYGNjgwkTJiA5ORkWFhZYtWpVtW65VNHXcElkMhnGjx8PAPjjjz+KzX/Pz8/H6tWrAQAvvPBCuYsbNmjQAK6urlCr1dKx9u3bY/HixWjfvn258Tg5OQEAoqOjDboPAGjVqhV69eoFoOQF1SIiInDy5EkA+lueVYTuMT58+LDBcZXk33//RUREBIDC91aZrPifkZMmTYKHh0el26jqmIvas2eP9Joubf2IN998U3rel/Y+rFKpMG3atBLP6X63PPzeWZ6iv2/MZbvJsrZh7NGjB1q0aAEA0mutqJMnT+LSpUsAUGx7u+XLl0vHS3uuNGrUCP369QNQ9nspUW3BpJuITEL3R2ZZ7t27h8DAQPTs2RNOTk5QKBTS4i9t2rQBULhieGkLojk6OqJ58+YlnnN3d5e+L3q9t7c3Wrdujby8PHTv3h3z5s3DuXPnDE4KHnb27FmIoggAeOyxx0otN3DgQACFf7CVtohMRR47R0dHeHt7l3hOt+dymzZtYGNjU2aZhx9b3R/C58+flxK2kr5mzZoFALhx40aJ9Tdv3hwuLi7l3kdp4uLipO+r+g9U3f/Tw6rq3oHCxYnEwtFmEEUReXl5iIqKwhdffIHz589j7NixJX5oUlRgYKBeHSV9lbWYUmpqqpScF/1woUmTJvj333/xwgsvlNl+RRj7Gi7LK6+8AkEQkJGRUWzhvx07duDu3btSufIcOnQIMTExSElJQUJCAn788UckJCRgwIABePXVV8tdyV73HCz6vDSELpk+ePAgrly5ondOt4CaRqORFm0rKiwsDG+++Sbat28PtVoNmUwmPcZvvvkmgNIXgjOUbt9ohUKB3r17l1hGJpOVuQAbAERFRWHatGno3Lkz7O3tIZfLpZiHDh1apTEXpYu/cePG0i4BD5PL5ejfv79e+Yf5+vqW+kGO7ndL0ddURRR93zGH1citrKzQqVOnMsvokuk1a9YUe9/UJeLdu3cv9ljr3ku///77Mt9L9+7dC6Ds91Ki2oJJNxGZRHkJ17Fjx9C6dWvMmjULx48fR2JiIqysrODi4gJXV1c4OztLZXWrEz/Mzs6u1PqLbh1UNLmVy+VYt24dmjZtihs3buDjjz/GI488ArVajYEDB2Lp0qV6PeMVFRsbK31fVi+Qrvdfq9WW+kdbRZLVitx7Rco8nPjrevKysrLK7GHVrcJe2mNlTMINQG91YJVKZVRdDyuaAOp6MIGqu/eSKBQKNG3aFB999BHmz58PAJg3bx4OHDhQFbdUopUrV0rJeUpKCvbv349evXrh5s2bePnll41ePb2yr+Hffvut1D/Cjx49KpVr1qyZlNzpElMd3c+tW7fGo48+alDcjo6OeOWVV3DkyBHY2tpixYoVWLZsWZnXWFlZAUClV60eOXKk9Hos2tut1WqxZs0aAMDo0aOldnSWLFmCTp06YenSpfjvv/+Qnp4OjUYDV1dXvZ770t4jDaV7H3N2di7zdVfWKKY///wTbdq0wYIFC3D27FmkpKTA1tZWel7oVoyvqpiL0sVfXk+8Lv6i79tFVeS909AtB4u+HqpylFVlOTk5lTiSoahx48ZJK6AXHZmQl5eHdevWASjcqq+ovLw8acXzlJSUMt9Lda+nyvzOJTI3TLqJyCTKGh6t1WoxevRoJCcno2PHjti+fTtSU1ORlpaGe/fuISYmRm9bmdJ6JiurQ4cOuHjxIjZs2IDJkyejbdu2yMrKwt69e/Hmm2+idevW+O+//6q0zZKU1ttRkaHl1UXX4//666+X28sqimKx7Wh0jL2HoslwZXpJyxIWFgagMJkv+sd5Vd17eV599VXp/76saQZVSa1Wo2/fvti9ezd8fX1x/PhxvP3225Wuz5jXcFkfauTm5uq1o+shPnr0qDSUNT4+Hlu3btU7Xxmenp7SdI/ytgPTfUBW9HlpCBsbG2lkwc8//4yCggIAhdv53bt3D0Dxe7lw4QLef/99FBQU4Pnnn8fJkyeRnZ2NpKQkxMTEICYmBgsXLgRQ9e+Rle2JTUhIwIQJE5CTk4P+/fsjNDQUmZmZUvIVExOD9evXV2msJalo/DXZ41x0e7B//vmnxtotTUXeo728vODn5weg8Hmrs3PnTsTHx0OpVGLUqFF61xQdNbZu3boKvZcW3Q6OqLZi0k1EZufYsWO4ceMG5HI5tm7discff7xYz0JMTEy1xqBUKvHMM8/gu+++w3///Ye4uDgsW7YMjo6OuHXrljSftKKK9uyWNWxSd06hUEg9PuakYcOGAFAjHzqUpeg8bkOHcZYlOzsb+/btA1A4Z9HS0lI6V1P3bm1tLfV6Xbt2rVrbKqntxYsXAwBWrVql17NsCGNewxMmTCj1j++Hhy0/++yz0joMuh7i1atXIy8vDwqFothcUkPpPnS5evVqmeV0z0Fj1hfQJdW3b9/G7t27ATzosW/Xrh26dOmiV/6PP/5Afn4+fHx8sG7dOnTt2hVKpVKvTFW/T+rex+Li4qR1CEpS2poEug9fHBwcsGXLFvj7+xfrva/O93Zd/Ldu3SqznO59uKrXiyhLly5doNFoABSOBqgsXU97WaMuUlJSKl3/w3Q92evXr5fa1A0tHzp0aLHpP5aWltJ9mvr3CFFNYtJNRGZH9wdRgwYNSh0GqJvrVVOcnJzw2muvYd68eQAKeyIMGQLYqVMnaaje33//XWo53X116NABFhYWRkRcPXTzyY8fP27SeXYODg5SEhwVFVVl9S5ZskQa+jhhwgS9czV179nZ2dJzq7Q599WpX79+8Pf3B4BKL3ZXU69hS0tLvPjiiwAKe9ry8/Ol5PuJJ56Q1iaoLN1zq6yF2NLS0qTnjI+PT6Xb6tGjhzTPfcWKFbh37x62b98OoOQee91j3KFDh1KHAVf1+6Qu8ddqtaUudFZQUIDQ0NASz+libtWqVYmLSQJlx6y7z8r23Oviv337Ni5fvlximfz8fOzfvx8A0LVr10q1UxkKhQKTJ08GUPg74uDBgxW+VjcyAoD0YW1sbGypH4ycOHHCiEj1jRw5EpaWlkhJScGWLVukf4HiQ8t1dO+l69ev14udqC5j0k1EZkf3KbhuSOnDbt++jW+//bZa2i6r9waAXq+MIUOk7e3tMXjwYADAl19+WeIctbCwMGzYsAEApBWwzc24ceNgZWWF/Px8vPXWW2UuMFdQUIDk5ORqi6VPnz4AIK3sbKz169fjk08+AQC0bdsWY8eO1TtfU/e+bt066Q/Rh3s3a8rMmTMBFC54tGfPHoOvr8nXsC4hvXv3LkJCQqTes/KGlpc35zYiIgKbNm0CgDIXBjt9+jQKCgqgUCgqtMhhWXQxb968GYsWLYJWq4VSqSz2XASg11tYUhK6Y8eOUpPfymrfvr30wcLnn39eYsK0YsWKUkfz6GK+fPlyiT2x586dw9q1a0ttXzdHvbKvrYEDB0pTAEpbvfy7776T1m+o6ffh6dOnSwuxjR49GuHh4WWWz8rKwptvvqnXY9yhQwcAhR9MlNRjnpWVha+//rrKYlar1dKK7T///LPU4+3o6CitRP8w3YcLly9fxpdffllm/RkZGcWmlRDVRky6icjs+Pn5wcbGBqIoYuTIkVKPRH5+Pnbt2oW+fftW21y7devWoVevXvjuu+/0elB1betWlO7Zs6c0rLWiPv/8c1hYWODKlSsYPHiw9IdSQUEBtm/fjqFDh0Kr1cLb2xuvvfZald1TVWrYsCG++OILAIXzTQcOHIgjR45ICagoirh48SIWLlyItm3bSnNrq4MuETKm1yYmJgYbN27EsGHDMHLkSOTl5cHDwwNbt27VW2wPqP57z8jIwKpVq/Dee+8BKPxj1pg5ycYYOHCg1Mv32WefGXx9Tb6GO3XqhI4dOwIAQkJCAABubm54/PHHy7yuVatWWLhwIS5evKiXPMbGxmLp0qXw9/dHdnY2VCpVmY+B7vnXqVOncrcmK8+4ceNgYWGBnJwcaUG9p556qsS54kOGDAEAhIeH46233pKGuGdkZOC7777Dc889V+k55mX5/PPPARSuwP/iiy9KCXZ2djaWLVuGt99+u9T3xkGDBkEmkyExMRFjxoyRhqHn5ubi999/x6BBg8pcpKxt27YACu+5MlMfrKyspGT7119/xeuvvy59KJSZmYnFixdL2yi+8MIL6Ny5s8FtGMPZ2RkbNmyAWq1GdHQ0unfvjk8++QTnz5+XPljRvc/Mnz8f3t7eWLp0qd6HLo0aNZLmWU+dOhV79+6V3qPOnDmDxx57rNQF4ipLN41j586dWLJkCYDCx+/h6Q46Tz31FJ5++mkAhVtbvvHGG3ojD3Jzc3HixAl89NFH8PT0rPJ4iUyiCvb6JiKSBAYGigDE0t5edOf2799fZj1Lly6VygIQbW1tRUtLSxGA6OzsLG7evFk6d+3aNb1rV65cKQIQPT09S63/2rVrJV6vu1b3pVKpRCcnJ1Emk0nH3N3dxQsXLhSr09PTUwQgrly5stR2161bJyqVSqkutVot3RcAsXHjxmJERESx6/bv31/m42rIvev+j/z9/UstM378eBGAOH78+BLPz58/X5TL5VJMSqVSdHJyEi0sLPQevzVr1hjcdkXdu3dPeiwvX75cYpmi/89qtVp0dXUVXV1dxQYNGuj9PwAQ5XK5OG7cODEhIaHMdit770X/Dx0cHKRYXF1diz3HHB0dS32N6MrY2Njo1VHS19NPP13q41HW81QURfHPP/+Uym7durXEMrrnSUnPN2New4ZavHixXlsff/xxudcULa9QKEQnJyfRzs5O73iDBg3EXbt2lVlPz549RQDiokWLjLoHnWeffVYvhp07d5ZadtSoUXpl7e3tpedm586dpcelpP+fsl6L5b1OZ86cqdeug4ODqFAoRABi7969xRkzZpR6/UcffaR3rUajkV47TZs2FX/55ZdS3+vy8vLEVq1a6bXr6ekpenp6iuvXr5fKlff+NWXKFKkOQRD04gcg9uvXT0xNTTX4cRHFir9XlyUiIkLs1KlTseeoo6OjXpwAxMGDB4vx8fF61//zzz96z2VLS0vRxsZGBCC6urqK27ZtM+r358Py8vJEV1dXvbiOHTtW5jUZGRnFnr82Njaig4OD3nshAPH27dsVjoXIXLGnm4jM0uuvv45t27ahb9++sLW1hVarhYeHB9555x2EhYWhXbt21dLu8OHD8fPPP+Pll19Ghw4doNFokJKSAjs7O3Tr1g0hISEIDw9H69atK1X/Cy+8gPDwcLz22mvw9vZGTk4OFAoFOnbsiODgYJw/f96oeaE15cMPP8TFixcxZcoUtG/fHpaWlkhOToatrS26du2K6dOn4+jRo9J82+rg4uKCESNGAAB++eWXcssX3Zc6JSUFarUaPj4+eOGFF7Bw4ULcvHkTP//8c7n7flfFvSclJemtyp2cnAyNRoOePXti1qxZuHjxYrl7HWdkZJS53c7D+28b6qmnnpJ6FgMCAgy+viZfw2PGjNFb9K4ie3Nv2bIFU6dORY8ePeDm5iYNY3V3d8egQYOwaNEiXL58GYMGDSq1jmvXruHYsWOwsrIqdf6qoYqObmjcuDEGDhxYatlffvkFixYtQvv27aFSqZCfn4927dph7ty50pZn1WH27NnYunUr+vfvD7VajZycHPj4+OCLL77A33//XWoPJwB88cUX+Pnnn9GtWzdYWVkhLy8PzZs3xyeffIJ//vlHGl5dEoVCgb///hsTJ06El5cXMjIycOPGDdy4ccOgLe4WLlyIffv24dlnn4WrqyvS09NhZ2eHfv36YcWKFdizZ0+ZPe7VzcfHB2fOnMHWrVvx6quvonXr1rC1tUVqairUajW6du2KKVOm4MyZM9i5c2exEQ0dO3bEyZMnMWrUKLi4uKCgoADOzs546623cO7cOWntgKqiUCj0huK3aNECPXr0KPMaa2tr/Prrr9i/fz/GjRuHZs2aoaCgAOnp6XBxcUH//v0xf/58REZGlrvFG1FtIIhiFe8jQUREVEMOHjwIf39/eHt7IzIyska3+CGaNWsWAgMD8fLLLxfbK5yIiEiHSTcREdVqgwcPxu7du/Hbb79h5MiRpg6H6omMjAx4eXkhLS0Nly5dgqenp6lDIiIiM8Xh5UREVKt99dVXkMlkmDVrFrefoRqj217u3XffZcJNRERlUpRfhIiIyHy1a9cOP/74I65fv467d+9y/h/VCBsbGwQFBUmrXRMREZWGw8uJiIiIiIiIqgmHlxMRERERERFVEw4vN2MFBQWIjo6GnZ0dV+QlIiIiIiIyI6IoIi0tDe7u7pDJSu/PZtJtxqKjo9G4cWNTh0FERERERESluHXrFho1alTqeSbdZszOzg5A4X+iWq02cTRERERERESkk5qaisaNG0t5W2mYdJsx3ZBytVrNpJuIiIiIiMgMlTcVmAupEREREREREVUTJt1ERERERERE1YRJNxEREREREVE1YdJNREREREREVE2YdBMRERERERFVEybdRERERERERNWESTcRERERERFRNWHSTURERERERFRNmHQTERERERERVRMm3URERERERETVRGHqAIiIiOqK/AIRJ68lIjYtGy52lujW1BFymWDqsIiIiMiEmHQTERFVgZ3n7yJ4SwTupmRLx9w0lgh8sg2GtHUzYWRERERkShxeTkREZKSd5+/ijTVn9RJuAIhJycYba85i5/m7JoqMiIiITK3WJN2nTp3C0KFD4eDgABsbG3Tr1g1r1641qI7k5GQEBASgffv2sLOzg7OzM7p27YolS5YgOzu71Ov+/PNPDBw4EE5OTrCyskLTpk0xevRo3Lp1q1jZ1NRUTJ06FZ6enlCpVPD09MTUqVORmppq8D0TEZH5yy8QEbwlAmIJ53THgrdEIL+gpBJERERU19WK4eWhoaEYPHgwlEolRo0aBY1Gg40bN2LMmDG4fv06Pvnkk3LrSE5ORufOnREVFQU/Pz+89tpryMnJwY4dO/DOO+/gzz//xJ49eyCTPfgcQhRFvP766/j+++/h7e2NUaNGwc7ODtHR0Thw4ABu3LiBxo0bS+UzMjLg7++Pc+fOYeDAgRg9ejTCwsLw9ddfY//+/Th8+DBsbGyq5TEiIqLqkZmrRXxaLuLScxB//yshPVf6Pio2o1gPd1EigLsp2Vhz/AZGdmkMK6W85oInIiIikxNEUTTrj961Wi1at26N27dv49ixY3jkkUcAAGlpaejZsycuXbqEiIgItGjRosx65s+fj48++ghTpkzBwoULpeO5ubnw8/PDqVOncODAAfTp00c69+233+K9997DW2+9hW+++QZyuf4fSlqtFgrFg88tAgMDMWvWLEyfPh3z5s0rdjwgIADBwcEVvvfU1FRoNBqkpKRArVZX+DoiIiqdKIpIzdYWJs1pOYi/n0AnpOcgrkgyXXg+F1l5+VXWtkwAvBvYop2HBr4eGrR1V8PXQwNbVa34DJyIiIiKqGi+ZvZJ9+7duzF48GC8/PLLWLFihd653377DaNGjcKMGTMwZ86cMut5/fXX8d1332HPnj147LHH9M7NnDkTc+bMwfr16/Hcc88BALKystCoUSPY29vj0qVLesl1SURRRKNGjZCamoqYmBi9Hu3s7Gy4u7vD2toat27dgiBUbCVbJt1ERBVTUCAiKTNXSqDj03MQl5aDhIzc+4l10eQ6F7n5BQbVr1LI4GyrgrOdCg1slYXf26rgZKtEUkYuvt13pdw61JYWSM3OK3ZcEICmTjbw9dCgnYcabd018HXXQGNtYVCMREREVLMqmq+Z/UfroaGhAIBBgwYVO6c7duDAgXLr8fX1BQDs3LlTL+nOy8vD3r17YWVlhZ49e0rH9+zZg8TEREyYMAH5+fnYvHkzLl++DHt7ezz22GNo3ry5Xv2RkZGIjo7G4MGDiw0ht7S0RJ8+fbBp0yZcuXKl3F55IiIC8vILkJiRi7iHkuZ4XTJ9P7GOT89FYkYODJ0ybadSwKlIAu1sp7yfSOsn1s52Ktgo5aV+YJpfIGL9mduISckucV63AKChxhKHP+qPhPQc/HcnBefvpOJ8dArO30nB3ZRsRMVnICo+A1vCoqXrmjhao62HGr7uGrTz0KCthwaONkrDbpKIiIhMzuyT7sjISAAoMVF1cHCAs7OzVKYsEydOxOrVq7FgwQKcPn0aXbt2RU5ODnbu3ImkpCSsXbsWHh4eUvnTp08DABQKBTp06IBLly5J52QyGaZMmYKvvvqqQnEWPR4ZGVlqmZycHOTk5Eg/c/E1IqprsvPyHyTQaUWGcesN6y78PjmzeK9weRysLeBkq4JzkaS5gZ0KTjZKKYHWnbO0qJq51XKZgMAn2+CNNWchAHqJty5ND3yyDeQyAS5qSwxQW2KAj6tUJj49B+HRqTh/pzAJPx+dgluJWbiZmImbiZnY/l+MVNZdY4m29xPwth5qtPXQwMXOskrug4iIiKqH2SfdKSkpAACNRlPiebVajdu3b5dbj5WVFUJDQ/Haa69hzZo1Uu+4TCbD22+/DT8/P73ysbGxAIAFCxagU6dOOHnyJHx8fPDPP/9g8uTJWLBgAby9vfHGG29UOM6i5Uoyd+5cg+Z8ExGZmiiKSM/RIj49Fwm6Yd1FEuqEh5Lp9BytQfXLZQIcbZRwslGigd39nueHhnfrEmtHGyUs5KbZlGNIWzcsHdup2D7dDSuwT7ezrQr+LRvAv2UD6VhyZu6DRPz+v9fiMxCdko3olGzsjrgnlXWxUz1IxN0LE3E3jWWFpzIRERFR9TL7pLuqxMfH46mnnkJsbCy2bduGXr16ITs7G5s3b8YHH3yArVu34vTp03BwcAAAFBQUzvdTKpX466+/4O7uDgDo3bs3/vjjD7Rv3x4LFiyQku6qMGPGDEydOlX6OTU1VW91dCKimiCKIpIz80rogS5cWCwhQz+xztEaNj9aKZcVJs7FeqD1E2pnWyUcrJWQyWpH8jikrRsGtmmIk9cSEZuWDRc7S3Rr6gh5JeK3t1aiV3Nn9GruLB1Ly85DRHQq/ruTIiXkV+PSEZuWg30XY7HvYqxU1slGKS3Uphua3sjBiok4ERGRCZh90q3rOS6th1g3eb08U6dOxdGjRxEWFob27dtLdU+aNAn5+fl44403sGjRIqmnWVdnly5dpIRbx9fXF82aNcOVK1eQnJwMe3v7CsVZtN6SqFQqqFSqcu+FiMhQ2vwCJGbmSkmzLoEu7JnW75FOSM+F1sAJ0tZKuZQoO+mGdd9PrJ1t7yfX979XWyrqbPInlwno6e1ULXXbWVqgezMndG/2oP7MXC0u3E3F+Tup9+eKpyAyNh0JGbk4eDkOBy/HSWU1VhaFQ9LdH6yc7uVkU2s+1CAiIqqtzD7pLjoXunPnznrnkpKSEB8fj0cffbTcerZt2wZHR0cp4S6qf//+AIAzZ85Ix1q1agUAsLe3L7E+3fGsrCzY29vrxVmS8uZ8ExEZKkebX2z4dtFkuujw7sTMXBi6V4XaUlFKD7RK6ql2tilcgMxaafa/Tuoka6UCnT0d0dnTUTqWnZePizFpOH8nBeHRKfjvTgouxaQhJSsPR64k4MiVBKmsrUqBNu6FiXi7RoX/NmtgW6neeSIiIiqZ2f+V5O/vj7lz52L37t0YNWqU3rndu3dLZcqTm5uL7Oxs5ObmQqnUX/01Lq6wJ6BoL3O/fv0AABcuXChWV15eHq5cuQIbGxs0aFA4B69FixZwd3fHkSNHkJGRUWzLsIMHD8Ld3b3YqudEREVl5moRn5aLuPSS5kTfT6gzClfwTs02bH60IACO1rrh3PdX6rZ58H2DIvOknWyVUCmqZqExqlmWFnJ0bGyPjo3tpWO52gJcvpcmLdR2/k4qLtxNRXqOFievJeLktUSprJWF/H4irr6/jZkGzV1sTTZfnoiIqLYz+6R7wIABaNasGdauXYt3330XHTt2BACkpaUhJCQECoUCEyZMkMrHx8cjPj4ezs7OcHZ+MBeuV69e2LVrF0JCQhASEiIdz8nJkX7WJdoA4O3tjUGDBmH37t1Yvnw5Jk6cKJ374osvkJycjLFjx0r7dwuCgIkTJ2LWrFmYNWsW5s2bJ5WfO3cukpKS8M4779TZIZVEVDJRFJGarZW2uopPvz+8O+3+vOiHkuvM3HyD6lfIBP1tr4r2StvpLzjmaK2EgolTvaRUyKTF1nS0+QW4EpdeuH3Z/aHpEXdTkZmbjzM3knDmRpLe9T4N7Yos2KZBy4a2/GCGiIioAgRRNHTAYc3bv38/Bg8eDJVKhdGjR0OtVmPjxo24du0aZs+ejZkzZ0plg4KCEBwcjMDAQAQFBUnHz507hz59+iAtLQ3dunWTFlLbtWsXoqKi0LlzZxw+fBiWlg+2Xrl69SoeffRRxMbGYtiwYWjdujX++ecf7Nu3D56enjh+/DgaNmwolc/IyICfnx/OnTuHgQMHonPnzggLC8OOHTvQsWNHHD58uNge3mWp6GbrRFSzCgpEJGXmlrjNVfxDe0onpOciN9+whcZUCpm0uFiDElbqLlytW3l/frQF5+RSlckvEHEtPkNv+7LwO6lIK2HVeQu5gJaudmjrrkHbRoVzxH3c1FW2FRsREZG5q2i+ViuSbgA4efIkAgMDcezYMeTm5sLX1xfvv/8+xowZo1eutKQbKJxXPXfuXPz999+4e/cuFAoFmjdvjueeew7Tpk2DtbV1sXZv3bqFgIAA7Ny5EwkJCWjYsCGGDx+OgIAAuLi4FCufkpKC4OBg/PHHH4iJiUHDhg3x3HPPITAwsEILvhXFpJuo5uTlFyAxIxdxRZLmhIcS6rj7PdWJGTkwcJ0x2KkU+j3SuuHdtvqJtbOdCjZKOUfFkNkoKBBxMzET5+/PDw+/v2hbSlbxfdTlMgEtXGzh6164j3g7Dw183NSwUZn9wDoiIiKD1bmkuz5i0k1knOy8/AdJc1pO8V7pIt8nZxZPIMrjYG1xf6Xuoj3QD2+DVfg9e/+oLhFFEbeTshB+f364buX0hIzcYmUFAWjmbCNtXebrroGvhxpqSwsTRE5ERFR1mHTXAUy6ifSJooiM3Hy9BFq3X3ThPGn9ZDq9hCGxZZHLBDjaKOFko0SDElbt1vVUN7BTwdFGyYWliIoQRRH3UnOkBFy3cvq91JwSy3s5Wd/fuqxwsTZfdzUcbJQlliUiIjJHTLrrACbdVB+IoojkzDwkZOQgLk1/pW7d4mJxRXqqc7SGzY9WymVF9o4u2gP98DZYSjhYKzk/mqiKxaZlIzw6FedvP1g5/U5yVollPeyt7veIP1g53dlWVWJZIiIiU2PSXQcw6abaKr9ARELGQ9tdSQl18cRaa+AEaWulXEqUnXTDunX7RtveH959/3u1pYLzo4nMTGJGrjQ0vTART8GNhMwSyzZUW6Kth1paNb2thwauahVf10REZHJMuusAJt1kTnK0+UhIzy3S+/wgmU7I0E+sEzNzYeg7i9pSUUoP9P2f7VRwvr+ntLWSizIR1TUpWXmIiE4tspd4CqLiM0p8L3G2VRUm4veT8LYeanjYWzERJyKiGsWkuw5g0k3VLTNXi/i0XMSl59xfqVu/F7roNlip2YbNjxYEwNFaf79oJ5sH3zcoMk/ayVbJ/X6JqJj0HC0u3C1MxHUrp0fGppW4e4CDtYW0UJtu5fQmjtZMxImIqNow6a4DmHSToURRRGq2VkqUEzIeJM1x0r7RD5LpzNx8g+pXyAT9ba/05knrLzjmaK2EgguNEVEVy8rNx4WYVITfebBy+uV7aSVOU7GzVMDXXa23cnozZxuu3UBERFWCSXcdwKSbgMI9cpMyc0vc5kq3uFhCxv2FxjJykWvgQmMqhUxaXKxBCSt1F67Wrbw/P9qCf6wSkdnJ0ebjckx64crp0SkIv5OCCzFpJb4f2ijlaOOuhu/9VdPbemjg3cCGHxISEZHBmHTXAUy66668/AIkZuQiLk1/le6iCXXc/Z7qxIxc5Bu40JidSqHfI60b3m2rn1g726lgo5Rz+CUR1Tl5+QWIvJcuzQ8/fycFEXdTkZ1XPBG3tJDBx003R7wwIW/pagelgok4ERGVjkl3HcCku3bJzst/kDTr9o1Of5BY684lpOcgKTPP4PodrC30t726v1+0k03RbbAKv7e04PxoIqKH5ReIiIq73yN+f+X0iOhUpOcUX7NCKZehVUM7vZXTWzW04/srERFJmHTXAUy6TUsURWTk5ktDuHX7RScU2wKrsKc6rYQ/2soilwlwtFHCyUaJBg+t2l00uW5gp4KjjRIWHPpIRFTlCgpEXE/IwHndyun3v0paPFIhE9DC1Q5t3e8n4h4atHFTw0rJRJyIqD5i0l0HMOmueqIoIiUr7/7wbf2kuWhireupLmkYYlmUclmRvaOL9kA/vA2WEg7WSs6PJiIyQ6Io4lZiljQ0/b87KQiPTkViRm6xsjIB8G5gi3YeGvh6aNDWXQ1fDw1sVRXf2jC/QMTJa4mITcuGi50lujV1hJy/H4iIzB6T7jrAnJNuc/oDIb9ARGLGQ1tdpeUiPkO/N1qXXJe0wm1ZrJVyKVF20g3r1u0bbXt/ePf979WWCs6PJiKqg0RRxN2U7Ae94dGFK6fHpeWUWL6Zsw18PTRod38/cV93DTTWFsXK7Tx/F8FbInA3JVs65qaxROCTbTCkrVu13Q8RERmPSXcdYK5Jd038gZCjzS9MpO8nzXEl9EjrziVm5sLQZ7HaUlFKD/T9n+1UcL6/p7S1suK9FUREVL/EpmbjfHQK/rudKq2cHl3k92NRTRytpYXa2nlocC81G9P/+BcP/wrTfXS7dGwnJt5ERGaMSXcdYI5J987zd/HGmrOV+gMhM1eLhPTcwgQ6rci2V/eT6Tgpmc4pcS5dWQQBcLTW3y/ayebB9w2KbIPlZKuESsH5d0REVD0S0nOkOeLh0YXD028lZhlcj7OtEmsn9YDGygK2KgWsudsEEZFZYdJdB5hb0p1fIMJv3j69Hu6Hqa0UeKmHJxIy8h4sOHY/uc7MzTeoPYVM0N/2Sm+etP5+0o7WSu6xSkREZislM09KwM9Hp+L0tUTcTS3992lJBAGwUSpgo5LDVqWArUoBm/tfdkW+t71/3qZIGVvLIt/fr4O/N4mIjMOkuw4wt6T72NUEjP7huFF1qBQyaXGxovtFO+ltg6W8Pz/agguNERFRnbTp3B28t+5cueUsLWTI1RbAwOVIKsTSQvYgcVc+lJiXlLjrJfpy2KksYKOSw0algEohYy88EdU7Fc3XOFmVKiw2rWKfyPdq7oSuXo5wstVPrJ3tVLDh0DgiIiK42FlWqNzKCd3Qo5kjsvLykZ6jRUZOPjJytEjL1iIjR4uMXC3Sc7RIv/9z+v3z6fe/Hv4+IycfufmFO3Nk5xUgOy8X8enFV2U3lEImwNbyfvJ+Pym3tbSArUp+v3deATvLh3vjLaRe+6K99RxGT0R1DZNuqrCK/oHwdr8W6OntVM3REBER1V7dmjrCTWOJmJTsYuukAIVrpTTUFO4OIggCrJWKwoU97YxvO0ebLyXvumQ8TUrKCxP39OwHCb3ueNr9Yxk5+VKin5VXOHVMWyAiOTMPyZl5RsenG0YvJe8l9rTfT+KV8gfnLIv3zNso6+YwenPaRYaIysekmyrMkD8QiIiIqHRymYDAJ9vgjTVnIQB6v1d1qVPgk22qJZFSKeRQKeRwtFEaXVd+gXg/ES9MwnW98Q/3tJfU466f6Bf+WyACogipbFXQDaMvmrDbqvSH0hc/9nA58xlGz23miGofzuk2Y+Y2pxt4sHo5UPIfCNzehIiIqOKYQD0gimK1DKOvShZy4cEceL3edXmxefH6C9w9WPxOd74yw+iN2UWGiKoeF1KrA8wx6Qb4BwIREVFV4lDh6lEdw+irkiDg/kryRZJyvXnxRZJ4pRxWSjnm7rhY6hB+3YjDwx/15/OHqIYw6a4DzDXpBvgHAhEREdUf1TGMvrr8OqkH19YhqiFcvZyqlVwm8A2diIiI6gW5TIDa0gJqSwtAY1xdlR1GHxWXjgsxaeXWX9HdZoio5jDpJiIiIiKqIZVdjf7Y1QSM/uF4ueUqutsMEdWcureHAhERERFRHaPbRaa0yXwCCtfY4S4yROaHSTcRERERkZnTbTMHoNTEu7q2mSMi4zDpJiIiIiKqBYa0dcPSsZ3QUFN8CHmv5k7cRYbITHFONxERERFRLTGkrRsGtmko7SKTlJGLoC0ROHI1Af/eTkb7RvamDpGIHsKkm4iIiIioFnl4F5lzt5Lx17loBGwKx8Y3HoWMQ8yJzAqHlxMRERER1WIzhvrARinHuVvJ2HD2tqnDIaKHMOkmIiIiIqrFXNWWeHdACwDAvJ0XkZqdZ+KIiKgoJt1ERERERLXcy72aolkDG8Sn52LRnkhTh0NERTDpJiIiIiKq5ZQKGYKe9AUArDp2HZfvpZk4IiLSYdJNRERERFQH9GnZAIN9XZFfICJwUzhEUTR1SEQEJt1ERERERHXGp8PaQKWQ4VhUArb/F2PqcIgITLqJiIiIiOqMxo7WeN3fGwAwe1sEMnO1Jo6IiJh0ExERERHVIW/09UYjByvcTcnG//ZfNXU4RPUek24iIiIiojrE0kKOT4e1AQB8fzAK1+MzTBwRUf3GpJuIiIiIqI4Z7OuK3i2ckZtfgJCtEaYOh6heY9JNRERERFTHCIKAwCd9oZAJ+PtiLPZdvGfqkIjqLSbdRERERER1UHMXW7zq1xQAMGtLBHK0+SaOiKh+YtJNRERERFRHvTOgBVzsVLiekInlh66ZOhyieolJNxERERFRHWWrUuCToT4AgCX7riA6OcvEERHVP0y6iYiIiIjqsKc6uqOrlwOy8vIxZ/sFU4dDVO8w6SYiIiIiqsMEQUDQcF/IBGDrv3dx9Gq8qUMiqleYdBMRERER1XG+7hqM6e4JAAjeHAFtfoGJIyKqP5h0ExERERHVAx8MagkHawtcupeG1cdvmDoconqDSTcRERERUT1gb63Eh4NbAwAW7rmM+PQcE0dEVD8w6SYiIiIiqide6NoYbT3USMvWYv7Oi6YOh6heYNJNRERERFRPyGUCgoe3BQD8fvo2/rmZZOKIiOo+Jt1ERERERPVIZ08HPNupEQAgcHM4CgpEE0dEVLcx6SYiIiIiqmc+erwVbFUK/Hs7Bb+fvmXqcIjqNCbdRERERET1jIudJd5/rAUAYP6uS0jJzDNxRER1F5NuIiIiIqJ6aPyjXmjhYovEjFx8vfeyqcMhqrOYdBMRERER1UMWchmChvsCAH4+dh0X7qaaOCKiuolJNxERERFRPdWruTOGtmuIArFwUTVR5KJqRFWNSTcRERERUT02c1gbWFrIcPJaIjaHRZs6HKI6h0k3EREREVE95mFvhbf6NgcAzNl+ARk5WhNHRFS31Jqk+9SpUxg6dCgcHBxgY2ODbt26Ye3atQbVkZycjICAALRv3x52dnZwdnZG165dsWTJEmRnZxcr7+XlBUEQSvx6/fXXi5UPCgoqtbylpWWl752IiIiIqDpN6tMMTRytcS81B4v3XTF1OER1isLUAVREaGgoBg8eDKVSiVGjRkGj0WDjxo0YM2YMrl+/jk8++aTcOpKTk9G5c2dERUXBz88Pr732GnJycrBjxw688847+PPPP7Fnzx7IZPqfQ2g0Grz//vvF6uvSpUupbY0fPx5eXl56xxSKWvFQExEREVE9ZGkhR8ATbTDx59P48XAURnZphGYNbE0dFlGdYPaZoFarxcSJEyEIAg4ePIhHHnkEABAYGIiePXsiMDAQzz//PFq0aFFmPd9//z2ioqIwZcoULFy4UDqem5sLPz8/7Nu3D4cPH0afPn30rrO3t0dQUJBBMU+YMAF9+/Y16BoiIiIiIlMa4OOCvq0aIPRSHIK3ROCnl7tCEARTh0VU65n98PJ9+/bh6tWrePHFF6WEGwDs7Ozw2WefQavVYuXKleXWExUVBQAYOnSo3nGlUomBAwcCAGJjY6swciIiIiKi2kMQBAQ+6QulXIYDl+Ow9wL/NiaqCmbf0x0aGgoAGDRoULFzumMHDhwotx5f38I9CHfu3InHHntMOp6Xl4e9e/fCysoKPXv2LHZdTk4OVq1ahTt37sDBwQGPPvooOnToUGZbhw4dwsmTJyGXy9G6dWs89thjUKlU5cZIRERERGRKTZ1t8GrvplgaehWztoajdwtnWFrITR0WUa1m9kl3ZGQkAJQ4fNzBwQHOzs5SmbJMnDgRq1evxoIFC3D69Gl07doVOTk52LlzJ5KSkrB27Vp4eHgUuy4mJgYTJkzQOzZkyBCsXr0azs7OJbYVEBCg97ObmxtWrVol9aiXJicnBzk5OdLPqamp5d4XEREREVFVertfc/x59g5uJWbh+4NReHdA2dM4iahsZj+8PCUlBUDhgmYlUavVUpmyWFlZITQ0FGPHjsWBAwfw1VdfYfHixdLQdT8/v2LXvPLKKwgNDUVcXBxSU1Nx/PhxPP7449i5cyeGDx8OURT1ynfs2BGrVq3C9evXkZWVhcjISISEhCA5ORnDhw9HWFhYmTHOnTsXGo1G+mrcuHG590VEREREVJVsVAp8MswHAPC/0Cu4nZRp4oiIajdBfDhzNDODBg3Cnj17EBkZiebNmxc77+3tjdu3b+v1EJckPj4eTz31FGJjY/HNN9+gV69eyM7OxubNm/HBBx+gQYMGOH36NBwcHMqsp6CgAP7+/jh8+DC2bt2KYcOGlXsPP/zwAyZPnoznnnsO69evL7VcST3djRs3RkpKCtRqdbntEBERERFVBVEUMer74zhxLRGPt22IpWM7mzokIrOTmpoKjUZTbr5m9j3duh7u0nqzdTdanqlTp+Lo0aPYsGEDhg4dCo1GA1dXV0yaNAnz589HVFQUFi1aVG49MpkML7/8MgDgyJEjFbqH8ePHQ6FQlFtepVJBrVbrfRERERER1TRBEBA03BdymYAd52NwODLe1CER1Vpmn3Tr5nKXNG87KSkJ8fHx5W4XBgDbtm2Do6Mj2rdvX+xc//79AQBnzpypUEy6udyZmRUbaqNUKmFnZ1fh8kREREREpubjpsa4Hp4AgKAt4cjLLzBxRES1k9kn3f7+/gCA3bt3FzunO6YrU5bc3FykpqYiNze32Lm4uDgAqPAK4ydOnAAAeHl5Vah8ZGQkkpKSKlyeiIiIiMgcTBnYEk42SlyJTceqo9dNHQ5RrWT2SfeAAQPQrFkzrF27FufOnZOOp6WlISQkBAqFQm918fj4eFy8eBHx8fpDYHr16gWtVouQkBC94zk5OdKxfv36SccjIiKQnJxcLJ7Dhw9j4cKFUKlUeOaZZ/Ti+ffff4uVT0pKwquvvgoAGD16dIXvm4iIiIjI1DRWFpg+pBUAYNHeSMSmZZs4IqLap0oWUhNFEfHx8YiLi0NWVhacnZ3RoEEDWFtbV0WM2L9/PwYPHgyVSoXRo0dDrVZj48aNuHbtGmbPno2ZM2dKZYOCghAcHIzAwEAEBQVJx8+dO4c+ffogLS0N3bp1kxZS27VrF6KiotC5c2ccPnwYlpaWUj3z58/HgAED4OXlBZVKhfPnz2P37t2QyWRYtmwZJk6cKNV//fp1NG3aFF26dEG7du3g4uKCO3fuYMeOHUhISMDAgQOxdetWKJXKCt93RSfmExERERFVl4ICEU//7wjCbqfgmU4eWDiyo6lDIjILFc3XKr1Pd2RkJH777TccPHgQx44dK3G+cosWLdC7d28MGjQII0aMgIWFRaXa6tevHw4fPozAwED8/vvvyM3Nha+vL0JCQjBmzJgK1dGxY0ecOXMGc+fOxd9//40lS5ZAoVCgefPmCA4OxrRp06SEW9fmhQsXcPbsWRw4cADZ2dlwdXXFCy+8gClTpqBbt2569Ts6OuKtt97C8ePHsWXLFiQnJ8PGxgbt2rXD2LFjMXHiRMjl8krdPxERERGRqchkAoKfaosR/3cEG8/ewZjuTdDZ09HUYRHVGgb3dK9fvx5LlizB4cOHAUDaq1omk0Gj0cDKygqJiYnIzn4w9EQQBDg6OuKll17C1KlT4eHhUYW3UHexp5uIiIiIzMX0P8Lw++nb8HVXY/PbfpDLBFOHRGRSVb5l2N9//42uXbti1KhROHToENq3b49PPvkEmzZtQnR0NPLy8pCQkIDbt28jMzMTWVlZOH36NP73v/9h9OjRyM3Nxddff42WLVtixowZpW4BRkRERERE5mf6kNaws1QgPDoV607dNHU4RLVGhXu6dT3Zb7zxBsaPH49WrVoZ1FBOTg62bNmCxYsX49ChQwgKCkJAQEClgq4v2NNNREREROZk5ZFrCN4SAXtrC+z/oC8cbCq+XhFRXVPlPd3BwcG4fv065syZY3DCDRRux/Xcc8/hwIEDOHDgAB555BGD6yAiIiIiItMZ18MTrVztkJyZhwV7Lpk6HKJaoUpWL6fqwZ5uIiIiIjI3x6MSMOr745AJwOa3/dDWQ2PqkIhMosp7uomIiIiIiHo0c8KTHdxRIAJBm8PBPjyislVp0p2VlYXz58/j2LFjOH/+PLKysqqyeiIiIiIiMgOfDG0NKws5Tt9Iwl/n7pg6HCKzViVJ965du9C3b19oNBp06NABfn5+6NChAzQaDfr374/du3dXRTNERERERGQG3DRWeLt/cwDAnO0XkZadZ+KIiMyX0Ul3UFAQhg4dioMHD0Kr1cLCwgLu7u6wsLCAVqtFaGgoHn/8cQQFBVVBuEREREREZA4m9m4KLydrxKXlYPG+K6YOh8hsGZV079y5E7NmzYJMJsObb76JS5cuITs7G7du3UJ2djYuXbqEN998E3K5HCEhIdi1a1dVxU1ERERERCakUsgR+KQvAGDF4Wu4Eptm4oiIzJNRSfe3334LQRCwYsUKLFmyBC1atNA736JFCyxZsgQrVqyAKIr45ptvjAqWiIiIiIjMR7/WLnjMxwXaAhHBWyK4qBpRCYzaMqxBgwawtrbGjRs3yi3r6emJjIwMxMfHV7a5eodbhhERERGRubuRkIGBXx9ErrYAy8Z2xpC2DU0dElGNqJEtw9LS0uDq6lqhsq6ursjIyDCmOSIiIiIiMjOeTjZ4rU8zAEDI1ghk5eabOCIi82JU0u3u7o6LFy+Wm0xnZGTgwoULcHNzM6Y5IiIiIiIyQ2/2bQ53jSXuJGdh2YGrpg6HyKwYlXQPHjwY6enpmDRpEnJzc0ssk5ubi4kTJyIzMxNDhgwxpjkiIiIiIjJDVko5Zg5rAwBYeuAqbiVmmjgiIvNh1JzuW7duoUOHDkhJSYGrqysmTZqENm3awMXFBbGxsYiIiMAPP/yAe/fuQaPRICwsDI0bN67K+Os0zukmIiIiotpCFEWMWX4CR68mYFAbV3z/UhdTh0RUrSqarxmVdAPAiRMnMHLkSNy6dQuCIBQ7L4oimjRpgt9//x3dunUzpql6h0k3EREREdUml++l4fFvDiG/QMSqV7rBv2UDU4dEVG1qLOkGgKysLKxduxa7d+/G5cuXkZ6eDltbW7Rs2RKDBw/G6NGjYWVlZWwz9Q6TbiIiIiKqbUK2RuDHw9fQzNkGO9/vA6XCqBmtRGarRpLugwcPAgB69uwJCwuLylZDpWDSTURERES1TWp2Hvp/dQDx6TmY8XhrvObvbeqQiKpFjWwZ1rdvX7z00ktMuImIiIiICACgtrTAx4+3BgB8+3ck7qVmmzgiItMyKul2cnJCw4YNqyoWIiIiIiKqA555xAOPNLFHRm4+5m6/YOpwiEzKqKS7S5cuuHLlCgoKCqoqHiIiIiIiquVkMgGzhreFIAB/nYvGyWuJpg6JyGSMSrqnT5+O5ORkzJ07t6riISIiIiKiOqBdIw1GdW0CAAjYdB7afHbUUf2kMOZib29vzJ49GwEBATh9+jTGjRsHHx8f2NjYlHpNkyZNjGmSiIiIiIhqiQ8Ht8L2/+7iYkwa1p68iZd6epk6JKIaZ9Tq5TKZDIIgQBTFEvfoLtaYIECr1Va2uXqHq5cTERERUW23+th1fLYpHBorC+yf1heONkpTh0RUJSqarxnV092kSZMKJdtERERERFQ/vdjdE2tP3sKFu6n4ctclzH2mnalDIqpRRiXd169fr6IwiIiIiIioLpLLBMx6yhfPLzuGdaduYnS3xmjfyN7UYRHVGKMWUiMiIiIiIipPVy9HjOjoDlEEAjeHo6Cg0jNciWodJt1ERERERFTtZgz1gY1Sjn9uJmPD2dumDoeoxhiVdB88eBD9+/fHd999V2a5ZcuWoX///jhy5IgxzRERERERUS3lqrbEuwNaAADm7byI1Ow8E0dEVDOMSrqXL1+OAwcOoGfPnmWW69mzJ0JDQ7FixQpjmiMiIiIiolrs5V5N0ayBDeLTc7FoT6SpwyGqEUYl3cePH4ejoyPat29fZrkOHTrAycmJPd1ERERERPWYUiFD0JO+AIBVx67j8r00E0dEVP2MSrrv3LkDLy+vCpX18vLCnTt3jGmOiIiIiIhquT4tG2BQG1fkF4gI3BQOUeSialS3GZV0K5VKpKVV7NOptLQ0yGRct42IiIiIqL777Ik2UClkOBaVgO3/xZg6HKJqZVQW3Lp1a0RGRuLy5ctllrt8+TIuX76Mli1bGtMcERERERHVAY0drfG6vzcA4PNtEcjM1Zo4IqLqY1TS/eyzz0IURbz00ktITk4usUxycjLGjx8PQRDw/PPPG9McERERERHVEW/09UYjBytEp2Tjf/uvmjocomojiEZMosjKykLnzp1x6dIluLi44NVXX0X37t1hb2+P5ORkHD9+HCtWrMC9e/fQunVrnDlzBlZWVlUZf52WmpoKjUaDlJQUqNVqU4dDRERERFSldp6PwetrzkApl2H3lD7wcrYxdUhEFVbRfM2opBsAbt26haeffhpnz56FIAjFzouiiC5dumDDhg1o3LixMU3VO0y6iYiIiKguE0URL604iUOR8RjQ2gU/Tuhq6pCIKqzGkm4AKCgowMaNG7Fp0yZcuHABqampsLOzg6+vL0aMGIERI0ZwEbVKYNJNRERERHXdldh0DFl0ENoCESsmdEH/1q6mDomoQmo06abqwaSbiIiIiOqDOdsv4PuDUfByssauKX2gUshNHRJRuSqar7H7mYiIiIiITOqd/s3hYqfC9YRMLD90zdThEFUpJt1ERERERGRSdpYWmDG0NQBgyb4ruJuSZeKIiKqOoioqOXToEH755ReEhYUhMTEReXl5JZYTBAFXr3I7ACIiIiIi0jeiowfWnriJU9eT8Pm2C1jyYidTh0RUJYxOut966y0sW7YMFZkaXtLq5kRERERERIIgIGi4L55cfBhb/72LMd0T0NPbydRhERnNqOHla9aswdKlS+Hj44O9e/eiS5cuEAQBkZGR2LdvH77++mt4enrCysoKy5YtQ1RUVFXFTUREREREdYyvuwYvdm8CAAjaHA5tfoGJIyIynlFJ9/LlyyEIAtatW4f+/ftDpVIBALy9vdG3b1+89957iIyMxLBhw/Duu+8iLi6uSoImIiIiIqK6adqgVnCwtsCle2lYffyGqcMhMppRSfe///6LJk2aoG3btgAeDB8vOtRcoVDghx9+gFwux+eff25Mc0REREREVMfZWysxbXArAMDCPZcRn55j4oiIjGNU0p2VlQUXFxfpZysrKwBAcnKyXjmNRoM2bdrg6NGjxjRHRERERET1wKiuTdDWQ420bC3m77xo6nCIjGJU0t2wYUMkJSVJP7u5uQEAIiIiipWNi4tDamqqMc0REREREVE9IJcJCB5eOJr299O3ce5WsmkDIjKCUUl3q1atEB0dLQ0n9/PzgyiKmDdvnt62YatXr8bNmzfRrFkz46IlIiIiIqJ6obOnA57t1AgAELjpPAoKyt8ticgcGZV0Dxs2DJmZmTh48CAAYNSoUXBzc8O2bdvQqlUrPP/88+jTpw8mTJgAQRDw+uuvV0nQRERERERU9330eCvYqhQIu52C9WdumTocokoxap/ukSNHIjU1FRYWFgAAW1tbbN26FSNHjsTVq1dx/fr1wkYUCrz//vt45513jA6YiIiIiIjqBxc7S7z/WAvM3nYB83ZewhBfN2isLUwdFpFBBLHoUuNVpKCgACdPnsT169dhZWWFHj16wNXVtaqbqfNSU1Oh0WiQkpICtVpt6nCIiIiIiGpcXn4BHv/mEK7EpmPCo14IGu5r6pCIAFQ8X6uWpJuqBpNuIiIiIiLgyJV4jFl+AjIB2PZub/i48W9jMr2K5mtGzekmIiIiIiKqbr2aO2Nou4YoEIHAzeFgvyHVJgbN6b5586bRDTZp0sToOoiIiIiIqH6ZOawN9l2Mxclridjy710M7+Bu6pCIKsSgpNvLywuCIFS6MUEQoNVqK309ERERERHVTx72Vnirb3Ms2HMZn2+LwIDWLrBRGbUuNFGNqNTwcplMVqkvYxJ2IiIiIiKq3yb1aYYmjta4l5qDJfuvmDocogqpVNLdtGlTBAQE4PLly8jLyzPoi4iIiIiIqDIsLeT47Ik2AIDlh6IQFZdu4oiIymdQ0v3XX3/h2Wefxe3btxEUFITmzZujd+/e+P7775GUlFRdMQIATp06haFDh8LBwQE2Njbo1q0b1q5da1AdycnJCAgIQPv27WFnZwdnZ2d07doVS5YsQXZ2drHyuuH0JX29/vrrJbaRmpqKqVOnwtPTEyqVCp6enpg6dSpSU1Mrdd9ERERERPTAYz4u6NuqAfLyRQRvieCiamT2KrVlWGpqKn7//XesXr0ahw8fBgBYWFhg2LBhGDt2LJ544glYWFTdpvWhoaEYPHgwlEolRo0aBY1Gg40bN+LatWv4/PPP8cknn5RbR3JyMjp37oyoqCj4+fmhe/fuyMnJwY4dO3D16lX0798fe/bsgUz24HMILy8vJCcn4/333y9WX5cuXfDEE0/oHcvIyICfnx/OnTuHgQMHolOnTggLC8POnTvRsWNHHD58GDY2NhW+b24ZRkRERERUXFRcOgYvOoi8fBE/vNQFA9u4mjokqodqbJ/uW7duYfXq1VizZg0uXrwIQRBgb2+PkSNHYsyYMfDz8zOmemi1WrRu3Rq3b9/GsWPH8MgjjwAA0tLS0LNnT1y6dAkRERFo0aJFmfXMnz8fH330EaZMmYKFCxdKx3Nzc+Hn54dTp07hwIED6NOnj3TOy8sLAHD9+vUKxRoYGIhZs2Zh+vTpmDdvXrHjAQEBCA4OruCdM+kmIiIiIirNvJ0XsTT0Kpo4WmP3lD6wtJCbOiSqZ2psn+7GjRvjk08+QUREBE6dOoV33nkHSqUS33//Pfz9/TFy5Eij6t+3bx+uXr2KF198UUq4AcDOzg6fffYZtFotVq5cWW49UVFRAIChQ4fqHVcqlRg4cCAAIDY2ttJxiqKI5cuXw9bWFgEBAXrnZsyYAQcHB/z4448c/kJEREREVAXe7tccDdWWuJmYiR8ORpk6HKJSGZ10F9W5c2csXLgQ3333HRo3bgxRFJGcnGxUnaGhoQCAQYMGFTunO3bgwIFy6/H19QUA7Ny5U+94Xl4e9u7dCysrK/Ts2bPYdTk5OVi1ahXmzJmDpUuXIiwsrMT6IyMjER0djV69ehUbQm5paYk+ffrgzp07uHKFqywSERERERnLRqXAJ8N8AAD/F3oFt5MyTRwRUcmqbGO706dPY82aNVi3bh3i4uIgiiKaNm2K5557zqh6IyMjAaDE4eMODg5wdnaWypRl4sSJWL16NRYsWIDTp0+ja9euyMnJwc6dO5GUlIS1a9fCw8Oj2HUxMTGYMGGC3rEhQ4Zg9erVcHZ2rlCcRY9HRkaWWiYnJwc5OTnSz1x8jYiIiIiodE+2d8Mvx2/gxLVEzNl+Af8b09nUIREVY1RP940bNzBnzhz4+Pige/fu+Pbbb5GXl4fJkyfj8OHDuHr1KiZPnmxUgCkpKQAAjUZT4nm1Wi2VKYuVlRVCQ0MxduxYHDhwAF999RUWL14sDV0vae75K6+8gtDQUMTFxSE1NRXHjx/H448/jp07d2L48OF6Q8UrEmfRciWZO3cuNBqN9NW4ceNy74uIiIiIqL4SBAFBw30hE4Dt/8XgyJV4U4dEVIzBSXdKSgp++OEH+Pv7w9vbG59++imuXbuGESNGYOPGjYiJicHSpUvx6KOPVke8lRYfH4+BAwfi+PHj2LZtG5KTkxETE4Nly5Zh5cqV6N69e7FtzwICAuDv7w9nZ2fY2dmhe/fu2Lp1K/z8/HDs2DFs3769SmOcMWMGUlJSpK9bt25Vaf1ERERERHWNj5saL/X0AgAEbg5HXn6BaQMieohBw8uff/55bN26Fbm5uQCARx99FOPGjcPIkSNhb29fHfFJPcel9RDrVowrz9SpU3H06FGEhYWhffv2Ut2TJk1Cfn4+3njjDSxatKjc1cVlMhlefvllHD58GEeOHMGwYcMqHGfRciVRqVRQqVTl3gsRERERET0w5bGW2BwWjSux6Vh19Dom9m5m6pCIJAYl3Rs2bIAgCGjVqhXGjBmDpk2bAoBBPb4vvviiQQEWnQvdubP+HI2kpCTEx8dXqFd927ZtcHR0lBLuovr37w8AOHPmTIVi0s3lzsx8sFhD0ThLUt6cbyIiIiIiqhyNtQU+GtIKH234D4v2RmJ4R3e42FmaOiwiAJVcSO3SpUvFtsWqKEOTbn9/f8ydOxe7d+/GqFGj9M7t3r1bKlOe3NxcZGdnIzc3F0qlUu9cXFwcAFS4l/nEiRMAHuzjDRQm0+7u7jhy5AgyMjL0VjDPzs7GwYMH4e7ujubNm1eoDSIiIiIiqrjnOzfG2hM3EXY7BfN2XMKCkR1MHRIRAAOT7j59+kAQhOqKpUQDBgxAs2bNsHbtWrz77rvo2LEjACAtLQ0hISFQKBR6q4vHx8cjPj4ezs7OequL9+rVC7t27UJISAhCQkKk4zk5OdLP/fr1k45HRETA3d292LD5w4cPY+HChVCpVHjmmWek44IgYOLEiZg1axZmzZqFefPmSefmzp2LpKQkvPPOOzX++BERERER1QcymYDgp9pixP8dwYazt/Fi98bo7Olo6rCIIIhFl+A2U/v378fgwYOhUqkwevRoqNVqbNy4EdeuXcPs2bMxc+ZMqWxQUBCCg4MRGBiIoKAg6fi5c+fQp08fpKWloVu3bujVqxeys7Oxa9cuREVFoXPnzjh8+DAsLS2leubPn48BAwbAy8sLKpUK58+fx+7duyGTybBs2TJMnDhRL86MjAz4+fnh3LlzGDhwIDp37oywsDDs2LEDHTt2xOHDh4vt4V0W3Xz1lJQUafVzIiIiIiIq3fQ/wvD76dto66HGprf8IJex04uqR0XzNaO2DKsp/fr1w+HDh+Hn54fff/8d//vf/+Dk5IQ1a9boJdxl6dixI86cOYOXX34ZMTExWLJkCX766SfY2NggODgYBw8elBJuXZtPPvkkLl68iFWrVuHbb79FeHg4XnjhBRw9erRYwg0ANjY2CA0NxZQpU3Dx4kUsWLAA58+fx5QpUxAaGmpQwk1ERERERIabPqQ17CwVOH8nFetO3TR1OES1o6e7vmJPNxERERGR4VYeuYbgLRGwt7bA/g/6wsFGWf5FRAaq8p7u27dvV0lgOtHR0VVaHxEREREREQCM6+GJVq52SM7Mw4I9l0wdDtVzFU66vb298cYbb+DGjRuVbqygoABr166Fr68vli9fXul6iIiIiIiISqOQyxA03BcAsPbETZy/k2LiiKg+q3DS/dRTT+G7776Dt7c3BgwYgOXLl1eotzovLw9Hjx7Fe++9Bw8PD4wbNw4pKSno3bu3UYETERERERGVpqe3E55o74YCEQjaHA7OqiVTMWhO96lTp/Dxxx9j//790tZXbm5u6Ny5M9zc3ODo6AiVSoXk5GQkJibiwoUL+O+//5CbmwtRFOHg4IBp06bh/fffh5WVVbXdVF3BOd1ERERERJV3NyUL/b86gKy8fHz9Qgc8/UgjU4dEdUhF87VKLaR28eJFfPfdd1i/fr1eb7cuES9apYWFBXr16oVXX30Vzz33HFQqlaHN1VtMuomIiIiIjPN/+6/gy12X0MBOhX0f+MPO0sLUIVEdUa1Jd1FXr17F0aNHcePGDcTHxyM7OxuOjo5wcXFBx44d0b17d/ZqVxKTbiIiIiIi4+Ro8zH464O4npCJyX2a4ZOhPqYOieqIGku6qfow6SYiIiIiMt7+i7F4+adTUMgE7Hy/D5q72Jo6JKoDqnzLMCIiIiIiotqoX2sXDGjtAm2BiOAtXFSNahaTbiIiIiIiqvMCnmwDpVyGQ5Hx2BV+z9ThUD3CpJuIiIiIiOo8TycbTO7TDAAQsjUCWbn5Jo6I6gsm3UREREREVC+82c8b7hpL3EnOwrIDV00dDtUTTLqJiIiIiKhesFYqMHNYGwDAsgNXcSsx08QRUX3ApJuIiIiIiOqNoe0a4lFvJ+RoCxCyNcLU4VA9wKSbiIiIiIjqDUEQEDTcF3KZgN0R93DgcpypQ6I6jkk3ERERERHVKy1d7TC+pxcAIHhzOHK1BaYNiOq0Kk26o6OjcerUKRw8eLAqqyUiIiIiIqpS7w9sAWdbJaLiM7DyyDVTh0N1WJUk3UuXLkWLFi3QuHFj9OjRA/3799c7/8EHH+DRRx/FzZs3q6I5IiIiIiIio6gtLfDRkNYAgG//jsS91GwTR0R1lVFJtyiKeOGFF/D2228jKioKXl5esLW1hSiKeuW6d++O48ePY+PGjUYFS0REREREVFWe7dQIjzSxR0ZuPuZuv2DqcKiOMirp/vHHH7F+/Xq0adMG586dw9WrV9G+ffti5YYNGwa5XI5t27YZ0xwREREREVGVkckEzBreFoIA/HUuGievJZo6JKqDjE66ZTIZ1q9fj3bt2pVazsbGBt7e3oiKijKmOSIiIiIioirVrpEGo7o2AQAEbg5HfoFYzhVEhjEq6Q4PD0ezZs3QunXrcss6ODjg7t27xjRHRERERERU5T4c3AoaKwtcuJuKtSdumDocqmOMSroLCgqgUqkqVDY1NbXCZYmIiIiIiGqKo40SHwxqCQD4avdlJGbkmjgiqkuMSrqbNm2KK1euID09vcxyMTExuHTpEnx8fIxpjoiIiIiIqFq82K0JfNzUSMnKw5e7Lpk6HKpDjEq6hw8fjpycHAQEBJRZ7oMPPoAoinj66aeNaY6IiIiIiKhaKOQyBA/3BQCsO3UT/95ONm1AVGcYlXRPmzYN7u7u+Oabb/D8889j586dyM4u3N/u2rVr2Lx5Mx577DH8+uuvaNq0Kd58880qCZqIiIiIiKiqdWvqiBEd3SGKhYuqFXBRNaoCgvjwptoGCg8Px1NPPYWoqCgIglDsvCiKaNasGbZt24ZWrVoZ01S9k5qaCo1Gg5SUFKjValOHQ0RERERU591LzUb/r0KRkZuPr57vgOc6NzJ1SGSmKpqvGdXTDQC+vr74999/8c0338Df3x+Ojo6Qy+XQaDTo2bMnvvrqK4SFhTHhJiIiIiIis+eqtsS7A1oAAL7YcQGp2XkmjohqO6N6um/evAkAaNSoEWQyo/N3egh7uomIiIiIal6utgBDvjmIqLgMvOrXFJ890cbUIZEZqpGebi8vL3Tv3t2YKoiIiIiIiMyKUiFD4JOFi6r9dPQ6Lt9LM3FEVJsZlXRrNBp4enqyl5uIiIiIiOoU/5YNMKiNK/ILRARtDoeRS2FRPWZUttyuXTtpiDkREREREVFd8tkTbaBSyHD0agK2/xdj6nColjIq6X7vvfcQExODFStWVFU8REREREREZqGxozVe9/cGAHy+LQKZuVoTR0S1kVFJ97PPPosvvvgCb731FqZMmYKzZ88iKyurqmIjIiIiIiIyqTf6esPD3grRKdlYGnrV1OFQLWTU6uVyudywxgQBWi0/Haoorl5ORERERGR6O8/H4PU1Z6CUy7Bnah94OtmYOiQyAzWyerkoigZ9FRQUGNMcERERERFRjRvs64reLZyRm1+AkK0Rpg6Hahmjku6CggKDv4iIiIiIiGoTQRAQ+KQvFDIBey/EYv/FWFOHRLUI9/oiIiIiIiIqR3MXW7zi1xQAELwlHDnafBNHRLUFk24iIiIiIqIKeKd/czSwU+F6QiaWH7pm6nCollBUVUWhoaHYvXs3Ll++jLS0NNjZ2aFly5YYPHgw/P39q6oZIiIiIiIik7CztMAnQ1tjym9hWLLvCp7p5AE3jZWpwyIzZ9Tq5QBw/fp1vPjiizhx4gSAwsXVpMoFAQDQs2dPrFmzBl5eXsY0Ve9w9XIiIiIiIvMiiiKeX3YMp28k4ckO7lg8+hFTh0QmUtF8zaikOykpCZ06dcKNGzegVCrx7LPPwtfXF66urrh37x7Cw8OxYcMG5ObmwsvLC2fOnIGDg0Nlm6t3mHQTEREREZmf8OgUPLn4MApE4NdJPdDT28nUIZEJVDRfM2p4+bx583Djxg34+flh3bp1cHd3L1bmyy+/xKhRo3DkyBHMnz8fc+fONaZJIiIiIiIik/J11+DF7k2w5vhNBG0Ox7Z3/aCQc7ksKplRz4xNmzZBpVLhjz/+KDHhBgB3d3esX78eFhYW+PPPP41pjoiIiIiIyCx8MLAV7K0tcOleGlYfv2HqcMiMGZV037hxA23btoWLi0uZ5VxdXdG2bVvcvHnTmOaIiIiIiIjMgoONEh8ObgUAWLjnMuLTc0wcEZkro5JulUqF5OTkCpVNTU2FSqUypjkiIiIiIiKzMaprE7T1UCMtW4v5Oy+aOhwyU0Yl3e3bt0dUVBT27dtXZrl9+/bhypUr6NChgzHNERERERERmQ25TEDwcF8AwO+nb+PcrWTTBkRmyaike9KkSRBFEc888wwWL16MrKwsvfOZmZn49ttv8eyzz0IQBEyaNMmoYImIiIiIiMxJZ09HPNPJAwAQuOk8CgqM2pGZ6iCj9+keM2YMfv31VwiCAEtLSzRp0gQuLi6IjY3FzZs3kZ2dDVEUMWbMGKxevbqq4q4XuGUYEREREZH5i03LRv+vDiA9R4t5z7bDC12bmDokqgEVzdeMXtf+l19+wbfffotGjRohKysLly5dwqFDh3Dp0iVkZWWhcePGWLx4MRNuIiIiIiKqk1zsLPH+Yy0AAPN3XkJKZp6JIyJzYnRPd1EXLlzA5cuXkZ6eDltbW7Rs2RI+Pj5VVX29w55uIiIiIqLaIS+/AI9/cwhXYtMx4VEvBN2f6011V0XztSpNuqlqMekmIiIiIqo9DkfGY+yPJyATgG3v9oaPG/+Gr8tqbHg5ERERERERAX4tnPF424YoEIHAzeFg/yYBRibdq1atglwux6xZs8osFxISArlcjrVr1xrTHBERERERkVmbOcwHlhYynLyWiC3/3jV1OGQGjEq6f/vtNwiCgMmTJ5dZ7tVXXwUArFu3zpjmiIiIiIiIzFojB2u82bc5AODzbRHIyNGaOCIyNaOS7vDwcLi7u6Nhw4ZllnN3d4eHhwf+++8/Y5ojIiIiIiIye5P7NEMTR2vcS83Bkv1XTB0OmZhRSfe9e/fg7u5eobJubm6IiYkxpjkiIiIiIiKzZ2khx2dPtAEALD8Uhai4dBNHRKZkVNKt0Whw+/btCpW9c+cObG1tjWmOiIiIiIioVnjMxwX+LRsgL1/ErK0RXFStHjMq6e7cuTPu3r2LPXv2lFluz549iI6OxiOPPGJMc0RERERERLWCIAgIfLINLOQCQi/F4e8LsaYOiUzEqKT75ZdfhiiKGDt2LI4ePVpimWPHjmHcuHEQBAGvvPJKpds6deoUhg4dCgcHB9jY2KBbt24Gr4aenJyMgIAAtG/fHnZ2dnB2dkbXrl2xZMkSZGdnl3v9/PnzIQgCBEHA8ePHi50PCgqSzj/8ZWlpaVCsRERERERUuzVrYItX/ZoBAGZtjUB2Xr6JIyJTUBhz8fPPP49ff/0Vf/31F3r37o0ePXqgR48esLe3R3JyMo4fP47jx49DFEWMGDECo0aNqlQ7oaGhGDx4MJRKJUaNGgWNRoONGzdizJgxuH79Oj755JNy60hOTkbnzp0RFRUFPz8/vPbaa8jJycGOHTvwzjvv4M8//8SePXsgk5X8OcSFCxcQEBAAGxsbZGRklNnW+PHj4eXlpXdMoTDqoSYiIiIiolronf7N8ec/t3EzMRM/HIzCOwNamDokqmGCaOTkgry8PEyfPh3/+9//kJeXV1ipIEhzFiwsLPD2229j7ty5UCqVBtev1WrRunVr3L59G8eOHZOGqKelpaFnz564dOkSIiIi0KJF2U/e+fPn46OPPsKUKVOwcOFC6Xhubi78/Pxw6tQpHDhwAH369Cl2bX5+Pnr27AlBENCyZUusWbMGx44dQ48ePfTKBQUFITg4GPv370ffvn0NvteHpaamQqPRICUlBWq12uj6iIiIiIio5m06dwfvrTsHSwsZ9k71RyMHa1OHRFWgovmaUcPLgcKk+uuvv8b169fxww8/YOrUqXj11VcxZcoULF++HDdu3MCCBQsqlXADwL59+3D16lW8+OKLenPC7ezs8Nlnn0Gr1WLlypXl1hMVFQUAGDp0qN5xpVKJgQMHAgBiY0ueZzFv3jyEhYVhxYoVkMvllboPIiIiIiKqn4Z3cEe3po7IzivAnO0XTB0O1bAqG/Ps5uaGV199taqqk4SGhgIABg0aVOyc7tiBAwfKrcfX1xcAsHPnTjz22GPS8by8POzduxdWVlbo2bNnsevOnz+P4OBgfPrpp1Id5Tl06BBOnjwJuVyO1q1b47HHHoNKparQtUREREREVLcIgoDg4b4Y9u0hbP8vBkeuxKNXc2dTh0U1xOwnGkdGRgJAicPHHRwc4OzsLJUpy8SJE7F69WosWLAAp0+fRteuXZGTk4OdO3ciKSkJa9euhYeHh941Wq0WEyZMgI+PDz7++OMKxxwQEKD3s5ubG1atWiX1qJcmJycHOTk50s+pqakVbpOIiIiIiMyXj5sa43p4YtWxGwjcHI4d7/WGhdzogcdUC1T5//Lly5fx2muv4ZFHHoGvry9GjBiBzZs3V7q+lJQUAIV7gpdErVZLZcpiZWWF0NBQjB07FgcOHMBXX32FxYsXS0PX/fz8il0zZ84caVi5hYVFuW107NgRq1atwvXr15GVlYXIyEiEhIQgOTkZw4cPR1hYWJnXz507FxqNRvpq3LhxuW0SEREREVHtMHVgKzjaKHElNh2rjl43dThUQwxKunfv3g0XFxc8+eSTJZ4/cOAAOnXqhOXLlyMsLAwXLlzA5s2b8fTTTxvUU1wd4uPjMXDgQBw/fhzbtm1DcnIyYmJisGzZMqxcuRLdu3dHUlKSVD4sLAyzZ8/GtGnT0KlTpwq1MWLECLz00kvw9PSEpaUlmjdvjk8//RTffPMNsrOzMXv27DKvnzFjBlJSUqSvW7duGXXPRERERERkPjTWFpg+uBUAYNHeSMSmlb9tMdV+BiXde/fuRUJCAkaOHFnsXG5uLsaPH4/MzExYW1vjww8/xNKlSzF27FgAwJdfflnqXt5l0fVwl9abrVsxrjxTp07F0aNHsWHDBgwdOhQajQaurq6YNGkS5s+fj6ioKCxatEgqP378eHh7eyMoKMjgmB82fvx4KBQKHDlypMxyKpUKarVa74uIiIiIiOqOkV0ao0MjDdJztJi345Kpw6EaYFDSfeTIEQiCgKeeeqrYub/++gs3b96ETCbDrl27MG/ePLz22mv4+eefMXPmTIiiiOXLlxscoG4ud0nztpOSkhAfH1/udmEAsG3bNjg6OqJ9+/bFzvXv3x8AcObMGelYWFgYLl68CEtLSwiCIH2tWrUKAKQtxP76669y21YqlbCzs0NmZma5ZYmIiIiIqO6SyQQEDS9coHnD2ds4cyPRxBFRdTNoIbXbt2/D29u7xB7YnTt3AgD69u2LRx99VO/cBx98gPnz51eqp9vf3x9z587F7t27MWrUKL1zu3fvlsqUJzc3F9nZ2cjNzS22fVlcXBwA6K0wXtpK7AcPHkRkZCSGDx+OBg0awMvLq9y2IyMjkZSUhA4dOpRbloiIiIiI6rZHmjhgZJdG+P30bQRuDsemt/wglwmmDouqiUFJd1xcXKmJ47FjxyAIQrF9sIHCIeKenp64c+eOwQEOGDAAzZo1w9q1a/Huu++iY8eOAIC0tDSEhIRAoVBgwoQJUvn4+HjEx8fD2dkZzs4PluHv1asXdu3ahZCQEISEhEjHc3JypJ/79esnHS+tV37ChAmIjIzEjBkz0KNHD+l4Wloarl27VqwnPSkpSUrgR48ebfD9ExERERFR3TN9SGvsOB+D83dS8dupW3ixexNTh0TVxKDh5TKZDLGxscWOp6am4vLlywCA7t27l3itg4MDtFqtwQEqFAosX74cBQUF6N27NyZPnoxp06ahQ4cOCA8PR1BQEFq2bCmVX7JkCXx8fLBkyRK9er744gvY2dlh9uzZ6N69O6ZOnYo333wTbdq0wa5du9C5c2dMnDjR4Ph0EhIS0KFDB3Tt2hWvvPIKPv74Y4wbNw4tWrTAoUOHMHDgQEyZMqXS9RMRERERUd3hbKvC1IGFecyXuy4iOTPXxBFRdTEo6W7atClu3bqF27dv6x3fu3cvRFGEUqlEly5dSrw2Li4ODRs2rFSQ/fr1w+HDh+Hn54fff/8d//vf/+Dk5IQ1a9Zg5syZFaqjY8eOOHPmDF5++WXExMRgyZIl+Omnn2BjY4Pg4GAcPHgQlpaWlYoPABwdHfHWW29BFEVs2bIFCxYswJYtW+Dj44Nly5Zhx44dxYa1ExERERFR/TWuhydaudohKTMPC3ZfNnU4VE0EURTFihaeOnUqFi1ahCeffBK//fYbLC0tkZqaigEDBuDs2bMYOnQotmzZUuy6xMREODs7o1evXjh06FCV3kBdpluZPSUlhSuZExERERHVQceuJmD0D8chE4At7/jB1738nZnIPFQ0XzOop3vKlCmws7PD1q1b4ebmhu7du8PLywtnz54FAEybNq3E6zZu3AigcF41ERERERERFerp7YQn2ruhQAQCN4XDgD5RqiUMSrobN26MP//8E46OjkhJScGpU6eQnJwMQRAwe/bsUlcRX7JkCQRBwOOPP14lQRMREREREdUVM4f5wMpCjtM3kvDXOcMXnybzZtDq5UDhntZRUVHYvn07oqKioFarMWjQoFL3yk5ISMDLL78MQRDg5+dndMBERERERER1iZvGCm/3b44vd13C3O0XMbBNQ9iqDE7VyEwZNKebahbndBMRERER1Q852nwM/vogridk4rU+zTBjqI+pQ6JyVMucbiIiIiIiIqp6KoUcgU/6AgB+PHwNV2LTTRwRVRUm3URERERERGagX2sXDGjtAm2BiOAtXFStrmDSTUREREREZCY+e6INlHIZDkXGY1f4PVOHQ1WASTcREREREZGZ8HK2weQ+zQAAIVsjkJ2Xb+KIyFhMuomIiIiIiMzIm/284a6xxJ3kLCwNvWrqcMhITLqJiIiIiIjMiLVSgZnD2gAAlh24iluJmSaOiIzBpJuIiIiIiMjMDG3XED2bOSFHW4DZ2yJMHQ4ZgUk3ERERERGRmREEAcFP+UIuE7Ar/B4OXo4zdUhUSUy6iYiIiIiIzFBLVzuM7+kFAAjaEo5cbYFpA6JKqbGku3PnzvD29q6p5oiIiIiIiGq99we2gLOtElFxGVh55Jqpw6FKqLGk++bNm7h+/XpNNUdERERERFTrqS0t8NGQ1gCAb/+OxL3UbBNHRIbi8HIiIiIiIiIz9mynRnikiT0ycvMxd/sFU4dDBlIYUvjo0aOVbkir1Vb6WiIiIiIiovpKJhMQPNwXT/3fEfx1LhovdvdEt6aOpg6LKsigpNvPzw+CIFSqIVEUK30tERERERFRfda+kT1GdW2MX0/eQuDmcGx9xw9yGfOr2sCgpFvHw8MDcrncoGtu3boFURQr0xwREREREVG99+Hg1tj+Xwwu3E3F2hM3MO7+yuZk3gxKur28vHDjxg38/vvv6NGjh0ENNWjQAImJiQZdQ0RERERERIUcbZT4YFBLBGwKx1e7L2NYe3c42ihNHRaVw6CF1Lp37w4AOHXqVLUEQ0RERERERKV7sVsTtG5oh5SsPHy565Kpw6EKMCjp7tatG0RRxIkTJwxuiEPLiYiIiIiIjKOQyzDrqbYAgHWnbuK/2ykmjojKY1DS3bt3b3To0AHZ2YbvDffRRx8hICDA4OuIiIiIiIjogW5NHfFUR3eIIhCw+TwKCtjBac4EkV3QZis1NRUajQYpKSlQq9WmDoeIiIiIiMzEvdRs9P8qFBm5+fjq+Q54rnMjU4dU71Q0XzOop5uIiIiIiIhMz1VtiXcGtAAAfLHjAlKz80wcEZWGSTcREREREVEt9EqvpmjmbIP49Fx8szfS1OFQKQxKur/99lts2LChumIhIiIiIiKiClIqZAgc7gsA+OnodVy+l2biiKgkBiXd77//Pr755psSz/Xv3x/vv/9+VcREREREREREFeDfsgEGtnFFfoGIoM3h3DXKDFXZ8PLQ0FCcPXu2qqojIiIiIiKiCgh4og2UChmOXk3AjvMxpg6HHsI53URERERERLVYY0drvO7vDQCYvTUCmblaE0dERTHpJiIiIiIiquXe8PeGh70VolOysTT0qqnDoSKYdBMREREREdVyVko5PnvCBwDw3YEo3EjIMHFEpMOkm4iIiIiIqA4Y7NsQvVs4Ize/ACFbI0wdDt2nMPSC2NhY/Pzzzwaf03nppZcMbZKIiIiIiIjKIQgCAp/0xZBFB7H3Qiz2X4xFv9Yupg6r3hNEA9aUl8lkEASh8o0JArRaTuqvqNTUVGg0GqSkpECtVps6HCIiIiIiqgU+3xaBHw5dg5eTNXZN6QOVQm7qkOqkiuZrBvV0N2nSxKikm4iIiIiIiKrXuwNa4K9z0biekIkfD1/Dm32bmzqkes2gpPv69evVFAYRERERERFVBTtLC8x4vDWm/h6GxX9fwdOPeMBNY2XqsOotLqRGRERERERUxzz9iAe6eDogKy8fc7ZfNHU49RqTbiIiIiIiojpGEAQEDfeFIABbwqJx7GqCqUOqt5h0ExERERER1UFtPTQY070JACB4Szi0+QUmjqh+YtJNRERERERUR30wsBXsrS1wMSYNa47fMHU49RKTbiIiIiIiojrKwUaJaYNaAQAW7LmM+PQcE0dU/zDpJiIiIiIiqsNGd2sCX3c10rK1+HLnJVOHU+8w6SYiIiIiIqrD5DIBs57yBQD8dvoWzt1KNm1A9QyTbiIiIiIiojqus6cjnunkAQAI3HQeBQWiiSOqP5h0ExERERER1QMfP94atioFwm6nYP2ZW6YOp95g0k1ERERERFQPuNhZ4v3HWgAA5u+8hJSsPBNHVD8w6SYiIiIiIqonxj/qheYutkjIyMXXey6bOpx6gUk3ERERERFRPWEhlyHoycJF1VYfv4GLMakmjqjuY9JNRERERERUj/i1cMbjbRsiv0BE4KZwiCIXVatOTLqJiIiIiIjqmZnDfGBpIcOJa4nY8u9dU4dTpzHpJiIiIiIiqmcaOVjjzb7NAQBztl1ARo7WxBHVXUy6iYiIiIiI6qHJfZqhsaMVYlKzsWT/FVOHU2cx6SYiIiIiIqqHLC3kCHiicFG15YeicC0+w8QR1U1MuomIiIiIiOqpx3xc4N+yAfLyRQRv4aJq1YFJNxERERERUT0lCAICn2wDC7mA0Etx+PtCrKlDqnOYdBMREREREdVjzRrY4lW/ZgCAWVsjkJ2Xb+KI6hYm3URERERERPXcO/2bw1Wtws3ETPxwMMrU4dQptSbpPnXqFIYOHQoHBwfY2NigW7duWLt2rUF1JCcnIyAgAO3bt4ednR2cnZ3RtWtXLFmyBNnZ2eVeP3/+fAiCAEEQcPz48RLLpKamYurUqfD09IRKpYKnpyemTp2K1NRUg2IlIiIiIiKqKTYqBT4Z6gMA+L/QK7iTnGXiiOqOWpF0h4aGws/PD4cOHcJzzz2HN954A/Hx8RgzZgzmzJlToTqSk5PRuXNnhISEQKPR4LXXXsPo0aORlJSEd955B8OGDUNBQUGp11+4cAEBAQGwsbEptUxGRgb8/f3x9ddfo1WrVpgyZQratGmDr7/+Gv7+/sjI4GqARERERERknoZ3cEe3po7IzivA59siTB1OnWH2SbdWq8XEiRMhCAIOHjyIH374AV999RXCwsLg6+uLwMBAREZGllvP999/j6ioKEyZMgWHDh3CV199hcWLFyMiIgJdu3bFvn37cPjw4RKvzc/Px/jx49GhQwc8/fTTpbYxf/58nDt3DtOnT8fu3bvxxRdfYMeOHQgICMC5c+cwf/78Sj8ORERERERE1UkQBAQP94VMALb/F4MjV+JNHVKdYPZJ9759+3D16lW8+OKLeOSRR6TjdnZ2+Oyzz6DVarFy5cpy64mKKpyXMHToUL3jSqUSAwcOBADExpa8Ut+8efMQFhaGFStWQC6Xl1hGFEUsX74ctra2CAgI0Ds3Y8YMODg44Mcff+QS/EREREREZLZ83NQY18MTABC4ORx5+aWPBqaKMfukOzQ0FAAwaNCgYud0xw4cOFBuPb6+hZu+79y5U+94Xl4e9u7dCysrK/Ts2bPYdefPn0dwcDA+/fRTqY6SREZGIjo6Gr169So2BN3S0hJ9+vTBnTt3cOXKlXJjJSIiIiIiMpWpA1vB0UaJK7HpWHX0uqnDqfXMPunWDR1v0aJFsXMODg5wdnau0PDyiRMnomvXrliwYAH69u2LDz/8EO+++y58fX0RFRWFtWvXwsPDQ+8arVaLCRMmwMfHBx9//HGl4yx6vKxYc3JykJqaqvdFRERERERUkzTWFpg+uBUA4Ju9kYhNK3/RaSqd2SfdKSkpAACNRlPiebVaLZUpi5WVFUJDQzF27FgcOHBAmtOtG7ru5+dX7Jo5c+ZIw8otLCyMjrNouZLMnTsXGo1G+mrcuHG590VERERERFTVRnZpjPaNNEjL0WLejkumDqdWM/uku6rEx8dj4MCBOH78OLZt24bk5GTExMRg2bJlWLlyJbp3746kpCSpfFhYGGbPno1p06ahU6dONRLjjBkzkJKSIn3dunWrRtolIiIiIiIqSiYrXFQNADacvY0zN5LKuYJKY/ZJt67nuLQe4tTU1FJ7l4uaOnUqjh49ig0bNmDo0KHQaDRwdXXFpEmTMH/+fERFRWHRokVS+fHjx8Pb2xtBQUFVFmfRciVRqVRQq9V6X0RERERERKbwSBMHPN+5EQAgcPN55BdwUejKMPuku6y50ElJSYiPjy91HnVR27Ztg6OjI9q3b1/sXP/+/QEAZ86ckY6FhYXh4sWLsLS0hCAI0teqVasAAD179oQgCPjrr7/KjbPo8YrESkREREREZA6mD2kNO0sFzt9JxW+nOBK3MhSmDqA8/v7+mDt3Lnbv3o1Ro0bpndu9e7dUpjy5ubnIzs5Gbm4ulEql3rm4uDgAhT3NOq+++mqJ9Rw8eBCRkZEYPnw4GjRoAC8vLwCFybS7uzuOHDmCjIwMvRXMs7OzcfDgQbi7u6N58+bl3zQREREREZEZaGCnwpTHWmLW1gh8uesihrZrCHtrZfkXksTse7oHDBiAZs2aYe3atTh37px0PC0tDSEhIVAoFJgwYYJ0PD4+HhcvXkR8vP5G7r169YJWq0VISIje8ZycHOlYv379pOPLly8v8evRRx8FUDj/evny5ejYsSOAwo3kJ06ciPT0dMyaNUuvjblz5yIpKQkTJ06EIAjGPiREREREREQ15qWenmjlaoekzDws2H3Z1OHUOmafdCsUCixfvhwFBQXo3bs3Jk+ejGnTpqFDhw4IDw9HUFAQWrZsKZVfsmQJfHx8sGTJEr16vvjiC9jZ2WH27Nno3r07pk6dijfffBNt2rTBrl270LlzZ0ycONGoWKdPn46OHTti/vz5GDRoEGbMmIGhQ4di1qxZ6NixI6ZPn25U/URERERERDVNIZch6P6iar+cuIHw6PJ3j6IHzD7pBgp7oA8fPgw/Pz/8/vvv+N///gcnJyesWbMGM2fOrFAdHTt2xJkzZ/Dyyy8jJiYGS5YswU8//QQbGxsEBwfj4MGDsLS0NCpOGxsbhIaGYsqUKbh48SIWLFiA8+fPY8qUKQgNDdUbck5ERERERFRb9PR2wrD2bigQgaDN4RBFLqpWUYLIR8ts6VZmT0lJ4UrmRERERERkUtHJWRiw4ACy8vKx6IWOGPGIh6lDMqmK5mu1oqebiIiIiIiITMvd3gpv9y9cGHrO9gtIz9GaOKLagUk3ERERERERVcjE3k3h5WSN2LQcLP675O2SSR+TbiIiIiIiIqoQlUKOgCfbAAB+PHwNV2LTTRyR+WPSTURERERERBXWv7UrBrR2gbZARPAWLqpWHibdREREREREZJDPnmgDpVyGQ5Hx2B1xz9ThmDUm3URERERERGQQL2cbTOrTFAAQsjUC2Xn5Jo7IfDHpJiIiIiIiIoO91a853DSWuJ2UhWUHrpo6HLPFpJuIiIiIiIgMZq1UYOYwHwDA0tCruJWYaeKIzBOTbiIiIiIiIqqUYe3c0LOZE3K0BZi9LcLU4ZglJt1ERERERERUKYIgIPgpX8hlAnaF38PBy3GmDsnsMOkmIiIiIiKiSmvpaofxPb0AAEFbwpGrLTBtQGaGSTcREREREREZ5f2BLeBsq0RUXAZ+OnrN1OGYFSbdREREREREZBS1pQWmD2kNAPhmbyTupWabOCLzwaSbiIiIiIiIjPZcp0bo2NgeGbn5+GLHRVOHYzaYdBMREREREZHRZDIBs57yhSAAf/5zB6euJ5o6JLPApJuIiIiIiIiqRPtG9hjVtTEAIGBTOPILRBNHZHpMuomIiIiIiKjKTBvUCmpLBS7cTcXaEzdMHY7JMekmIiIiIiKiKuNkq8K0wa0AAF/tvozEjFwTR2RaTLqJiIiIiIioSr3YrQlaN7RDSlYevtp9ydThmBSTbiIiIiIiIqpSCrkMwcN9AQC/nryJ/26nmDgi02HSTURERERERFWuezMnPNXRHaIIBG4+j4J6uqgak24iIiIiIiKqFjMe94G1Uo6zN5Ox8Z87pg7HJJh0ExERERERUbVoqLHEuwNaAAC+2HERqdl5Jo6o5jHpJiIiIiIiomrzSq+maOZsg/j0HHyzN9LU4dQ4Jt1ERERERERUbZQKGQLvL6q26uh1RN5LM3FENYtJNxEREREREVUr/5YNMLCNK7QFIoK2hEMU68+iaky6iYiIiIiIqNp9NqwNlAoZjlxJwI7zMaYOp8Yw6SYiIiIiIqJq18TJGq/7ewMAZm+NQFZuvokjqhlMuomIiIiIiKhGvOHvDQ97K0SnZON/oVdMHU6NYNJNRERERERENcJKKcdnT/gAAL47GIUbCRkmjqj6MekmIiIiIiKiGjPYtyH8mjsjV1uAkK0Rpg6n2jHpJiIiIiIiohojCAKChreBQiZg74VY7L8Ya+qQqhWTbiKi/2/vzuOiKvc/gH9m2JFNRAVFwQAVFEEFQdHAJcTtZpam3QzXsle2uNy0sp+gZqVm9tKr3dsimqVZmqZW6i0UUZQUTXHfwj0XBAYRZPn+/vDOuYwzIwwyDsjn/XrxUs7znOf5nnOeOYfvnI2IiIiIHir/Rs4YGeULAEjccBhFJY/uQ9WYdBMREREREdFD91rPADR0tsOfNwrwRepZS4djNky6iYiIiIiI6KFztrfBW31aAwAW/XYKl3NvWzgi82DSTURERERERBbxVPum6OhTHwV3SjH7p2OWDscsmHQTERERERGRRahUKiT+rQ1UKmDDH5ew+8wNS4dU7Zh0ExERERERkcW0beqK5zo1BwAk/HgYJaVlFo6oejHpJiIiIiIiIouaHNsKbo42OHZFgxW7sywdTrVi0k1EREREREQWVb+eLSbHtgIAfLT1BK7nF1k4ourDpJuIiIiIiIgsblin5mjTxAWawhJ8+PMxpJ2+gfUHLiLt9A2Ulomlw6sylYjU3ugfcXl5eXB1dUVubi5cXFwsHQ4REREREZFZ7cvKxtNL0vSme7naY/qAIMS19bJAVIZVNl/jmW4iIiIiIiKqEa5pDF9WfiW3EC+vyMAvmZcfckQPjkk3ERERERERWVxpmSBxwxGDZdrLsxM3HKl1l5oz6SYiIiIiIiKLSz+bjcu5hUbLBcDl3EKkn81+eEFVAybdREREREREZHFXNcYT7qrUqymYdBMREREREZHFNXK2r9Z6NQWTbiIiIiIiIrK4Ti3c4eVqD5WRchXuPsW8Uwv3hxnWA2PSTURERERERBZnpVZh+oAgANBLvLW/Tx8QBCu1sbS8ZmLSTURERERERDVCXFsvLHm+AzxddS8h93S1x5LnO9So93RXlrWlAyAiIiIiIiLSimvrhSeCPJF+NhtXNYVo5Hz3kvLadoZbi0k3ERERERER1ShWahU6+zWwdBjVgpeXExEREREREZkJk24iIiIiIiIiM2HSTURERERERGQmTLqJiIiIiIiIzIRJNxEREREREZGZMOkmIiIiIiIiMhMm3URERERERERmwqSbiIiIiIiIyEyYdBMRERERERGZCZNuIiIiIiIiIjOxtnQAZJyIAADy8vIsHAkRERERERGVp83TtHmbMUy6azCNRgMAaNasmYUjISIiIiIiIkM0Gg1cXV2NlqukorScLKasrAyXLl2Cs7MzVCrVA7UVHh6O33//vZoiuysvLw/NmjXD+fPn4eLiUq1t06PLHGOxLqpL67G2LWtN3jdacl0+zL7N3RePqVQTcMxUn9p2nHkQtW1Za+o4165HEYFGo0GTJk2gVhu/c5tnumswtVoNb2/vamnLysrKbAPVxcWlRn0IqGYz51isS+rSeqyty1oT942WXJcPs29z98VjKtUkHDMPrrYeZ6qiti5rTRvn5dfj/c5wa/FBanXEK6+8YukQiABwLFaXurQe69Kympsl1+XD7NvcfXFMEj1a6tJnui4tqzmZuh55eTlVWV5eHlxdXZGbm1ujvnkiIrIk7hupKjhuyFQcM1QXPCrjnGe6qcrs7Owwffp02NnZWToUIqIag/tGqgqOGzIVxwzVBY/KOOeZbiIiIiIiIiIz4ZluIiIiIiIiIjNh0k1ERERERERkJky6iYiIiIiIiMyESfcjasWKFXjppZcQFhYGOzs7qFQqJCUlPZS+i4qKMGPGDLRs2RL29vbw8vLCmDFjcOXKFaPzlJWV4csvv0TXrl3h5uYGR0dHtGzZEiNHjoRGo3kocRNR3eDr6wuVSmXwZ9y4cWbtm/vH2qk2HVONjW2VSoUPPvjgocRc1128eBELFixAbGwsmjdvDltbW3h6euLpp5/Gnj17zN4/xww9TLXpmGrJsc4HqT2ifH19kZWVBQ8PD9SrVw9ZWVlYunQpRowYYdZ+y8rK0LdvX2zevBkRERGIiYnB6dOnsXbtWnh7e2PPnj3w9PTUmaeoqAjPPPMMNm7ciHbt2qF79+6ws7PDuXPn8Ntvv2Hfvn3w9vY2a9xEVHf4+voiJycHb7zxhl5ZWFgY+vfvb5Z+uX+svWrTMVWlUsHHx8dgbL169ULXrl3NGjMBU6dOxYcffgg/Pz9ER0ejUaNGOHnyJNatWwcRwcqVKzFkyBCz9M0xQw9bbTqmWnSsCz2Stm7dKn/++aeIiLz//vsCQJYuXWr2fr/88ksBIEOHDpWysjK96S+88ILePBMmTBAA8sEHH+iVlZaWSmlpqVljJqK6xcfHR3x8fB56v9w/1l616ZgKQKKjo80eGxm3Zs0aSUlJ0ZuekpIiNjY24u7uLoWFhWbpm2OGHrbadEy15Fhn0l0HVOYPhL/++kveeOMN8fPzE1tbW2nQoIEMGjRIDh06ZFJfnTt3FgDKHyflBQYGip2dneTl5SnTLly4INbW1tKtWzeT+iEiqipT/0Dg/pHKq8nHVBEmUDVdbGysAJDff/9dZzrHDNVWteWYKmLZsW5tvnPoVFucPn0aMTExuHjxImJjYzFw4EBcvXoVa9aswebNm/Hrr78iIiKiwnYKCwuxZ88etGrVCj4+PnrlsbGx+OSTT7B792488cQTAIA1a9agpKQEgwcPhkajwY8//ohz586hcePG6N27N5o2bVrty0tEVFRUhGXLluHixYuoX78+unTpgpCQEL163D+SqSw5ZrRycnLw+eef4+rVq2jYsCFiYmIQEBBQbctIVWdjYwMAsLb+35/gHDNU29WGY6qWxca6RVJ9eqgq+la+S5cuYm1tLVu2bNGZfvz4cXF2dpbg4OBK9ZOZmSkApH///gbLFy1aJADkn//8pzJt+PDhAkBmzpwpXl5eAkD5sbW1lfnz51duIYmIKsnHx0dnX6P9iYuLk2vXrunU5f6R7lWTj6kiYnBsq1Qqef755+XWrVuV6pvMIysrS+zs7MTT01NKSkqU6RwzVJvVlmOqiGXHOp9eXsft378fu3btQnx8vN43QS1btsTYsWNx6NAhZGZmVthWbm4uAMDV1dVguYuLi049ALh69SoAICEhASEhITh8+DDy8vKwceNGeHh4YOLEifjpp5+qtGxERIaMGjUK27Ztw7Vr15CXl4fdu3ejT58++OWXX/C3v/0N8t/ni3L/SKay9JgBgMmTJ2PPnj3Izs7GzZs38dtvvyEiIgIrVqzA6NGjq7JYVA2Ki4sxfPhwFBUVYc6cObCysgLAMUO1X205pgKWHeu8vLyO2717NwDgypUrSEhI0Cs/duyY8m/btm2xbt06HDhwQKdOTEwMYmJiqtR/WVkZAKBRo0ZYs2YNHB0dAQD9+vXDF198gT59+mD+/Pno27dvldonIrrX//3f/+n8HhERgY0bNyI6Ohqpqan46aef0K9fP+4fyWSWHjMAMHfuXJ3fu3fvjl9//RUhISFYtWoVpk2bhjZt2lS5fTJdWVkZRo0ahZSUFIwdOxbDhw9XyjhmqLarLcdUwLJjnUl3HZednQ0A2LRpEzZt2mS03q1btwAA69atw7Jly/TKY2JilG+b7v1WSSsvLw+A7rdS2v/36tVL+YNSKzY2FnZ2dti7d29lF4eIqErUajVGjhyJ1NRU7Ny5E/369eP+kUxm6TFjjKOjI4YNG4aZM2di586dTKAeIhHB2LFjsWLFCjz//PP49NNPdco5ZuhRVBOPqcY8rLHOpLuO015+sXDhQowfP77C+klJSUhKSjJY5ufnB7VajZMnTxos104v/7CCVq1aAQDc3Nz06qvVajg7OysfHCIic/Lw8AAAFBQUAOD+kUxn6TFzP/eObzK/srIyjBkzBkuXLsWwYcOQlJQEtVr3zk6OGXpU1bRjqimxmgPv6a7jtE8ITEtLe+C27O3t0alTJxw/fhxZWVl65Vu2bIGdnZ3OUwl79OgBADhy5Ihe/WvXruH69evw9fV94NiIiCqyZ88eAFD2Odw/kqksPWbu597xTeZVPuF+9tln8dVXXyn3cZfHMUOPqpp2TDUlVrMw62PaqEao6EmrERERolKpZNWqVXplpaWlsm3btkr3ZeqL6ktKSiQwMFAA6DzJsKysTMaMGSMAZNq0aZXun4jofg4fPiw3b97Um75jxw6xt7cXOzs7ycrKUqZz/0j3qsnH1IyMDINP4F29erWoVCrx8PAQjUZT6f6pakpLS2XEiBECQAYPHizFxcX3rc8xQ7VVbTqmWnqsq0T++0g5eqR8/vnnSE1NBQAcOnQIGRkZiIqKgr+/PwBg4MCBGDhwIADg7Nmz6N69O7KyshAZGYmOHTvC3t4e586dQ1paGq5du4bCwsJK9VtaWop+/fph8+bNiIiIQExMDM6cOYM1a9agadOmSE9Ph6enp848e/bsQY8ePXDnzh089dRTaNasGVJTU5Geno4OHTogJSUF9erVq76VQ0R1VkJCAubMmYOePXvC19cXdnZ2yMzMxJYtW6BWq/Hpp59izJgxSn3uHwmoPcfUESNGYN26dejZsyeaN28OEUFGRgZ27NgBe3t7rFmzhg/eewgSEhKQmJgIJycnvP766zrv5NYaOHAgQkNDAXDMUO1Vm46pFh/rZkvnyaLi4+MNvotO+zN9+nSd+tnZ2TJt2jRp27atODg4iJOTkwQEBMhzzz0na9euNanvwsJCSUxMFH9/f7G1tZXGjRvLqFGj5NKlS0bnyczMlKeffloaNGggNjY24ufnJ2+99Ra/XSWiarVt2zYZMmSI+Pv7i7Ozs9jY2Ii3t7cMHTpU9uzZY3Ae7h+pthxT165dK08++aT4+vqKo6Oj2NraSosWLWT06NFy9OjRB1kFZIKKxgsMXCnBMUO1UW06plp6rPNMNxEREREREZGZ8EFqRERERERERGbCpJuIiIiIiIjITJh0ExEREREREZkJk24iIiIiIiIiM2HSTURERERERGQmTLqJiIiIiIiIzIRJNxEREREREZGZMOkmIiIiIiIiMhMm3URERERERERmwqSbiIjoAfn6+kKlUuHPP/+0dChUTmRkJDw8PJCfn68zndurarZt2waVSoWYmJhqaW/GjBlQqVTYunVrtbRHRFRTMekmIqJqo01mkpKSLB0K3SMpKQkqlUrnR61Wo379+ujcuTPmzZuHwsLCau0zISEBCQkJ1dpmZX333XfYs2cPJk6cCCcnJ4vEQPf32muvwdXVFVOnToWIWDocIiKzYdJNRET0gPz8/NCqVSvY2NhYOpQK2dnZISoqClFRUYiIiICjoyN2796Nf/zjH4iKioJGo6m2vhITE5GYmFht7VVWWVkZ3nnnHbi4uGD8+PEPvX+qHDc3N7z88svIyMjA6tWrLR0OEZHZMOkmIiJ6QL/++iuOHTuGpk2bWjqUCnl6eiI1NRWpqalIS0vDxYsX8csvv6BevXrIyMjABx98YOkQH9jmzZtx8uRJPPXUU3BxcbF0OHQf8fHxAIBFixZZOBIiIvNh0k1ERFTH9e7dGxMmTAAArF271sLRPLh///vfAIBhw4ZZOBKqSOvWrRESEoLU1FQcP37c0uEQEZkFk24iIrKogoICfPjhhwgLC4OLiwscHR0RGhqKuXPnoqioSK/+7du3sXLlSgwdOhStWrWCk5MTnJycEBoailmzZuHWrVsG+yn/8Kzk5GT06dMHHh4eUKlU2LZtGwAo9zoDwM8//4zHH38czs7OcHV1RZ8+fbB///4K2y4vJiZGaf/YsWMYPHgwPDw84ODggI4dO973klqNRoM333wTvr6+sLe3R4sWLTBlyhTcunULI0aMqPZ758PDwwHA4MPFrly5goULF6J3795KPPXr10d0dDS++uorvfoJCQnKegSgdy/5vX1cuHABr732Glq2bAkHBwe4ubmhe/fu+P77701ejlu3bmHTpk2wt7dHjx49TJ6/uLgYCxcuRKdOneDi4oJ69eohJCQE7733HgoKCozOt3//fgwYMAD169eHk5MTIiMjlfjLj6vKunHjBiZPnozWrVvD3t4e9erVg6+vL+Li4rB48WKD82RnZ2P69Olo3749XFxc4OTkhMDAQIwbN05v7GZmZmL69Ono3LkzvLy8YGtrCy8vLwwaNAi7du0yKVYtUz/LWv379wcAfPvtt1Xql4ioxhMiIqJq4uPjIwBk6dKllap/4cIFCQoKEgBibW0t/v7+EhgYKNbW1gJAunbtKgUFBTrz7NixQ6nv7e0tYWFhEhAQoMzToUMHvXnKxzZ79mxRq9VSv359CQ8PF29vb0lOThYREQACQJYsWSIqlUq8vLykQ4cOUq9ePQEgTk5OcvToUaNtnz17Vmd6dHS0AJB58+aJk5OTODs7S8eOHaVhw4ZKX1999ZVee7m5udK+fXsBIGq1WoKDg6VNmzaiUqkkPDxchg0bZtJ6FhFZunSpABAfHx+D5StXrhQA4u7urlc2c+ZMASAODg7i5+cnYWFh0rx5c2UZxo0bp1P/iy++kKioKKU8KipK5+fy5ctK3W3btomrq6vSfnBwsDRr1kyZd9KkSZVeRhGRrVu3CgDp3Lmz0TrGtldBQYH06NFD6TswMFDatWsnarVaAEhoaKhcv37dYJ92dnYCQFxcXCQsLEy8vLwEgMyfP19pr7JycnLEz89PAIitra0EBQVJhw4dpFGjRqJSqcTV1VVvngMHDkiTJk2UMRMUFCShoaHi4uIiACQ+Pl6nfs+ePQWAuLm5SWBgoHTo0EE8PDwEgFhZWcnXX3+t10dycrIAkOjoaL2yqnyWtdavXy8ApGfPnpVeR0REtQmTbiIiqjamJN2lpaXSpUsXASBDhw6VK1euKGXnz5+Xbt26CQCZPHmyznx//vmnrF69WjQajc70y5cvyzPPPCMAJCEhwWhsVlZWkpiYKMXFxSIiUlZWJoWFhSLyv6Tb0dFRZxny8vKUJOXZZ5812raxpNvGxkbGjx8vt2/fVvqcMmWKAJAmTZpISUmJznyvvPKKAJDHHntMjhw5okzPzMwUHx8fsbGxqfak+4UXXhAA0qNHD72yHTt2yG+//aYX5x9//CGBgYECQLZt26Y3X0XJ5sWLF8Xd3V1UKpXMnj1b2Q4iIjt37pSmTZsKANmwYUMll1IkMTFRAMj48eON1jG2vSZNmqRsk3379inTT548Ka1btxYAMmTIEJ158vLyxNPTUwDIyJEjlcSyrKxMFi1apCTjpiTd8+bNEwASGxsrN27c0CnLysqSjz/+WGdabm6u8iVIXFycnD9/Xqc8JSVFVqxYoTPtu+++k4MHD+pMKysrk3Xr1omTk5O4uLhIXl6eTrmxpLuqn2WtS5cuKZ+7e8cYEdGjgEk3ERFVG1OS7h9//FEASHh4uJIAl3fp0iVxcnISJycno2fI7lVQUCC2trYSEBBgNLYBAwYYnV+bHL366qt6ZQcPHhQABs8yVpR0h4SESGlpqU7ZnTt3lGQtIyNDmZ6TkyP29vYCQFJTU/X60iY+1ZF0l5SUyJkzZ+Ttt98WlUolarVafvnll0q3KSLyn//8RwDI2LFj9coqSjYnTpwoAGTChAkGyzds2GD0iwBjRo0aJQDkvffeM1rH0PbKzc0VR0dHASA//PCD3jzp6ekCQFQqlZw6dUqZ/umnnwoAad26tcFxHB8fb3LS/dJLLwkAWb9+faXqz5kzRzkzX/6Li6qaNm2aANA7220s6X7Qz3JpaalyNUH5hJ2I6FFhbeyycyIiInPSPrBrxIgRsLbWPxx5eXkhPDwcycnJ2LdvH7p27aqUlZWVYcOGDdiyZQvOnDmD/Px85T2/KpUKJ0+eREFBARwdHfXafeGFFyqMbcyYMXrTgoODYW9vj9zcXNy4cQMNGjSo9LKOGjUKarXuY1RsbGwQEhKCK1eu4MyZM2jfvj0AYMeOHSgsLERAQACioqL02oqJiUGLFi1w9uzZSvdfXlZWlsH7i5s3b465c+eid+/eBufTaDRYtWoVUlNTcfnyZdy+fRsiotyr+8cff5gci3YMGFrfABAXFwdbW1vs2rULJSUlBsfJva5fvw4AcHd3NymW1NRUFBQUoHnz5njyySf1ysPDw9G5c2ekpaVh69at8PPzAwBs3boVADB8+HCD8Y0cORLLli0zKZZmzZoBAH744Qf07du3wuVev349AOD111+HnZ1dpfs5d+4cvvnmG2RkZOD69eu4c+cOAODq1asA7m7T5557rsJ2HuSzDABqtRqurq64efMmrl27hsaNG1d6GYiIagMm3UREZBGHDh0CACxZsgTffPONwTonTpwAAFy8eFGZlpOTg759+yItLe2+7d+8edNg0h0YGFhhbNqE6l4NGzbE+fPnkZ+fb1LSbay9Ro0aAQDy8/OVaSdPngQAtGvXzmh7wcHBVU667ezsEBYWBuDuQ+lOnjwJjUYDDw8PREZGGpxn//796N+/Py5dumS03ezsbJPiyM/PVx6o9uKLL963bmFhIW7cuFGpZKywsBAATEo+gf+NtdatWxt96FmbNm2Qlpam1AUq3l73247GjBw5EnPnzkVSUhJ+/vlnxMXFoVu3bujevTsee+wxvfpHjx4FAKPbz5Bly5Zh3LhxyvoypLLbtKqf5fIcHBxw8+ZN3L59u1J9EhHVJky6iYjIInJzcwHcfYpyRcr/IT5x4kSkpaWhVatWmD17NiIjI+Hh4QFbW1sAgLe3Ny5evIji4mKDbdWrV6/C/ozV0Z6t1p5VryxT2tM+fd3Z2dloe/crq4j2Pd1a+fn5mDhxIj777DP07dsXe/fuhb29vVJeWlqKIUOG4NKlS+jbty+mTJmCNm3awM3NDVZWVjh16hQCAgKMrm9jtNsfAHbu3Flh/comY9oz3Dk5OSbFo/3iQ/tFiCHapF+j0SjTKtpeVdlWTZo0QVpaGt59911s2rQJy5YtU86WR0ZGYv78+ejcubNSPy8vDwDg5uZWqfZPnz6NsWPHori4GJMmTcLzzz8PPz8/ODk5QaVS4fPPP1fKK6Oqn+XytAm+h4dHpfokIqpNmHQTEZFFODk5Abh7eW6vXr0qNU9JSYnymq3169ejVatWeuVXrlyp3kAfMm2CXv7s973KJ30PysnJCUuWLMG+ffuQkZGBefPmYdq0aUp5eno6Tp06BR8fH6xdu1bvDPL58+er3K/WnTt3YGNjU7UFuIc2aTb1zLs2Hu2l1Yb89ddfAHQT6Yq2V1W3VWBgIL7//nsUFRUhLS0N27dvx6pVq7B7927Exsbi0KFD8PX1VeK5efMmcnJy4OPjU2Hbq1evRnFxMYYOHYp58+bplZu6TavyWS6vsLBQOePesGFDk+cnIqrp+J5uIiKyiKCgIACVOzumde3aNdy6dQvu7u56Cbe2rdLS0mqL0RJatmwJADh48KDROtrLeauLlZUVZs+eDQCYN2+ezllo7SXgHTt2NHjJdlXu5QYAV1dXNGnSBABw+PDhKrVhSGhoKID/XXJdWdr1fvToUaNXMmjj1NYt/39j2+tBt5WdnR1iYmIwffp0ZGZmIioqCvn5+Vi5cqVSp02bNgCA3bt3V6pN7Tbt0qWLwXJTt2lVPsvladdrQECAzpcxRESPCibdRERkEYMGDQIA/Otf/7rvfaXlOTg4ALh7Oa2hy1TnzJlTfQFaSNeuXWFvb48TJ04YvG89JSWlyvdz30/v3r3Rvn175ObmYtGiRcp07TrXnuUtr7i4GAsWLDDapnZeY5cUa8fA/dowlfYhXXv37jV5PkdHR5w/f155MFl5e/fuRVpaGlQqFZ544glluvb/K1asMPiFT1JSkklx3I+VlRXCw8MBQOf++oEDBwIAFi5cqDwM7X7ut02PHTuGDRs2mBRXVT7L5aWnpwMAunXrZvK8RES1AZNuIiKyiKeeegqRkZE4duwYBgwYgFOnTumUFxUVYdOmTRg1apQyzc3NDW3atEFJSQkmTJigJBilpaX48MMP8e233yr3dtdWrq6uGD16NIC7T8Q+fvy4UnbkyBHEx8dX26XY93rzzTcB3E2CCwoKANy9h9ja2ho7d+7E8uXLlbq5ubn4+9//bjBx09I+9Gv79u0Gy6dMmQJ3d3csW7YMEydO1LsPOzs7G19++SVmzZpV6WUICAhAixYtkJWVhQsXLlR6PhcXF7z88ssAgPHjx2P//v1K2enTpxEfHw8AGDJkiM6D8YYNGwZPT08cOXJE58FkInLfB4vdzzvvvIMvvvhCb31kZmYqt1d06NBBmf7iiy/Cx8cHhw8fxqBBg/QeVpaamoqvv/5a+V37xcTixYtx4MABZfqJEycwePBgkz9DVfksl6e9pz82NtakfomIag1Lvq+MiIgeLdr3Hzs5OUmDBg2M/hw6dEhE7r6/t3379sp7jP39/SUiIkKCgoLE1tZWAEjjxo11+vjxxx9FpVIJAHF3d5ewsDDx8PAQAPLuu+8afWe2senloYL3KZvatvY93cnJyQbb077D+d73befm5kpoaKgAELVaLe3atZPg4GBRqVQSFhYmQ4cOFQCyfPlyo7Hey9B7uu9VUlIiLVq0EADy8ccfK9MnT56srJvmzZtLx44dxcHBQWxsbGTJkiVG250xY4YAECsrK2nfvr1ER0dLdHS0XL58WamTmpqqbD8bGxsJDg6WiIgIeeyxx5Tt/Oyzz1Z6OUVEZs6cKQBk3rx5BsuNba+CggLp3r27sqxBQUESEhIiVlZWyvvWr1+/rtfe1q1blfHq6uoq4eHh0qRJEwEgH330kbIdK+vJJ59U5vH395dOnTqJv7+/Elf37t313od94MAB5b3varVa2rRpI6GhoeLq6ioAJD4+XqlbXFwskZGRyrYJDAyUtm3bikqlEi8vL5k1a5bePCLG39MtUrXPsojI7du3xdnZWdzd3avlHeNERDURz3QTEVG1y8/Px40bN4z+lJSUALj7/t60tDQsXrwYjz/+OG7cuIH9+/dDo9GgU6dOSExMRHJysk7bAwYMwM8//4wuXbrg9u3bOH78OPz9/bFixQrMmDHDEotb7VxcXJCSkoLJkyfD29sbx44dQ15eHiZMmIDk5GRl/T3IU8wNsbKywqRJkwAAH330kXIlwZw5c7BgwQK0bt0aV65cQVZWFnr16oUdO3YgLi7OaHtTp07F9OnT4e/vjyNHjmD79u3Yvn27ziXIUVFROHLkCN555x0EBQXh7NmzOHjwINRqNeLi4rB48WJ88sknJi3HqFGjYG1trXN2tzIcHBywefNmfPLJJwgLC0NWVhZOnDiBoKAgzJo1C7t27TL4qrhevXohLS0N/fr1A3D3ioSmTZti5cqVeOmllwCYtq2mTZuGqVOnIjw8HPn5+Thw4ABu376N6OhoLF++HFu2bNF7H3ZISAgyMzPx1ltvITAwEGfPnsXp06fRpEkTvPzyy5gwYYJS19raGps3b8arr76Kxo0b49SpU8jJycHo0aOxb98+NG3a1KT1BlTtswwAGzduhEajwfDhw01+zRsRUW2hEjHxvSdERERkUcHBwcjMzMT+/fuVB4eRrhdffBGfffYZduzYoVxObQn79u1DWFgYQkJCdC7lpruio6ORnp6OEydOoFmzZpYOh4jILHimm4iIqBb5/fffkZmZqdzfToYlJibC0dHR4lc/LF26FMDdM/qkKyUlBSkpKXj11VeZcBPRI41JNxERUQ309ttv6z0QKz09HUOGDAFw9xJqcz1Q7VHg5eWF5cuXK6/YMqfk5GSsWrUKRUVFyrTi4mLMnz8fS5YsgVqtxtixY80aQ22Uk5OD6dOn46233rJ0KEREZsXLy4mIiGoglUoFAPD09ESzZs1w9epVZGVlAQDCwsKQnJzMdxrXEElJSRg5ciRsbGzQokULuLi44MSJE8jLywMAvP/++5g6daqFoyQiIkth0k1ERFQDzZkzBz/99BOOHz+O7Oxs2NraolWrVhgyZAjGjx8PR0dHS4dI/3X69GksWLAAycnJuHTpEjQaDdzd3REREYHx48fzVVhERHUck24iIiIiIiIiM+E93URERERERERmwqSbiIiIiIiIyEyYdBMRERERERGZCZNuIiIiIiIiIjNh0k1ERERERERkJky6iYiIiIiIiMyESTcRERERERGRmTDpJiIiIiIiIjITJt1EREREREREZvL/adeNCSiIw1sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_validation_curve(xticks, log_scale, val_f1s, filename):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    if log_scale:\n",
    "        # Log-scale line plot\n",
    "        plt.semilogx(xticks, val_f1s, marker=\"o\") # , label=\"Validation\")\n",
    "        plt.xticks(xticks, [f\"{x:.0e}\" for x in xticks], fontsize=14)\n",
    "    else:\n",
    "        plt.plot(xticks, val_f1s) # , label=\"Validation\")\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel(\"Learning Rate (log scale)\" if log_scale else \"Learning Rate\", fontsize=16)\n",
    "    plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n",
    "    plt.title(\"Transformer (DeBERTa-V3) Validation Curve\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "\n",
    "# learning_rate=1e-6, batch_size=16 (EPOCH 16, val_f1=0.8583, test_f1=0.848050)\n",
    "# learning_rate=5e-6, batch_size=16 (EPOCH 7, val_f1=0.8603, test_f1=0.85244) => BEST\n",
    "# learning_rate=1e-5, batch_size=16 (EPOCH 5, val_f1=0.8584, test_f1=0.85042)\n",
    "# learning_rate=2e-5, batch_size=16 (EPOCH 3, val_f1=0.8579, test_f1=0.85392)\n",
    "# learning_rate=5e-5, batch_size=16 (EPOCH 2, val_f1=0.8363, test_f1=0.836272)\n",
    "\n",
    "# learning_rate=1e-4, batch_size=16 (EPOCH 1~3, val_f1=0.2623)\n",
    "\n",
    "val_f1_scores = [0.8583, 0.8603, 0.8584, 0.8579] # , 0.2623]\n",
    "learning_rates = [1e-6, 5e-6, 1e-5, 2e-5]\n",
    "plot_validation_curve(learning_rates, True, val_f1_scores, \"pretrained_transformer_f1_score_val_curve1.png\")\n",
    "# learning_rates = [\"1e-6\\n(epoch=16)\", \"5e-6\\n(epoch=7)\", \"1e-5\\n(epoch=5)\", \"2e-5\\n(epoch=3)\"]\n",
    "# plot_validation_curve(learning_rates, False, val_f1_scores, \"pretrained_transformer_f1_score_val_curve_epoch1.png\")\n",
    "\n",
    "val_f1_scores = [0.8583, 0.8603, 0.8584, 0.8579, 0.8363] # , 0.2623]\n",
    "learning_rates = [1e-6, 5e-6, 1e-5, 2e-5, 5e-5]\n",
    "plot_validation_curve(learning_rates, True, val_f1_scores, \"pretrained_transformer_f1_score_val_curve2.png\")\n",
    "# learning_rates = [\"1e-6\\n(epoch=16)\", \"5e-6\\n(epoch=7)\", \"1e-5\\n(epoch=5)\", \"2e-5\\n(epoch=3)\", \"5e-5\\n(epoch=2)\"]\n",
    "# plot_validation_curve(learning_rates, False, val_f1_scores, \"pretrained_transformer_f1_score_val_curve_epoch2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ab5e3-0e5d-4942-bc60-b7f9bf723604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a809155e-ab79-411a-a178-8a504ee294af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_95996/312600777.py:44: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38236' max='76370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38236/76370 4:44:25 < 4:43:40, 2.24 it/s, Epoch 5.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341084</td>\n",
       "      <td>0.901881</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.888816</td>\n",
       "      <td>0.873895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.218777</td>\n",
       "      <td>0.935504</td>\n",
       "      <td>0.909765</td>\n",
       "      <td>0.919633</td>\n",
       "      <td>0.913919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.164746</td>\n",
       "      <td>0.959142</td>\n",
       "      <td>0.939431</td>\n",
       "      <td>0.952655</td>\n",
       "      <td>0.945791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.973907</td>\n",
       "      <td>0.963635</td>\n",
       "      <td>0.966295</td>\n",
       "      <td>0.964884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.087381</td>\n",
       "      <td>0.982927</td>\n",
       "      <td>0.976098</td>\n",
       "      <td>0.977472</td>\n",
       "      <td>0.976734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[60], line 56\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     45\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     46\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 56\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=10, learning_rate=2e-5, batch_size=8, output_dir=\"./deberta-v3-crisis/2\")\n",
    "# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# print(eval_results)\n",
    "\n",
    "#  # [38186/76370 4:35:02 < 4:35:02, 2.31 it/s, Epoch 5/10]\n",
    "# # Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# # 1\tNo log\t0.341084\t0.901881\t0.866828\t0.888816\t0.873895\n",
    "# # 2\tNo log\t0.218777\t0.935504\t0.909765\t0.919633\t0.913919\n",
    "# # 3\tNo log\t0.164746\t0.959142\t0.939431\t0.952655\t0.945791\n",
    "# # 4\tNo log\t0.109434\t0.973907\t0.963635\t0.966295\t0.964884\n",
    "# # 5\tNo log\t0.087381\t0.982927\t0.976098\t0.977472\t0.976734\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73ddf31d-8048-40dc-8c6b-a97d893d5872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/281152571.py:115: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='276' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 276/2710 10:21 < 1:31:57, 0.44 it/s, Epoch 1.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319999</td>\n",
       "      <td>0.888491</td>\n",
       "      <td>0.851906</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.849046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.8885, prec=0.8519, rec=0.8495, f1=0.8490\n",
      "[valid] acc=0.8709, prec=0.8351, rec=0.8190, f1=0.8247\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(eval_results)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 127\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    115\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    116\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    117\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 127\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4020\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   4019\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4020\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4022\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   4023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4024\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4025\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   4026\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4110\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4108\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   4109\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 4110\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   4112\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   4113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1102\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1102\u001b[0m     label_index \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=10, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/batchsize64\")\n",
    "# # eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# # print(eval_results)\n",
    "\n",
    "# #  [ 272/2710 07:04 < 1:03:52, 0.64 it/s, Epoch 1/10]\n",
    "# # Step\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# # 271\tNo log\t0.360962\t0.870866\t0.835089\t0.818979\t0.824688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a2faa6-fd37-4f29-ad7a-6a952b848fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/3149821493.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1014' max='9550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1014/9550 1:00:22 < 8:29:14, 0.28 it/s, Epoch 1.06/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262881</td>\n",
       "      <td>0.903174</td>\n",
       "      <td>0.863936</td>\n",
       "      <td>0.888640</td>\n",
       "      <td>0.874394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "  [train] acc=0.9032, prec=0.8639, rec=0.8886, f1=0.8744  (n=None)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[12], line 120\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    108\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    109\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    110\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 120\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=10, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/batchsize64_1\")\n",
    "# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# print(eval_results)\n",
    "# #  [1014/9550 1:00:22 < 8:29:14, 0.28 it/s, Epoch 1.06/10]\n",
    "# # Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# # 1\tNo log\t0.262881\t0.903174\t0.863936\t0.888640\t0.874394\n",
    "\n",
    "# # ================================================================================\n",
    "# # [EPOCH 1]\n",
    "# #   [train] acc=0.9032, prec=0.8639, rec=0.8886, f1=0.8744  (n=None)\n",
    "\n",
    "# # Batch size can't be as high as 256?\n",
    "# # RuntimeError: MPS backend out of memory (MPS allocated: 27.10 GB, other allocations: 832.00 KB, max allowed: 27.20 GB). Tried to allocate 375.29 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5675a2b6-2ca4-4ccf-a66a-1a82c8139042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class TrainMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, train_dataset):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.trainer = None\n",
    "        self.last_eval_metrics = None\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        if any(k.startswith(\"eval_\") for k in metrics.keys()):\n",
    "            self.last_eval_metrics = metrics\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.trainer is None:\n",
    "            return control\n",
    "\n",
    "        train_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.train_dataset,\n",
    "            metric_key_prefix=\"train\", # train_accuracy, train_f1, ...\n",
    "        )\n",
    "\n",
    "        epoch = state.epoch\n",
    "        train_acc = train_metrics.get(\"train_accuracy\", None)\n",
    "        train_f1  = train_metrics.get(\"train_f1\", None)\n",
    "\n",
    "        val_acc = None\n",
    "        val_f1  = None\n",
    "        if self.last_eval_metrics is not None:\n",
    "            val_acc = self.last_eval_metrics.get(\"eval_accuracy\", None)\n",
    "            val_f1  = self.last_eval_metrics.get(\"eval_f1\", None)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[EPOCH {epoch:.0f}]\")\n",
    "        if train_acc is not None and train_f1 is not None:\n",
    "            print(f\"  train_acc = {train_acc:.4f}, train_f1 = {train_f1:.4f}\")\n",
    "        if val_acc is not None and val_f1 is not None:\n",
    "            print(f\"  val_acc   = {val_acc:.4f}, val_f1   = {val_f1:.4f}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        return control\n",
    "\n",
    "\n",
    "def train(epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\"):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epoch,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    train_callback = TrainMetricsCallback(tokenized_datasets[\"train\"])\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[train_callback],\n",
    "    )\n",
    "\n",
    "    train_callback.trainer = trainer\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7e8d34-f563-4067-8dae-d3726081c67f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/2795326635.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2716' max='2865' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2716/2865 1:24:08 < 04:37, 0.54 it/s, Epoch 2.84/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265105</td>\n",
       "      <td>0.901373</td>\n",
       "      <td>0.860023</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.873302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.204079</td>\n",
       "      <td>0.928432</td>\n",
       "      <td>0.897973</td>\n",
       "      <td>0.917152</td>\n",
       "      <td>0.907176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "  train_acc = 0.9014, train_f1 = 0.8733\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "  train_acc = 0.9284, train_f1 = 0.9072\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/test2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[10], line 87\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     75\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     76\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     77\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 87\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=3, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/test2\")\n",
    "# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# print(eval_results)\n",
    "\n",
    "# # Batch size can't be as high as 256?\n",
    "# # RuntimeError: MPS backend out of memory (MPS allocated: 27.10 GB, other allocations: 832.00 KB, max allowed: 27.20 GB). Tried to allocate 375.29 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc0f71a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_84643/3190309381.py:41: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7802' max='11457' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7802/11457 1:12:17 < 33:52, 1.80 it/s, Epoch 2.04/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.322661</td>\n",
       "      <td>0.888241</td>\n",
       "      <td>0.851410</td>\n",
       "      <td>0.855949</td>\n",
       "      <td>0.852308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.300615</td>\n",
       "      <td>0.893398</td>\n",
       "      <td>0.853491</td>\n",
       "      <td>0.866558</td>\n",
       "      <td>0.859771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 50\u001b[0m\n\u001b[1;32m     26\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     27\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./deberta-v3-crisis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     42\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     43\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\")\n",
    "\n",
    "# # Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall  \tF1\n",
    "# # 1\t    0.311500\t    0.322661\t    0.888241\t0.851410\t0.855949\t0.852308\n",
    "# # 2\t    0.239700\t    0.300615\t    0.893398\t0.853491\t0.866558\t0.859771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09147530-f5a5-4c5a-8a5f-e8d56169444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c2942-0c4a-430e-889f-c765fa6daab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V6E1",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
