{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a9ab23-f031-44a3-88cd-4d08f1f6381c",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ec020-a4bb-430f-b561-1f0367e5f486",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7346fe-d763-4501-9a45-1c4c7a9ab363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <473B02F4-48EA-3880-8B82-14AA228F6939> /Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0869bbce-6ad5-4929-9439-c2f4bc6249f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "generator = torch.Generator()\n",
    "_ = generator.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f2506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_strs = ['time_critical', 'support_and_relief', 'non_informative']\n",
    "label2id = {label: i for i, label in enumerate(all_label_strs)}\n",
    "id2label = {i: label for label, i in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83365a1-379c-4bc6-bbcc-eb8ca273209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./data/crisisbench/preprocessed_data_train.csv\n",
      "Loading: ./data/crisisbench/preprocessed_data_dev.csv\n",
      "Loading: ./data/crisisbench/preprocessed_data_test.csv\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    df = {}\n",
    "    for d in ['train', 'dev', 'test']:\n",
    "        output_path = f\"./data/crisisbench/preprocessed_data_{d}.csv\"\n",
    "        df[d] = pd.read_csv(output_path).loc[:, ['text', 'class_label_group', 'class_label_group_num']]\n",
    "        print(\"Loading:\", output_path)\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43775508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: N=61089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approximately km long firebreaks have been con...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>god bless you</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cracked wine casks damaged historical building...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i m really just excited for new undies and pin...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rescue effort e ands in india pakistan as floo...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class_label_group  \\\n",
       "0  approximately km long firebreaks have been con...     time_critical   \n",
       "1                                      god bless you   non_informative   \n",
       "2  cracked wine casks damaged historical building...     time_critical   \n",
       "3  i m really just excited for new undies and pin...   non_informative   \n",
       "4  rescue effort e ands in india pakistan as floo...     time_critical   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      0  \n",
       "1                      2  \n",
       "2                      0  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_train: N={len(df['train'])}\")\n",
    "df['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ce818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dev: N=8921\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>congrats to all my liverpool supporting fans f...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collapsed buildings in mexico city earthquake ...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>here s your flower</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ready for a relaxing weekend but have too much...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public private information portal developed to...</td>\n",
       "      <td>support_and_relief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   class_label_group  \\\n",
       "0  congrats to all my liverpool supporting fans f...     non_informative   \n",
       "1  collapsed buildings in mexico city earthquake ...       time_critical   \n",
       "2                                 here s your flower     non_informative   \n",
       "3  ready for a relaxing weekend but have too much...     non_informative   \n",
       "4  public private information portal developed to...  support_and_relief   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      2  \n",
       "1                      0  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_dev: N={len(df['dev'])}\")\n",
    "df['dev'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d208947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test: N=17335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class_label_group</th>\n",
       "      <th>class_label_group_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staff at our feeding centre say chronic malnou...</td>\n",
       "      <td>support_and_relief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you comin down for the summer semesters right</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yea it s upstate i m like a few hours away</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teach every pakistani that it is not enough to...</td>\n",
       "      <td>non_informative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stay with for live cvg as typhoon hagupit slam...</td>\n",
       "      <td>time_critical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   class_label_group  \\\n",
       "0  staff at our feeding centre say chronic malnou...  support_and_relief   \n",
       "1      you comin down for the summer semesters right     non_informative   \n",
       "2         yea it s upstate i m like a few hours away     non_informative   \n",
       "3  teach every pakistani that it is not enough to...     non_informative   \n",
       "4  stay with for live cvg as typhoon hagupit slam...       time_critical   \n",
       "\n",
       "   class_label_group_num  \n",
       "0                      1  \n",
       "1                      2  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"df_test: N={len(df['test'])}\")\n",
    "df['test'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d27fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ea0a0",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a00974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8566f4e",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defa4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "MAX_SEQ_LEN = 64 # depends on tweet length\n",
    "EMBED_DIM = 50\n",
    "FILTER_SIZES = (3, 4, 5)\n",
    "NUM_FILTERS = 100\n",
    "DROPOUT = 0.5 # tune\n",
    "BATCH_SIZE = 64 # tune \n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 10\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "GLOVE_PATH = \"./data/crisisbench/glove_word_embeddings.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb1266",
   "metadata": {},
   "source": [
    "### Tokenizer and Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf53496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits on whitespace\n",
    "    \"\"\"\n",
    "    return text.strip().split()\n",
    "\n",
    "def build_vocab(\n",
    "    texts: List[str],\n",
    "    max_size: int,\n",
    "    min_freq: int = 1\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Build a word -> index vocab from training texts.\n",
    "    Reserves index 0 for PAD and 1 for UNK.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = simple_tokenize(text)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
    "    for word, freq in counter.most_common():\n",
    "        if freq < min_freq:\n",
    "            continue\n",
    "        if len(vocab) >= max_size:\n",
    "            break\n",
    "        vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def encode_text(\n",
    "    text: str,\n",
    "    vocab: Dict[str, int],\n",
    "    max_len: int\n",
    ") -> List[int]:\n",
    "    tokens = simple_tokenize(text)\n",
    "    ids = [vocab.get(tok, vocab[UNK_TOKEN]) for tok in tokens][:max_len]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [vocab[PAD_TOKEN]] * (max_len - len(ids))\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81ae81",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95f7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: List[int],\n",
    "        vocab: Dict[str, int],\n",
    "        max_len: int,\n",
    "    ):\n",
    "        assert len(texts) == len(labels)\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        input_ids = encode_text(text, self.vocab, self.max_len)\n",
    "        return torch.tensor(input_ids, dtype=torch.long), label\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_texts: List[str],\n",
    "    train_labels: List[int],\n",
    "    val_texts: List[str],\n",
    "    val_labels: List[int],\n",
    "    max_vocab_size: int,\n",
    "    max_seq_len: int,\n",
    "    batch_size: int,\n",
    ") -> Tuple[DataLoader, DataLoader, Dict[str, int], int]:\n",
    "    vocab = build_vocab(train_texts, max_vocab_size)\n",
    "    num_classes = len(set(train_labels))\n",
    "\n",
    "    train_dataset = TextDataset(train_texts, train_labels, vocab, max_seq_len)\n",
    "    val_dataset = TextDataset(val_texts, val_labels, vocab, max_seq_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, vocab, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d02775",
   "metadata": {},
   "source": [
    "### Load GloVe & build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1645084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(\n",
    "    glove_path: str,\n",
    "    embed_dim: int,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Load GloVe file into a dict: word -> vector (torch.Tensor).\n",
    "    Expects each line: word val1 val2 ... valD\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != embed_dim + 1:\n",
    "                # ignore malformed lines\n",
    "                continue\n",
    "            word = parts[0]\n",
    "            vec = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float32)\n",
    "            embeddings[word] = vec\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def build_embedding_matrix(\n",
    "    vocab: Dict[str, int],\n",
    "    glove_embeddings: Dict[str, torch.Tensor],\n",
    "    embed_dim: int,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create an embedding matrix of shape [vocab_size, embed_dim]\n",
    "    where row i is the vector for the word with index i.\n",
    "    Words not found in GloVe are randomly initialized (small normal).\n",
    "    \"\"\"\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_matrix = torch.empty(vocab_size, embed_dim, dtype=torch.float32)\n",
    "\n",
    "    # Initialize OOV embeddings to small random values\n",
    "    torch.nn.init.normal_(embedding_matrix, mean=0.0, std=0.05)\n",
    "\n",
    "    # Set PAD embedding to zeros\n",
    "    pad_idx = vocab[PAD_TOKEN]\n",
    "    embedding_matrix[pad_idx] = torch.zeros(embed_dim, dtype=torch.float32)\n",
    "\n",
    "    oov_count = 0\n",
    "    for word, idx in vocab.items():\n",
    "        if word in (PAD_TOKEN, UNK_TOKEN):\n",
    "            continue\n",
    "        vec = glove_embeddings.get(word)\n",
    "        if vec is not None:\n",
    "            embedding_matrix[idx] = vec\n",
    "        else:\n",
    "            oov_count += 1\n",
    "\n",
    "    print(f\"GloVe OOV words: {oov_count}/{vocab_size}\")\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60863f21",
   "metadata": {},
   "source": [
    "### Text CNN model (with optional pretrained embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f94c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        num_classes: int,\n",
    "        pad_idx: int = 0,\n",
    "        num_filters: int = 100,\n",
    "        filter_sizes: Tuple[int, ...] = (3, 4, 5),\n",
    "        dropout: float = 0.5,\n",
    "        pretrained_embeddings: torch.Tensor | None = None,\n",
    "        freeze_embeddings: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embed_dim,\n",
    "            padding_idx=pad_idx,\n",
    "        )\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            if pretrained_embeddings.shape != (vocab_size, embed_dim):\n",
    "                raise ValueError(\n",
    "                    f\"Pretrained embeddings shape {pretrained_embeddings.shape} \"\n",
    "                    f\"does not match (vocab_size, embed_dim)=({vocab_size}, {embed_dim})\"\n",
    "                )\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "            if freeze_embeddings:\n",
    "                self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=embed_dim,\n",
    "                out_channels=num_filters,\n",
    "                kernel_size=fs,\n",
    "            )\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        embedded = self.embedding(input_ids)          # [B, L, D]\n",
    "        embedded = embedded.transpose(1, 2)           # [B, D, L]\n",
    "\n",
    "        conv_outputs = []\n",
    "        for conv in self.convs:\n",
    "            x = conv(embedded)                        # [B, F, L']\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool1d(x, x.size(2)).squeeze(2) # [B, F]\n",
    "            conv_outputs.append(x)\n",
    "\n",
    "        cat = torch.cat(conv_outputs, dim=1)          # [B, F * len(filter_sizes)]\n",
    "        cat = self.dropout(cat)\n",
    "        logits = self.fc(cat)                         # [B, num_classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93543e0d",
   "metadata": {},
   "source": [
    "### Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1baee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for input_ids, labels in dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * input_ids.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(input_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67776a78",
   "metadata": {},
   "source": [
    "### Main CNN Train Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99044bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 20000, Num classes: 3\n",
      "Loading GloVe embeddings...\n",
      "GloVe OOV words: 882/20000\n",
      "Epoch 01 | Train Loss: 0.4595, Train Acc: 0.8258 | Val Loss: 0.3805, Val Acc: 0.8552\n",
      "Epoch 02 | Train Loss: 0.3572, Train Acc: 0.8675 | Val Loss: 0.3513, Val Acc: 0.8696\n",
      "Epoch 03 | Train Loss: 0.3088, Train Acc: 0.8865 | Val Loss: 0.3488, Val Acc: 0.8734\n",
      "Epoch 04 | Train Loss: 0.2718, Train Acc: 0.9027 | Val Loss: 0.3552, Val Acc: 0.8731\n",
      "Epoch 05 | Train Loss: 0.2348, Train Acc: 0.9148 | Val Loss: 0.3815, Val Acc: 0.8666\n",
      "Epoch 06 | Train Loss: 0.2045, Train Acc: 0.9268 | Val Loss: 0.3986, Val Acc: 0.8658\n",
      "Epoch 07 | Train Loss: 0.1774, Train Acc: 0.9370 | Val Loss: 0.4382, Val Acc: 0.8646\n",
      "Epoch 08 | Train Loss: 0.1547, Train Acc: 0.9453 | Val Loss: 0.4868, Val Acc: 0.8606\n",
      "Epoch 09 | Train Loss: 0.1365, Train Acc: 0.9517 | Val Loss: 0.5132, Val Acc: 0.8562\n",
      "Epoch 10 | Train Loss: 0.1208, Train Acc: 0.9579 | Val Loss: 0.5814, Val Acc: 0.8569\n",
      "Best validation accuracy: 0.8734\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_df = df['train'].dropna(subset=['text'])\n",
    "train_texts = train_df['text'].tolist()\n",
    "train_label_strs = train_df['class_label_group']\n",
    "\n",
    "val_df = df['dev'].dropna(subset=['text'])\n",
    "val_texts = val_df['text'].tolist()\n",
    "val_label_strs = val_df['class_label_group']\n",
    "\n",
    "all_label_strs = sorted(set(train_label_strs) | set(val_label_strs))\n",
    "label2id = {label: i for i, label in enumerate(all_label_strs)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "train_labels = [label2id[l] for l in train_label_strs]\n",
    "val_labels   = [label2id[l] for l in val_label_strs]\n",
    "# Create loaders and vocab\n",
    "train_loader, val_loader, vocab, num_classes = create_dataloaders(\n",
    "    train_texts=train_texts,\n",
    "    train_labels=train_labels,\n",
    "    val_texts=val_texts,\n",
    "    val_labels=val_labels,\n",
    "    max_vocab_size=MAX_VOCAB_SIZE,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "print(f\"Vocab size: {len(vocab)}, Num classes: {num_classes}\")\n",
    "\n",
    "# Load GloVe embeddings\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "glove_embeds = load_glove_embeddings(GLOVE_PATH, EMBED_DIM)\n",
    "embedding_matrix = build_embedding_matrix(vocab, glove_embeds, EMBED_DIM)\n",
    "\n",
    "# Initialize model with pretrained embeddings\n",
    "print(\"Model Initialization...\")\n",
    "model = TextCNN(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_classes=num_classes,\n",
    "    pad_idx=vocab[PAD_TOKEN],\n",
    "    num_filters=NUM_FILTERS,\n",
    "    filter_sizes=FILTER_SIZES,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_embeddings=embedding_matrix,\n",
    "    freeze_embeddings=False,   # set True if you want to freeze GloVe\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0.0\n",
    "print(\"Training...\")\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "    val_loss, val_acc = evaluate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_textcnn_glove.pt\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b973a",
   "metadata": {},
   "source": [
    "### Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1fdb0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics:\n",
      "accuracy: 0.8734\n",
      "precision: 0.8467\n",
      "recall: 0.8108\n",
      "f1: 0.8272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Helper to get predictions + labels from a DataLoader\n",
    "def get_all_preds_and_labels(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(input_ids)          # [B, num_classes]\n",
    "            preds = logits.argmax(dim=1)      # [B]\n",
    "\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# compute accuracy, precision, recall, F1 (macro)\n",
    "def compute_classification_metrics(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "    average: str = \"macro\",   # \"macro\", \"micro\", or \"weighted\"\n",
    "):\n",
    "    preds, labels = get_all_preds_and_labels(model, dataloader, device)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=average,\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_textcnn_glove.pt\", map_location=device))\n",
    "\n",
    "# For validation metrics\n",
    "val_metrics = compute_classification_metrics(model, val_loader, device, average=\"macro\")\n",
    "print(\"Validation metrics:\")\n",
    "for k, v in val_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051a548-63f6-4e96-8f3d-fed56f14f42e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b22bed-3c0a-4439-a1a8-7090fa815932",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "032841ea-0f01-437d-aff7-2e43f2d574f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        num_labels = 3,\n",
    "        max_length = 64,\n",
    "        d_model = 256, # hidden size\n",
    "        nhead = 4, # number of attention heads\n",
    "        num_layers = 4, # number of encoder layers\n",
    "        dim_feedforward = 512,  # FFN inner dim\n",
    "        dropout = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Embedding(max_length, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True, # (batch, seq, dim)\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, num_labels),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch_size, seq_len = input_ids.size()\n",
    "        if seq_len > self.max_length:\n",
    "            raise ValueError(f\"seq_len {seq_len} > max_length {self.max_length}\")\n",
    "\n",
    "        token_emb = self.token_embedding(input_ids)  # (B, L, D)\n",
    "\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)  # (1, L)\n",
    "        pos_emb = self.pos_embedding(positions)  # (1, L, D)\n",
    "\n",
    "        x = token_emb + pos_emb  # (B, L, D)\n",
    "\n",
    "        src_key_padding_mask = (attention_mask == 0)  # (B, L), bool\n",
    "\n",
    "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)  # (B, L, D)\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        mask = attention_mask.unsqueeze(-1)  # (B, L, 1)\n",
    "        masked_x = x * mask  # (B, L, D)\n",
    "\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)  # (B, 1)\n",
    "        pooled = masked_x.sum(dim=1) / lengths  # (B, D)\n",
    "\n",
    "        logits = self.classifier(pooled)  # (B, num_labels)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a35066bf-4d49-4551-b3d0-562a55e3f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_preds(all_logits, all_labels):\n",
    "    logits = np.concatenate(all_logits, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc4272-73e0-47e6-a9ea-1a4763bdc1e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "795519ff-4e33-408a-9759-503266752b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_texts = df[\"train\"][\"text\"].tolist()\n",
    "dev_texts   = df[\"dev\"][\"text\"].tolist()\n",
    "test_texts   = df[\"test\"][\"text\"].tolist()\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=30000, # could be adjusted\n",
    "    min_frequency=2,\n",
    "    special_tokens=special_tokens,\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(train_texts, trainer=trainer)\n",
    "\n",
    "max_length = 64\n",
    "pad_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "\n",
    "tokenizer.enable_truncation(max_length=max_length)\n",
    "tokenizer.enable_padding(\n",
    "    length=max_length,\n",
    "    pad_id=pad_id,\n",
    "    pad_token=\"[PAD]\",\n",
    ")\n",
    "\n",
    "def encode_batch(texts):\n",
    "    encodings = tokenizer.encode_batch(texts)\n",
    "    input_ids = [e.ids for e in encodings]\n",
    "    attention_mask = [e.attention_mask for e in encodings]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "train_enc = encode_batch(train_texts)\n",
    "dev_enc   = encode_batch(dev_texts)\n",
    "test_enc   = encode_batch(test_texts)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      train_enc[\"input_ids\"],\n",
    "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"train\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      dev_enc[\"input_ids\"],\n",
    "    \"attention_mask\": dev_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"dev\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\":      test_enc[\"input_ids\"],\n",
    "    \"attention_mask\": test_enc[\"attention_mask\"],\n",
    "    \"label\":          df[\"test\"][\"class_label_group_num\"].tolist(),\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829ec10-0fca-4019-a3c1-f1e129e0f0ad",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b20bfc4-260d-4557-9450-51fa9d8bcd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluate\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            all_logits.append(logits.detach().cpu().numpy())\n",
    "            all_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(data_loader)\n",
    "    metrics = compute_metrics_from_preds(all_logits, all_labels)\n",
    "    metrics[\"loss\"] = val_loss\n",
    "    return metrics\n",
    "    \n",
    "def train(\n",
    "        d_model=256,\n",
    "        nhead=4,\n",
    "        num_layers=4,\n",
    "        dim_feedforward=512,\n",
    "        dropout=0.1,\n",
    "        lr=1e-4,\n",
    "        batch_size = 32,\n",
    "        weight_decay=0.01,\n",
    "        last_epoch=0,\n",
    "        max_epochs=3,\n",
    "        save_path=\"./transformers/best_transformer_1.pt\"\n",
    "    ):\n",
    "    num_labels = len(label2id)\n",
    "    vocab_size = tokenizer.get_vocab_size()\n",
    "    max_length = 64\n",
    "    \n",
    "    model = TransformerClassifier(\n",
    "        vocab_size=vocab_size,\n",
    "        num_labels=num_labels,\n",
    "        max_length=max_length,\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_layers=num_layers,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        dropout=dropout,\n",
    "    ).to(device)\n",
    "    \n",
    "    # AdamW + weight decay\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        tokenized_datasets[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        tokenized_datasets[\"validation\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        tokenized_datasets[\"test\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        state = torch.load(save_path, map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "    else: # not os.path.exists(save_path) or last_epoch > 0:\n",
    "        logging_steps = 50\n",
    "        best_f1 = 0.0\n",
    "        best_state_dict = None\n",
    "        global_step = 0\n",
    "        \n",
    "        for epoch in range(last_epoch, max_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "        \n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs} [train]\")\n",
    "            for batch in pbar:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(logits, labels)\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                total_loss += loss.item()\n",
    "                global_step += 1\n",
    "        \n",
    "                if global_step % logging_steps == 0:\n",
    "                    avg_loss = total_loss / logging_steps\n",
    "                    pbar.set_postfix({\"loss\": f\"{avg_loss:.4f}\"})\n",
    "                    total_loss = 0.0\n",
    "    \n",
    "            # print performance every epoch\n",
    "            train_metrics = evaluate_model(model, train_loader)\n",
    "            val_metrics   = evaluate_model(model, val_loader)\n",
    "\n",
    "            print(f\"Epoch {epoch+1} train: train_loss  = {train_metrics['loss']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: accuracy    = {train_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: precision   = {train_metrics['precision']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: recall      = {train_metrics['recall']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} train: f1          = {train_metrics['f1']:.4f}\")\n",
    "\n",
    "            print(f\"Epoch {epoch+1} validation: val_loss    = {val_metrics['loss']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: accuracy    = {val_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: precision   = {val_metrics['precision']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: recall      = {val_metrics['recall']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1} validation: f1          = {val_metrics['f1']:.4f}\")\n",
    "\n",
    "            # save best model (highest f1)\n",
    "            if val_metrics[\"f1\"] > best_f1:\n",
    "                best_f1 = val_metrics[\"f1\"]\n",
    "                best_state_dict = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "                torch.save(best_state_dict, save_path)\n",
    "                print(f\"New best model (f1={best_f1:.4f}) saved.\\n\")\n",
    "            \n",
    "        # load best model\n",
    "        if best_state_dict is not None:\n",
    "            model.load_state_dict(best_state_dict)\n",
    "            print(f\"Loaded best model with f1={best_f1:.4f}\")\n",
    "    return model, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e763b1-3338-486c-9aa7-41615300b3de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "272f765d-dbea-4fe1-97cd-d7242e1499f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d98e0fa93940e5be2a9f443d3f67de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8400346120565331, 'precision': 0.7853384733927123, 'recall': 0.791181843157427, 'f1': 0.7880170998346174, 'loss': 0.4298086559805483}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=10, save_path=\"./transformers/best_transformer_1_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   f1          = 0.7790\n",
    "# Epoch 1 validation:\n",
    "#   f1          = 0.7610\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   f1          = 0.8281\n",
    "# Epoch 2 validation:\n",
    "#   f1          = 0.7858\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   f1          = 0.8610\n",
    "# Epoch 3 validation:\n",
    "#   f1          = 0.7978\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   f1          = 0.8896\n",
    "# Epoch 4 validation:\n",
    "#   f1          = 0.8002\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8400346120565331, 'precision': 0.7853384733927123, 'recall': 0.791181843157427, 'f1': 0.7880170998346174, 'loss': 0.4298086559805483}\n",
    "#### Overfitting ######\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   f1          = 0.9136\n",
    "# Epoch 5 validation:\n",
    "#   f1          = 0.7984\n",
    "\n",
    "# Epoch 6 train:\n",
    "#   f1          = 0.9454\n",
    "# Epoch 6 validation:\n",
    "#   f1          = 0.7911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7bf33-240d-48d6-8db9-4a3afe262ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.4335\n",
    "#   accuracy    = 0.8384\n",
    "#   precision   = 0.8024\n",
    "#   recall      = 0.7603\n",
    "#   f1          = 0.7790\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.4582\n",
    "#   accuracy    = 0.8268\n",
    "#   precision   = 0.7841\n",
    "#   recall      = 0.7429\n",
    "#   f1          = 0.7610\n",
    "# New best model (f1=0.7610) saved.\n",
    "\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   train_loss  = 0.3628\n",
    "#   accuracy    = 0.8716\n",
    "#   precision   = 0.8343\n",
    "#   recall      = 0.8230\n",
    "#   f1          = 0.8281\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss    = 0.4280\n",
    "#   accuracy    = 0.8413\n",
    "#   precision   = 0.7921\n",
    "#   recall      = 0.7802\n",
    "#   f1          = 0.7858\n",
    "# New best model (f1=0.7858) saved.\n",
    "\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   train_loss  = 0.2929\n",
    "#   accuracy    = 0.8966\n",
    "#   precision   = 0.8722\n",
    "#   recall      = 0.8507\n",
    "#   f1          = 0.8610\n",
    "\n",
    "# Epoch 3 validation:\n",
    "#   val_loss    = 0.4102\n",
    "#   accuracy    = 0.8530\n",
    "#   precision   = 0.8135\n",
    "#   recall      = 0.7843\n",
    "#   f1          = 0.7978\n",
    "# New best model (f1=0.7978) saved.\n",
    "\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   train_loss  = 0.2442\n",
    "#   accuracy    = 0.9165\n",
    "#   precision   = 0.8866\n",
    "#   recall      = 0.8927\n",
    "#   f1          = 0.8896\n",
    "\n",
    "# Epoch 4 validation:\n",
    "#   val_loss    = 0.4170\n",
    "#   accuracy    = 0.8504\n",
    "#   precision   = 0.8002\n",
    "#   recall      = 0.8006\n",
    "#   f1          = 0.8002\n",
    "# New best model (f1=0.8002) saved.\n",
    "\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   train_loss  = 0.1945\n",
    "#   accuracy    = 0.9336\n",
    "#   precision   = 0.9034\n",
    "#   recall      = 0.9247\n",
    "#   f1          = 0.9136\n",
    "\n",
    "# Epoch 5 validation:\n",
    "#   val_loss    = 0.4526\n",
    "#   accuracy    = 0.8463\n",
    "#   precision   = 0.7909\n",
    "#   recall      = 0.8072\n",
    "#   f1          = 0.7984\n",
    "\n",
    "\n",
    "# Epoch 6 train:\n",
    "#   train_loss  = 0.1474\n",
    "#   accuracy    = 0.9585\n",
    "#   precision   = 0.9492\n",
    "#   recall      = 0.9417\n",
    "#   f1          = 0.9454\n",
    "\n",
    "# Epoch 6 validation:\n",
    "#   val_loss    = 0.4453\n",
    "#   accuracy    = 0.8478\n",
    "#   precision   = 0.8033\n",
    "#   recall      = 0.7803\n",
    "#   f1          = 0.7911\n",
    "\n",
    "\n",
    "# Epoch 7 train:\n",
    "#   train_loss  = 0.1082\n",
    "#   accuracy    = 0.9660\n",
    "#   precision   = 0.9628\n",
    "#   recall      = 0.9469\n",
    "#   f1          = 0.9543\n",
    "\n",
    "# Epoch 7 validation:\n",
    "#   val_loss    = 0.5228\n",
    "#   accuracy    = 0.8459\n",
    "#   precision   = 0.8061\n",
    "#   recall      = 0.7696\n",
    "#   f1          = 0.7849\n",
    "\n",
    "\n",
    "# Epoch 8 train:\n",
    "#   train_loss  = 0.0803\n",
    "#   accuracy    = 0.9758\n",
    "#   precision   = 0.9719\n",
    "#   recall      = 0.9637\n",
    "#   f1          = 0.9677\n",
    "\n",
    "# Epoch 8 validation:\n",
    "#   val_loss    = 0.5808\n",
    "#   accuracy    = 0.8446\n",
    "#   precision   = 0.8029\n",
    "#   recall      = 0.7728\n",
    "#   f1          = 0.7867"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7f725-7ea2-4f1d-96de-d680ac9b89b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbce5ab7-1dbf-4d74-9614-8781b96abd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6387aeb920ac4325a3e90082e3a8502a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30fcbf12aa642c18e2fccb89d23dde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c5d60ced0b47b3b39cf220134b19bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train: train_loss  = 0.5130\n",
      "Epoch 1 train: accuracy    = 0.8026\n",
      "Epoch 1 train: precision   = 0.7595\n",
      "Epoch 1 train: recall      = 0.7103\n",
      "Epoch 1 train: f1          = 0.7275\n",
      "Epoch 1 validation: val_loss    = 0.5323\n",
      "Epoch 1 validation: accuracy    = 0.7972\n",
      "Epoch 1 validation: precision   = 0.7488\n",
      "Epoch 1 validation: recall      = 0.7015\n",
      "Epoch 1 validation: f1          = 0.7189\n",
      "New best model (f1=0.7189) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e066ce449c574414800673366d03c803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3311fcbb2f05407abde1f88f7ad59b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37425a67e685433eae554efae36bd166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train: train_loss  = 0.4540\n",
      "Epoch 2 train: accuracy    = 0.8300\n",
      "Epoch 2 train: precision   = 0.7967\n",
      "Epoch 2 train: recall      = 0.7502\n",
      "Epoch 2 train: f1          = 0.7626\n",
      "Epoch 2 validation: val_loss    = 0.4897\n",
      "Epoch 2 validation: accuracy    = 0.8115\n",
      "Epoch 2 validation: precision   = 0.7644\n",
      "Epoch 2 validation: recall      = 0.7226\n",
      "Epoch 2 validation: f1          = 0.7331\n",
      "New best model (f1=0.7331) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184693d561a94aedb386395c82b7777d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b828be4032e45b9b26f6cc168d03373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aeb1acd54a4990bea5af2c8d1a384b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train: train_loss  = 0.3880\n",
      "Epoch 3 train: accuracy    = 0.8566\n",
      "Epoch 3 train: precision   = 0.8315\n",
      "Epoch 3 train: recall      = 0.7796\n",
      "Epoch 3 train: f1          = 0.8023\n",
      "Epoch 3 validation: val_loss    = 0.4413\n",
      "Epoch 3 validation: accuracy    = 0.8349\n",
      "Epoch 3 validation: precision   = 0.8002\n",
      "Epoch 3 validation: recall      = 0.7471\n",
      "Epoch 3 validation: f1          = 0.7700\n",
      "New best model (f1=0.7700) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64d880b025d4ec8867455d763d629d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc3911432114d40a6eedd5c3477dd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64214bcc38f64804bc459b179b8321a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train: train_loss  = 0.3526\n",
      "Epoch 4 train: accuracy    = 0.8742\n",
      "Epoch 4 train: precision   = 0.8360\n",
      "Epoch 4 train: recall      = 0.8275\n",
      "Epoch 4 train: f1          = 0.8314\n",
      "Epoch 4 validation: val_loss    = 0.4302\n",
      "Epoch 4 validation: accuracy    = 0.8385\n",
      "Epoch 4 validation: precision   = 0.7880\n",
      "Epoch 4 validation: recall      = 0.7778\n",
      "Epoch 4 validation: f1          = 0.7824\n",
      "New best model (f1=0.7824) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da61e4ae3d54b87a29074bb13d66ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3a5688b2574c51beab9d8ed0fed221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d06bc2b234cbc9625af237518a784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train: train_loss  = 0.3248\n",
      "Epoch 5 train: accuracy    = 0.8821\n",
      "Epoch 5 train: precision   = 0.8390\n",
      "Epoch 5 train: recall      = 0.8512\n",
      "Epoch 5 train: f1          = 0.8446\n",
      "Epoch 5 validation: val_loss    = 0.4381\n",
      "Epoch 5 validation: accuracy    = 0.8349\n",
      "Epoch 5 validation: precision   = 0.7781\n",
      "Epoch 5 validation: recall      = 0.7863\n",
      "Epoch 5 validation: f1          = 0.7815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5223c3290754a5283c10295557d3cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeea49fc1d946a8a693bd72ff6b9928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22adda1d841942529b3f8bfac7934000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train: train_loss  = 0.3030\n",
      "Epoch 6 train: accuracy    = 0.8875\n",
      "Epoch 6 train: precision   = 0.8918\n",
      "Epoch 6 train: recall      = 0.8104\n",
      "Epoch 6 train: f1          = 0.8443\n",
      "Epoch 6 validation: val_loss    = 0.4422\n",
      "Epoch 6 validation: accuracy    = 0.8413\n",
      "Epoch 6 validation: precision   = 0.8258\n",
      "Epoch 6 validation: recall      = 0.7434\n",
      "Epoch 6 validation: f1          = 0.7765\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559cef063ba04efcb52ef89af38a04df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623f25210a0847289437c5b956819c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c999f62300c453180149d8e606351ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train: train_loss  = 0.2480\n",
      "Epoch 7 train: accuracy    = 0.9143\n",
      "Epoch 7 train: precision   = 0.9079\n",
      "Epoch 7 train: recall      = 0.8629\n",
      "Epoch 7 train: f1          = 0.8830\n",
      "Epoch 7 validation: val_loss    = 0.4434\n",
      "Epoch 7 validation: accuracy    = 0.8452\n",
      "Epoch 7 validation: precision   = 0.8135\n",
      "Epoch 7 validation: recall      = 0.7608\n",
      "Epoch 7 validation: f1          = 0.7835\n",
      "New best model (f1=0.7835) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724be301a5e14ce5a557ee36fe4e129e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9dc6f57f8a4ca1a1232037ac2777d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116e803f27294a2bb75c9f1d90cb4612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train: train_loss  = 0.2141\n",
      "Epoch 8 train: accuracy    = 0.9270\n",
      "Epoch 8 train: precision   = 0.9154\n",
      "Epoch 8 train: recall      = 0.8900\n",
      "Epoch 8 train: f1          = 0.9017\n",
      "Epoch 8 validation: val_loss    = 0.4528\n",
      "Epoch 8 validation: accuracy    = 0.8452\n",
      "Epoch 8 validation: precision   = 0.8071\n",
      "Epoch 8 validation: recall      = 0.7687\n",
      "Epoch 8 validation: f1          = 0.7856\n",
      "New best model (f1=0.7856) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afff0f572edb47449088cb0fa1e38b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae9d9a7ff5541458812e04c70ac947d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdccdcb663447fbb7962ef837252941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train: train_loss  = 0.1827\n",
      "Epoch 9 train: accuracy    = 0.9407\n",
      "Epoch 9 train: precision   = 0.9337\n",
      "Epoch 9 train: recall      = 0.9081\n",
      "Epoch 9 train: f1          = 0.9199\n",
      "Epoch 9 validation: val_loss    = 0.4592\n",
      "Epoch 9 validation: accuracy    = 0.8447\n",
      "Epoch 9 validation: precision   = 0.8086\n",
      "Epoch 9 validation: recall      = 0.7655\n",
      "Epoch 9 validation: f1          = 0.7844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd38f4d07034d57be814c13f753f27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65903f1c2bc14f51b5cc222826cbe91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/_monitor.py\", line 84, in run\n",
      "    instance.refresh(nolock=True)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/std.py\", line 1347, in refresh\n",
      "    self.display()\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/tqdm/notebook.py\", line 171, in display\n",
      "    rtext.value = right\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 716, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 706, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/traitlets/traitlets.py\", line 1513, in _notify_trait\n",
      "    self.notify_change(\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 700, in notify_change\n",
      "    self.send_state(key=name)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 586, in send_state\n",
      "    self._send(msg, buffers=buffers)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipywidgets/widgets/widget.py\", line 825, in _send\n",
      "    self.comm.send(data=msg, buffers=buffers)\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/comm/base_comm.py\", line 144, in send\n",
      "    self.publish_msg(\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipykernel/comm/comm.py\", line 42, in publish_msg\n",
      "    parent=self.kernel.get_parent(),\n",
      "  File \"/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 797, in get_parent\n",
      "    return self._shell_parent.get()\n",
      "LookupError: <ContextVar name='shell_parent' at 0x1213bd300>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bb4bb7df8043668b65a10cd43afe99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train: train_loss  = 0.1740\n",
      "Epoch 10 train: accuracy    = 0.9423\n",
      "Epoch 10 train: precision   = 0.9192\n",
      "Epoch 10 train: recall      = 0.9270\n",
      "Epoch 10 train: f1          = 0.9217\n",
      "Epoch 10 validation: val_loss    = 0.4961\n",
      "Epoch 10 validation: accuracy    = 0.8335\n",
      "Epoch 10 validation: precision   = 0.7845\n",
      "Epoch 10 validation: recall      = 0.7833\n",
      "Epoch 10 validation: f1          = 0.7799\n",
      "Loaded best model with f1=0.7856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43871e160fe448968b8fa7049a788252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/2167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=10, save_path=\"./transformers/best_transformer_2_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 8 validation: f1          = 0.7856\n",
    "# Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb4d3f-9d18-4709-8a1e-3c03c6a57422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train: train_loss  = 0.5130\n",
    "# Epoch 1 train: accuracy    = 0.8026\n",
    "# Epoch 1 train: precision   = 0.7595\n",
    "# Epoch 1 train: recall      = 0.7103\n",
    "# Epoch 1 train: f1          = 0.7275\n",
    "# Epoch 1 validation: val_loss    = 0.5323\n",
    "# Epoch 1 validation: accuracy    = 0.7972\n",
    "# Epoch 1 validation: precision   = 0.7488\n",
    "# Epoch 1 validation: recall      = 0.7015\n",
    "# Epoch 1 validation: f1          = 0.7189\n",
    "# New best model (f1=0.7189) saved.\n",
    "\n",
    "# Epoch 2 train: train_loss  = 0.4540\n",
    "# Epoch 2 train: accuracy    = 0.8300\n",
    "# Epoch 2 train: precision   = 0.7967\n",
    "# Epoch 2 train: recall      = 0.7502\n",
    "# Epoch 2 train: f1          = 0.7626\n",
    "# Epoch 2 validation: val_loss    = 0.4897\n",
    "# Epoch 2 validation: accuracy    = 0.8115\n",
    "# Epoch 2 validation: precision   = 0.7644\n",
    "# Epoch 2 validation: recall      = 0.7226\n",
    "# Epoch 2 validation: f1          = 0.7331\n",
    "# New best model (f1=0.7331) saved.\n",
    "\n",
    "# Epoch 3 train: train_loss  = 0.3880\n",
    "# Epoch 3 train: accuracy    = 0.8566\n",
    "# Epoch 3 train: precision   = 0.8315\n",
    "# Epoch 3 train: recall      = 0.7796\n",
    "# Epoch 3 train: f1          = 0.8023\n",
    "# Epoch 3 validation: val_loss    = 0.4413\n",
    "# Epoch 3 validation: accuracy    = 0.8349\n",
    "# Epoch 3 validation: precision   = 0.8002\n",
    "# Epoch 3 validation: recall      = 0.7471\n",
    "# Epoch 3 validation: f1          = 0.7700\n",
    "# New best model (f1=0.7700) saved.\n",
    "\n",
    "# Epoch 4 train: train_loss  = 0.3526\n",
    "# Epoch 4 train: accuracy    = 0.8742\n",
    "# Epoch 4 train: precision   = 0.8360\n",
    "# Epoch 4 train: recall      = 0.8275\n",
    "# Epoch 4 train: f1          = 0.8314\n",
    "# Epoch 4 validation: val_loss    = 0.4302\n",
    "# Epoch 4 validation: accuracy    = 0.8385\n",
    "# Epoch 4 validation: precision   = 0.7880\n",
    "# Epoch 4 validation: recall      = 0.7778\n",
    "# Epoch 4 validation: f1          = 0.7824\n",
    "# New best model (f1=0.7824) saved.\n",
    "\n",
    "# Epoch 5 train: train_loss  = 0.3248\n",
    "# Epoch 5 train: accuracy    = 0.8821\n",
    "# Epoch 5 train: precision   = 0.8390\n",
    "# Epoch 5 train: recall      = 0.8512\n",
    "# Epoch 5 train: f1          = 0.8446\n",
    "# Epoch 5 validation: val_loss    = 0.4381\n",
    "# Epoch 5 validation: accuracy    = 0.8349\n",
    "# Epoch 5 validation: precision   = 0.7781\n",
    "# Epoch 5 validation: recall      = 0.7863\n",
    "# Epoch 5 validation: f1          = 0.7815\n",
    "\n",
    "# Epoch 6 train: train_loss  = 0.3030\n",
    "# Epoch 6 train: accuracy    = 0.8875\n",
    "# Epoch 6 train: precision   = 0.8918\n",
    "# Epoch 6 train: recall      = 0.8104\n",
    "# Epoch 6 train: f1          = 0.8443\n",
    "# Epoch 6 validation: val_loss    = 0.4422\n",
    "# Epoch 6 validation: accuracy    = 0.8413\n",
    "# Epoch 6 validation: precision   = 0.8258\n",
    "# Epoch 6 validation: recall      = 0.7434\n",
    "# Epoch 6 validation: f1          = 0.7765\n",
    "\n",
    "# Epoch 7 train: train_loss  = 0.2480\n",
    "# Epoch 7 train: accuracy    = 0.9143\n",
    "# Epoch 7 train: precision   = 0.9079\n",
    "# Epoch 7 train: recall      = 0.8629\n",
    "# Epoch 7 train: f1          = 0.8830\n",
    "# Epoch 7 validation: val_loss    = 0.4434\n",
    "# Epoch 7 validation: accuracy    = 0.8452\n",
    "# Epoch 7 validation: precision   = 0.8135\n",
    "# Epoch 7 validation: recall      = 0.7608\n",
    "# Epoch 7 validation: f1          = 0.7835\n",
    "# New best model (f1=0.7835) saved.\n",
    "\n",
    "# Epoch 8 train: train_loss  = 0.2141\n",
    "# Epoch 8 train: accuracy    = 0.9270\n",
    "# Epoch 8 train: precision   = 0.9154\n",
    "# Epoch 8 train: recall      = 0.8900\n",
    "# Epoch 8 train: f1          = 0.9017\n",
    "# Epoch 8 validation: val_loss    = 0.4528\n",
    "# Epoch 8 validation: accuracy    = 0.8452\n",
    "# Epoch 8 validation: precision   = 0.8071\n",
    "# Epoch 8 validation: recall      = 0.7687\n",
    "# Epoch 8 validation: f1          = 0.7856\n",
    "# New best model (f1=0.7856) saved.\n",
    "\n",
    "# Epoch 9 train: train_loss  = 0.1827\n",
    "# Epoch 9 train: accuracy    = 0.9407\n",
    "# Epoch 9 train: precision   = 0.9337\n",
    "# Epoch 9 train: recall      = 0.9081\n",
    "# Epoch 9 train: f1          = 0.9199\n",
    "# Epoch 9 validation: val_loss    = 0.4592\n",
    "# Epoch 9 validation: accuracy    = 0.8447\n",
    "# Epoch 9 validation: precision   = 0.8086\n",
    "# Epoch 9 validation: recall      = 0.7655\n",
    "# Epoch 9 validation: f1          = 0.7844\n",
    "\n",
    "# Epoch 10 train: train_loss  = 0.1740\n",
    "# Epoch 10 train: accuracy    = 0.9423\n",
    "# Epoch 10 train: precision   = 0.9192\n",
    "# Epoch 10 train: recall      = 0.9270\n",
    "# Epoch 10 train: f1          = 0.9217\n",
    "# Epoch 10 validation: val_loss    = 0.4961\n",
    "# Epoch 10 validation: accuracy    = 0.8335\n",
    "# Epoch 10 validation: precision   = 0.7845\n",
    "# Epoch 10 validation: recall      = 0.7833\n",
    "# Epoch 10 validation: f1          = 0.7799\n",
    "# Loaded best model with f1=0.7856\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8290164407268532, 'precision': 0.7781233569073217, 'recall': 0.779202518179055, 'f1': 0.7745706072789392, 'loss': 0.5107962098306782}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1560ac-d830-4f9c-af1d-831caf614038",
   "metadata": {},
   "source": [
    "#### best_transformer_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24663986-5fc7-4f11-80da-72e2cd2bf2eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dcec888c204373805b33c5da8e4322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b79733d05242c78a921989b618d2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9673dbd6727466e9b23e93abe353ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train: train_loss  = 0.5427\n",
      "Epoch 1 train: accuracy    = 0.7908\n",
      "Epoch 1 train: precision   = 0.7750\n",
      "Epoch 1 train: recall      = 0.6531\n",
      "Epoch 1 train: f1          = 0.6932\n",
      "Epoch 1 validation: val_loss    = 0.5459\n",
      "Epoch 1 validation: accuracy    = 0.7876\n",
      "Epoch 1 validation: precision   = 0.7631\n",
      "Epoch 1 validation: recall      = 0.6470\n",
      "Epoch 1 validation: f1          = 0.6848\n",
      "New best model (f1=0.6848) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7679b127de24816a5b21969deb4cfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966d23eda40478e81fd1f0a59fcc6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d34ff15530e422ea044aaac3a7708dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train: train_loss  = 0.4633\n",
      "Epoch 2 train: accuracy    = 0.8244\n",
      "Epoch 2 train: precision   = 0.7907\n",
      "Epoch 2 train: recall      = 0.7311\n",
      "Epoch 2 train: f1          = 0.7563\n",
      "Epoch 2 validation: val_loss    = 0.4769\n",
      "Epoch 2 validation: accuracy    = 0.8165\n",
      "Epoch 2 validation: precision   = 0.7775\n",
      "Epoch 2 validation: recall      = 0.7193\n",
      "Epoch 2 validation: f1          = 0.7439\n",
      "New best model (f1=0.7439) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4973df55f1ff450e8d0518450f24d542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b59e7fbdcb422fbf97f42710936b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f98cc7e0db4db2b596b955f0bb27bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train: train_loss  = 0.4280\n",
      "Epoch 3 train: accuracy    = 0.8397\n",
      "Epoch 3 train: precision   = 0.8104\n",
      "Epoch 3 train: recall      = 0.7568\n",
      "Epoch 3 train: f1          = 0.7788\n",
      "Epoch 3 validation: val_loss    = 0.4552\n",
      "Epoch 3 validation: accuracy    = 0.8291\n",
      "Epoch 3 validation: precision   = 0.7945\n",
      "Epoch 3 validation: recall      = 0.7392\n",
      "Epoch 3 validation: f1          = 0.7618\n",
      "New best model (f1=0.7618) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8845fe7273419a82255ff6ee3a6e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c5b3b2ea7c4c3bac9cc13c25ae1eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5668e50faf485e8f961f2586b7968b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train: train_loss  = 0.3918\n",
      "Epoch 4 train: accuracy    = 0.8547\n",
      "Epoch 4 train: precision   = 0.8102\n",
      "Epoch 4 train: recall      = 0.8011\n",
      "Epoch 4 train: f1          = 0.8055\n",
      "Epoch 4 validation: val_loss    = 0.4373\n",
      "Epoch 4 validation: accuracy    = 0.8350\n",
      "Epoch 4 validation: precision   = 0.7836\n",
      "Epoch 4 validation: recall      = 0.7700\n",
      "Epoch 4 validation: f1          = 0.7765\n",
      "New best model (f1=0.7765) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3caa513ff394c98ab10707aebbdeca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0630c5085f640bd8817aaca144c54ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76486ece0c5544609f40906206daf6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train: train_loss  = 0.3623\n",
      "Epoch 5 train: accuracy    = 0.8659\n",
      "Epoch 5 train: precision   = 0.8320\n",
      "Epoch 5 train: recall      = 0.8071\n",
      "Epoch 5 train: f1          = 0.8181\n",
      "Epoch 5 validation: val_loss    = 0.4230\n",
      "Epoch 5 validation: accuracy    = 0.8440\n",
      "Epoch 5 validation: precision   = 0.8027\n",
      "Epoch 5 validation: recall      = 0.7758\n",
      "Epoch 5 validation: f1          = 0.7876\n",
      "New best model (f1=0.7876) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fc70599a0c4b149c1e62515bcb5534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09b993453a14cb893900bb3ff4357d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b434f477b90493fbe16f8bbd2d79dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train: train_loss  = 0.3344\n",
      "Epoch 6 train: accuracy    = 0.8765\n",
      "Epoch 6 train: precision   = 0.8492\n",
      "Epoch 6 train: recall      = 0.8171\n",
      "Epoch 6 train: f1          = 0.8308\n",
      "Epoch 6 validation: val_loss    = 0.4085\n",
      "Epoch 6 validation: accuracy    = 0.8468\n",
      "Epoch 6 validation: precision   = 0.8068\n",
      "Epoch 6 validation: recall      = 0.7739\n",
      "Epoch 6 validation: f1          = 0.7877\n",
      "New best model (f1=0.7877) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f36b5afae5b4e6eb05ff3965396a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6f3944d55840c7b93b7858ac96cde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d9d0a42bdb4d9eb0cb3aec2ca6ede9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train: train_loss  = 0.3135\n",
      "Epoch 7 train: accuracy    = 0.8857\n",
      "Epoch 7 train: precision   = 0.8603\n",
      "Epoch 7 train: recall      = 0.8300\n",
      "Epoch 7 train: f1          = 0.8441\n",
      "Epoch 7 validation: val_loss    = 0.4137\n",
      "Epoch 7 validation: accuracy    = 0.8537\n",
      "Epoch 7 validation: precision   = 0.8199\n",
      "Epoch 7 validation: recall      = 0.7828\n",
      "Epoch 7 validation: f1          = 0.7996\n",
      "New best model (f1=0.7996) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2611e5fcc334e2eb2acaa9d451f6b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cf0f15021c44bca172a665a8052d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6c9db5cf3a43cfbad6e6a0f291e73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train: train_loss  = 0.2867\n",
      "Epoch 8 train: accuracy    = 0.8962\n",
      "Epoch 8 train: precision   = 0.8761\n",
      "Epoch 8 train: recall      = 0.8443\n",
      "Epoch 8 train: f1          = 0.8590\n",
      "Epoch 8 validation: val_loss    = 0.4044\n",
      "Epoch 8 validation: accuracy    = 0.8523\n",
      "Epoch 8 validation: precision   = 0.8169\n",
      "Epoch 8 validation: recall      = 0.7792\n",
      "Epoch 8 validation: f1          = 0.7963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0f41640fe14cf3a4b114606102e77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0cbea3b34d4711a0478f17f8bbdf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab07d8b1202f4398b8707b7247f5e975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train: train_loss  = 0.2706\n",
      "Epoch 9 train: accuracy    = 0.9026\n",
      "Epoch 9 train: precision   = 0.8843\n",
      "Epoch 9 train: recall      = 0.8545\n",
      "Epoch 9 train: f1          = 0.8674\n",
      "Epoch 9 validation: val_loss    = 0.4110\n",
      "Epoch 9 validation: accuracy    = 0.8528\n",
      "Epoch 9 validation: precision   = 0.8164\n",
      "Epoch 9 validation: recall      = 0.7832\n",
      "Epoch 9 validation: f1          = 0.7972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91da248a5a5c4796a99c15902bec8b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [train]:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03141e05e69404aa19308077b45ae8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/7637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba195f8468c4aa9a1194a28b3b58d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train: train_loss  = 0.2498\n",
      "Epoch 10 train: accuracy    = 0.9113\n",
      "Epoch 10 train: precision   = 0.8779\n",
      "Epoch 10 train: recall      = 0.8867\n",
      "Epoch 10 train: f1          = 0.8822\n",
      "Epoch 10 validation: val_loss    = 0.4073\n",
      "Epoch 10 validation: accuracy    = 0.8541\n",
      "Epoch 10 validation: precision   = 0.8042\n",
      "Epoch 10 validation: recall      = 0.8063\n",
      "Epoch 10 validation: f1          = 0.8052\n",
      "New best model (f1=0.8052) saved.\n",
      "\n",
      "Loaded best model with f1=0.8052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7f2a4d27224028a9e6d6aa103a71d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/2167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8478223247764638, 'precision': 0.7947469165050163, 'recall': 0.803183331774572, 'f1': 0.7988119336768936, 'loss': 0.43349864214906286}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1 => 0.3\n",
    "model, test_loader = train(dropout=0.3, lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=10, save_path=\"./transformers/best_transformer_3.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 10 validation: f1          = 0.8052\n",
    "# Final eval_results: {'accuracy': 0.8478223247764638, 'precision': 0.7947469165050163, 'recall': 0.803183331774572, 'f1': 0.7988119336768936, 'loss': 0.43349864214906286}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2ed1bc9-3e1b-422a-a8c7-0034645c384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 train: train_loss  = 0.5427\n",
    "# Epoch 1 train: accuracy    = 0.7908\n",
    "# Epoch 1 train: precision   = 0.7750\n",
    "# Epoch 1 train: recall      = 0.6531\n",
    "# Epoch 1 train: f1          = 0.6932\n",
    "# Epoch 1 validation: val_loss    = 0.5459\n",
    "# Epoch 1 validation: accuracy    = 0.7876\n",
    "# Epoch 1 validation: precision   = 0.7631\n",
    "# Epoch 1 validation: recall      = 0.6470\n",
    "# Epoch 1 validation: f1          = 0.6848\n",
    "# New best model (f1=0.6848) saved.\n",
    "\n",
    "# Epoch 2 train: train_loss  = 0.4633\n",
    "# Epoch 2 train: accuracy    = 0.8244\n",
    "# Epoch 2 train: precision   = 0.7907\n",
    "# Epoch 2 train: recall      = 0.7311\n",
    "# Epoch 2 train: f1          = 0.7563\n",
    "# Epoch 2 validation: val_loss    = 0.4769\n",
    "# Epoch 2 validation: accuracy    = 0.8165\n",
    "# Epoch 2 validation: precision   = 0.7775\n",
    "# Epoch 2 validation: recall      = 0.7193\n",
    "# Epoch 2 validation: f1          = 0.7439\n",
    "# New best model (f1=0.7439) saved.\n",
    "\n",
    "# Epoch 3 train: train_loss  = 0.4280\n",
    "# Epoch 3 train: accuracy    = 0.8397\n",
    "# Epoch 3 train: precision   = 0.8104\n",
    "# Epoch 3 train: recall      = 0.7568\n",
    "# Epoch 3 train: f1          = 0.7788\n",
    "# Epoch 3 validation: val_loss    = 0.4552\n",
    "# Epoch 3 validation: accuracy    = 0.8291\n",
    "# Epoch 3 validation: precision   = 0.7945\n",
    "# Epoch 3 validation: recall      = 0.7392\n",
    "# Epoch 3 validation: f1          = 0.7618\n",
    "# New best model (f1=0.7618) saved.\n",
    "\n",
    "# Epoch 4 train: train_loss  = 0.3918\n",
    "# Epoch 4 train: accuracy    = 0.8547\n",
    "# Epoch 4 train: precision   = 0.8102\n",
    "# Epoch 4 train: recall      = 0.8011\n",
    "# Epoch 4 train: f1          = 0.8055\n",
    "# Epoch 4 validation: val_loss    = 0.4373\n",
    "# Epoch 4 validation: accuracy    = 0.8350\n",
    "# Epoch 4 validation: precision   = 0.7836\n",
    "# Epoch 4 validation: recall      = 0.7700\n",
    "# Epoch 4 validation: f1          = 0.7765\n",
    "# New best model (f1=0.7765) saved.\n",
    "\n",
    "# Epoch 5 train: train_loss  = 0.3623\n",
    "# Epoch 5 train: accuracy    = 0.8659\n",
    "# Epoch 5 train: precision   = 0.8320\n",
    "# Epoch 5 train: recall      = 0.8071\n",
    "# Epoch 5 train: f1          = 0.8181\n",
    "# Epoch 5 validation: val_loss    = 0.4230\n",
    "# Epoch 5 validation: accuracy    = 0.8440\n",
    "# Epoch 5 validation: precision   = 0.8027\n",
    "# Epoch 5 validation: recall      = 0.7758\n",
    "# Epoch 5 validation: f1          = 0.7876\n",
    "# New best model (f1=0.7876) saved.\n",
    "\n",
    "# Epoch 6 train: train_loss  = 0.3344\n",
    "# Epoch 6 train: accuracy    = 0.8765\n",
    "# Epoch 6 train: precision   = 0.8492\n",
    "# Epoch 6 train: recall      = 0.8171\n",
    "# Epoch 6 train: f1          = 0.8308\n",
    "# Epoch 6 validation: val_loss    = 0.4085\n",
    "# Epoch 6 validation: accuracy    = 0.8468\n",
    "# Epoch 6 validation: precision   = 0.8068\n",
    "# Epoch 6 validation: recall      = 0.7739\n",
    "# Epoch 6 validation: f1          = 0.7877\n",
    "# New best model (f1=0.7877) saved.\n",
    "\n",
    "# Epoch 7 train: train_loss  = 0.3135\n",
    "# Epoch 7 train: accuracy    = 0.8857\n",
    "# Epoch 7 train: precision   = 0.8603\n",
    "# Epoch 7 train: recall      = 0.8300\n",
    "# Epoch 7 train: f1          = 0.8441\n",
    "# Epoch 7 validation: val_loss    = 0.4137\n",
    "# Epoch 7 validation: accuracy    = 0.8537\n",
    "# Epoch 7 validation: precision   = 0.8199\n",
    "# Epoch 7 validation: recall      = 0.7828\n",
    "# Epoch 7 validation: f1          = 0.7996\n",
    "# New best model (f1=0.7996) saved.\n",
    "\n",
    "# Epoch 8 train: train_loss  = 0.2867\n",
    "# Epoch 8 train: accuracy    = 0.8962\n",
    "# Epoch 8 train: precision   = 0.8761\n",
    "# Epoch 8 train: recall      = 0.8443\n",
    "# Epoch 8 train: f1          = 0.8590\n",
    "# Epoch 8 validation: val_loss    = 0.4044\n",
    "# Epoch 8 validation: accuracy    = 0.8523\n",
    "# Epoch 8 validation: precision   = 0.8169\n",
    "# Epoch 8 validation: recall      = 0.7792\n",
    "# Epoch 8 validation: f1          = 0.7963\n",
    "\n",
    "# Epoch 9 train: train_loss  = 0.2706\n",
    "# Epoch 9 train: accuracy    = 0.9026\n",
    "# Epoch 9 train: precision   = 0.8843\n",
    "# Epoch 9 train: recall      = 0.8545\n",
    "# Epoch 9 train: f1          = 0.8674\n",
    "# Epoch 9 validation: val_loss    = 0.4110\n",
    "# Epoch 9 validation: accuracy    = 0.8528\n",
    "# Epoch 9 validation: precision   = 0.8164\n",
    "# Epoch 9 validation: recall      = 0.7832\n",
    "# Epoch 9 validation: f1          = 0.7972\n",
    "\n",
    "# Epoch 10 train: train_loss  = 0.2498\n",
    "# Epoch 10 train: accuracy    = 0.9113\n",
    "# Epoch 10 train: precision   = 0.8779\n",
    "# Epoch 10 train: recall      = 0.8867\n",
    "# Epoch 10 train: f1          = 0.8822\n",
    "# Epoch 10 validation: val_loss    = 0.4073\n",
    "# Epoch 10 validation: accuracy    = 0.8541\n",
    "# Epoch 10 validation: precision   = 0.8042\n",
    "# Epoch 10 validation: recall      = 0.8063\n",
    "# Epoch 10 validation: f1          = 0.8052\n",
    "# New best model (f1=0.8052) saved.\n",
    "\n",
    "# Loaded best model with f1=0.8052"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa53ba-8be6-4d60-921e-10ff3e7bbe8e",
   "metadata": {},
   "source": [
    "#### best_transformer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2f534-6150-439d-accc-25d0c4a1cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=3, save_path=\"./transformers/best_transformer_1.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "# Epoch 1 validation:\n",
    "#   val_loss  = 0.4957\n",
    "#   accuracy  = 0.8108\n",
    "#   precision = 0.7511\n",
    "#   recall    = 0.7480\n",
    "#   f1        = 0.7490\n",
    "#    New best model (f1=0.7490) saved.\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss  = 0.4397\n",
    "#   accuracy  = 0.8314\n",
    "#   precision = 0.7872\n",
    "#   recall    = 0.7633\n",
    "#   f1        = 0.7724\n",
    "#    New best model (f1=0.7724) saved.\n",
    "\n",
    "# Epoch 3 validation:\n",
    "#   val_loss  = 0.4129\n",
    "#   accuracy  = 0.8471\n",
    "#   precision = 0.7982\n",
    "#   recall    = 0.7925\n",
    "#   f1        = 0.7945\n",
    "#    New best model (f1=0.7945) saved.\n",
    "\n",
    "# Final eval_results: {'accuracy': 0.8394577444476493, 'precision': 0.7870732957272955, 'recall': 0.7865639150630909, 'f1': 0.7861628773510826, 'loss': 0.4266800470237802}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ace50-196b-422f-9e85-e40009fa500c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### best_transformer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef3f4c-320b-4c7d-98b4-17c43888ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(lr=2e-5, batch_size = 8, weight_decay=0.01, max_epochs=5, save_path=\"./transformers/best_transformer_2.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss  = 0.5102\n",
    "#   accuracy  = 0.8056\n",
    "#   precision = 0.7564\n",
    "#   recall    = 0.7051\n",
    "#   f1        = 0.7269\n",
    "#    New best model (f1=0.7269) saved.\n",
    "\n",
    "# Epoch 2 validation:\n",
    "#   val_loss  = 0.4723\n",
    "#   accuracy  = 0.8213\n",
    "#   precision = 0.7739\n",
    "#   recall    = 0.7437\n",
    "#   f1        = 0.7558\n",
    "#    New best model (f1=0.7558) saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441298a9-7661-4dc0-ba4c-3923cec091ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model=128 <= 256,\n",
    "# nhead=4,\n",
    "# num_layers=2 <= 4,\n",
    "# dim_feedforward=256 <= 512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(d_model=128, num_layers=2, dim_feedforward=256, lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=5, save_path=\"./transformers/best_transformer_3.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.5239\n",
    "#   accuracy    = 0.7990\n",
    "#   precision   = 0.7548\n",
    "#   recall      = 0.6899\n",
    "#   f1          = 0.7164\n",
    "\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.5276\n",
    "#   accuracy    = 0.7989\n",
    "#   precision   = 0.7494\n",
    "#   recall      = 0.6869\n",
    "#   f1          = 0.7125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a847f2e-1488-4b64-bd40-61667954ba75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342536e4a5b24ad6b78c920010143482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98311f72cd524a31a772ecb616b9d684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bba808f4112402f9668d47a395fc166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 train:\n",
      "  train_loss  = 0.4597\n",
      "  accuracy    = 0.8261\n",
      "  precision   = 0.8127\n",
      "  recall      = 0.7218\n",
      "  f1          = 0.7500\n",
      "\n",
      "Epoch 1 validation:\n",
      "  val_loss    = 0.4887\n",
      "  accuracy    = 0.8144\n",
      "  precision   = 0.7946\n",
      "  recall      = 0.7015\n",
      "  f1          = 0.7282\n",
      "New best model (f1=0.7282) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e44998c7a544999de13a6c5c2b8803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe27b80e50b4a42b9223307effeab74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc508d999fc44a188ab6b0fc028c9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 train:\n",
      "  train_loss  = 0.3688\n",
      "  accuracy    = 0.8639\n",
      "  precision   = 0.8235\n",
      "  recall      = 0.8156\n",
      "  f1          = 0.8188\n",
      "\n",
      "Epoch 2 validation:\n",
      "  val_loss    = 0.4365\n",
      "  accuracy    = 0.8378\n",
      "  precision   = 0.7905\n",
      "  recall      = 0.7755\n",
      "  f1          = 0.7823\n",
      "New best model (f1=0.7823) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc435c3b73c54a2480d1ddbd09a03810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f3066eec8d4e7eaef5df3bc715ac22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee883b31d0fe41329319033100cdb61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 train:\n",
      "  train_loss  = 0.3202\n",
      "  accuracy    = 0.8813\n",
      "  precision   = 0.8689\n",
      "  recall      = 0.8117\n",
      "  f1          = 0.8369\n",
      "\n",
      "Epoch 3 validation:\n",
      "  val_loss    = 0.4392\n",
      "  accuracy    = 0.8396\n",
      "  precision   = 0.8122\n",
      "  recall      = 0.7477\n",
      "  f1          = 0.7750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f162af6c9c4c4f34864e9c4d4dab1009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae7b1dd2ad8479f8ea75bd9964a1505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823b20a43ac44949a5fd6ce1f32f5ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 train:\n",
      "  train_loss  = 0.2600\n",
      "  accuracy    = 0.9077\n",
      "  precision   = 0.8946\n",
      "  recall      = 0.8575\n",
      "  f1          = 0.8738\n",
      "\n",
      "Epoch 4 validation:\n",
      "  val_loss    = 0.4221\n",
      "  accuracy    = 0.8499\n",
      "  precision   = 0.8175\n",
      "  recall      = 0.7718\n",
      "  f1          = 0.7914\n",
      "New best model (f1=0.7914) saved.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28479706ac794003b64acfdcc7d86f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5 [train]:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11f4bc2e6e442dcaf3b19cd9cc7cbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818b5f0725e84440a7647ee9a48977e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 train:\n",
      "  train_loss  = 0.2058\n",
      "  accuracy    = 0.9299\n",
      "  precision   = 0.9085\n",
      "  recall      = 0.9060\n",
      "  f1          = 0.9066\n",
      "\n",
      "Epoch 5 validation:\n",
      "  val_loss    = 0.4409\n",
      "  accuracy    = 0.8463\n",
      "  precision   = 0.7998\n",
      "  recall      = 0.7894\n",
      "  f1          = 0.7935\n",
      "New best model (f1=0.7935) saved.\n",
      "\n",
      "Loaded best model with f1=0.7935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75067f72aa76493d84d75954fc3a2666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate:   0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval_results: {'accuracy': 0.8404384193827517, 'precision': 0.7916469260389406, 'recall': 0.7848264806284927, 'f1': 0.786880109334091, 'loss': 0.4544476669185496}\n"
     ]
    }
   ],
   "source": [
    "# d_model=256,\n",
    "# nhead=4,\n",
    "# num_layers=3 <= 4,\n",
    "# dim_feedforward=512,\n",
    "# dropout=0.1,\n",
    "model, test_loader = train(d_model=256, num_layers=3, dim_feedforward=512, lr=1e-4, batch_size = 32, weight_decay=0.01, last_epoch=0, max_epochs=5, save_path=\"./transformers/best_transformer_4.pt\")\n",
    "eval_results = evaluate_model(model, test_loader)\n",
    "print(\"Final eval_results:\", eval_results)\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   f1          = 0.7500\n",
    "# Epoch 1 validation:\n",
    "#   f1          = 0.7282\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   f1          = 0.8188\n",
    "# Epoch 2 validation:\n",
    "#   f1          = 0.7823\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   f1          = 0.8369\n",
    "# Epoch 3 validation:\n",
    "#   f1          = 0.7750 <= first sign of overfitting\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   f1          = 0.8738 <= increasing\n",
    "# Epoch 4 validation:\n",
    "#   f1          = 0.7914\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   f1          = 0.9066 <= increasing\n",
    "# Epoch 5 validation:\n",
    "#   f1          = 0.7935 <= not increasing much. oscilating\n",
    "\n",
    "# test f1 = 0.786880109334091\n",
    "\n",
    "############################################\n",
    "############################################\n",
    "\n",
    "# Epoch 1 train:\n",
    "#   train_loss  = 0.4597\n",
    "#   accuracy    = 0.8261\n",
    "#   precision   = 0.8127\n",
    "#   recall      = 0.7218\n",
    "#   f1          = 0.7500\n",
    "# Epoch 1 validation:\n",
    "#   val_loss    = 0.4887\n",
    "#   accuracy    = 0.8144\n",
    "#   precision   = 0.7946\n",
    "#   recall      = 0.7015\n",
    "#   f1          = 0.7282\n",
    "# New best model (f1=0.7282) saved.\n",
    "\n",
    "\n",
    "# Epoch 2 train:\n",
    "#   train_loss  = 0.3688\n",
    "#   accuracy    = 0.8639\n",
    "#   precision   = 0.8235\n",
    "#   recall      = 0.8156\n",
    "#   f1          = 0.8188\n",
    "# Epoch 2 validation:\n",
    "#   val_loss    = 0.4365\n",
    "#   accuracy    = 0.8378\n",
    "#   precision   = 0.7905\n",
    "#   recall      = 0.7755\n",
    "#   f1          = 0.7823\n",
    "# New best model (f1=0.7823) saved.\n",
    "\n",
    "\n",
    "# Epoch 3 train:\n",
    "#   train_loss  = 0.3202\n",
    "#   accuracy    = 0.8813\n",
    "#   precision   = 0.8689\n",
    "#   recall      = 0.8117\n",
    "#   f1          = 0.8369\n",
    "# Epoch 3 validation:\n",
    "#   val_loss    = 0.4392\n",
    "#   accuracy    = 0.8396\n",
    "#   precision   = 0.8122\n",
    "#   recall      = 0.7477\n",
    "#   f1          = 0.7750\n",
    "\n",
    "\n",
    "# Epoch 4 train:\n",
    "#   train_loss  = 0.2600\n",
    "#   accuracy    = 0.9077\n",
    "#   precision   = 0.8946\n",
    "#   recall      = 0.8575\n",
    "#   f1          = 0.8738\n",
    "# Epoch 4 validation:\n",
    "#   val_loss    = 0.4221\n",
    "#   accuracy    = 0.8499\n",
    "#   precision   = 0.8175\n",
    "#   recall      = 0.7718\n",
    "#   f1          = 0.7914\n",
    "# New best model (f1=0.7914) saved.\n",
    "\n",
    "# Epoch 5 train:\n",
    "#   train_loss  = 0.2058\n",
    "#   accuracy    = 0.9299\n",
    "#   precision   = 0.9085\n",
    "#   recall      = 0.9060\n",
    "#   f1          = 0.9066\n",
    "\n",
    "# Epoch 5 validation:\n",
    "#   val_loss    = 0.4409\n",
    "#   accuracy    = 0.8463\n",
    "#   precision   = 0.7998\n",
    "#   recall      = 0.7894\n",
    "#   f1          = 0.7935\n",
    "# New best model (f1=0.7935) saved.\n",
    "\n",
    "# Loaded best model with f1=0.7935\n",
    "# Final eval_results: {'accuracy': 0.8404384193827517, 'precision': 0.7916469260389406, 'recall': 0.7848264806284927, 'f1': 0.786880109334091, 'loss': 0.4544476669185496}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946d83a",
   "metadata": {},
   "source": [
    "## Transformer (Deberta-V3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a099e1-fd9f-4f7c-be51-2d4991a19dc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f53fd-66c4-468d-9873-9b8bba8750f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce20be-4d58-4806-851b-833a82b7301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class TrainMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, train_dataset, val_dataset, last_epoch = None):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.trainer = None\n",
    "        self.last_epoch = last_epoch\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.trainer is None:\n",
    "            return control\n",
    "\n",
    "        if self.last_epoch is None:\n",
    "            epoch = state.epoch\n",
    "        else:\n",
    "            self.last_epoch += 1\n",
    "            epoch = self.last_epoch\n",
    "\n",
    "        # --- train metrics ---\n",
    "        train_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.train_dataset,\n",
    "            metric_key_prefix=\"train\",  # train_accuracy, train_f1, ...\n",
    "        )\n",
    "\n",
    "        # --- validation metrics ---\n",
    "        val_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.val_dataset,\n",
    "            metric_key_prefix=\"eval\",   # eval_accuracy, eval_f1, ...\n",
    "        )\n",
    "\n",
    "        val_loss = val_metrics.get(\"eval_loss\")\n",
    "        val_acc  = val_metrics.get(\"eval_accuracy\")\n",
    "        val_prec = val_metrics.get(\"eval_precision\")\n",
    "        val_rec  = val_metrics.get(\"eval_recall\")\n",
    "        val_f1   = val_metrics.get(\"eval_f1\")\n",
    "\n",
    "        train_loss = train_metrics.get(\"train_loss\")\n",
    "        train_acc  = train_metrics.get(\"train_accuracy\")\n",
    "        train_prec = train_metrics.get(\"train_precision\")\n",
    "        train_rec  = train_metrics.get(\"train_recall\")\n",
    "        train_f1   = train_metrics.get(\"train_f1\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[EPOCH {epoch:.0f}]\")\n",
    "        if train_acc is not None:\n",
    "            print(f\"[train] loss={train_loss:.4f}, acc={train_acc:.4f}, prec={train_prec:.4f}, rec={train_rec:.4f}, f1={train_f1:.4f}\")\n",
    "        if val_acc is not None:\n",
    "            print(f\"[valid] loss={val_loss:.4f}, acc={val_acc:.4f}, prec={val_prec:.4f}, rec={val_rec:.4f}, f1={val_f1:.4f}\")\n",
    "        return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1ba95a9-9135-42dc-945e-d7ceb7abad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name=\"./deberta\", last_epoch = None, epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\"):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"no\", # \"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epoch,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=False, # True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    train_callback = TrainMetricsCallback(\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        val_dataset=tokenized_datasets[\"validation\"],\n",
    "        last_epoch=last_epoch,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[train_callback],\n",
    "    )\n",
    "\n",
    "    train_callback.trainer = trainer\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b57fb38-6247-4be0-a593-fce04a5191ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "def load_and_test_eval(ckpt_dir = \"./deberta-v3-crisis/batchsizeXX/checkpoint-XXXXX\"):\n",
    "    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\".\", # any\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    eval_trainer = Trainer(\n",
    "        model=model_ckpt,\n",
    "        args=eval_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    eval_results = eval_trainer.evaluate(\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        metric_key_prefix=\"test\",\n",
    "    )\n",
    "    # {'test_loss': 0.4593863785266876, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8740698009806749, 'test_precision': 0.8326252068193959, 'test_recall': 0.8500324417218078, 'test_f1': 0.8369876991837396, 'test_runtime': 123.8232, 'test_samples_per_second': 139.998, 'test_steps_per_second': 2.189}\n",
    "    print(eval_results)\n",
    "    print(f\"[test] acc={eval_results['test_accuracy']}, prec={eval_results['test_precision']}, rec={eval_results['test_recall']}, f1={eval_results['test_f1']}\")\n",
    "    # print(f\"test_loss = {eval_results['test_loss']}\")\n",
    "    # print(f\"test_accuracy = {eval_results['test_accuracy']}\")\n",
    "    # print(f\"test_precision = {eval_results['test_precision']}\")\n",
    "    # print(f\"test_recall = {eval_results['test_recall']}\")\n",
    "    # print(f\"test_f1 = {eval_results['test_f1']}\")\n",
    "    return eval_results\n",
    "\n",
    "def load_and_val_eval(ckpt_dir = \"./deberta-v3-crisis/batchsizeXX/checkpoint-XXXXX\"):\n",
    "    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\".\", # any\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    eval_trainer = Trainer(\n",
    "        model=model_ckpt,\n",
    "        args=eval_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    eval_results = eval_trainer.evaluate(\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        metric_key_prefix=\"val\",\n",
    "    )\n",
    "    print(eval_results)\n",
    "    print(f\"[test] acc={eval_results['val_accuracy']}, prec={eval_results['val_precision']}, rec={eval_results['val_recall']}, f1={eval_results['val_f1']}\")\n",
    "    return eval_results['val_f1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657a561",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4996611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinwoojeong/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 15.0\n",
      "mean: 16.42866733323811\n",
      "95th percentile: 29.0\n",
      "99th percentile: 42.0\n",
      "max: 1126\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download everything from https://huggingface.co/microsoft/deberta-v3-base/tree/main\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"./deberta\", # \"microsoft/deberta-v3-base\"\n",
    "    use_fast=True, # DeBERTa fast tokenizer \n",
    "    local_files_only=True,\n",
    ")\n",
    "\n",
    "max_length = 64 # adjust based on the maximum input size?\n",
    "\n",
    "# 1. Tokenize directly\n",
    "train_encodings = tokenizer(\n",
    "    df[\"train\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    df[\"dev\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "test_encodings = tokenizer(\n",
    "    df[\"test\"]['text'].to_list(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "# 2. Build HF Datasets from encoded inputs + labels\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"train\"]['class_label_group_num'],\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": val_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": val_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"dev\"]['class_label_group_num'],\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "    \"label\": df[\"test\"]['class_label_group_num'],\n",
    "})\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "# 3. Set format for PyTorch\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")\n",
    "\n",
    "# Check appropriate token size\n",
    "tmp_train = tokenizer(df[\"train\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n",
    "lens_train = [len(ids) for ids in tmp_train[\"input_ids\"]]\n",
    "\n",
    "tmp_dev = tokenizer(df[\"dev\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n",
    "lens_dev = [len(ids) for ids in tmp_dev[\"input_ids\"]]\n",
    "\n",
    "lengths = lens_train + lens_dev\n",
    "\n",
    "print(\"median:\", np.median(lengths))\n",
    "print(\"mean:\", np.mean(lengths))\n",
    "print(\"95th percentile:\", np.percentile(lengths, 95))\n",
    "print(\"99th percentile:\", np.percentile(lengths, 99))\n",
    "print(\"max:\", np.max(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058da24c-3882-4647-81db-49bda443f998",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2589f8da-61ae-416a-9ff0-4374a926115a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=1e-6, batch_size=16 (EPOCH 16, val_f1=0.8583, test_f1=0.848050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4d6c967-1608-4294-ac88-970d0d5b6370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.480494886636734, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.8834150562445918, 'test_precision': 0.8357564455145318, 'test_recall': 0.8623533790050426, 'test_f1': 0.8480500870596009, 'test_runtime': 131.5435, 'test_samples_per_second': 131.781, 'test_steps_per_second': 2.06}\n",
      "[test] acc=0.8834150562445918, prec=0.8357564455145318, rec=0.8623533790050426, f1=0.8480500870596009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.480494886636734,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.8834150562445918,\n",
       " 'test_precision': 0.8357564455145318,\n",
       " 'test_recall': 0.8623533790050426,\n",
       " 'test_f1': 0.8480500870596009,\n",
       " 'test_runtime': 131.5435,\n",
       " 'test_samples_per_second': 131.781,\n",
       " 'test_steps_per_second': 2.06}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr1e6_cont_from_13/checkpoint-11457\")\n",
    "# [test] acc=0.8834150562445918, prec=0.8357564455145318, rec=0.8623533790050426, f1=0.8480500870596009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a93d9-339b-4675-a4b6-b33c68b64f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.8767, prec=0.8325, rec=0.8395, f1=0.8359\n",
    "# [valid] acc=0.8722, prec=0.8275, rec=0.8291, f1=0.8283\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.8833, prec=0.8349, rec=0.8651, f1=0.8489\n",
    "# [valid] acc=0.8745, prec=0.8228, rec=0.8486, f1=0.8348\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.8958, prec=0.8568, rec=0.8691, f1=0.8625\n",
    "# [valid] acc=0.8815, prec=0.8382, rec=0.8441, f1=0.8409\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9020, prec=0.8662, rec=0.8761, f1=0.8708\n",
    "# [valid] acc=0.8829, prec=0.8418, rec=0.8448, f1=0.8431\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9039, prec=0.8650, rec=0.8854, f1=0.8744\n",
    "# [valid] acc=0.8834, prec=0.8389, rec=0.8537, f1=0.8456\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9066, prec=0.8676, rec=0.8938, f1=0.8797\n",
    "# [valid] acc=0.8830, prec=0.8375, rec=0.8570, f1=0.8466\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9139, prec=0.8792, rec=0.8964, f1=0.8875\n",
    "# [valid] acc=0.8875, prec=0.8456, rec=0.8559, f1=0.8506\n",
    "# ================================================================================\n",
    "# [EPOCH 8]\n",
    "# [train] acc=0.9181, prec=0.8857, rec=0.8996, f1=0.8923\n",
    "# [valid] acc=0.8872, prec=0.8460, rec=0.8548, f1=0.8501\n",
    "# ================================================================================\n",
    "# [EPOCH 9]\n",
    "# [train] acc=0.9184, prec=0.8835, rec=0.9044, f1=0.8934\n",
    "# [valid] acc=0.8867, prec=0.8431, rec=0.8584, f1=0.8503\n",
    "# ================================================================================\n",
    "# [EPOCH 10]\n",
    "# [train] acc=0.9256, prec=0.8985, rec=0.9054, f1=0.9018\n",
    "# [valid] acc=0.8898, prec=0.8521, rec=0.8544, f1=0.8532\n",
    "# ================================================================================\n",
    "# [EPOCH 11]\n",
    "# [train] acc=0.9236, prec=0.8896, rec=0.9119, f1=0.9001\n",
    "# [valid] acc=0.8884, prec=0.8447, rec=0.8625, f1=0.8530\n",
    "# ================================================================================\n",
    "# [EPOCH 12]\n",
    "# [train] acc=0.9302, prec=0.9042, rec=0.9119, f1=0.9079\n",
    "# [valid] acc=0.8910, prec=0.8532, rec=0.8558, f1=0.8544\n",
    "# ================================================================================\n",
    "# [EPOCH 13]\n",
    "# [train] acc=0.9310, prec=0.9036, rec=0.9149, f1=0.9091\n",
    "# [valid] acc=0.8901, prec=0.8510, rec=0.8569, f1=0.8538\n",
    "# ================================================================================\n",
    "# [EPOCH 14]\n",
    "# [train] loss=0.2028, acc=0.9325, prec=0.9112, rec=0.9126, f1=0.9105\n",
    "# [valid] loss=0.3398, acc=0.8919, prec=0.8602, rec=0.8542, f1=0.8553\n",
    "# ================================================================================\n",
    "# [EPOCH 15]\n",
    "# [train] loss=0.1456, acc=0.9541, prec=0.9361, rec=0.9437, f1=0.9395\n",
    "# [valid] loss=0.3407, acc=0.8885, prec=0.8528, rec=0.8540, f1=0.8524\n",
    "# ================================================================================\n",
    "# [EPOCH 16]\n",
    "# [train] loss=0.1172, acc=0.9672, prec=0.9503, rec=0.9643, f1=0.9570\n",
    "# [valid] loss=0.4375, acc=0.8927, prec=0.8514, rec=0.8660, f1=0.8583\n",
    "# ================================ OVERFITTING ===================================\n",
    "# [EPOCH 17]\n",
    "# [train] loss=0.0874, acc=0.9782, prec=0.9702, rec=0.9718, f1=0.9710\n",
    "# [valid] loss=0.5064, acc=0.8922, prec=0.8592, rec=0.8508, f1=0.8548\n",
    "# ================================================================================\n",
    "# [EPOCH 18]\n",
    "# [train] loss=0.0626, acc=0.9846, prec=0.9825, rec=0.9771, f1=0.9798\n",
    "# [valid] loss=0.5907, acc=0.8882, prec=0.8626, rec=0.8347, f1=0.8473\n",
    "# ================================================================================\n",
    "# [EPOCH 19]\n",
    "# [train] loss=0.0577, acc=0.9866, prec=0.9793, rec=0.9852, f1=0.9822\n",
    "# [valid] loss=0.6760, acc=0.8839, prec=0.8362, rec=0.8612, f1=0.8479\n",
    "# ================================================================================\n",
    "# [EPOCH 20]\n",
    "# [train] loss=0.0370, acc=0.9913, prec=0.9875, rec=0.9893, f1=0.9884\n",
    "# [valid] loss=0.6766, acc=0.8887, prec=0.8456, rec=0.8604, f1=0.8527\n",
    "# ================================================================================\n",
    "# [EPOCH 21]\n",
    "# [train] loss=0.0259, acc=0.9940, prec=0.9914, rec=0.9923, f1=0.9919\n",
    "# [valid] loss=0.7654, acc=0.8873, prec=0.8462, rec=0.8547, f1=0.8504\n",
    "# ================================================================================\n",
    "# [EPOCH 22]\n",
    "# [train] loss=0.0217, acc=0.9950, prec=0.9927, rec=0.9938, f1=0.9932\n",
    "# [valid] loss=0.8305, acc=0.8854, prec=0.8409, rec=0.8579, f1=0.8490\n",
    "# ================================================================================\n",
    "# [EPOCH 23]\n",
    "# [train] loss=0.0176, acc=0.9959, prec=0.9943, rec=0.9945, f1=0.9944\n",
    "# [valid] loss=0.8476, acc=0.8860, prec=0.8447, rec=0.8522, f1=0.8484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26a56375-02e2-4788-af3f-2cc10ecabce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49665' max='76380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49665/76380 12:43:14 < 6:50:34, 1.08 it/s, Epoch 13.00/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.369860</td>\n",
       "      <td>0.872212</td>\n",
       "      <td>0.827513</td>\n",
       "      <td>0.829133</td>\n",
       "      <td>0.828306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.354365</td>\n",
       "      <td>0.874454</td>\n",
       "      <td>0.822754</td>\n",
       "      <td>0.848556</td>\n",
       "      <td>0.834804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.345816</td>\n",
       "      <td>0.881516</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.844074</td>\n",
       "      <td>0.840875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.338899</td>\n",
       "      <td>0.882861</td>\n",
       "      <td>0.841793</td>\n",
       "      <td>0.844776</td>\n",
       "      <td>0.843076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340324</td>\n",
       "      <td>0.883421</td>\n",
       "      <td>0.838853</td>\n",
       "      <td>0.853732</td>\n",
       "      <td>0.845645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346092</td>\n",
       "      <td>0.882973</td>\n",
       "      <td>0.837511</td>\n",
       "      <td>0.857025</td>\n",
       "      <td>0.846615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346158</td>\n",
       "      <td>0.887457</td>\n",
       "      <td>0.845644</td>\n",
       "      <td>0.855859</td>\n",
       "      <td>0.850622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30552</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343148</td>\n",
       "      <td>0.887232</td>\n",
       "      <td>0.845960</td>\n",
       "      <td>0.854781</td>\n",
       "      <td>0.850057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34371</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356693</td>\n",
       "      <td>0.886672</td>\n",
       "      <td>0.843079</td>\n",
       "      <td>0.858372</td>\n",
       "      <td>0.850271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38190</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343051</td>\n",
       "      <td>0.889811</td>\n",
       "      <td>0.852127</td>\n",
       "      <td>0.854418</td>\n",
       "      <td>0.853157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42009</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.360168</td>\n",
       "      <td>0.888353</td>\n",
       "      <td>0.844676</td>\n",
       "      <td>0.862494</td>\n",
       "      <td>0.852971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45828</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356609</td>\n",
       "      <td>0.891044</td>\n",
       "      <td>0.853206</td>\n",
       "      <td>0.855824</td>\n",
       "      <td>0.854363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49647</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.359416</td>\n",
       "      <td>0.890147</td>\n",
       "      <td>0.850972</td>\n",
       "      <td>0.856922</td>\n",
       "      <td>0.853833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.8767, prec=0.8325, rec=0.8395, f1=0.8359\n",
      "[valid] acc=0.8722, prec=0.8275, rec=0.8291, f1=0.8283\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.8833, prec=0.8349, rec=0.8651, f1=0.8489\n",
      "[valid] acc=0.8745, prec=0.8228, rec=0.8486, f1=0.8348\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.8958, prec=0.8568, rec=0.8691, f1=0.8625\n",
      "[valid] acc=0.8815, prec=0.8382, rec=0.8441, f1=0.8409\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9020, prec=0.8662, rec=0.8761, f1=0.8708\n",
      "[valid] acc=0.8829, prec=0.8418, rec=0.8448, f1=0.8431\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9039, prec=0.8650, rec=0.8854, f1=0.8744\n",
      "[valid] acc=0.8834, prec=0.8389, rec=0.8537, f1=0.8456\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9066, prec=0.8676, rec=0.8938, f1=0.8797\n",
      "[valid] acc=0.8830, prec=0.8375, rec=0.8570, f1=0.8466\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 7]\n",
      "[train] acc=0.9139, prec=0.8792, rec=0.8964, f1=0.8875\n",
      "[valid] acc=0.8875, prec=0.8456, rec=0.8559, f1=0.8506\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 8]\n",
      "[train] acc=0.9181, prec=0.8857, rec=0.8996, f1=0.8923\n",
      "[valid] acc=0.8872, prec=0.8460, rec=0.8548, f1=0.8501\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 9]\n",
      "[train] acc=0.9184, prec=0.8835, rec=0.9044, f1=0.8934\n",
      "[valid] acc=0.8867, prec=0.8431, rec=0.8584, f1=0.8503\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 10]\n",
      "[train] acc=0.9256, prec=0.8985, rec=0.9054, f1=0.9018\n",
      "[valid] acc=0.8898, prec=0.8521, rec=0.8544, f1=0.8532\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 11]\n",
      "[train] acc=0.9236, prec=0.8896, rec=0.9119, f1=0.9001\n",
      "[valid] acc=0.8884, prec=0.8447, rec=0.8625, f1=0.8530\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 12]\n",
      "[train] acc=0.9302, prec=0.9042, rec=0.9119, f1=0.9079\n",
      "[valid] acc=0.8910, prec=0.8532, rec=0.8558, f1=0.8544\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 13]\n",
      "[train] acc=0.9310, prec=0.9036, rec=0.9149, f1=0.9091\n",
      "[valid] acc=0.8901, prec=0.8510, rec=0.8569, f1=0.8538\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr1e6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 104\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     93\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     94\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    100\u001b[0m )\n\u001b[1;32m    102\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2740\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2737\u001b[0m     context \u001b[38;5;241m=\u001b[39m implicit_replication\n\u001b[1;32m   2739\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2740\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2742\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;66;03m# get leaning rate before update\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/optimizer.py:179\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/adamw.py:243\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    230\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    232\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    233\u001b[0m         group,\n\u001b[1;32m    234\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m         state_steps,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[0;32m--> 243\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/adamw.py:875\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 875\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/optim/adamw.py:425\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    422\u001b[0m     device_beta1 \u001b[38;5;241m=\u001b[39m beta1\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_beta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=13, learning_rate=1e-6, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6b0dd15-5e9a-4e91-9692-2dda17f89f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38190' max='38190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38190/38190 7:22:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.339816</td>\n",
       "      <td>0.891940</td>\n",
       "      <td>0.860151</td>\n",
       "      <td>0.854168</td>\n",
       "      <td>0.855299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340729</td>\n",
       "      <td>0.888465</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.854037</td>\n",
       "      <td>0.852405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.437489</td>\n",
       "      <td>0.892725</td>\n",
       "      <td>0.851411</td>\n",
       "      <td>0.865999</td>\n",
       "      <td>0.858273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.506365</td>\n",
       "      <td>0.892165</td>\n",
       "      <td>0.859224</td>\n",
       "      <td>0.850820</td>\n",
       "      <td>0.854820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.590669</td>\n",
       "      <td>0.888241</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>0.834667</td>\n",
       "      <td>0.847338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676042</td>\n",
       "      <td>0.883870</td>\n",
       "      <td>0.836201</td>\n",
       "      <td>0.861162</td>\n",
       "      <td>0.847859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676595</td>\n",
       "      <td>0.888690</td>\n",
       "      <td>0.845560</td>\n",
       "      <td>0.860393</td>\n",
       "      <td>0.852680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30552</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.765361</td>\n",
       "      <td>0.887344</td>\n",
       "      <td>0.846230</td>\n",
       "      <td>0.854750</td>\n",
       "      <td>0.850361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34371</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.830512</td>\n",
       "      <td>0.885439</td>\n",
       "      <td>0.840894</td>\n",
       "      <td>0.857950</td>\n",
       "      <td>0.849048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38190</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.847613</td>\n",
       "      <td>0.885999</td>\n",
       "      <td>0.844708</td>\n",
       "      <td>0.852216</td>\n",
       "      <td>0.848392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 14]\n",
      "[train] loss=0.2028, acc=0.9325, prec=0.9112, rec=0.9126, f1=0.9105\n",
      "[valid] loss=0.3398, acc=0.8919, prec=0.8602, rec=0.8542, f1=0.8553\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 15]\n",
      "[train] loss=0.1456, acc=0.9541, prec=0.9361, rec=0.9437, f1=0.9395\n",
      "[valid] loss=0.3407, acc=0.8885, prec=0.8528, rec=0.8540, f1=0.8524\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 16]\n",
      "[train] loss=0.1172, acc=0.9672, prec=0.9503, rec=0.9643, f1=0.9570\n",
      "[valid] loss=0.4375, acc=0.8927, prec=0.8514, rec=0.8660, f1=0.8583\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 17]\n",
      "[train] loss=0.0874, acc=0.9782, prec=0.9702, rec=0.9718, f1=0.9710\n",
      "[valid] loss=0.5064, acc=0.8922, prec=0.8592, rec=0.8508, f1=0.8548\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 18]\n",
      "[train] loss=0.0626, acc=0.9846, prec=0.9825, rec=0.9771, f1=0.9798\n",
      "[valid] loss=0.5907, acc=0.8882, prec=0.8626, rec=0.8347, f1=0.8473\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 19]\n",
      "[train] loss=0.0577, acc=0.9866, prec=0.9793, rec=0.9852, f1=0.9822\n",
      "[valid] loss=0.6760, acc=0.8839, prec=0.8362, rec=0.8612, f1=0.8479\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 20]\n",
      "[train] loss=0.0370, acc=0.9913, prec=0.9875, rec=0.9893, f1=0.9884\n",
      "[valid] loss=0.6766, acc=0.8887, prec=0.8456, rec=0.8604, f1=0.8527\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 21]\n",
      "[train] loss=0.0259, acc=0.9940, prec=0.9914, rec=0.9923, f1=0.9919\n",
      "[valid] loss=0.7654, acc=0.8873, prec=0.8462, rec=0.8547, f1=0.8504\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 22]\n",
      "[train] loss=0.0217, acc=0.9950, prec=0.9927, rec=0.9938, f1=0.9932\n",
      "[valid] loss=0.8305, acc=0.8854, prec=0.8409, rec=0.8579, f1=0.8490\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 23]\n",
      "[train] loss=0.0176, acc=0.9959, prec=0.9943, rec=0.9945, f1=0.9944\n",
      "[valid] loss=0.8476, acc=0.8860, prec=0.8447, rec=0.8522, f1=0.8484\n"
     ]
    }
   ],
   "source": [
    "trainer = train(model_name=\"./deberta-v3-crisis/batchsize16_lr1e6/checkpoint-49647\",\n",
    "                last_epoch=13, epoch=10, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e6_cont_from_13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d1baab-ce2e-48c2-84b0-fbff5f56c716",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=5e-6, batch_size=16 (EPOCH 7, val_f1=0.8603, test_f1=0.85244) => BEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e0cff26-9d86-4b26-af93-d86b3f5b944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.44441157579421997, 'test_model_preparation_time': 0.0016, 'test_accuracy': 0.8876261897894433, 'test_precision': 0.8431801450425511, 'test_recall': 0.8625945973329592, 'test_f1': 0.8524425110946661, 'test_runtime': 130.2498, 'test_samples_per_second': 133.09, 'test_steps_per_second': 2.081}\n",
      "[test] acc=0.8876261897894433, prec=0.8431801450425511, rec=0.8625945973329592, f1=0.8524425110946661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.44441157579421997,\n",
       " 'test_model_preparation_time': 0.0016,\n",
       " 'test_accuracy': 0.8876261897894433,\n",
       " 'test_precision': 0.8431801450425511,\n",
       " 'test_recall': 0.8625945973329592,\n",
       " 'test_f1': 0.8524425110946661,\n",
       " 'test_runtime': 130.2498,\n",
       " 'test_samples_per_second': 133.09,\n",
       " 'test_steps_per_second': 2.081}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32815efa-a78f-4c8e-b826-778d114323b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.8983, prec=0.8618, rec=0.8756, f1=0.8673\n",
    "# [valid] acc=0.8816, prec=0.8414, rec=0.8494, f1=0.8440\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9174, prec=0.8843, rec=0.9019, f1=0.8927\n",
    "# [valid] acc=0.8908, prec=0.8504, rec=0.8638, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9314, prec=0.9065, rec=0.9128, f1=0.9095\n",
    "# [valid] acc=0.8935, prec=0.8584, rec=0.8579, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9448, prec=0.9269, rec=0.9279, f1=0.9274\n",
    "# [valid] acc=0.8927, prec=0.8597, rec=0.8541, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9510, prec=0.9316, rec=0.9389, f1=0.9351\n",
    "# [valid] acc=0.8936, prec=0.8566, rec=0.8598, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9532, prec=0.9325, rec=0.9467, f1=0.9393\n",
    "# [valid] acc=0.8924, prec=0.8516, rec=0.8659, f1=0.8584\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9569, prec=0.9386, rec=0.9489, f1=0.9436\n",
    "# [valid] acc=0.8942, prec=0.8557, rec=0.8651, f1=0.8603\n",
    "# ============================= OVERFITTING ======================================\n",
    "# [EPOCH 8]\n",
    "# [train] loss=0.1480, acc=0.9574, prec=0.9391, rec=0.9508, f1=0.9444\n",
    "# [valid] loss=0.4439, acc=0.8864, prec=0.8488, rec=0.8546, f1=0.8505\n",
    "# ================================================================================\n",
    "# [EPOCH 9]\n",
    "# [train] loss=0.1104, acc=0.9689, prec=0.9530, rec=0.9652, f1=0.9589\n",
    "# [valid] loss=0.4663, acc=0.8887, prec=0.8475, rec=0.8598, f1=0.8533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47629d0e-9806-4a75-96eb-d924def9b554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26733' max='26733' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26733/26733 5:00:09, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.332313</td>\n",
       "      <td>0.881628</td>\n",
       "      <td>0.841446</td>\n",
       "      <td>0.849445</td>\n",
       "      <td>0.844033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306507</td>\n",
       "      <td>0.890819</td>\n",
       "      <td>0.850377</td>\n",
       "      <td>0.863838</td>\n",
       "      <td>0.856841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.329520</td>\n",
       "      <td>0.893510</td>\n",
       "      <td>0.858364</td>\n",
       "      <td>0.857872</td>\n",
       "      <td>0.857992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343858</td>\n",
       "      <td>0.892725</td>\n",
       "      <td>0.859702</td>\n",
       "      <td>0.854125</td>\n",
       "      <td>0.856828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.361830</td>\n",
       "      <td>0.893622</td>\n",
       "      <td>0.856642</td>\n",
       "      <td>0.859780</td>\n",
       "      <td>0.857983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.397974</td>\n",
       "      <td>0.892389</td>\n",
       "      <td>0.851599</td>\n",
       "      <td>0.865910</td>\n",
       "      <td>0.858416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.413612</td>\n",
       "      <td>0.894182</td>\n",
       "      <td>0.855740</td>\n",
       "      <td>0.865078</td>\n",
       "      <td>0.860305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.8983, prec=0.8618, rec=0.8756, f1=0.8673\n",
      "[valid] acc=0.8816, prec=0.8414, rec=0.8494, f1=0.8440\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9174, prec=0.8843, rec=0.9019, f1=0.8927\n",
      "[valid] acc=0.8908, prec=0.8504, rec=0.8638, f1=0.8568\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9314, prec=0.9065, rec=0.9128, f1=0.9095\n",
      "[valid] acc=0.8935, prec=0.8584, rec=0.8579, f1=0.8580\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9448, prec=0.9269, rec=0.9279, f1=0.9274\n",
      "[valid] acc=0.8927, prec=0.8597, rec=0.8541, f1=0.8568\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9510, prec=0.9316, rec=0.9389, f1=0.9351\n",
      "[valid] acc=0.8936, prec=0.8566, rec=0.8598, f1=0.8580\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9532, prec=0.9325, rec=0.9467, f1=0.9393\n",
      "[valid] acc=0.8924, prec=0.8516, rec=0.8659, f1=0.8584\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 7]\n",
      "[train] acc=0.9569, prec=0.9386, rec=0.9489, f1=0.9436\n",
      "[valid] acc=0.8942, prec=0.8557, rec=0.8651, f1=0.8603\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=7, learning_rate=5e-6, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr5e6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4823d845-8fa2-4ca6-bb2a-f1bc079c2a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8148' max='38190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8148/38190 1:34:59 < 5:50:19, 1.43 it/s, Epoch 2.13/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.443878</td>\n",
       "      <td>0.886448</td>\n",
       "      <td>0.848826</td>\n",
       "      <td>0.854559</td>\n",
       "      <td>0.850476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466330</td>\n",
       "      <td>0.888690</td>\n",
       "      <td>0.847531</td>\n",
       "      <td>0.859838</td>\n",
       "      <td>0.853341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 8]\n",
      "[train] loss=0.1480, acc=0.9574, prec=0.9391, rec=0.9508, f1=0.9444\n",
      "[valid] loss=0.4439, acc=0.8864, prec=0.8488, rec=0.8546, f1=0.8505\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 9]\n",
      "[train] loss=0.1104, acc=0.9689, prec=0.9530, rec=0.9652, f1=0.9589\n",
      "[valid] loss=0.4663, acc=0.8887, prec=0.8475, rec=0.8598, f1=0.8533\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlast_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e6_cont_after_7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 112\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_name, last_epoch, epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    101\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    102\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 112\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2618\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2616\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2617\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2618\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[38;5;66;03m# Store the number of batches for current gradient accumulation\u001b[39;00m\n\u001b[1;32m   2620\u001b[0m \u001b[38;5;66;03m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001b[39;00m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_gradient_accumulation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:5654\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5652\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5653\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5654\u001b[0m         batch_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   5655\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5656\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/data_loader.py:577\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[1;32m    579\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/utils/operations.py:154\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    152\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:837\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    838\u001b[0m         k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(v\u001b[38;5;241m.\u001b[39mto) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    840\u001b[0m     }\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    842\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:838\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 838\u001b[0m         k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(v\u001b[38;5;241m.\u001b[39mto) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    840\u001b[0m     }\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    842\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(model_name=\"./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\",\n",
    "                last_epoch=7, epoch=10, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr5e6_cont_after_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d8086-7cd1-4e04-9835-2ec31ef799e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=1e-5, batch_size=16 (EPOCH 5, val_f1=0.8584, test_f1=0.85042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a24e793-165c-48ef-a869-6ba71041e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.4733332693576813, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.8879146235938852, 'test_precision': 0.8480751638235061, 'test_recall': 0.8532187935966081, 'test_f1': 0.8504206093957811, 'test_runtime': 131.1168, 'test_samples_per_second': 132.21, 'test_steps_per_second': 2.067}\n",
      "[test] acc=0.8879146235938852, prec=0.8480751638235061, rec=0.8532187935966081, f1=0.8504206093957811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.4733332693576813,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.8879146235938852,\n",
       " 'test_precision': 0.8480751638235061,\n",
       " 'test_recall': 0.8532187935966081,\n",
       " 'test_f1': 0.8504206093957811,\n",
       " 'test_runtime': 131.1168,\n",
       " 'test_samples_per_second': 132.21,\n",
       " 'test_steps_per_second': 2.067}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr1e5/checkpoint-19095\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2df7826b-e72b-45ce-a4d4-b5ee2615252f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26733' max='26733' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26733/26733 5:55:23, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.325811</td>\n",
       "      <td>0.884206</td>\n",
       "      <td>0.841713</td>\n",
       "      <td>0.857896</td>\n",
       "      <td>0.848201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302651</td>\n",
       "      <td>0.889698</td>\n",
       "      <td>0.848987</td>\n",
       "      <td>0.863118</td>\n",
       "      <td>0.855654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.351273</td>\n",
       "      <td>0.894519</td>\n",
       "      <td>0.856339</td>\n",
       "      <td>0.863506</td>\n",
       "      <td>0.859627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.387684</td>\n",
       "      <td>0.892949</td>\n",
       "      <td>0.859153</td>\n",
       "      <td>0.854211</td>\n",
       "      <td>0.856652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.444698</td>\n",
       "      <td>0.894743</td>\n",
       "      <td>0.860771</td>\n",
       "      <td>0.856631</td>\n",
       "      <td>0.858374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22914</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.518066</td>\n",
       "      <td>0.888129</td>\n",
       "      <td>0.842856</td>\n",
       "      <td>0.867592</td>\n",
       "      <td>0.854441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26733</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.558347</td>\n",
       "      <td>0.891604</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.860968</td>\n",
       "      <td>0.856229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.9042, prec=0.8665, rec=0.8892, f1=0.8762\n",
      "[valid] acc=0.8842, prec=0.8417, rec=0.8579, f1=0.8482\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9313, prec=0.9018, rec=0.9200, f1=0.9105\n",
      "[valid] acc=0.8897, prec=0.8490, rec=0.8631, f1=0.8557\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9497, prec=0.9291, rec=0.9388, f1=0.9338\n",
      "[valid] acc=0.8945, prec=0.8563, rec=0.8635, f1=0.8596\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9668, prec=0.9558, rec=0.9571, f1=0.9564\n",
      "[valid] acc=0.8929, prec=0.8592, rec=0.8542, f1=0.8567\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9753, prec=0.9674, rec=0.9678, f1=0.9675\n",
      "[valid] acc=0.8947, prec=0.8608, rec=0.8566, f1=0.8584\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9757, prec=0.9628, rec=0.9745, f1=0.9685\n",
      "[valid] acc=0.8881, prec=0.8429, rec=0.8676, f1=0.8544\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 7]\n",
      "[train] acc=0.9813, prec=0.9730, rec=0.9777, f1=0.9753\n",
      "[valid] acc=0.8916, prec=0.8517, rec=0.8610, f1=0.8562\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=7, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e5\")\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.9042, prec=0.8665, rec=0.8892, f1=0.8762\n",
    "# [valid] acc=0.8842, prec=0.8417, rec=0.8579, f1=0.8482\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9313, prec=0.9018, rec=0.9200, f1=0.9105\n",
    "# [valid] acc=0.8897, prec=0.8490, rec=0.8631, f1=0.8557\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9497, prec=0.9291, rec=0.9388, f1=0.9338\n",
    "# [valid] acc=0.8945, prec=0.8563, rec=0.8635, f1=0.8596\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9668, prec=0.9558, rec=0.9571, f1=0.9564\n",
    "# [valid] acc=0.8929, prec=0.8592, rec=0.8542, f1=0.8567\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9753, prec=0.9674, rec=0.9678, f1=0.9675\n",
    "# [valid] acc=0.8947, prec=0.8608, rec=0.8566, f1=0.8584\n",
    "# =============================== OVERFITTING ====================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9757, prec=0.9628, rec=0.9745, f1=0.9685\n",
    "# [valid] acc=0.8881, prec=0.8429, rec=0.8676, f1=0.8544\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9813, prec=0.9730, rec=0.9777, f1=0.9753\n",
    "# [valid] acc=0.8916, prec=0.8517, rec=0.8610, f1=0.8562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc52583-12a9-423a-b001-575ef67d1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = train(model_name=\"./deberta-v3-crisis/batchsize16_lr1e5/checkpoint-26733\",\n",
    "#                 last_epoch = None, epoch=10, learning_rate=1e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e5_epoch7_cont\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8386e4f-958e-4525-a9cd-4de5c00f85e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=2e-5, batch_size=16 (EPOCH 3, val_f1=0.8579, test_f1=0.85392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adf0cb55-a32f-4106-a411-de4b135e84fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/2837947494.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19095' max='19095' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19095/19095 3:36:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346062</td>\n",
       "      <td>0.884542</td>\n",
       "      <td>0.843709</td>\n",
       "      <td>0.856845</td>\n",
       "      <td>0.848527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312487</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.847801</td>\n",
       "      <td>0.863210</td>\n",
       "      <td>0.855002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.415822</td>\n",
       "      <td>0.893622</td>\n",
       "      <td>0.855097</td>\n",
       "      <td>0.860775</td>\n",
       "      <td>0.857898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.430682</td>\n",
       "      <td>0.892837</td>\n",
       "      <td>0.856731</td>\n",
       "      <td>0.856669</td>\n",
       "      <td>0.856693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.889698</td>\n",
       "      <td>0.847530</td>\n",
       "      <td>0.860315</td>\n",
       "      <td>0.853732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.9095, prec=0.8759, rec=0.8929, f1=0.8827\n",
      "[valid] acc=0.8845, prec=0.8437, rec=0.8568, f1=0.8485\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9421, prec=0.9170, rec=0.9328, f1=0.9245\n",
      "[valid] acc=0.8893, prec=0.8478, rec=0.8632, f1=0.8550\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9647, prec=0.9501, rec=0.9570, f1=0.9535\n",
      "[valid] acc=0.8936, prec=0.8551, rec=0.8608, f1=0.8579\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9771, prec=0.9689, rec=0.9711, f1=0.9700\n",
      "[valid] acc=0.8928, prec=0.8567, rec=0.8567, f1=0.8567\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9802, prec=0.9714, rec=0.9770, f1=0.9742\n",
      "[valid] acc=0.8897, prec=0.8475, rec=0.8603, f1=0.8537\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=5, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16\")\n",
    "\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.9095, prec=0.8759, rec=0.8929, f1=0.8827\n",
    "# [valid] acc=0.8845, prec=0.8437, rec=0.8568, f1=0.8485\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9421, prec=0.9170, rec=0.9328, f1=0.9245\n",
    "# [valid] acc=0.8893, prec=0.8478, rec=0.8632, f1=0.8550\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9647, prec=0.9501, rec=0.9570, f1=0.9535\n",
    "# [valid] acc=0.8936, prec=0.8551, rec=0.8608, f1=0.8579\n",
    "# ================================= OVERFITTING ===================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9771, prec=0.9689, rec=0.9711, f1=0.9700\n",
    "# [valid] acc=0.8928, prec=0.8567, rec=0.8567, f1=0.8567\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9802, prec=0.9714, rec=0.9770, f1=0.9742\n",
    "# [valid] acc=0.8897, prec=0.8475, rec=0.8603, f1=0.8537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3644d122-eb2f-475d-9429-d8984aefcd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:121: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 14:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.4428344666957855, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8888952985289876, 'test_precision': 0.8469517407076887, 'test_recall': 0.8614854411684476, 'test_f1': 0.8539233722507791, 'test_runtime': 843.0977, 'test_samples_per_second': 20.561, 'test_steps_per_second': 0.321}\n",
      "[test] acc=0.8888952985289876, prec=0.8469517407076887, rec=0.8614854411684476, f1=0.8539233722507791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.4428344666957855,\n",
       " 'test_model_preparation_time': 0.0011,\n",
       " 'test_accuracy': 0.8888952985289876,\n",
       " 'test_precision': 0.8469517407076887,\n",
       " 'test_recall': 0.8614854411684476,\n",
       " 'test_f1': 0.8539233722507791,\n",
       " 'test_runtime': 843.0977,\n",
       " 'test_samples_per_second': 20.561,\n",
       " 'test_steps_per_second': 0.321}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16/checkpoint-11457\")\n",
    "# [test] acc=0.8888952985289876, prec=0.8469517407076887, rec=0.8614854411684476, f1=0.8539233722507791"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7f6657-99ae-42da-9502-bf3603eccd10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=5e-5, batch_size=16 (EPOCH 2, val_f1=0.8363, test_f1=0.836272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "718415df-f7ce-47bd-b48a-0c456e05c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1381527606.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 01:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.3785085082054138, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.873893061315996, 'test_precision': 0.8232246134894181, 'test_recall': 0.8519248854229843, 'test_f1': 0.8362720804971207, 'test_runtime': 65.9497, 'test_samples_per_second': 135.27, 'test_steps_per_second': 2.123}\n",
      "[test] acc=0.873893061315996, prec=0.8232246134894181, rec=0.8519248854229843, f1=0.8362720804971207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.3785085082054138,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.873893061315996,\n",
       " 'test_precision': 0.8232246134894181,\n",
       " 'test_recall': 0.8519248854229843,\n",
       " 'test_f1': 0.8362720804971207,\n",
       " 'test_runtime': 65.9497,\n",
       " 'test_samples_per_second': 135.27,\n",
       " 'test_steps_per_second': 2.123}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr5e5/checkpoint-7638\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89465347-8a07-4e53-8f31-2b419364f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] loss=0.3701, acc=0.8898, prec=0.8705, rec=0.8344, f1=0.8504\n",
    "# [valid] loss=0.4345, acc=0.8714, prec=0.8502, rec=0.8026, f1=0.8232\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] loss=0.2995, acc=0.9050, prec=0.8625, rec=0.8906, f1=0.8756\n",
    "# [valid] loss=0.3785, acc=0.8739, prec=0.8232, rec=0.8519, f1=0.8363\n",
    "# ============================= OVERFITTING =====================================\n",
    "# [EPOCH 3]\n",
    "# [train] loss=0.3244, acc=0.9158, prec=0.8993, rec=0.8725, f1=0.8826\n",
    "# [valid] loss=0.4700, acc=0.8808, prec=0.8584, rec=0.8188, f1=0.8324\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] loss=0.3399, acc=0.9151, prec=0.8885, rec=0.8804, f1=0.8835\n",
    "# [valid] loss=0.4732, acc=0.8783, prec=0.8438, rec=0.8265, f1=0.8335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81cd60c9-60db-4492-9ce4-fcd2bbe518f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15483' max='38190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15483/38190 2:57:41 < 4:20:38, 1.45 it/s, Epoch 4.05/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434464</td>\n",
       "      <td>0.871427</td>\n",
       "      <td>0.850153</td>\n",
       "      <td>0.802633</td>\n",
       "      <td>0.823238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.873893</td>\n",
       "      <td>0.823225</td>\n",
       "      <td>0.851925</td>\n",
       "      <td>0.836272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.880843</td>\n",
       "      <td>0.858400</td>\n",
       "      <td>0.818754</td>\n",
       "      <td>0.832363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.473155</td>\n",
       "      <td>0.878265</td>\n",
       "      <td>0.843796</td>\n",
       "      <td>0.826548</td>\n",
       "      <td>0.833529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] loss=0.3701, acc=0.8898, prec=0.8705, rec=0.8344, f1=0.8504\n",
      "[valid] loss=0.4345, acc=0.8714, prec=0.8502, rec=0.8026, f1=0.8232\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] loss=0.2995, acc=0.9050, prec=0.8625, rec=0.8906, f1=0.8756\n",
      "[valid] loss=0.3785, acc=0.8739, prec=0.8232, rec=0.8519, f1=0.8363\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] loss=0.3244, acc=0.9158, prec=0.8993, rec=0.8725, f1=0.8826\n",
      "[valid] loss=0.4700, acc=0.8808, prec=0.8584, rec=0.8188, f1=0.8324\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] loss=0.3399, acc=0.9151, prec=0.8885, rec=0.8804, f1=0.8835\n",
      "[valid] loss=0.4732, acc=0.8783, prec=0.8438, rec=0.8265, f1=0.8335\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize16_lr5e5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 112\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_name, last_epoch, epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    101\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    102\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 112\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=10, learning_rate=5e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr5e5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc44e0-edaa-4231-9f1f-d84caf01e592",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=1e-4, batch_size=16 (EPOCH 1, val_f1=0.2623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdbffa6e-f9c4-44fb-a28b-31bd5ecc5f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19095' max='19095' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19095/19095 3:50:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.901548</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7638</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.908638</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11457</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.957057</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15276</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.923322</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19095</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.934442</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
      "[valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n"
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=5, learning_rate=1e-4, batch_size=16, output_dir=\"./deberta-v3-crisis/batchsize16_lr1e4\")\n",
    "\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.6474, prec=0.2158, rec=0.3333, f1=0.2620\n",
    "# [valid] acc=0.6486, prec=0.2162, rec=0.3333, f1=0.2623"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fff49-1ba1-4642-a1b1-51f366e31e9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### learning_rate=2e-5, batch_size=8 (EPOCH 3, val_f1=0.8575, test_f1=0.85072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4692839d-ee61-4ebb-9999-7eb5b5fa21f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/2837947494.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50505' max='76370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50505/76370 11:58:42 < 6:08:05, 1.17 it/s, Epoch 6.61/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7637</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.438154</td>\n",
       "      <td>0.878713</td>\n",
       "      <td>0.838978</td>\n",
       "      <td>0.848959</td>\n",
       "      <td>0.840268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15274</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357016</td>\n",
       "      <td>0.891044</td>\n",
       "      <td>0.853015</td>\n",
       "      <td>0.857961</td>\n",
       "      <td>0.855069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22911</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.542490</td>\n",
       "      <td>0.893510</td>\n",
       "      <td>0.857933</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.857463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30548</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.478209</td>\n",
       "      <td>0.887905</td>\n",
       "      <td>0.848656</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>0.851310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38185</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.670134</td>\n",
       "      <td>0.885999</td>\n",
       "      <td>0.849009</td>\n",
       "      <td>0.845102</td>\n",
       "      <td>0.846945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45822</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.671519</td>\n",
       "      <td>0.888017</td>\n",
       "      <td>0.847992</td>\n",
       "      <td>0.854826</td>\n",
       "      <td>0.851258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.9054, prec=0.8719, rec=0.8880, f1=0.8770\n",
      "[valid] acc=0.8787, prec=0.8390, rec=0.8490, f1=0.8403\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "[train] acc=0.9380, prec=0.9154, rec=0.9203, f1=0.9176\n",
      "[valid] acc=0.8910, prec=0.8530, rec=0.8580, f1=0.8551\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 3]\n",
      "[train] acc=0.9611, prec=0.9465, rec=0.9496, f1=0.9480\n",
      "[valid] acc=0.8935, prec=0.8579, rec=0.8575, f1=0.8575\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 4]\n",
      "[train] acc=0.9740, prec=0.9634, rec=0.9674, f1=0.9654\n",
      "[valid] acc=0.8879, prec=0.8487, rec=0.8541, f1=0.8513\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 5]\n",
      "[train] acc=0.9843, prec=0.9790, rec=0.9786, f1=0.9788\n",
      "[valid] acc=0.8860, prec=0.8490, rec=0.8451, f1=0.8469\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 6]\n",
      "[train] acc=0.9898, prec=0.9853, rec=0.9868, f1=0.9861\n",
      "[valid] acc=0.8880, prec=0.8480, rec=0.8548, f1=0.8513\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 104\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     93\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     94\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    100\u001b[0m )\n\u001b[1;32m    102\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train(epoch=10, learning_rate=2e-5, batch_size=8, output_dir=\"./deberta-v3-crisis/batchsize8\")\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.9054, prec=0.8719, rec=0.8880, f1=0.8770\n",
    "# [valid] acc=0.8787, prec=0.8390, rec=0.8490, f1=0.8403\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9380, prec=0.9154, rec=0.9203, f1=0.9176\n",
    "# [valid] acc=0.8910, prec=0.8530, rec=0.8580, f1=0.8551\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9611, prec=0.9465, rec=0.9496, f1=0.9480\n",
    "# [valid] acc=0.8935, prec=0.8579, rec=0.8575, f1=0.8575\n",
    "\n",
    "# test_loss = 0.577634871006012\n",
    "# test_accuracy = 0.8872800692241131\n",
    "# test_precision = 0.8469312572131958\n",
    "# test_recall = 0.855374024799894\n",
    "# test_f1 = 0.8507208362474484\n",
    "# ============================= OVERFITTING =====================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9740, prec=0.9634, rec=0.9674, f1=0.9654\n",
    "# [valid] acc=0.8879, prec=0.8487, rec=0.8541, f1=0.8513\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9843, prec=0.9790, rec=0.9786, f1=0.9788\n",
    "# [valid] acc=0.8860, prec=0.8490, rec=0.8451, f1=0.8469\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9898, prec=0.9853, rec=0.9868, f1=0.9861\n",
    "# [valid] acc=0.8880, prec=0.8480, rec=0.8548, f1=0.8513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "818e1317-f3df-4e54-8a22-b99b795abba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1140767481.py:121: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0023, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 124.2977, 'test_samples_per_second': 139.464, 'test_steps_per_second': 2.18}\n",
      "[test] acc=0.8872800692241131, prec=0.8469312572131958, rec=0.855374024799894, f1=0.8507208362474484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.577634871006012,\n",
       " 'test_model_preparation_time': 0.0023,\n",
       " 'test_accuracy': 0.8872800692241131,\n",
       " 'test_precision': 0.8469312572131958,\n",
       " 'test_recall': 0.855374024799894,\n",
       " 'test_f1': 0.8507208362474484,\n",
       " 'test_runtime': 124.2977,\n",
       " 'test_samples_per_second': 139.464,\n",
       " 'test_steps_per_second': 2.18}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-22911\")\n",
    "# [test] acc=0.8872800692241131, prec=0.8469312572131958, rec=0.855374024799894, f1=0.8507208362474484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0685b9f-94a6-49ba-9847-d5d27c436e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.37746426463127136, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8849149120276897, 'test_precision': 0.8430869630919547, 'test_recall': 0.8545599129431753, 'test_f1': 0.8482132493443325, 'test_runtime': 125.0236, 'test_samples_per_second': 138.654, 'test_steps_per_second': 2.168}\n",
      "test_loss = 0.37746426463127136\n",
      "test_accuracy = 0.8849149120276897\n",
      "test_precision = 0.8430869630919547\n",
      "test_recall = 0.8545599129431753\n",
      "test_f1 = 0.8482132493443325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 125.0976, 'test_samples_per_second': 138.572, 'test_steps_per_second': 2.166}\n",
      "test_loss = 0.577634871006012\n",
      "test_accuracy = 0.8872800692241131\n",
      "test_precision = 0.8469312572131958\n",
      "test_recall = 0.855374024799894\n",
      "test_f1 = 0.8507208362474484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.49717429280281067, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8831843092010384, 'test_precision': 0.8392270903901514, 'test_recall': 0.8564725619023125, 'test_f1': 0.8473071372190685, 'test_runtime': 125.1699, 'test_samples_per_second': 138.492, 'test_steps_per_second': 2.165}\n",
      "test_loss = 0.49717429280281067\n",
      "test_accuracy = 0.8831843092010384\n",
      "test_precision = 0.8392270903901514\n",
      "test_recall = 0.8564725619023125\n",
      "test_f1 = 0.8473071372190685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.6949165463447571, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8830689356792616, 'test_precision': 0.842145954123632, 'test_recall': 0.8472896061789302, 'test_f1': 0.8445861775113469, 'test_runtime': 128.6307, 'test_samples_per_second': 134.766, 'test_steps_per_second': 2.107}\n",
      "test_loss = 0.6949165463447571\n",
      "test_accuracy = 0.8830689356792616\n",
      "test_precision = 0.842145954123632\n",
      "test_recall = 0.8472896061789302\n",
      "test_f1 = 0.8445861775113469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/1611466591.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.715135395526886, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8819728872223824, 'test_precision': 0.836460218016704, 'test_recall': 0.8544100282915196, 'test_f1': 0.8450040779020537, 'test_runtime': 125.2994, 'test_samples_per_second': 138.349, 'test_steps_per_second': 2.163}\n",
      "test_loss = 0.715135395526886\n",
      "test_accuracy = 0.8819728872223824\n",
      "test_precision = 0.836460218016704\n",
      "test_recall = 0.8544100282915196\n",
      "test_f1 = 0.8450040779020537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.715135395526886,\n",
       " 'test_model_preparation_time': 0.0013,\n",
       " 'test_accuracy': 0.8819728872223824,\n",
       " 'test_precision': 0.836460218016704,\n",
       " 'test_recall': 0.8544100282915196,\n",
       " 'test_f1': 0.8450040779020537,\n",
       " 'test_runtime': 125.2994,\n",
       " 'test_samples_per_second': 138.349,\n",
       " 'test_steps_per_second': 2.163}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-7637\")\n",
    "# {'test_loss': 0.4593863785266876, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8740698009806749, 'test_precision': 0.8326252068193959, 'test_recall': 0.8500324417218078, 'test_f1': 0.8369876991837396, 'test_runtime': 123.8232, 'test_samples_per_second': 139.998, 'test_steps_per_second': 2.189}\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-15274\")\n",
    "# {'test_loss': 0.37746426463127136, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8849149120276897, 'test_precision': 0.8430869630919547, 'test_recall': 0.8545599129431753, 'test_f1': 0.8482132493443325, 'test_runtime': 125.0236, 'test_samples_per_second': 138.654, 'test_steps_per_second': 2.168}\n",
    "# test_loss = 0.37746426463127136\n",
    "# test_accuracy = 0.8849149120276897\n",
    "# test_precision = 0.8430869630919547\n",
    "# test_recall = 0.8545599129431753\n",
    "# test_f1 = 0.8482132493443325\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-22911\")\n",
    "# {'test_loss': 0.577634871006012, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8872800692241131, 'test_precision': 0.8469312572131958, 'test_recall': 0.855374024799894, 'test_f1': 0.8507208362474484, 'test_runtime': 125.0976, 'test_samples_per_second': 138.572, 'test_steps_per_second': 2.166}\n",
    "# test_loss = 0.577634871006012\n",
    "# test_accuracy = 0.8872800692241131\n",
    "# test_precision = 0.8469312572131958\n",
    "# test_recall = 0.855374024799894\n",
    "# test_f1 = 0.8507208362474484\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-30548\")\n",
    "# {'test_loss': 0.49717429280281067, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8831843092010384, 'test_precision': 0.8392270903901514, 'test_recall': 0.8564725619023125, 'test_f1': 0.8473071372190685, 'test_runtime': 125.1699, 'test_samples_per_second': 138.492, 'test_steps_per_second': 2.165}\n",
    "# test_loss = 0.49717429280281067\n",
    "# test_accuracy = 0.8831843092010384\n",
    "# test_precision = 0.8392270903901514\n",
    "# test_recall = 0.8564725619023125\n",
    "# test_f1 = 0.8473071372190685\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-38185\")\n",
    "# {'test_loss': 0.6949165463447571, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8830689356792616, 'test_precision': 0.842145954123632, 'test_recall': 0.8472896061789302, 'test_f1': 0.8445861775113469, 'test_runtime': 128.6307, 'test_samples_per_second': 134.766, 'test_steps_per_second': 2.107}\n",
    "# test_loss = 0.6949165463447571\n",
    "# test_accuracy = 0.8830689356792616\n",
    "# test_precision = 0.842145954123632\n",
    "# test_recall = 0.8472896061789302\n",
    "# test_f1 = 0.8445861775113469\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize8/checkpoint-45822\")\n",
    "# {'test_loss': 0.715135395526886, 'test_model_preparation_time': 0.0013, 'test_accuracy': 0.8819728872223824, 'test_precision': 0.836460218016704, 'test_recall': 0.8544100282915196, 'test_f1': 0.8450040779020537, 'test_runtime': 125.2994, 'test_samples_per_second': 138.349, 'test_steps_per_second': 2.163}\n",
    "# test_loss = 0.715135395526886\n",
    "# test_accuracy = 0.8819728872223824\n",
    "# test_precision = 0.836460218016704\n",
    "# test_recall = 0.8544100282915196\n",
    "# test_f1 = 0.8450040779020537"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fae6d-678a-45ed-b0c7-d1b8ab081f2f",
   "metadata": {},
   "source": [
    "### Learning and Validation Curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3306b97e-c319-4e42-94eb-c2ed962a53e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/831986743.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [271/271 02:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.44441157579421997, 'test_model_preparation_time': 0.0012, 'test_accuracy': 0.8876261897894433, 'test_precision': 0.8431801450425511, 'test_recall': 0.8625945973329592, 'test_f1': 0.8524425110946661, 'test_runtime': 126.022, 'test_samples_per_second': 137.555, 'test_steps_per_second': 2.15}\n",
      "[test] acc=0.8876261897894433, prec=0.8431801450425511, rec=0.8625945973329592, f1=0.8524425110946661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.44441157579421997,\n",
       " 'test_model_preparation_time': 0.0012,\n",
       " 'test_accuracy': 0.8876261897894433,\n",
       " 'test_precision': 0.8431801450425511,\n",
       " 'test_recall': 0.8625945973329592,\n",
       " 'test_f1': 0.8524425110946661,\n",
       " 'test_runtime': 126.022,\n",
       " 'test_samples_per_second': 137.555,\n",
       " 'test_steps_per_second': 2.15}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model\n",
    "# learning_rate=5e-6, batch_size=16 (EPOCH 7, val_f1=0.8603, test_f1=0.85244) => BEST\n",
    "load_and_test_eval(\"./deberta-v3-crisis/batchsize16_lr5e6/checkpoint-26733\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f05f654d-04d8-4061-9a6b-c06908ef9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = [0.8673, 0.8927, 0.9095, 0.9274, 0.9351, 0.9393, 0.9436,\n",
    "            0.9444, 0.9589]\n",
    "best_model_val_f1 = [0.8440, 0.8568, 0.8580, 0.8568, 0.8580, 0.8584, 0.8603,\n",
    "          0.8505, 0.8533]\n",
    "# ================================================================================\n",
    "# [EPOCH 1]\n",
    "# [train] acc=0.8983, prec=0.8618, rec=0.8756, f1=0.8673\n",
    "# [valid] acc=0.8816, prec=0.8414, rec=0.8494, f1=0.8440\n",
    "# ================================================================================\n",
    "# [EPOCH 2]\n",
    "# [train] acc=0.9174, prec=0.8843, rec=0.9019, f1=0.8927\n",
    "# [valid] acc=0.8908, prec=0.8504, rec=0.8638, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 3]\n",
    "# [train] acc=0.9314, prec=0.9065, rec=0.9128, f1=0.9095\n",
    "# [valid] acc=0.8935, prec=0.8584, rec=0.8579, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 4]\n",
    "# [train] acc=0.9448, prec=0.9269, rec=0.9279, f1=0.9274\n",
    "# [valid] acc=0.8927, prec=0.8597, rec=0.8541, f1=0.8568\n",
    "# ================================================================================\n",
    "# [EPOCH 5]\n",
    "# [train] acc=0.9510, prec=0.9316, rec=0.9389, f1=0.9351\n",
    "# [valid] acc=0.8936, prec=0.8566, rec=0.8598, f1=0.8580\n",
    "# ================================================================================\n",
    "# [EPOCH 6]\n",
    "# [train] acc=0.9532, prec=0.9325, rec=0.9467, f1=0.9393\n",
    "# [valid] acc=0.8924, prec=0.8516, rec=0.8659, f1=0.8584\n",
    "# ================================================================================\n",
    "# [EPOCH 7]\n",
    "# [train] acc=0.9569, prec=0.9386, rec=0.9489, f1=0.9436\n",
    "# [valid] acc=0.8942, prec=0.8557, rec=0.8651, f1=0.8603\n",
    "# ============================= OVERFITTING ======================================\n",
    "# [EPOCH 8]\n",
    "# [train] loss=0.1480, acc=0.9574, prec=0.9391, rec=0.9508, f1=0.9444\n",
    "# [valid] loss=0.4439, acc=0.8864, prec=0.8488, rec=0.8546, f1=0.8505\n",
    "# ================================================================================\n",
    "# [EPOCH 9]\n",
    "# [train] loss=0.1104, acc=0.9689, prec=0.9530, rec=0.9652, f1=0.9589\n",
    "# [valid] loss=0.4663, acc=0.8887, prec=0.8475, rec=0.8598, f1=0.8533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e5bd818-577e-44d9-9fec-4d5cad0c8b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(train_f1s, val_f1s):\n",
    "    N = len(train_f1s)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(train_f1s, label=\"Train\")\n",
    "    # plt.plot(val_f1s, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.plot(range(1, N+1), train_f1s, label=\"Train\")\n",
    "    plt.plot(range(1, N+1), val_f1s, label=\"Validation\")\n",
    "    plt.axvline(x=7, color='red', linestyle='--', linewidth=1.5) # , label=\"overfitting threshold\")\n",
    "    plt.xticks([i for i in range(1, N+1)])\n",
    "    plt.ylabel(\"F1 Score (Macro)\")\n",
    "    plt.title(\"Transformer (Deberta-V3) Learning Curve\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"pretrained_transformer_f1_score_curve.png\")\n",
    "\n",
    "plot_learning_curve(best_model_train_f1, best_model_val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07447846-6f37-4387-9a74-ca0066315c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/936105137.py:16: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_31811/936105137.py:16: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_validation_curve(xticks, log_scale, val_f1s, filename):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    if log_scale:\n",
    "        # Log-scale line plot\n",
    "        plt.semilogx(xticks, val_f1s, marker=\"o\") # , label=\"Validation\")\n",
    "        plt.xticks(xticks, [f\"{x:.0e}\" for x in xticks])\n",
    "    else:\n",
    "        plt.plot(xticks, val_f1s) # , label=\"Validation\")\n",
    "\n",
    "    plt.xlabel(\"Learning Rate (log scale)\" if log_scale else \"Learning Rate\")\n",
    "    plt.ylabel(\"F1 Score (Macro)\")\n",
    "    plt.title(\"Transformer (DeBERTa-V3) Validation Curve\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "\n",
    "# learning_rate=1e-6, batch_size=16 (EPOCH 16, val_f1=0.8583, test_f1=0.848050)\n",
    "# learning_rate=5e-6, batch_size=16 (EPOCH 7, val_f1=0.8603, test_f1=0.85244) => BEST\n",
    "# learning_rate=1e-5, batch_size=16 (EPOCH 5, val_f1=0.8584, test_f1=0.85042)\n",
    "# learning_rate=2e-5, batch_size=16 (EPOCH 3, val_f1=0.8579, test_f1=0.85392)\n",
    "# learning_rate=5e-5, batch_size=16 (EPOCH 2, val_f1=0.8363, test_f1=0.836272)\n",
    "\n",
    "# learning_rate=1e-4, batch_size=16 (EPOCH 1~3, val_f1=0.2623)\n",
    "\n",
    "val_f1_scores = [0.8583, 0.8603, 0.8584, 0.8579] # , 0.2623]\n",
    "learning_rates = [1e-6, 5e-6, 1e-5, 2e-5]\n",
    "plot_validation_curve(learning_rates, True, val_f1_scores, \"pretrained_transformer_f1_score_val_curve1.png\")\n",
    "# learning_rates = [\"1e-6\\n(epoch=16)\", \"5e-6\\n(epoch=7)\", \"1e-5\\n(epoch=5)\", \"2e-5\\n(epoch=3)\"]\n",
    "# plot_validation_curve(learning_rates, False, val_f1_scores, \"pretrained_transformer_f1_score_val_curve_epoch1.png\")\n",
    "\n",
    "val_f1_scores = [0.8583, 0.8603, 0.8584, 0.8579, 0.8363] # , 0.2623]\n",
    "learning_rates = [1e-6, 5e-6, 1e-5, 2e-5, 5e-5]\n",
    "plot_validation_curve(learning_rates, True, val_f1_scores, \"pretrained_transformer_f1_score_val_curve2.png\")\n",
    "# learning_rates = [\"1e-6\\n(epoch=16)\", \"5e-6\\n(epoch=7)\", \"1e-5\\n(epoch=5)\", \"2e-5\\n(epoch=3)\", \"5e-5\\n(epoch=2)\"]\n",
    "# plot_validation_curve(learning_rates, False, val_f1_scores, \"pretrained_transformer_f1_score_val_curve_epoch2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ab5e3-0e5d-4942-bc60-b7f9bf723604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a809155e-ab79-411a-a178-8a504ee294af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_95996/312600777.py:44: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38236' max='76370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38236/76370 4:44:25 < 4:43:40, 2.24 it/s, Epoch 5.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341084</td>\n",
       "      <td>0.901881</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.888816</td>\n",
       "      <td>0.873895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.218777</td>\n",
       "      <td>0.935504</td>\n",
       "      <td>0.909765</td>\n",
       "      <td>0.919633</td>\n",
       "      <td>0.913919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.164746</td>\n",
       "      <td>0.959142</td>\n",
       "      <td>0.939431</td>\n",
       "      <td>0.952655</td>\n",
       "      <td>0.945791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.973907</td>\n",
       "      <td>0.963635</td>\n",
       "      <td>0.966295</td>\n",
       "      <td>0.964884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.087381</td>\n",
       "      <td>0.982927</td>\n",
       "      <td>0.976098</td>\n",
       "      <td>0.977472</td>\n",
       "      <td>0.976734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[60], line 56\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     45\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     46\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 56\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=10, learning_rate=2e-5, batch_size=8, output_dir=\"./deberta-v3-crisis/2\")\n",
    "# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# print(eval_results)\n",
    "\n",
    "#  # [38186/76370 4:35:02 < 4:35:02, 2.31 it/s, Epoch 5/10]\n",
    "# # Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# # 1\tNo log\t0.341084\t0.901881\t0.866828\t0.888816\t0.873895\n",
    "# # 2\tNo log\t0.218777\t0.935504\t0.909765\t0.919633\t0.913919\n",
    "# # 3\tNo log\t0.164746\t0.959142\t0.939431\t0.952655\t0.945791\n",
    "# # 4\tNo log\t0.109434\t0.973907\t0.963635\t0.966295\t0.964884\n",
    "# # 5\tNo log\t0.087381\t0.982927\t0.976098\t0.977472\t0.976734\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73ddf31d-8048-40dc-8c6b-a97d893d5872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/281152571.py:115: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='276' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 276/2710 10:21 < 1:31:57, 0.44 it/s, Epoch 1.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319999</td>\n",
       "      <td>0.888491</td>\n",
       "      <td>0.851906</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.849046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "[train] acc=0.8885, prec=0.8519, rec=0.8495, f1=0.8490\n",
      "[valid] acc=0.8709, prec=0.8351, rec=0.8190, f1=0.8247\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(eval_results)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 127\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    115\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    116\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    117\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 127\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4020\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   4019\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4020\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4022\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   4023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4024\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4025\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   4026\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4110\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4108\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   4109\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 4110\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   4112\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   4113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1102\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1102\u001b[0m     label_index \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=10, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/batchsize64\")\n",
    "# # eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# # print(eval_results)\n",
    "\n",
    "# #  [ 272/2710 07:04 < 1:03:52, 0.64 it/s, Epoch 1/10]\n",
    "# # Step\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# # 271\tNo log\t0.360962\t0.870866\t0.835089\t0.818979\t0.824688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a2faa6-fd37-4f29-ad7a-6a952b848fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/3149821493.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1014' max='9550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1014/9550 1:00:22 < 8:29:14, 0.28 it/s, Epoch 1.06/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262881</td>\n",
       "      <td>0.903174</td>\n",
       "      <td>0.863936</td>\n",
       "      <td>0.888640</td>\n",
       "      <td>0.874394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "  [train] acc=0.9032, prec=0.8639, rec=0.8886, f1=0.8744  (n=None)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/batchsize64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[12], line 120\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m    108\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    109\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    110\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 120\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=10, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/batchsize64_1\")\n",
    "# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# print(eval_results)\n",
    "# #  [1014/9550 1:00:22 < 8:29:14, 0.28 it/s, Epoch 1.06/10]\n",
    "# # Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall\tF1\n",
    "# # 1\tNo log\t0.262881\t0.903174\t0.863936\t0.888640\t0.874394\n",
    "\n",
    "# # ================================================================================\n",
    "# # [EPOCH 1]\n",
    "# #   [train] acc=0.9032, prec=0.8639, rec=0.8886, f1=0.8744  (n=None)\n",
    "\n",
    "# # Batch size can't be as high as 256?\n",
    "# # RuntimeError: MPS backend out of memory (MPS allocated: 27.10 GB, other allocations: 832.00 KB, max allowed: 27.20 GB). Tried to allocate 375.29 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5675a2b6-2ca4-4ccf-a66a-1a82c8139042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class TrainMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, train_dataset):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.trainer = None\n",
    "        self.last_eval_metrics = None\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        if any(k.startswith(\"eval_\") for k in metrics.keys()):\n",
    "            self.last_eval_metrics = metrics\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if self.trainer is None:\n",
    "            return control\n",
    "\n",
    "        train_metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.train_dataset,\n",
    "            metric_key_prefix=\"train\", # train_accuracy, train_f1, ...\n",
    "        )\n",
    "\n",
    "        epoch = state.epoch\n",
    "        train_acc = train_metrics.get(\"train_accuracy\", None)\n",
    "        train_f1  = train_metrics.get(\"train_f1\", None)\n",
    "\n",
    "        val_acc = None\n",
    "        val_f1  = None\n",
    "        if self.last_eval_metrics is not None:\n",
    "            val_acc = self.last_eval_metrics.get(\"eval_accuracy\", None)\n",
    "            val_f1  = self.last_eval_metrics.get(\"eval_f1\", None)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[EPOCH {epoch:.0f}]\")\n",
    "        if train_acc is not None and train_f1 is not None:\n",
    "            print(f\"  train_acc = {train_acc:.4f}, train_f1 = {train_f1:.4f}\")\n",
    "        if val_acc is not None and val_f1 is not None:\n",
    "            print(f\"  val_acc   = {val_acc:.4f}, val_f1   = {val_f1:.4f}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        return control\n",
    "\n",
    "\n",
    "def train(epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\"):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epoch,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    train_callback = TrainMetricsCallback(tokenized_datasets[\"train\"])\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[train_callback],\n",
    "    )\n",
    "\n",
    "    train_callback.trainer = trainer\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7e8d34-f563-4067-8dae-d3726081c67f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_8707/2795326635.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2716' max='2865' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2716/2865 1:24:08 < 04:37, 0.54 it/s, Epoch 2.84/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265105</td>\n",
       "      <td>0.901373</td>\n",
       "      <td>0.860023</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.873302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.204079</td>\n",
       "      <td>0.928432</td>\n",
       "      <td>0.897973</td>\n",
       "      <td>0.917152</td>\n",
       "      <td>0.907176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EPOCH 1]\n",
      "  train_acc = 0.9014, train_f1 = 0.8733\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "[EPOCH 2]\n",
      "  train_acc = 0.9284, train_f1 = 0.9072\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deberta-v3-crisis/test2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "Cell \u001b[0;32mIn[10], line 87\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, learning_rate, batch_size, output_dir)\u001b[0m\n\u001b[1;32m     75\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     76\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     77\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[train_callback],\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m train_callback\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 87\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/accelerate/accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2852\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=3, learning_rate=2e-5, batch_size=64, output_dir=\"./deberta-v3-crisis/test2\")\n",
    "# eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "# print(eval_results)\n",
    "\n",
    "# # Batch size can't be as high as 256?\n",
    "# # RuntimeError: MPS backend out of memory (MPS allocated: 27.10 GB, other allocations: 832.00 KB, max allowed: 27.20 GB). Tried to allocate 375.29 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc0f71a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/s4/0k6rg3jx501349m2r7df_0_w0000gn/T/ipykernel_84643/3190309381.py:41: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7802' max='11457' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7802/11457 1:12:17 < 33:52, 1.80 it/s, Epoch 2.04/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.322661</td>\n",
       "      <td>0.888241</td>\n",
       "      <td>0.851410</td>\n",
       "      <td>0.855949</td>\n",
       "      <td>0.852308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.300615</td>\n",
       "      <td>0.893398</td>\n",
       "      <td>0.853491</td>\n",
       "      <td>0.866558</td>\n",
       "      <td>0.859771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 50\u001b[0m\n\u001b[1;32m     26\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     27\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./deberta-v3-crisis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     42\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     43\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crisisbench-dl/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer = train(epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\")\n",
    "\n",
    "# # Epoch\tTraining Loss\tValidation Loss\tAccuracy\tPrecision\tRecall  \tF1\n",
    "# # 1\t    0.311500\t    0.322661\t    0.888241\t0.851410\t0.855949\t0.852308\n",
    "# # 2\t    0.239700\t    0.300615\t    0.893398\t0.853491\t0.866558\t0.859771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09147530-f5a5-4c5a-8a5f-e8d56169444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c2942-0c4a-430e-889f-c765fa6daab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V6E1",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
