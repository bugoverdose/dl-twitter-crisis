{"cells":[{"cell_type":"markdown","id":"10a9ab23-f031-44a3-88cd-4d08f1f6381c","metadata":{"id":"10a9ab23-f031-44a3-88cd-4d08f1f6381c"},"source":["# Deep Learning"]},{"cell_type":"markdown","id":"733ec020-a4bb-430f-b561-1f0367e5f486","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"733ec020-a4bb-430f-b561-1f0367e5f486"},"source":["## Setup"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"7VwrqPX4-zGH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764588781326,"user_tz":-540,"elapsed":44495,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"8c40e6a2-9338-4500-f81b-24c546f448e9"},"id":"7VwrqPX4-zGH","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import csv\n","import pandas as pd\n","import numpy as np\n","import sys\n","\n","GOOGLE_DRIVE_PATH_POST_MYDRIVE = 'dl-twitter-crisis'\n","GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n","if 'google.colab' in sys.modules:\n","  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n","else:\n","  GOOGLE_DRIVE_PATH = '.'\n","  print('Running locally.')\n","\n","print(GOOGLE_DRIVE_PATH)\n","sys.path.append(GOOGLE_DRIVE_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_z_xRX2-0Gz","executionInfo":{"status":"ok","timestamp":1764588932360,"user_tz":-540,"elapsed":1756,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"bb397b69-53d3-4cf7-de41-db606b79d571"},"id":"T_z_xRX2-0Gz","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['anomaly_detection.ipynb', 'anomaly_detection_local.ipynb', 'crisis_bench_preprocess.ipynb', 'crisis_bench_local.ipynb', 'overleaf.tex', 'best_textcnn_glove.pt', 'cnn_acc_curve.png', 'cnn_num_filters_validation_curve.png', 'nltk_data', 'docs', 'transformers', '.ipynb_checkpoints', 'paper', 'data', '.git', '.DS_Store', 'README.md', '.gitignore', 'environment.yml', 'textcnn_results.csv', 'textcnn_results2.csv', 'cnn_f1_score_curve.png', 'cnn_loss_curve.png', 'transformer_learning_curve_f1.png', 'transformer_lr_validation_curve_f1.png', 'textcnn_learning_curve_best_num_filters_75.png', 'textcnn_learning_curve_best_100.png', 'textcnn_learning_curve_best_75.png', 'textcnn_learning_curves_by_num_filters.png', 'best_textcnn_glove_numfilters_25.pt', 'best_textcnn_glove_numfilters_50.pt', 'best_textcnn_glove_numfilters_75.pt', 'best_textcnn_glove_numfilters_100.pt', 'best_custom_transformer_lr.pt', 'custom_transformer_lr_validation_curve.png', 'pretrained_transformer_f1_score_curve.png', 'best_transformer.zip', 'checkpoint-26733', 'time_critical_fp_fn_test.csv', 'pretrained_transformer_high_conf_disagreements_val.csv', 'custom_transformer_learning_curve.png', 'pretrained_transformer_all_labels_fp_fn_test.csv', 'deberta_all_labels_fp_fn_test_per_label_confusion.csv', 'textcnn_fp_fn_all_labels_test.csv', 'custom_transformer_fp_fn_all_labels_test.csv', 'textcnn_non_informative_test.csv', 'deberta_all_labels_fp_fn_test.csv', 'textcnn_learning_curve_best_50.png', 'deberta_tc_ni_fp_fn_test.csv', 'deberta_ni_tc_fp_fn_test.csv', 'deberta_sr_tc_fp_fn_test.csv', 'deberta_sr_ni_fp_fn_test.csv', 'crisis_bench_jinwoo.ipynb', 'custom_transformer_validation_curve.png', 'textcnn_validation_curve_num_filters.png', 'pretrained_transformer_f1_score_val_curve.png', 'crisis_bench_jade.ipynb']\n","Running in google colab. Our path is `/content/drive/MyDrive/dl-twitter-crisis`\n","/content/drive/MyDrive/dl-twitter-crisis\n"]}]},{"cell_type":"code","execution_count":3,"id":"fc7346fe-d763-4501-9a45-1c4c7a9ab363","metadata":{"id":"fc7346fe-d763-4501-9a45-1c4c7a9ab363","executionInfo":{"status":"ok","timestamp":1764588940677,"user_tz":-540,"elapsed":5151,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["import os\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n","\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score"]},{"cell_type":"code","execution_count":4,"id":"0869bbce-6ad5-4929-9439-c2f4bc6249f5","metadata":{"id":"0869bbce-6ad5-4929-9439-c2f4bc6249f5","executionInfo":{"status":"ok","timestamp":1764588940691,"user_tz":-540,"elapsed":7,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["import random\n","\n","SEED = 42\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(SEED)\n","    torch.cuda.manual_seed_all(SEED)\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","generator = torch.Generator()\n","_ = generator.manual_seed(SEED)"]},{"cell_type":"code","execution_count":5,"id":"25f2506b","metadata":{"id":"25f2506b","executionInfo":{"status":"ok","timestamp":1764588940732,"user_tz":-540,"elapsed":36,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["all_label_strs = ['time_critical', 'support_and_relief', 'non_informative']\n","label2id = {label: i for i, label in enumerate(all_label_strs)}\n","id2label = {i: label for label, i in label2id.items()}"]},{"cell_type":"code","execution_count":6,"id":"f83365a1-379c-4bc6-bbcc-eb8ca273209f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f83365a1-379c-4bc6-bbcc-eb8ca273209f","executionInfo":{"status":"ok","timestamp":1764588952962,"user_tz":-540,"elapsed":3074,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"3baad986-8664-470b-8413-199c5d947d49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading: /content/drive/MyDrive/dl-twitter-crisis/data/crisisbench/preprocessed_data_train.csv\n","Loading: /content/drive/MyDrive/dl-twitter-crisis/data/crisisbench/preprocessed_data_dev.csv\n","Loading: /content/drive/MyDrive/dl-twitter-crisis/data/crisisbench/preprocessed_data_test.csv\n"]}],"source":["def load_data():\n","    df = {}\n","    for d in ['train', 'dev', 'test']:\n","        output_path = GOOGLE_DRIVE_PATH + f\"/data/crisisbench/preprocessed_data_{d}.csv\"\n","        df[d] = pd.read_csv(output_path).loc[:, ['text_raw', 'text', 'class_label_group', 'class_label_group_num']]\n","        print(\"Loading:\", output_path)\n","    return df\n","\n","df = load_data()"]},{"cell_type":"code","execution_count":null,"id":"43775508","metadata":{"id":"43775508","outputId":"6157b9bd-97f0-4907-8d62-694cfa7614b2","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1764342203885,"user_tz":-540,"elapsed":42,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["df_train: N=61089\n"]},{"output_type":"execute_result","data":{"text/plain":["                                            text_raw  \\\n","0  Approximately 100km long firebreaks have been ...   \n","1           God bless you... https://t.co/AnEy1ydkkz   \n","2  RT @perreaux: Cracked wine casks, damaged hist...   \n","3  I'm really just excited for new undies and pin...   \n","4  Rescue effort expands in India, Pakistan as fl...   \n","\n","                                                text class_label_group  \\\n","0  approximately km long firebreaks have been con...     time_critical   \n","1                                      god bless you   non_informative   \n","2  cracked wine casks damaged historical building...     time_critical   \n","3  i m really just excited for new undies and pin...   non_informative   \n","4  rescue effort e ands in india pakistan as floo...     time_critical   \n","\n","   class_label_group_num  \n","0                      0  \n","1                      2  \n","2                      0  \n","3                      2  \n","4                      0  "],"text/html":["\n","  <div id=\"df-3c3b81db-1c74-4718-8bbb-bbd0b2381571\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_raw</th>\n","      <th>text</th>\n","      <th>class_label_group</th>\n","      <th>class_label_group_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Approximately 100km long firebreaks have been ...</td>\n","      <td>approximately km long firebreaks have been con...</td>\n","      <td>time_critical</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>God bless you... https://t.co/AnEy1ydkkz</td>\n","      <td>god bless you</td>\n","      <td>non_informative</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>RT @perreaux: Cracked wine casks, damaged hist...</td>\n","      <td>cracked wine casks damaged historical building...</td>\n","      <td>time_critical</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I'm really just excited for new undies and pin...</td>\n","      <td>i m really just excited for new undies and pin...</td>\n","      <td>non_informative</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Rescue effort expands in India, Pakistan as fl...</td>\n","      <td>rescue effort e ands in india pakistan as floo...</td>\n","      <td>time_critical</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c3b81db-1c74-4718-8bbb-bbd0b2381571')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3c3b81db-1c74-4718-8bbb-bbd0b2381571 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3c3b81db-1c74-4718-8bbb-bbd0b2381571');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-14f1fd23-f9b0-4b72-a09d-650ed883316f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14f1fd23-f9b0-4b72-a09d-650ed883316f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-14f1fd23-f9b0-4b72-a09d-650ed883316f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df['train']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text_raw\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"God bless you... https://t.co/AnEy1ydkkz\",\n          \"Rescue effort expands in India, Pakistan as flood death toll tops 350 http://t.co/SlbqlhIHmi http://t.co/8F2zjKZ95f #india #asia\",\n          \"RT @perreaux: Cracked wine casks, damaged historical  buildings and coffee shops. This Napa earthquake is the biggest first world disaster \\u00e2\\u20ac\\u00a6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"god bless you\",\n          \"rescue effort e ands in india pakistan as flood death toll tops\",\n          \"cracked wine casks damaged historical buildings and coffee shops this napa earthquake is the biggest first world disaster\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_label_group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"non_informative\",\n          \"time_critical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_label_group_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":111}],"source":["print(f\"df_train: N={len(df['train'])}\")\n","df['train'].head()"]},{"cell_type":"code","execution_count":null,"id":"12ce818d","metadata":{"id":"12ce818d","outputId":"58796462-e4f4-4e26-8c59-d2d0b781b367"},"outputs":[{"name":"stdout","output_type":"stream","text":["df_dev: N=8921\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>class_label_group</th>\n","      <th>class_label_group_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>congrats to all my liverpool supporting fans f...</td>\n","      <td>non_informative</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>collapsed buildings in mexico city earthquake ...</td>\n","      <td>time_critical</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>here s your flower</td>\n","      <td>non_informative</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ready for a relaxing weekend but have too much...</td>\n","      <td>non_informative</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>public private information portal developed to...</td>\n","      <td>support_and_relief</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text   class_label_group  \\\n","0  congrats to all my liverpool supporting fans f...     non_informative   \n","1  collapsed buildings in mexico city earthquake ...       time_critical   \n","2                                 here s your flower     non_informative   \n","3  ready for a relaxing weekend but have too much...     non_informative   \n","4  public private information portal developed to...  support_and_relief   \n","\n","   class_label_group_num  \n","0                      2  \n","1                      0  \n","2                      2  \n","3                      2  \n","4                      1  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["print(f\"df_dev: N={len(df['dev'])}\")\n","df['dev'].head()"]},{"cell_type":"code","execution_count":null,"id":"0d208947","metadata":{"id":"0d208947","outputId":"6044879d-7474-4920-c787-991ccee3a28a"},"outputs":[{"name":"stdout","output_type":"stream","text":["df_test: N=17335\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>class_label_group</th>\n","      <th>class_label_group_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>staff at our feeding centre say chronic malnou...</td>\n","      <td>support_and_relief</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>you comin down for the summer semesters right</td>\n","      <td>non_informative</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yea it s upstate i m like a few hours away</td>\n","      <td>non_informative</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>teach every pakistani that it is not enough to...</td>\n","      <td>non_informative</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>stay with for live cvg as typhoon hagupit slam...</td>\n","      <td>time_critical</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text   class_label_group  \\\n","0  staff at our feeding centre say chronic malnou...  support_and_relief   \n","1      you comin down for the summer semesters right     non_informative   \n","2         yea it s upstate i m like a few hours away     non_informative   \n","3  teach every pakistani that it is not enough to...     non_informative   \n","4  stay with for live cvg as typhoon hagupit slam...       time_critical   \n","\n","   class_label_group_num  \n","0                      1  \n","1                      2  \n","2                      2  \n","3                      2  \n","4                      0  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["print(f\"df_test: N={len(df['test'])}\")\n","df['test'].head()"]},{"cell_type":"markdown","id":"736d27fb","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"736d27fb"},"source":["## CNN"]},{"cell_type":"markdown","id":"52640cad","metadata":{"id":"52640cad"},"source":["### CNN Paper Setup\n","We train the CNN models using the Adam optimizer (Kingma and Ba 2014). The batch size is 128 and maximum number of epochs is set to 1000. We use a filter size of 300 with both window size and pooling length of 2, 3, and 4, and a dropout rate 0.02. We set early stopping\n","criterion based on the accuracy of the development set with a patience of 200."]},{"cell_type":"markdown","id":"ec9ea0a0","metadata":{"id":"ec9ea0a0"},"source":["### Import Libraries"]},{"cell_type":"code","execution_count":7,"id":"f4a00974","metadata":{"id":"f4a00974","executionInfo":{"status":"ok","timestamp":1764588953088,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["\n","import math\n","from collections import Counter\n","from typing import List, Tuple, Dict\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n"]},{"cell_type":"markdown","id":"f8566f4e","metadata":{"id":"f8566f4e"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":8,"id":"defa4f5c","metadata":{"id":"defa4f5c","executionInfo":{"status":"ok","timestamp":1764588953951,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["MAX_VOCAB_SIZE = 5000\n","MAX_SEQ_LEN = 64 # depends on tweet length\n","EMBED_DIM = 50\n","FILTER_SIZES = (3, 4, 5)\n","NUM_FILTERS = 50\n","DROPOUT = 0.5 # tune\n","BATCH_SIZE = 64 # tune\n","LR = 1e-3\n","NUM_EPOCHS = 5\n","PAD_TOKEN = \"<pad>\"\n","UNK_TOKEN = \"<unk>\"\n","GLOVE_PATH = GOOGLE_DRIVE_PATH + \"/data/crisisbench/glove_word_embeddings.txt\""]},{"cell_type":"markdown","id":"c8fb1266","metadata":{"id":"c8fb1266"},"source":["### Tokenizer and Vocab"]},{"cell_type":"code","execution_count":9,"id":"ecf53496","metadata":{"id":"ecf53496","executionInfo":{"status":"ok","timestamp":1764588955124,"user_tz":-540,"elapsed":26,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["def simple_tokenize(text: str) -> List[str]:\n","    \"\"\"\n","    Splits on whitespace\n","    \"\"\"\n","    return text.strip().split()\n","\n","def build_vocab(\n","    texts: List[str],\n","    max_size: int,\n","    min_freq: int = 1\n",") -> Dict[str, int]:\n","    \"\"\"\n","    Build a word -> index vocab from training texts.\n","    Reserves index 0 for PAD and 1 for UNK.\n","    \"\"\"\n","    counter = Counter()\n","    for text in texts:\n","        tokens = simple_tokenize(text)\n","        counter.update(tokens)\n","\n","    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n","    for word, freq in counter.most_common():\n","        if freq < min_freq:\n","            continue\n","        if len(vocab) >= max_size:\n","            break\n","        vocab[word] = len(vocab)\n","\n","    return vocab\n","\n","\n","def encode_text(\n","    text: str,\n","    vocab: Dict[str, int],\n","    max_len: int\n",") -> List[int]:\n","    tokens = simple_tokenize(text)\n","    ids = [vocab.get(tok, vocab[UNK_TOKEN]) for tok in tokens][:max_len]\n","    if len(ids) < max_len:\n","        ids += [vocab[PAD_TOKEN]] * (max_len - len(ids))\n","    return ids\n"]},{"cell_type":"markdown","id":"fa81ae81","metadata":{"id":"fa81ae81"},"source":["### Dataset & DataLoader"]},{"cell_type":"code","execution_count":10,"id":"c95f7d93","metadata":{"id":"c95f7d93","executionInfo":{"status":"ok","timestamp":1764588956693,"user_tz":-540,"elapsed":10,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(\n","        self,\n","        texts: List[str],\n","        labels: List[int],\n","        vocab: Dict[str, int],\n","        max_len: int,\n","    ):\n","        assert len(texts) == len(labels)\n","        self.texts = texts\n","        self.labels = labels\n","        self.vocab = vocab\n","        self.max_len = max_len\n","\n","    def __len__(self) -> int:\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","        input_ids = encode_text(text, self.vocab, self.max_len)\n","        return torch.tensor(input_ids, dtype=torch.long), label\n","\n","\n","def create_dataloaders(\n","    train_texts: List[str],\n","    train_labels: List[int],\n","    val_texts: List[str],\n","    val_labels: List[int],\n","    max_vocab_size: int,\n","    max_seq_len: int,\n","    batch_size: int,\n",") -> Tuple[DataLoader, DataLoader, Dict[str, int], int]:\n","    vocab = build_vocab(train_texts, max_vocab_size)\n","    num_classes = len(set(train_labels))\n","\n","    train_dataset = TextDataset(train_texts, train_labels, vocab, max_seq_len)\n","    val_dataset = TextDataset(val_texts, val_labels, vocab, max_seq_len)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, val_loader, vocab, num_classes\n"]},{"cell_type":"markdown","id":"54d02775","metadata":{"id":"54d02775"},"source":["### Load GloVe & build embedding matrix"]},{"cell_type":"code","execution_count":11,"id":"1645084f","metadata":{"id":"1645084f","executionInfo":{"status":"ok","timestamp":1764588958339,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["def load_glove_embeddings(\n","    glove_path: str,\n","    embed_dim: int,\n",") -> Dict[str, torch.Tensor]:\n","    \"\"\"\n","    Load GloVe file into a dict: word -> vector (torch.Tensor).\n","    Expects each line: word val1 val2 ... valD\n","    \"\"\"\n","    embeddings = {}\n","    with open(glove_path, \"r\", encoding=\"utf8\") as f:\n","        for line in f:\n","            parts = line.strip().split()\n","            if len(parts) != embed_dim + 1:\n","                # ignore malformed lines\n","                continue\n","            word = parts[0]\n","            vec = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float32)\n","            embeddings[word] = vec\n","    return embeddings\n","\n","\n","def build_embedding_matrix(\n","    vocab: Dict[str, int],\n","    glove_embeddings: Dict[str, torch.Tensor],\n","    embed_dim: int,\n",") -> torch.Tensor:\n","    \"\"\"\n","    Create an embedding matrix of shape [vocab_size, embed_dim]\n","    where row i is the vector for the word with index i.\n","    Words not found in GloVe are randomly initialized (small normal).\n","    \"\"\"\n","    vocab_size = len(vocab)\n","    embedding_matrix = torch.empty(vocab_size, embed_dim, dtype=torch.float32)\n","\n","    # Initialize OOV embeddings to small random values\n","    torch.nn.init.normal_(embedding_matrix, mean=0.0, std=0.05)\n","\n","    # Set PAD embedding to zeros\n","    pad_idx = vocab[PAD_TOKEN]\n","    embedding_matrix[pad_idx] = torch.zeros(embed_dim, dtype=torch.float32)\n","\n","    oov_count = 0\n","    for word, idx in vocab.items():\n","        if word in (PAD_TOKEN, UNK_TOKEN):\n","            continue\n","        vec = glove_embeddings.get(word)\n","        if vec is not None:\n","            embedding_matrix[idx] = vec\n","        else:\n","            oov_count += 1\n","\n","    print(f\"GloVe OOV words: {oov_count}/{vocab_size}\")\n","    return embedding_matrix"]},{"cell_type":"markdown","id":"60863f21","metadata":{"id":"60863f21"},"source":["### Text CNN model (with optional pretrained embeddings)"]},{"cell_type":"code","execution_count":12,"id":"c0f94c80","metadata":{"id":"c0f94c80","executionInfo":{"status":"ok","timestamp":1764588961064,"user_tz":-540,"elapsed":22,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["class TextCNN(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size: int,\n","        embed_dim: int,\n","        num_classes: int,\n","        pad_idx: int = 0,\n","        num_filters: int = 100,\n","        filter_sizes: Tuple[int, ...] = (3, 4, 5),\n","        dropout: float = 0.5,\n","        pretrained_embeddings: torch.Tensor | None = None,\n","        freeze_embeddings: bool = False,\n","    ):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=embed_dim,\n","            padding_idx=pad_idx,\n","        )\n","\n","        if pretrained_embeddings is not None:\n","            if pretrained_embeddings.shape != (vocab_size, embed_dim):\n","                raise ValueError(\n","                    f\"Pretrained embeddings shape {pretrained_embeddings.shape} \"\n","                    f\"does not match (vocab_size, embed_dim)=({vocab_size}, {embed_dim})\"\n","                )\n","            self.embedding.weight.data.copy_(pretrained_embeddings)\n","            if freeze_embeddings:\n","                self.embedding.weight.requires_grad = False\n","\n","        self.convs = nn.ModuleList([\n","            nn.Conv1d(\n","                in_channels=embed_dim,\n","                out_channels=num_filters,\n","                kernel_size=fs,\n","            )\n","            for fs in filter_sizes\n","        ])\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n","\n","    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n","        embedded = self.embedding(input_ids)          # [B, L, D]\n","        embedded = embedded.transpose(1, 2)           # [B, D, L]\n","\n","        conv_outputs = []\n","        for conv in self.convs:\n","            x = conv(embedded)                        # [B, F, L']\n","            x = F.relu(x)\n","            x = F.max_pool1d(x, x.size(2)).squeeze(2) # [B, F]\n","            conv_outputs.append(x)\n","\n","        cat = torch.cat(conv_outputs, dim=1)          # [B, F * len(filter_sizes)]\n","        cat = self.dropout(cat)\n","        logits = self.fc(cat)                         # [B, num_classes]\n","        return logits"]},{"cell_type":"markdown","id":"93543e0d","metadata":{"id":"93543e0d"},"source":["### Training & Evaluation"]},{"cell_type":"code","execution_count":13,"id":"d1baee17","metadata":{"id":"d1baee17","executionInfo":{"status":"ok","timestamp":1764588963885,"user_tz":-540,"elapsed":33,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["def train_one_epoch(\n","    model: nn.Module,\n","    dataloader: DataLoader,\n","    optimizer: torch.optim.Optimizer,\n","    criterion: nn.Module,\n","    device: torch.device,\n","):\n","    model.train()\n","    total_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    all_preds = []\n","    all_targets = []\n","\n","    for input_ids, labels in dataloader:\n","        input_ids = input_ids.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        logits = model(input_ids)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * input_ids.size(0)\n","\n","        preds = logits.argmax(dim=1)\n","\n","        # accumulate predictions & ground truth\n","        all_preds.extend(preds.cpu().tolist())\n","        all_targets.extend(labels.cpu().tolist())\n","\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","\n","    avg_loss = total_loss / total\n","    accuracy = correct / total if total > 0 else 0.0\n","\n","    return avg_loss, accuracy, all_preds, all_targets\n","\n","\n","def evaluate(model, data_loader, criterion, device):\n","    model.eval()\n","    total_loss = 0.0\n","    total_correct = 0\n","    total_examples = 0\n","\n","    all_preds = []\n","    all_targets = []\n","\n","    with torch.no_grad():\n","        for x, y in data_loader:\n","            x, y = x.to(device), y.to(device)\n","\n","            logits = model(x)\n","            loss = criterion(logits, y)\n","\n","            preds = logits.argmax(dim=1)\n","\n","            total_loss += loss.item() * x.size(0)\n","            total_correct += (preds == y).sum().item()\n","            total_examples += x.size(0)\n","\n","            all_preds.extend(preds.cpu().tolist())\n","            all_targets.extend(y.cpu().tolist())\n","\n","    avg_loss = total_loss / total_examples\n","    avg_acc = total_correct / total_examples\n","\n","    # ---- Precision / Recall / F1 (macro) ----\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        all_targets,\n","        all_preds,\n","        average=\"macro\",\n","        zero_division=0\n","    )\n","\n","    return avg_loss, avg_acc, precision, recall, f1, all_preds, all_targets\n","\n"]},{"cell_type":"markdown","id":"67776a78","metadata":{"id":"67776a78"},"source":["### Main CNN Train Script"]},{"cell_type":"code","execution_count":null,"id":"99044bdc","metadata":{"id":"99044bdc","outputId":"ef9f9d31-d892-4266-e276-62cb84c60b8a","colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"status":"error","timestamp":1764372483093,"user_tz":-540,"elapsed":4232,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading GloVe embeddings...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-389282804.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# # Load GloVe embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading GloVe embeddings...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mglove_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_glove_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGLOVE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBED_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_embedding_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBED_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-4006749321.py\u001b[0m in \u001b[0;36mload_glove_embeddings\u001b[0;34m(glove_path, embed_dim)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# Create loaders and vocab\n","# train_loader, val_loader, vocab, num_classes = create_dataloaders(\n","#     train_texts=df['train']['text'].to_list(),\n","#     train_labels=df['train']['class_label_group_num'],\n","#     val_texts=df['dev']['text'].to_list(),\n","#     val_labels=df['dev']['class_label_group_num'],\n","#     max_vocab_size=MAX_VOCAB_SIZE,\n","#     max_seq_len=MAX_SEQ_LEN,\n","#     batch_size=BATCH_SIZE,\n","# )\n","\n","# # print(f\"Vocab size: {len(vocab)}, Num classes: {num_classes}\")\n","\n","# # # Load GloVe embeddings\n","# print(\"Loading GloVe embeddings...\")\n","# glove_embeds = load_glove_embeddings(GLOVE_PATH, EMBED_DIM)\n","# embedding_matrix = build_embedding_matrix(vocab, glove_embeds, EMBED_DIM)\n","\n","# # Initialize model with pretrained embeddings\n","# print(\"Model Initialization...\")\n","# model = TextCNN(\n","#     vocab_size=len(vocab),\n","#     embed_dim=EMBED_DIM,\n","#     num_classes=num_classes,\n","#     pad_idx=vocab[PAD_TOKEN],\n","#     num_filters=NUM_FILTERS,\n","#     filter_sizes=FILTER_SIZES,\n","#     dropout=DROPOUT,\n","#     pretrained_embeddings=embedding_matrix,\n","#     freeze_embeddings=False,   # set True if you want to freeze GloVe\n","# ).to(device)\n","\n","# optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","# criterion = nn.CrossEntropyLoss()\n","\n","# best_val_f1 = 0.0\n","\n","# train_losses = []\n","# train_accs = []\n","# train_f1s = []\n","# val_losses = []\n","# val_accs = []\n","# val_f1s = []\n","\n","# print(\"Training...\")\n","# for epoch in range(1, NUM_EPOCHS + 1):\n","#     train_loss, train_acc, train_preds, train_targets = train_one_epoch(\n","#         model, train_loader, optimizer, criterion, device\n","#     )\n","#     train_f1 = f1_score(train_targets, train_preds, average=\"macro\")\n","#     train_f1s.append(train_f1)\n","#     val_loss, val_acc, val_preds, val_targets = evaluate(\n","#         model, val_loader, criterion, device\n","#     )\n","#     val_f1 = f1_score(val_targets, val_preds, average=\"macro\")\n","#     val_f1s.append(val_f1)\n","\n","#     train_losses.append(train_loss)\n","#     train_accs.append(train_acc)\n","#     val_losses.append(val_loss)\n","#     val_accs.append(val_acc)\n","\n","#     if val_f1 > best_val_f1:\n","#         best_val_f1 = val_f1\n","#         torch.save(model.state_dict(), \"cnn/best_textcnn_glove.pt\")\n","\n","#     print(\n","#         f\"Epoch {epoch:02d} | \"\n","#         f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f} | \"\n","#         f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\"\n","#     )\n","\n","# print(f\"Best validation f1: {best_val_f1:.4f}\")"]},{"cell_type":"markdown","id":"774b973a","metadata":{"id":"774b973a"},"source":["### Calculate Test Metrics"]},{"cell_type":"code","execution_count":null,"id":"f1fdb0a8","metadata":{"id":"f1fdb0a8","outputId":"f1df6b82-ce7a-4787-ff19-d11ba4d33283","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764426068230,"user_tz":-540,"elapsed":23682,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading GloVe embeddings...\n","GloVe OOV words: 58/5000\n","Test F1 (macro): 0.8255\n","Test Precision (macro): 0.8276\n","Test Recall (macro): 0.8237\n","Test Loss: 0.3681, Test Acc: 0.8694\n","Test F1 (macro): 0.8255\n"]}],"source":["from sklearn.metrics import f1_score\n","\n","# --------- load best model ---------\n","best_ckpt_path = b=GOOGLE_DRIVE_PATH + f\"/best_textcnn_glove_numfilters_50.pt\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# Create loaders and vocab\n","train_loader, val_loader, vocab, num_classes = create_dataloaders(\n","    train_texts=df['train']['text'].to_list(),\n","    train_labels=df['train']['class_label_group_num'],\n","    val_texts=df['dev']['text'].to_list(),\n","    val_labels=df['dev']['class_label_group_num'],\n","    max_vocab_size=MAX_VOCAB_SIZE,\n","    max_seq_len=MAX_SEQ_LEN,\n","    batch_size=BATCH_SIZE,\n",")\n","\n","print(\"Loading GloVe embeddings...\")\n","glove_embeds = load_glove_embeddings(GLOVE_PATH, EMBED_DIM)\n","embedding_matrix = build_embedding_matrix(vocab, glove_embeds, EMBED_DIM)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","\n","# Rebuild model with best num_filters\n","model = TextCNN(\n","    vocab_size=5000,\n","    embed_dim=EMBED_DIM,\n","    num_classes=3,\n","    pad_idx=vocab[PAD_TOKEN],\n","    num_filters=50,\n","    filter_sizes=FILTER_SIZES,\n","    dropout=DROPOUT,\n","    pretrained_embeddings=embedding_matrix,\n","    freeze_embeddings=False,\n",").to(device)\n","model.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n","\n","best_optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","# model.load_state_dict(torch.load(\"cnn/best_textcnn_glove.pt\", map_location=device))\n","# model.to(device)\n","\n","# --------- build test loader ---------\n","test_dataset = TextDataset(\n","    texts=df['test']['text'].to_list(),\n","    labels=df['test']['class_label_group_num'],\n","    vocab=vocab,\n","    max_len=MAX_SEQ_LEN,\n",")\n","\n","cnn_test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n",")\n","\n","# --------- test loss + accuracy + preds ---------\n","test_loss, test_acc, test_prec, test_rec, test_f1, test_preds, test_targets = evaluate(\n","    model, cnn_test_loader, criterion, device\n",")\n","print(f\"Test F1 (macro): {test_f1:.4f}\")\n","print(f\"Test Precision (macro): {test_prec:.4f}\")\n","print(f\"Test Recall (macro): {test_rec:.4f}\")\n","print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n","\n","# --------- compute ONLY F1 (macro) ---------\n","test_f1 = f1_score(test_targets, test_preds, average=\"macro\")\n","\n","print(f\"Test F1 (macro): {test_f1:.4f}\")\n"]},{"cell_type":"code","source":["import os\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import f1_score\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# ------------------------------------------------\n","# 0. Data loaders + GloVe + loss\n","# ------------------------------------------------\n","train_loader, val_loader, vocab, num_classes = create_dataloaders(\n","    train_texts=df['train']['text'].to_list(),\n","    train_labels=df['train']['class_label_group_num'],\n","    val_texts=df['dev']['text'].to_list(),\n","    val_labels=df['dev']['class_label_group_num'],\n","    max_vocab_size=MAX_VOCAB_SIZE,\n","    max_seq_len=MAX_SEQ_LEN,\n","    batch_size=BATCH_SIZE,\n",")\n","\n","print(f\"Vocab size: {len(vocab)}, Num classes: {num_classes}\")\n","\n","# print(\"Loading GloVe embeddings...\")\n","# glove_embeds = load_glove_embeddings(GLOVE_PATH, EMBED_DIM)\n","# embedding_matrix = build_embedding_matrix(vocab, glove_embeds, EMBED_DIM)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# ------------------------------------------------\n","# 1. Hyperparameter sweep over num_filters\n","# ------------------------------------------------\n","num_filters_list = [25, 50, 75, 100]\n","max_epochs_cap = 10\n","\n","results = {}  # num_filters -> dict\n","\n","best_overall_f1 = -1.0\n","best_overall_cfg = None\n","\n","# for num_filters in num_filters_list:\n","#     print(\"\\n\" + \"=\" * 60)\n","#     print(f\"Training TextCNN with num_filters={num_filters}\")\n","#     print(\"=\" * 60)\n","\n","#     model = TextCNN(\n","#         vocab_size=len(vocab),\n","#         embed_dim=EMBED_DIM,\n","#         num_classes=num_classes,\n","#         pad_idx=vocab[PAD_TOKEN],\n","#         num_filters=num_filters,\n","#         filter_sizes=FILTER_SIZES,\n","#         dropout=DROPOUT,\n","#         pretrained_embeddings=embedding_matrix,\n","#         freeze_embeddings=False,\n","#     ).to(device)\n","\n","#     optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","\n","#     train_f1s = []\n","#     val_f1s = []\n","#     best_val_f1 = -1.0\n","#     best_epoch = 0\n","\n","#     ckpt_path = GOOGLE_DRIVE_PATH + f\"/best_textcnn_glove_numfilters_{num_filters}.pt\"\n","\n","#     for epoch in range(1, max_epochs_cap + 1):\n","#         # ---- Train one epoch ----\n","#         train_loss, train_acc, train_preds, train_targets = train_one_epoch(\n","#             model, train_loader, optimizer, criterion, device\n","#         )\n","#         train_f1 = f1_score(train_targets, train_preds, average=\"macro\")\n","\n","#         # ---- Validation ----\n","#         val_loss, val_acc, val_prec, val_rec, val_f1, val_preds, val_targets = evaluate(\n","#             model, val_loader, criterion, device\n","#         )\n","#         val_f1 = f1_score(val_targets, val_preds, average=\"macro\")\n","\n","#         train_f1s.append(train_f1)\n","#         val_f1s.append(val_f1)\n","\n","#         print(\n","#             f\"[num_filters={num_filters}] \"\n","#             f\"Epoch {epoch:02d} | \"\n","#             f\"Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f} | \"\n","#             f\"Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\"\n","#         )\n","\n","#         # update best for this num_filters\n","#         if val_f1 > best_val_f1:\n","#             best_val_f1 = val_f1\n","#             best_epoch = epoch\n","#             torch.save(model.state_dict(), ckpt_path)\n","#         # simple overfitting signal: first time val_f1 drops below best\n","#         elif val_f1 < best_val_f1:\n","#             print(\n","#                 f\"Overfitting signal detected at epoch {epoch} \"\n","#                 f\"(prev best val F1={best_val_f1:.4f} at epoch {best_epoch})\"\n","#             )\n","#             break\n","\n","#     results[num_filters] = {\n","#         \"train_f1s\": train_f1s,\n","#         \"val_f1s\": val_f1s,\n","#         \"best_val_f1\": best_val_f1,\n","#         \"best_epoch\": best_epoch,\n","#         \"ckpt_path\": ckpt_path,\n","#     }\n","\n","#     # track global best across all num_filters\n","#     if best_val_f1 > best_overall_f1:\n","#         best_overall_f1 = best_val_f1\n","#         best_overall_cfg = {\n","#             \"num_filters\": num_filters,\n","#             \"ckpt_path\": ckpt_path,\n","#             \"best_epoch\": best_epoch,\n","#         }\n","\n","# print(\"\\n=== Sweep complete ===\")\n","# print(f\"Best overall num_filters: {best_overall_cfg['num_filters']} \"\n","#       f\"(val F1={best_overall_f1:.4f} at epoch={best_overall_cfg['best_epoch']})\")\n","\n","\n","# ------------------------------------------------\n","# 2. Validation curve: num_filters vs best validation F1\n","#    + hard-coded list of best F1s\n","# ------------------------------------------------\n","# best_f1s = [results[nf][\"best_val_f1\"] for nf in num_filters_list]\n","best_f1s = [0.82, 0.8266, 0.8235, 0.8144]\n","\n","# # After you run once and see the values, you can hard-code them, e.g.:\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot([25,50,75,100], best_f1s, marker=\"o\")\n","plt.xlabel(\"Number of Filters\", fontsize=16)\n","plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n","plt.xticks([25,50,75,100], fontsize=14)\n","plt.yticks(fontsize=14)\n","plt.title(\"TextCNN Validation Curve\", fontsize=18)\n","plt.tight_layout()\n","plt.savefig(GOOGLE_DRIVE_PATH + \"/textcnn_validation_curve_num_filters.png\")\n","plt.show()\n","\n","# ------------------------------------------------\n","# 3. Using the best model config, load checkpoint and\n","#    plot learning curve for 10 epochs (Train + Val F1)\n","# ------------------------------------------------\n","best_num_filters = 50\n","best_ckpt_path = b=GOOGLE_DRIVE_PATH + f\"/best_textcnn_glove_numfilters_{best_num_filters}.pt\"\n","\n","print(f\"\\nReloading best model: num_filters={best_num_filters}, ckpt={best_ckpt_path}\")\n","\n","# Rebuild model with best num_filters\n","# best_model = TextCNN(\n","#     vocab_size=len(vocab),\n","#     embed_dim=EMBED_DIM,\n","#     num_classes=num_classes,\n","#     pad_idx=vocab[PAD_TOKEN],\n","#     num_filters=best_num_filters,\n","#     filter_sizes=FILTER_SIZES,\n","#     dropout=DROPOUT,\n","#     pretrained_embeddings=embedding_matrix,\n","#     freeze_embeddings=False,\n","# ).to(device)\n","\n","# best_model.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n","\n","# best_optimizer = torch.optim.Adam(best_model.parameters(), lr=LR)\n","\n","final_train_f1s = []\n","final_val_f1s = []\n","EPOCHS_FOR_CURVE = 10\n","epochs = [1,2,3,4,5,6,7,8,9,10]\n","\n","# print(\"\\nTraining best configuration for 10 epochs to plot learning curve...\")\n","# for epoch in range(1, EPOCHS_FOR_CURVE + 1):\n","#     best_model.train()\n","#     train_loss, train_acc, train_preds, train_targets = train_one_epoch(\n","#         best_model, train_loader, best_optimizer, criterion, device\n","#     )\n","#     train_f1 = f1_score(train_targets, train_preds, average=\"macro\")\n","\n","#     val_loss, val_acc, val_preds, val_targets = evaluate(\n","#         best_model, val_loader, criterion, device\n","#     )\n","#     val_f1 = f1_score(val_targets, val_preds, average=\"macro\")\n","\n","#     final_train_f1s.append(train_f1)\n","#     final_val_f1s.append(val_f1)\n","\n","#     print(\n","#         f\"[BEST num_filters={best_num_filters}] \"\n","#         f\"Epoch {epoch:02d} | \"\n","#         f\"Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f} | \"\n","#         f\"Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\"\n","#     )\n","\n","final_val_f1s = [0.8192, 0.8176, 0.8216, 0.8203, 0.8180, 0.8165, 0.8161, 0.8118, 0.8097, 0.8093]\n","final_train_f1s = [0.8602, 0.8675, 0.8752, 0.8819, 0.8888, 0.8952, 0.9010, 0.9063, 0.9115, 0.9171]\n","# Plot learning curve (train + val F1) for best configuration\n","plt.figure(figsize=(10, 5))\n","plt.plot(range(1, len(final_val_f1s)+1), final_train_f1s, label=\"Train\")\n","plt.plot(range(1, len(final_val_f1s)+1), final_val_f1s, label=\"Validation\")\n","plt.xticks([i for i in range(1, len(final_val_f1s)+1)], fontsize=14)\n","plt.axvline(x=5, color='red', linestyle='--', linewidth=1.5)\n","plt.yticks(fontsize=14)\n","plt.xlabel(\"Epoch\", fontsize=16)\n","plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n","plt.title(f\"TextCNN Learning Curve\", fontsize=18)\n","plt.legend(fontsize=14)\n","plt.tight_layout()\n","plt.savefig(GOOGLE_DRIVE_PATH + f\"/textcnn_learning_curve_best_{best_num_filters}.png\")\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"30EfVbF4EqCk","executionInfo":{"status":"ok","timestamp":1764590224192,"user_tz":-540,"elapsed":139,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"3576be23-8ff1-4caf-9370-a4c1e52d7d2d"},"id":"30EfVbF4EqCk","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab size: 5000, Num classes: 3\n","\n","============================================================\n","Training TextCNN with num_filters=25\n","============================================================\n","[num_filters=25] Epoch 01 | Train Loss: 0.5060, Train F1: 0.7331 | Val Loss: 0.3945, Val F1: 0.7966\n","[num_filters=25] Epoch 02 | Train Loss: 0.4082, Train F1: 0.7988 | Val Loss: 0.3786, Val F1: 0.8020\n","[num_filters=25] Epoch 03 | Train Loss: 0.3710, Train F1: 0.8164 | Val Loss: 0.3638, Val F1: 0.8170\n","[num_filters=25] Epoch 04 | Train Loss: 0.3468, Train F1: 0.8309 | Val Loss: 0.3628, Val F1: 0.8226\n","[num_filters=25] Epoch 05 | Train Loss: 0.3275, Train F1: 0.8408 | Val Loss: 0.3589, Val F1: 0.8258\n","[num_filters=25] Epoch 06 | Train Loss: 0.3110, Train F1: 0.8490 | Val Loss: 0.3672, Val F1: 0.8183\n","Overfitting signal detected at epoch 6 (prev best val F1=0.8258 at epoch 5)\n","\n","============================================================\n","Training TextCNN with num_filters=50\n","============================================================\n","[num_filters=50] Epoch 01 | Train Loss: 0.4832, Train F1: 0.7485 | Val Loss: 0.3843, Val F1: 0.8018\n","[num_filters=50] Epoch 02 | Train Loss: 0.3830, Train F1: 0.8075 | Val Loss: 0.3626, Val F1: 0.8125\n","[num_filters=50] Epoch 03 | Train Loss: 0.3490, Train F1: 0.8273 | Val Loss: 0.3511, Val F1: 0.8259\n","[num_filters=50] Epoch 04 | Train Loss: 0.3248, Train F1: 0.8403 | Val Loss: 0.3542, Val F1: 0.8202\n","Overfitting signal detected at epoch 4 (prev best val F1=0.8259 at epoch 3)\n","\n","============================================================\n","Training TextCNN with num_filters=75\n","============================================================\n","[num_filters=75] Epoch 01 | Train Loss: 0.4671, Train F1: 0.7567 | Val Loss: 0.3745, Val F1: 0.8100\n","[num_filters=75] Epoch 02 | Train Loss: 0.3746, Train F1: 0.8107 | Val Loss: 0.3623, Val F1: 0.8215\n","[num_filters=75] Epoch 03 | Train Loss: 0.3379, Train F1: 0.8316 | Val Loss: 0.3525, Val F1: 0.8217\n","[num_filters=75] Epoch 04 | Train Loss: 0.3101, Train F1: 0.8476 | Val Loss: 0.3532, Val F1: 0.8253\n","[num_filters=75] Epoch 05 | Train Loss: 0.2890, Train F1: 0.8593 | Val Loss: 0.3633, Val F1: 0.8146\n","Overfitting signal detected at epoch 5 (prev best val F1=0.8253 at epoch 4)\n","\n","============================================================\n","Training TextCNN with num_filters=100\n","============================================================\n","[num_filters=100] Epoch 01 | Train Loss: 0.4615, Train F1: 0.7602 | Val Loss: 0.3743, Val F1: 0.8081\n","[num_filters=100] Epoch 02 | Train Loss: 0.3693, Train F1: 0.8149 | Val Loss: 0.3555, Val F1: 0.8222\n","[num_filters=100] Epoch 03 | Train Loss: 0.3332, Train F1: 0.8328 | Val Loss: 0.3476, Val F1: 0.8242\n","[num_filters=100] Epoch 04 | Train Loss: 0.3070, Train F1: 0.8498 | Val Loss: 0.3501, Val F1: 0.8247\n","[num_filters=100] Epoch 05 | Train Loss: 0.2849, Train F1: 0.8593 | Val Loss: 0.3553, Val F1: 0.8191\n","Overfitting signal detected at epoch 5 (prev best val F1=0.8247 at epoch 4)\n","=== Sweep complete ===\n","Best overall num_filters: 50 (val F1=0.8259 at epoch=3)\n"]}]},{"cell_type":"markdown","id":"404be072","metadata":{"id":"404be072"},"source":["## Transformer"]},{"cell_type":"markdown","id":"91769e83","metadata":{"id":"91769e83"},"source":["### Model"]},{"cell_type":"code","execution_count":20,"id":"02235411","metadata":{"id":"02235411","executionInfo":{"status":"ok","timestamp":1764590295966,"user_tz":-540,"elapsed":56,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["import math\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class TransformerClassifier(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size,\n","        num_labels = 3,\n","        max_length = 64,\n","        d_model = 256, # hidden size\n","        nhead = 4, # number of attention heads\n","        num_layers = 2, # number of encoder layers\n","        dim_feedforward = 512,  # FFN inner dim\n","        dropout = 0.3,\n","    ):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.max_length = max_length\n","\n","        self.token_embedding = nn.Embedding(vocab_size, d_model)\n","        self.pos_embedding = nn.Embedding(max_length, d_model)\n","\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=nhead,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout,\n","            batch_first=True, # (batch, seq, dim)\n","        )\n","        self.encoder = nn.TransformerEncoder(\n","            encoder_layer,\n","            num_layers=num_layers,\n","        )\n","        self.layer_norm = nn.LayerNorm(d_model)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(d_model, d_model),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(d_model, num_labels),\n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        batch_size, seq_len = input_ids.size()\n","        if seq_len > self.max_length:\n","            raise ValueError(f\"seq_len {seq_len} > max_length {self.max_length}\")\n","\n","        token_emb = self.token_embedding(input_ids)  # (B, L, D)\n","\n","        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)  # (1, L)\n","        pos_emb = self.pos_embedding(positions)  # (1, L, D)\n","\n","        x = token_emb + pos_emb  # (B, L, D)\n","\n","        src_key_padding_mask = (attention_mask == 0)  # (B, L), bool\n","\n","        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)  # (B, L, D)\n","        x = self.layer_norm(x)\n","\n","        mask = attention_mask.unsqueeze(-1)  # (B, L, 1)\n","        masked_x = x * mask  # (B, L, D)\n","\n","        lengths = mask.sum(dim=1).clamp(min=1)  # (B, 1)\n","        pooled = masked_x.sum(dim=1) / lengths  # (B, D)\n","\n","        logits = self.classifier(pooled)  # (B, num_labels)\n","        return logits"]},{"cell_type":"code","execution_count":21,"id":"ec80daa9","metadata":{"id":"ec80daa9","executionInfo":{"status":"ok","timestamp":1764590299376,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}}},"outputs":[],"source":["def compute_metrics_from_preds(all_logits, all_labels):\n","    logits = np.concatenate(all_logits, axis=0)\n","    labels = np.concatenate(all_labels, axis=0)\n","\n","    preds = np.argmax(logits, axis=-1)\n","\n","    acc = accuracy_score(labels, preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        labels,\n","        preds,\n","        average=\"macro\",\n","        zero_division=0,\n","    )\n","    return {\n","        \"accuracy\": acc,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1\": f1,\n","    }"]},{"cell_type":"markdown","id":"0685e616","metadata":{"id":"0685e616"},"source":["### Tokenizer"]},{"cell_type":"code","execution_count":22,"id":"306f27c2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"306f27c2","executionInfo":{"status":"ok","timestamp":1764590310236,"user_tz":-540,"elapsed":9439,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"6286106a-8aea-4563-b414-b93ef513b735"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n","Collecting dill<0.4.1,>=0.3.0 (from datasets)\n","  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n","Collecting multiprocess<0.70.19 (from datasets)\n","  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n","Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n","Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n","Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n","Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n","Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n","Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n","Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n","Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n","Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, propcache, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 datasets-4.4.1 dill-0.4.0 frozenlist-1.8.0 multiprocess-0.70.18 propcache-0.4.1 xxhash-3.6.0 yarl-1.22.0\n"]}],"source":["!pip install datasets\n","from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n","from datasets import Dataset, DatasetDict\n","\n","train_texts = df[\"train\"][\"text\"].tolist()\n","dev_texts   = df[\"dev\"][\"text\"].tolist()\n","test_texts   = df[\"test\"][\"text\"].tolist()\n","\n","tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n","tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n","\n","special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n","trainer = trainers.BpeTrainer(\n","    vocab_size=30000, # could be adjusted\n","    min_frequency=2,\n","    special_tokens=special_tokens,\n",")\n","\n","tokenizer.train_from_iterator(train_texts, trainer=trainer)\n","\n","max_length = 64\n","pad_id = tokenizer.token_to_id(\"[PAD]\")\n","\n","tokenizer.enable_truncation(max_length=max_length)\n","tokenizer.enable_padding(\n","    length=max_length,\n","    pad_id=pad_id,\n","    pad_token=\"[PAD]\",\n",")\n","\n","def encode_batch(texts):\n","    encodings = tokenizer.encode_batch(texts)\n","    input_ids = [e.ids for e in encodings]\n","    attention_mask = [e.attention_mask for e in encodings]\n","    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n","\n","train_enc = encode_batch(train_texts)\n","dev_enc   = encode_batch(dev_texts)\n","test_enc   = encode_batch(test_texts)\n","\n","train_dataset = Dataset.from_dict({\n","    \"input_ids\":      train_enc[\"input_ids\"],\n","    \"attention_mask\": train_enc[\"attention_mask\"],\n","    \"label\":          df[\"train\"][\"class_label_group_num\"].tolist(),\n","    \"text\":           df[\"train\"][\"text\"].tolist(),\n","    \"text_raw\": df[\"train\"][\"text_raw\"].tolist(),\n","})\n","val_dataset = Dataset.from_dict({\n","    \"input_ids\":      dev_enc[\"input_ids\"],\n","    \"attention_mask\": dev_enc[\"attention_mask\"],\n","    \"label\":          df[\"dev\"][\"class_label_group_num\"].tolist(),\n","    \"text\":           df[\"dev\"][\"text\"].tolist(),\n","    \"text_raw\": df[\"dev\"][\"text_raw\"].tolist(),\n","})\n","test_dataset = Dataset.from_dict({\n","    \"input_ids\":      test_enc[\"input_ids\"],\n","    \"attention_mask\": test_enc[\"attention_mask\"],\n","    \"label\":          df[\"test\"][\"class_label_group_num\"].tolist(),\n","    \"text\":           df[\"test\"][\"text\"].tolist(),\n","    \"text_raw\": df[\"test\"][\"text_raw\"].tolist(),\n","})\n","\n","tokenized_datasets = DatasetDict({\n","    \"train\": train_dataset,\n","    \"validation\": val_dataset,\n","    \"test\": test_dataset,\n","})\n","\n","tokenized_datasets.set_format(\n","    type=\"torch\",\n","    columns=[\"input_ids\", \"attention_mask\", \"label\", \"text\", \"text_raw\"],\n",")"]},{"cell_type":"markdown","id":"d22588d1","metadata":{"id":"d22588d1"},"source":["### Plot Curves Using Best Model"]},{"cell_type":"code","execution_count":28,"id":"346b8289","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"346b8289","executionInfo":{"status":"ok","timestamp":1764595984882,"user_tz":-540,"elapsed":58928,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"49b64343-12af-47fe-c56c-716fcae9dc00"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Validation curve run: lr=0.0001 ===\n","[lr=0.0001] Epoch 1/10 | train_loss=0.5875, train_f1=0.7131, val_loss=0.5317, val_f1=0.7023\n","[lr=0.0001] Epoch 2/10 | train_loss=0.4583, train_f1=0.7988, val_loss=0.4345, val_f1=0.7765\n","[lr=0.0001] Epoch 3/10 | train_loss=0.4071, train_f1=0.7992, val_loss=0.4673, val_f1=0.7676\n","Overfitting signal detected at epoch 3 (prev best val F1=0.7765 at epoch 2)\n","Best val F1 for lr=0.0001: 0.7765\n","\n","=== Validation curve run: lr=0.0003 ===\n","[lr=0.0003] Epoch 1/10 | train_loss=0.5417, train_f1=0.7248, val_loss=0.5475, val_f1=0.7050\n","[lr=0.0003] Epoch 2/10 | train_loss=0.4127, train_f1=0.8363, val_loss=0.3986, val_f1=0.7920\n","[lr=0.0003] Epoch 3/10 | train_loss=0.3513, train_f1=0.8472, val_loss=0.4428, val_f1=0.7865\n","Overfitting signal detected at epoch 3 (prev best val F1=0.7920 at epoch 2)\n","Best val F1 for lr=0.0003: 0.7920\n","\n","=== Validation curve run: lr=0.001 ===\n","[lr=0.001] Epoch 1/10 | train_loss=0.5565, train_f1=0.7621, val_loss=0.5229, val_f1=0.7471\n","[lr=0.001] Epoch 2/10 | train_loss=0.4748, train_f1=0.7925, val_loss=0.4788, val_f1=0.7662\n","[lr=0.001] Epoch 3/10 | train_loss=0.4458, train_f1=0.8110, val_loss=0.4604, val_f1=0.7839\n","[lr=0.001] Epoch 4/10 | train_loss=0.4216, train_f1=0.8171, val_loss=0.4641, val_f1=0.7793\n","Overfitting signal detected at epoch 4 (prev best val F1=0.7920 at epoch 2)\n","Best val F1 for lr=0.001: 0.7839\n","\n","=== LR sweep complete ===\n","Best LR: 0.0003 with val F1=0.7920\n","Best model saved to: /content/drive/MyDrive/dl-twitter-crisis/best_custom_transformer_lr.pt\n"]}],"source":["import torch\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","\n","from torch.optim import AdamW\n","\n","\n","import torch\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from torch.optim import AdamW\n","from sklearn.metrics import f1_score\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# ------------------------------------------------\n","# Plotting helpers\n","# ------------------------------------------------\n","def plot_learning_curve(train_f1s, val_f1s):\n","    N = len(train_f1s)\n","    plt.figure(figsize=(10, 5))\n","    plt.xlabel(\"Epoch\", fontsize=16)\n","    plt.plot(range(1, N+1), train_f1s, label=\"Train\")\n","    plt.plot(range(1, N+1), val_f1s, label=\"Validation\")\n","    plt.axvline(x=4, color='red', linestyle='--', linewidth=1.5)\n","    plt.xticks([i for i in range(1, N+1)], fontsize=14)\n","    plt.yticks(fontsize=14)\n","    plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n","    plt.title(\"Custom Transformer Learning Curve\", fontsize=18)\n","    plt.legend(fontsize=14)\n","    plt.tight_layout()\n","    plt.savefig(GOOGLE_DRIVE_PATH + \"/custom_transformer_learning_curve.png\")\n","\n","def plot_validation_curve(xticks, log_scale, val_f1s):\n","    plt.figure(figsize=(10, 5))\n","\n","    if log_scale:\n","        plt.semilogx(xticks, val_f1s, marker=\"o\")\n","        plt.xticks(xticks, [f\"{x:.0e}\" for x in xticks], fontsize=14)\n","    else:\n","        plt.plot(xticks, val_f1s, marker=\"o\")\n","    plt.yticks(fontsize=14)\n","    plt.xlabel(\"Learning Rate (log scale)\" if log_scale else \"Learning Rate\", fontsize=16)\n","    plt.ylabel(\"F1 Score (Macro)\", fontsize=16)\n","    plt.title(\"Custom Transformer Validation Curve\", fontsize=18)\n","    plt.tight_layout()\n","    plt.savefig(GOOGLE_DRIVE_PATH + \"/custom_transformer_validation_curve.png\")\n","\n","# Fixed hyperparameters for this run\n","D_MODEL = 256\n","NUM_LAYERS = 2\n","DROPOUT = 0.3\n","BATCH_SIZE = 32\n","NHEAD = 4\n","DIM_FEEDFORWARD = 512\n","WEIGHT_DECAY = 0.01\n","MAX_LENGTH = 64\n","\n","MAX_EPOCHS_LEARNING_CURVE = 10  # epochs for final learning curve\n","\n","num_labels = len(label2id)\n","vocab_size = tokenizer.get_vocab_size()\n","\n","# Build DataLoaders\n","train_loader = DataLoader(\n","    tokenized_datasets[\"train\"],\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n",")\n","val_loader = DataLoader(\n","    tokenized_datasets[\"validation\"],\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n",")\n","transformer_test_loader = DataLoader(\n","    tokenized_datasets[\"test\"],\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n",")\n","\n","def evaluate_model(model, data_loader):\n","    model.eval()\n","    val_loss = 0.0\n","    all_logits = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","\n","            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n","            loss = criterion(logits, labels)\n","\n","            val_loss += loss.item()\n","            all_logits.append(logits.detach().cpu().numpy())\n","            all_labels.append(labels.detach().cpu().numpy())\n","\n","    val_loss /= len(data_loader)\n","    metrics = compute_metrics_from_preds(all_logits, all_labels)\n","    metrics[\"loss\"] = val_loss\n","    return metrics\n","\n","# ============================================================\n","# 1) SWEEP OVER LEARNING RATES: find best model and save it\n","# ============================================================\n","LR_VALUES = [5e-5, 1e-4, 3e-4, 1e-3]\n","VAL_F1_PER_LR = []\n","TRAIN_F1_PER_LR = []\n","\n","best_overall_f1 = -1.0\n","best_lr = None\n","best_model_path = GOOGLE_DRIVE_PATH + \"/best_custom_transformer_lr.pt\"\n","\n","EPOCHS_LR = 10  # small number of epochs for LR sweep\n","\n","for lr in LR_VALUES:\n","    print(f\"\\n=== Validation curve run: lr={lr} ===\")\n","\n","    # fresh model for each lr\n","    model_lr = TransformerClassifier(\n","        vocab_size=vocab_size,\n","        num_labels=num_labels,\n","        max_length=MAX_LENGTH,\n","        d_model=D_MODEL,\n","        nhead=NHEAD,\n","        num_layers=NUM_LAYERS,\n","        dim_feedforward=DIM_FEEDFORWARD,\n","        dropout=DROPOUT,\n","    ).to(device)\n","\n","    optimizer_lr = AdamW(\n","        model_lr.parameters(),\n","        lr=lr,\n","        weight_decay=WEIGHT_DECAY,\n","    )\n","\n","    best_val_f1_for_lr = -1.0\n","\n","    for epoch in range(1, EPOCHS_LR + 1):\n","        # ----- train one epoch -----\n","        model_lr.train()\n","        total_loss = 0.0\n","        for batch in train_loader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","\n","            optimizer_lr.zero_grad()\n","            logits = model_lr(input_ids=input_ids, attention_mask=attention_mask)\n","            loss = criterion(logits, labels)\n","            loss.backward()\n","            optimizer_lr.step()\n","\n","            total_loss += loss.item()\n","\n","        avg_train_loss = total_loss / len(train_loader)\n","\n","        # ----- compute train metrics (including train F1) -----\n","        train_metrics_lr = evaluate_model(model_lr, train_loader)\n","        train_f1 = train_metrics_lr[\"f1\"]\n","\n","        # ----- evaluate on validation -----\n","        val_metrics_lr = evaluate_model(model_lr, val_loader)\n","        val_f1 = val_metrics_lr[\"f1\"]\n","        best_val_f1_for_lr = max(best_val_f1_for_lr, val_f1)\n","\n","        print(\n","            f\"[lr={lr}] Epoch {epoch}/{EPOCHS_LR} | \"\n","            f\"train_loss={avg_train_loss:.4f}, \"\n","            f\"train_f1={train_f1:.4f}, \"\n","            f\"val_loss={val_metrics_lr['loss']:.4f}, \"\n","            f\"val_f1={val_f1:.4f}\"\n","        )\n","\n","        # Track global best model across all LRs\n","        if val_f1 > best_overall_f1:\n","            best_overall_f1 = val_f1\n","            best_lr = lr\n","            best_epoch = epoch  # make sure this exists\n","            torch.save(model_lr.state_dict(), best_model_path)\n","        elif val_f1 < best_val_f1_for_lr:\n","            print(\n","                f\"Overfitting signal detected at epoch {epoch} \"\n","                f\"(prev best val F1={best_overall_f1:.4f} at epoch {best_epoch})\"\n","            )\n","            break\n","\n","    VAL_F1_PER_LR.append(best_val_f1_for_lr)\n","    print(f\"Best val F1 for lr={lr}: {best_val_f1_for_lr:.4f}\")\n","\n","print(\"\\n=== LR sweep complete ===\")\n","print(f\"Best LR: {best_lr} with val F1={best_overall_f1:.4f}\")\n","print(\"Best model saved to:\", best_model_path)\n","\n","# VAL_F1_PER_LR = [0.7609, 0.7762, 0.7979, 0.7636]\n","\n","# # ------------------------------------------------\n","# # 2) Plot validation curve (LR vs best val F1)\n","# # ------------------------------------------------\n","# plot_validation_curve(\n","#     xticks=LR_VALUES,\n","#     log_scale=True,\n","#     val_f1s=VAL_F1_PER_LR,\n","# )\n","\n","# # ============================================================\n","# # 3) Load best model and plot learning curve for 10 epochs\n","# # ============================================================\n","# print(\"\\n=== Training learning-curve model from best LR ===\")\n","# print(f\"Reloading best LR={best_lr} and model from {best_model_path}\")\n","\n","# # Rebuild model with same architecture and best LR\n","# best_custom_transformer_model = TransformerClassifier(\n","#     vocab_size=vocab_size,\n","#     num_labels=num_labels,\n","#     max_length=MAX_LENGTH,\n","#     d_model=D_MODEL,\n","#     nhead=NHEAD,\n","#     num_layers=NUM_LAYERS,\n","#     dim_feedforward=DIM_FEEDFORWARD,\n","#     dropout=DROPOUT,\n","# ).to(device)\n","\n","# best_custom_transformer_model.load_state_dict(torch.load(best_model_path, map_location=device))\n","\n","# # best_optimizer = AdamW(\n","# #     best_model.parameters(),\n","# #     lr=best_lr,\n","# #     weight_decay=WEIGHT_DECAY,\n","# # )\n","\n","# train_f1s = [0.8851, 0.9041, 0.9190, 0.9334, 0.9410, 0.9543, 0.9628, 0.9641, 0.9677, 0.9730]\n","# val_f1s = [0.8067, 0.8078, 0.8103, 0.8141, 0.8066, 0.8088, 0.8075, 0.7996, 0.8027, 0.8018]\n","\n","# # for epoch in range(1, MAX_EPOCHS_LEARNING_CURVE + 1):\n","# #     # ----- train one epoch -----\n","# #     best_model.train()\n","# #     total_loss = 0.0\n","# #     for batch in train_loader:\n","# #         input_ids = batch[\"input_ids\"].to(device)\n","# #         attention_mask = batch[\"attention_mask\"].to(device)\n","# #         labels = batch[\"label\"].to(device)\n","\n","# #         best_optimizer.zero_grad()\n","# #         logits = best_model(input_ids=input_ids, attention_mask=attention_mask)\n","# #         loss = criterion(logits, labels)\n","# #         loss.backward()\n","# #         best_optimizer.step()\n","\n","# #         total_loss += loss.item()\n","\n","# #     avg_train_loss = total_loss / len(train_loader)\n","\n","# #     # Evaluate on train + validation for F1 curves\n","# #     train_metrics = evaluate_model(best_model, train_loader)\n","# #     val_metrics = evaluate_model(best_model, val_loader)\n","\n","# #     train_f1 = train_metrics[\"f1\"]\n","# #     val_f1 = val_metrics[\"f1\"]\n","\n","# #     train_f1s.append(train_f1)\n","# #     val_f1s.append(val_f1)\n","\n","# #     print(\n","# #         f\"[Best LR={best_lr}] Epoch {epoch}/{MAX_EPOCHS_LEARNING_CURVE} | \"\n","# #         f\"train_loss={avg_train_loss:.4f}, \"\n","# #         f\"train_f1={train_f1:.4f}, \"\n","# #         f\"val_loss={val_metrics['loss']:.4f}, \"\n","# #         f\"val_f1={val_f1:.4f}\"\n","# #     )\n","\n","# # Plot learning curve using your specified format\n","# plot_learning_curve(train_f1s, val_f1s)\n","\n","# # test model\n","# test_metrics = evaluate_model(best_custom_transformer_model, transformer_test_loader)\n","\n","# print(f\"\\nTest Metrics (Best LR={best_lr}):\")\n","# print(f\"  Test Loss: {test_metrics['loss']:.4f}\")\n","# print(f\"  Test Accuracy: {test_metrics['accuracy']:.4f}\")\n","# print(f\"  Test Precision: {test_metrics['precision']:.4f}\")\n","# print(f\"  Test Recall: {test_metrics['recall']:.4f}\")\n","# print(f\"  Test F1 (macro): {test_metrics['f1']:.4f}\")\n","\n"]},{"cell_type":"markdown","source":["## Qualitative Analysis"],"metadata":{"id":"G-yWh-qXK64k"},"id":"G-yWh-qXK64k"},{"cell_type":"code","source":["BEST_DEBERTA_MODEL = GOOGLE_DRIVE_PATH + \"/checkpoint-26733\"\n","BEST_CNN_MODEL = GOOGLE_DRIVE_PATH + \"/best_textcnn_glove_numfilters_50.pt\"\n","BEST_CUSTOM_TRANSFORMER_MODEL = GOOGLE_DRIVE_PATH + \"/transformers/transformer_learning_curve_ckpt.pt\""],"metadata":{"id":"0X7G7Qt-paXb"},"id":"0X7G7Qt-paXb","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### CNN Analysis"],"metadata":{"id":"yZDKIgFOpyQj"},"id":"yZDKIgFOpyQj"},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","\n","def build_fp_fn_table_for_all_labels(\n","    logits,\n","    true_ids,\n","    texts,\n","    raw_texts,\n","    id2label,\n","    model_name,\n","    output_csv,\n","):\n","    \"\"\"\n","    Given logits (N x C), gold labels (N,), and texts (len N),\n","    produce a CSV listing FP/FN for each label.\n","    \"\"\"\n","    logits = np.asarray(logits)\n","    true_ids = np.asarray(true_ids)\n","    assert logits.shape[0] == len(true_ids) == len(texts)\n","\n","    # probabilities / predictions\n","    probs = F.softmax(torch.tensor(logits), dim=-1).numpy()\n","    pred_ids = probs.argmax(axis=-1)\n","\n","    records = []\n","\n","    # id2label is dict like {0: \"time_critical\", 1: \"support_and_relief\", ...}\n","    for idx, (raw_txt, txt, y_true, y_pred, p_vec) in enumerate(\n","        zip(raw_texts, texts, true_ids, pred_ids, probs)\n","    ):\n","        if int(y_true) == int(y_pred):\n","            continue\n","        if int(y_pred) != 2: # only get the ones where model predicted non_informative\n","          continue\n","        records.append({\n","            \"text\": txt,\n","            \"text_raw\": raw_txt,\n","            \"true_label\": id2label[int(y_true)],\n","            \"pred_label\": id2label[int(y_pred)],\n","            \"pred_prob_pred_label\": float(p_vec[y_pred]),\n","        })\n","\n","    df = pd.DataFrame.from_records(records)\n","    df.to_csv(output_csv, index=False)\n","    print(f\"[{model_name}] Saved {len(df)} FP/FN rows to {output_csv}\")\n","    return df\n","\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def collect_fp_fn_textcnn_all_labels(\n","    ckpt_path=BEST_CNN_MODEL,\n","    test_loader=None,\n","    texts=None,\n","    raw_texts=None,\n","    output_csv=GOOGLE_DRIVE_PATH + \"/textcnn_fp_fn_all_labels_test.csv\",\n","):\n","    \"\"\"\n","    Load the best TextCNN checkpoint, run on the test_loader, and\n","    write FP/FN for every label to CSV.\n","    \"\"\"\n","\n","    # Recreate the model architecture exactly as in training\n","    # (use the same args you used before)\n","    model = TextCNN(\n","        vocab_size=len(vocab),\n","        embed_dim=EMBED_DIM,\n","        num_classes=num_classes,\n","        pad_idx=vocab[PAD_TOKEN],\n","        num_filters=50,\n","        filter_sizes=FILTER_SIZES,\n","        dropout=DROPOUT,\n","        pretrained_embeddings=embedding_matrix,\n","        freeze_embeddings=False,\n","    ).to(device)\n","\n","    model.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n","\n","    best_optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","\n","    model.eval()\n","\n","    all_logits = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch_x, batch_y in test_loader:\n","            batch_x = batch_x.to(device)\n","            batch_y = batch_y.to(device)\n","\n","            logits = model(batch_x)\n","            all_logits.append(logits.detach().cpu().numpy())\n","            all_labels.append(batch_y.detach().cpu().numpy())\n","\n","    logits = np.concatenate(all_logits, axis=0)\n","    true_ids = np.concatenate(all_labels, axis=0)\n","\n","    # texts should correspond 1:1 with loader order (shuffle=False)\n","    assert len(texts) == logits.shape[0] == len(true_ids)\n","\n","    df = build_fp_fn_table_for_all_labels(\n","        logits=logits,\n","        true_ids=true_ids,\n","        texts=texts,\n","        raw_texts=raw_texts,\n","        id2label=id2label,\n","        model_name=\"TextCNN\",\n","        output_csv=output_csv,\n","    )\n","    return df\n","\n"],"metadata":{"id":"NGlaZEvLpESg"},"id":"NGlaZEvLpESg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df_textcnn_fp_fn = collect_fp_fn_textcnn_all_labels(\n","#   ckpt_path=BEST_CNN_MODEL,\n","#   test_loader=cnn_test_loader,      # CNN test DataLoader\n","#   texts=df['test'][\"text\"].tolist(),\n","#   raw_texts=df['test'][\"text_raw\"].tolist(),\n","#   output_csv=GOOGLE_DRIVE_PATH + \"/textcnn_fp_fn_all_labels_test.csv\",\n","# )\n","\n","df_textcnn_fp_fn = collect_fp_fn_textcnn_all_labels(\n","  ckpt_path=BEST_CNN_MODEL,\n","  test_loader=cnn_test_loader,      # CNN test DataLoader\n","  texts=df['test'][\"text\"].tolist(),\n","  raw_texts=df['test'][\"text_raw\"].tolist(),\n","  output_csv=GOOGLE_DRIVE_PATH + \"/textcnn_non_informative_test.csv\",\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q58eW_qIpxpu","executionInfo":{"status":"ok","timestamp":1764341892358,"user_tz":-540,"elapsed":659,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"ed30bda9-05ab-4447-a5fb-41fe82cd02a5"},"id":"q58eW_qIpxpu","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[TextCNN] Saved 955 FP/FN rows to /content/drive/MyDrive/dl-twitter-crisis/textcnn_non_informative_test.csv\n"]}]},{"cell_type":"markdown","source":["### Custom Transformer Analysis"],"metadata":{"id":"5uUtMAgqwHt4"},"id":"5uUtMAgqwHt4"},{"cell_type":"code","source":["def collect_fp_fn_custom_transformer_all_labels(\n","    ckpt_path=BEST_CUSTOM_TRANSFORMER_MODEL,\n","    test_loader=None,\n","    texts=None,\n","    raw_texts=None,\n","    output_csv=GOOGLE_DRIVE_PATH + \"/custom_transformer_fp_fn_all_labels_test.csv\",\n","):\n","    \"\"\"\n","    Load the best custom Transformer checkpoint, run on the test_loader,\n","    and write FP/FN for every label to CSV.\n","    \"\"\"\n","    assert test_loader is not None, \"Pass the custom transformer test_loader\"\n","    assert texts is not None, \"Pass texts aligned with the test_loader order\"\n","\n","    # Recreate model with same hyperparameters as training\n","    # (match the constructor call you used above your training loop)\n","    best_custom_transformer_model.eval()\n","\n","    all_logits = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","\n","            logits = best_custom_transformer_model(input_ids=input_ids, attention_mask=attention_mask)\n","            all_logits.append(logits.detach().cpu().numpy())\n","            all_labels.append(labels.detach().cpu().numpy())\n","\n","    logits = np.concatenate(all_logits, axis=0)\n","    true_ids = np.concatenate(all_labels, axis=0)\n","\n","    assert len(texts) == logits.shape[0] == len(true_ids)\n","\n","    df = build_fp_fn_table_for_all_labels(\n","        logits=logits,\n","        true_ids=true_ids,\n","        texts=texts,\n","        raw_texts=raw_texts,\n","        id2label=id2label,\n","        model_name=\"CustomTransformer\",\n","        output_csv=output_csv,\n","    )\n","    return df\n"],"metadata":{"id":"_T1aVSVNwKV0"},"id":"_T1aVSVNwKV0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer_test_loader = DataLoader(\n","    tokenized_datasets[\"test\"],\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n",")\n","\n","transformer_test_texts = list(tokenized_datasets[\"test\"][\"text\"])\n","transformer_raw_texts = list(tokenized_datasets[\"test\"][\"text_raw\"])\n","\n","df_custom_fp_fn = collect_fp_fn_custom_transformer_all_labels(\n","    ckpt_path=BEST_CUSTOM_TRANSFORMER_MODEL,\n","    test_loader=transformer_test_loader,\n","    texts=transformer_test_texts,\n","    raw_texts=transformer_raw_texts,\n","    output_csv=GOOGLE_DRIVE_PATH + \"/custom_transformer_fp_fn_all_labels_test.csv\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"plKNBoVMwVln","executionInfo":{"status":"ok","timestamp":1764339322903,"user_tz":-540,"elapsed":7969,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"f3a98a61-bcf7-473c-d2b4-61c09b350fcb"},"id":"plKNBoVMwVln","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[CustomTransformer] Saved 2523 FP/FN rows to /content/drive/MyDrive/dl-twitter-crisis/custom_transformer_fp_fn_all_labels_test.csv\n","Positive label  = time_critical (id=0)\n","\n","Confusion Counts\n","------------------------------\n","TP = 1999\n","FP = 521\n","FN = 1041\n","TN = 13774\n","Positive label  = support_and_relief (id=1)\n","\n","Confusion Counts\n","------------------------------\n","TP = 2274\n","FP = 630\n","FN = 766\n","TN = 13665\n","Positive label  = non_informative (id=2)\n","\n","Confusion Counts\n","------------------------------\n","TP = 10539\n","FP = 1372\n","FN = 716\n","TN = 4708\n"]}]},{"cell_type":"markdown","source":["## Pretrained Transformer (Includes Analysis)"],"metadata":{"id":"a_2RoqZXHVKz"},"id":"a_2RoqZXHVKz"},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M2yOfDEBHqqJ","executionInfo":{"status":"ok","timestamp":1764426200473,"user_tz":-540,"elapsed":5320,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"d83f711b-b0fb-4f6f-d730-9309c95d716e"},"id":"M2yOfDEBHqqJ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n","Collecting datasets\n","  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n","Collecting dill<0.4.1,>=0.3.0 (from datasets)\n","  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n","Collecting multiprocess<0.70.19 (from datasets)\n","  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n","Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n","Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n","Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n","Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n","Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n","Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n","  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n","Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n","Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n","Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, propcache, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 datasets-4.4.1 dill-0.4.0 frozenlist-1.8.0 multiprocess-0.70.18 propcache-0.4.1 xxhash-3.6.0 yarl-1.22.0\n"]}]},{"cell_type":"code","source":["def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=-1)\n","\n","    acc = accuracy_score(labels, preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        labels,\n","        preds,\n","        average=\"macro\",\n","        zero_division=0,\n","    )\n","    return {\n","        \"accuracy\": acc,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1\": f1,\n","    }\n","\n","from transformers import TrainerCallback\n","\n","class TrainMetricsCallback(TrainerCallback):\n","    def __init__(self, train_dataset, val_dataset, last_epoch = None):\n","        super().__init__()\n","        self.train_dataset = train_dataset\n","        self.val_dataset = val_dataset\n","        self.trainer = None\n","        self.last_epoch = last_epoch\n","\n","    def on_epoch_end(self, args, state, control, **kwargs):\n","        if self.trainer is None:\n","            return control\n","\n","        if self.last_epoch is None:\n","            epoch = state.epoch\n","        else:\n","            self.last_epoch += 1\n","            epoch = self.last_epoch\n","\n","        # --- train metrics ---\n","        train_metrics = self.trainer.evaluate(\n","            eval_dataset=self.train_dataset,\n","            metric_key_prefix=\"train\",  # train_accuracy, train_f1, ...\n","        )\n","\n","        # --- validation metrics ---\n","        val_metrics = self.trainer.evaluate(\n","            eval_dataset=self.val_dataset,\n","            metric_key_prefix=\"eval\",   # eval_accuracy, eval_f1, ...\n","        )\n","\n","        val_loss = val_metrics.get(\"eval_loss\")\n","        val_acc  = val_metrics.get(\"eval_accuracy\")\n","        val_prec = val_metrics.get(\"eval_precision\")\n","        val_rec  = val_metrics.get(\"eval_recall\")\n","        val_f1   = val_metrics.get(\"eval_f1\")\n","\n","        train_loss = train_metrics.get(\"train_loss\")\n","        train_acc  = train_metrics.get(\"train_accuracy\")\n","        train_prec = train_metrics.get(\"train_precision\")\n","        train_rec  = train_metrics.get(\"train_recall\")\n","        train_f1   = train_metrics.get(\"train_f1\")\n","\n","        print(\"\\n\" + \"=\" * 80)\n","        print(f\"[EPOCH {epoch:.0f}]\")\n","        if train_acc is not None:\n","            print(f\"[train] loss={train_loss:.4f}, acc={train_acc:.4f}, prec={train_prec:.4f}, rec={train_rec:.4f}, f1={train_f1:.4f}\")\n","        if val_acc is not None:\n","            print(f\"[valid] loss={val_loss:.4f}, acc={val_acc:.4f}, prec={val_prec:.4f}, rec={val_rec:.4f}, f1={val_f1:.4f}\")\n","        return control\n","\n","def train(model_name=\"./deberta\", last_epoch = None, epoch=3, learning_rate=2e-5, batch_size=16, output_dir=\"./deberta-v3-crisis/1\"):\n","  model = AutoModelForSequenceClassification.from_pretrained(\n","      model_name,\n","      num_labels=len(label2id),\n","      id2label=id2label,\n","      label2id=label2id,\n","  )\n","\n","  training_args = TrainingArguments(\n","      output_dir=output_dir,\n","      eval_strategy=\"no\", # \"epoch\",\n","      save_strategy=\"epoch\",\n","      learning_rate=learning_rate,\n","      per_device_train_batch_size=batch_size,\n","      per_device_eval_batch_size=batch_size,\n","      num_train_epochs=epoch,\n","      weight_decay=0.01,\n","      load_best_model_at_end=False, # True,\n","      metric_for_best_model=\"f1\",\n","      logging_strategy=\"epoch\",\n","      report_to=\"none\",\n","  )\n","\n","  train_callback = TrainMetricsCallback(\n","      train_dataset=tokenized_datasets[\"train\"],\n","      val_dataset=tokenized_datasets[\"validation\"],\n","      last_epoch=last_epoch,\n","  )\n","\n","  trainer = Trainer(\n","      model=model,\n","      args=training_args,\n","      train_dataset=tokenized_datasets[\"train\"],\n","      eval_dataset=tokenized_datasets[\"validation\"],\n","      tokenizer=tokenizer,\n","      compute_metrics=compute_metrics,\n","      callbacks=[train_callback],\n","  )\n","\n","  train_callback.trainer = trainer\n","\n","  trainer.train()\n","  return trainer\n","\n","\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","def load_and_test_eval(ckpt_dir = GOOGLE_DRIVE_PATH + \"/checkpoint-26733\"):\n","    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n","        ckpt_dir,\n","        num_labels=len(label2id),\n","        id2label=id2label,\n","        label2id=label2id,\n","    )\n","    eval_args = TrainingArguments(\n","        output_dir=\".\", # any\n","        per_device_eval_batch_size=64,\n","        report_to=\"none\",\n","    )\n","    eval_trainer = Trainer(\n","        model=model_ckpt,\n","        args=eval_args,\n","        tokenizer=tokenizer,\n","        compute_metrics=compute_metrics,\n","    )\n","    eval_results = eval_trainer.evaluate(\n","        eval_dataset=tokenized_datasets[\"validation\"],\n","        metric_key_prefix=\"test\",\n","    )\n","    # {'test_loss': 0.4593863785266876, 'test_model_preparation_time': 0.0011, 'test_accuracy': 0.8740698009806749, 'test_precision': 0.8326252068193959, 'test_recall': 0.8500324417218078, 'test_f1': 0.8369876991837396, 'test_runtime': 123.8232, 'test_samples_per_second': 139.998, 'test_steps_per_second': 2.189}\n","    print(eval_results)\n","    print(f\"[test] acc={eval_results['test_accuracy']}, prec={eval_results['test_precision']}, rec={eval_results['test_recall']}, f1={eval_results['test_f1']}\")\n","    # print(f\"test_loss = {eval_results['test_loss']}\")\n","    # print(f\"test_accuracy = {eval_results['test_accuracy']}\")\n","    # print(f\"test_precision = {eval_results['test_precision']}\")\n","    # print(f\"test_recall = {eval_results['test_recall']}\")\n","    # print(f\"test_f1 = {eval_results['test_f1']}\")\n","    return eval_results\n","\n","def load_and_val_eval(ckpt_dir = \"/checkpoint-26733\"):\n","    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n","        ckpt_dir,\n","        num_labels=len(label2id),\n","        id2label=id2label,\n","        label2id=label2id,\n","    )\n","    eval_args = TrainingArguments(\n","        output_dir=\".\", # any\n","        per_device_eval_batch_size=64,\n","        report_to=\"none\",\n","    )\n","    eval_trainer = Trainer(\n","        model=model_ckpt,\n","        args=eval_args,\n","        tokenizer=tokenizer,\n","        compute_metrics=compute_metrics,\n","    )\n","    eval_results = eval_trainer.evaluate(\n","        eval_dataset=tokenized_datasets[\"validation\"],\n","        metric_key_prefix=\"val\",\n","    )\n","    print(eval_results)\n","    print(f\"[test] acc={eval_results['val_accuracy']}, prec={eval_results['val_precision']}, rec={eval_results['val_recall']}, f1={eval_results['val_f1']}\")\n","    return eval_results['val_f1']\n"],"metadata":{"id":"7arvSyKyHab_","executionInfo":{"status":"ok","timestamp":1764426170535,"user_tz":-540,"elapsed":7992,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"846795ee-5434-4ffe-d7bf-2f81d752fbcd"},"id":"7arvSyKyHab_","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["### Tokenizer"],"metadata":{"id":"ZSR_-uAQKAW_"},"id":"ZSR_-uAQKAW_"},{"cell_type":"code","source":["from datasets import Dataset, DatasetDict\n","from transformers import AutoTokenizer\n","\n","# Download everything from https://huggingface.co/microsoft/deberta-v3-base/tree/main\n","deberta_tokenizer = AutoTokenizer.from_pretrained(\n","    \"microsoft/deberta-v3-base\", # \"microsoft/deberta-v3-base\"\n","    use_fast=True, # DeBERTa fast tokenizer \n",")\n","\n","max_length = 64 # adjust based on the maximum input size?\n","\n","# 1. Tokenize directly\n","train_encodings = deberta_tokenizer(\n","    df[\"train\"]['text'].to_list(),\n","    padding=\"max_length\",\n","    truncation=True,\n","    max_length=max_length,\n",")\n","val_encodings = deberta_tokenizer(\n","    df[\"dev\"]['text'].to_list(),\n","    padding=\"max_length\",\n","    truncation=True,\n","    max_length=max_length,\n",")\n","test_encodings = deberta_tokenizer(\n","    df[\"test\"]['text'].to_list(),\n","    padding=\"max_length\",\n","    truncation=True,\n","    max_length=max_length,\n",")\n","\n","# 2. Build HF Datasets from encoded inputs + labels\n","train_dataset = Dataset.from_dict({\n","    \"input_ids\": train_encodings[\"input_ids\"],\n","    \"attention_mask\": train_encodings[\"attention_mask\"],\n","    \"label\": df[\"train\"]['class_label_group_num'],\n","    \"text\": df[\"train\"]['text'],\n","    \"text_raw\": df[\"train\"]['text_raw'],\n","})\n","val_dataset = Dataset.from_dict({\n","    \"input_ids\": val_encodings[\"input_ids\"],\n","    \"attention_mask\": val_encodings[\"attention_mask\"],\n","    \"label\": df[\"dev\"]['class_label_group_num'],\n","    \"text\": df[\"dev\"]['text'],\n","    \"text_raw\": df[\"dev\"]['text_raw'],\n","})\n","test_dataset = Dataset.from_dict({\n","    \"input_ids\": test_encodings[\"input_ids\"],\n","    \"attention_mask\": test_encodings[\"attention_mask\"],\n","    \"label\": df[\"test\"]['class_label_group_num'],\n","    \"text\": df[\"test\"]['text'],\n","    \"text_raw\": df[\"test\"]['text_raw'],\n","})\n","\n","tokenized_datasets = DatasetDict({\n","    \"train\": train_dataset,\n","    \"validation\": val_dataset,\n","    \"test\": test_dataset,\n","})\n","\n","# 3. Set format for PyTorch\n","tokenized_datasets.set_format(\n","    type=\"torch\",\n","    columns=[\"input_ids\", \"attention_mask\", \"label\", \"text\", \"text_raw\"],\n",")\n","\n","# Check appropriate token size\n","tmp_train = deberta_tokenizer(df[\"train\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n","lens_train = [len(ids) for ids in tmp_train[\"input_ids\"]]\n","\n","tmp_dev = deberta_tokenizer(df[\"dev\"]['text'].to_list(), truncation=False, add_special_tokens=True)\n","lens_dev = [len(ids) for ids in tmp_dev[\"input_ids\"]]\n","\n","lengths = lens_train + lens_dev\n","\n","print(\"median:\", np.median(lengths))\n","print(\"mean:\", np.mean(lengths))\n","print(\"95th percentile:\", np.percentile(lengths, 95))\n","print(\"99th percentile:\", np.percentile(lengths, 99))\n","print(\"max:\", np.max(lengths))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255,"referenced_widgets":["3347e59154364107886b56bc5b3927f9","eb3dbaee5fef431f9d57273518248154","ad1c93327f3f4b8996b9cebb9b429d3b","f98e19ffbb604c3bb05d9628123729b3","991f5350dfbc4621839755096ce73cb7","8b6f125867c44f77b343f0c584e21ed0","0c9c5359daf5454dae9bb276947ca4b9","d6be01b9e2814f5c95f8c8b5177472db","5a9b2437468c4c459451d26f083bb82d","0d20fefa490f4712b79e5850e4db4434","ec22e2b2cace4c5ba47938081d7c3fa3","cc76acfd5771491eaa0c424f45840896","c528b3ceb96147f4bfe13168aa722c45","bba699805f5044eb9bba145eaa3845b0","297e4cd1497b480aa44204f20a29538b","0456b343f3aa4cb69085a758999d2613","ea9c3351df0741148a83faa401120e96","fce827022b644d879f2af94a27ad2849","34c45e10b019464697ab6521f63df1d8","19f357cafbfe4d4cb8f02a874c613f0e","533cac6222634549b600fc1ab82b8cf5","a1fa295037bf48d9ae53f071317a5269","143e39d360bc40c6880a77495ed08bed","4ed4baddc7b042578c0e452af2565252","facbd4007f734bdf83050de57fc817c5","faaa7be6c0ab4a0fa38bdbcd50a19cec","8d65195791a045e7984c0f3e76f95136","c73f87272e7c414098bead380de835d3","8299c98977834fb5a40d5cefadf7bef8","dafe8b0ce4994a00b59795440753c0ef","d339bf0a38354a4a8d0885b94610e6b9","b50326d8de3646d59f39fd2448874498","bb8649f5bccd4a74af721f7cb52adf9f"]},"id":"pi8ih088J_dz","executionInfo":{"status":"ok","timestamp":1764426209373,"user_tz":-540,"elapsed":8896,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"875f444d-f20d-4cee-a7cc-aaa826cfa21b"},"id":"pi8ih088J_dz","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3347e59154364107886b56bc5b3927f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc76acfd5771491eaa0c424f45840896"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"143e39d360bc40c6880a77495ed08bed"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["median: 15.0\n","mean: 16.42866733323811\n","95th percentile: 29.0\n","99th percentile: 42.0\n","max: 1126\n"]}]},{"cell_type":"markdown","source":["### Pretrained Transformer Analysis"],"metadata":{"id":"gKSzfurqv7K5"},"id":"gKSzfurqv7K5"},{"cell_type":"code","source":["# from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","# def load_trainer_for_ckpt(ckpt_dir, batch_size=64):\n","#     \"\"\"\n","#     Load a Trainer for a saved checkpoint, ready for evaluation/prediction.\n","#     \"\"\"\n","#     model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n","#         ckpt_dir,\n","#         num_labels=len(label2id),\n","#         id2label=id2label,\n","#         label2id=label2id,\n","#     )\n","\n","#     eval_args = TrainingArguments(\n","#         output_dir=\".\",  # any temp dir\n","#         per_device_eval_batch_size=batch_size,\n","#         report_to=\"none\",\n","#     )\n","\n","#     eval_trainer = Trainer(\n","#         model=model_ckpt,\n","#         args=eval_args,\n","#         tokenizer=deberta_tokenizer,\n","#         compute_metrics=compute_metrics,\n","#     )\n","#     return eval_trainer\n","\n","\n","# def get_high_conf_disagreements(\n","#     ckpt_dir,\n","#     split=\"test\",\n","#     threshold=0.9,\n","#     max_examples=50,\n","#     text_column=\"text\",\n","#     batch_size=64,\n","# ):\n","#     \"\"\"\n","#     Find high-confidence disagreements between model predictions and gold labels.\n","\n","#     - ckpt_dir: path to saved checkpoint\n","#     - split: which split of tokenized_datasets to use (\"train\", \"validation\", \"test\")\n","#     - threshold: minimum predicted probability for the predicted class\n","#     - max_examples: stop after collecting this many disagreements (None for all)\n","#     - text_column: name of the column containing raw text (if still present)\n","#     - batch_size: eval batch size\n","#     \"\"\"\n","#     # 1. Load trainer + dataset\n","#     trainer = load_trainer_for_ckpt(ckpt_dir, batch_size=batch_size)\n","#     eval_dataset = tokenized_datasets[split]\n","\n","\n","#     # 2. Run prediction to get logits + labels\n","#     pred_output = trainer.predict(eval_dataset)\n","#     logits = pred_output.predictions\n","#     labels = pred_output.label_ids\n","\n","#     # 3. Convert logits to probabilities\n","#     probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n","#     pred_ids = probs.argmax(axis=-1)\n","#     pred_conf = probs.max(axis=-1)\n","\n","#     disagreements = []\n","\n","#     for i, (y_true, y_pred, conf) in enumerate(zip(labels, pred_ids, pred_conf)):\n","#         if int(y_true) != int(y_pred) and conf >= threshold:\n","#             # Try to grab the text if it exists on the dataset\n","#             text_value = eval_dataset[i][text_column]\n","\n","#             disagreements.append({\n","#                 \"idx\": i,\n","#                 \"text\": text_value,\n","#                 \"true_id\": int(y_true),\n","#                 \"true_label\": id2label[int(y_true)],\n","#                 \"pred_id\": int(y_pred),\n","#                 \"pred_label\": id2label[int(y_pred)],\n","#                 \"pred_conf\": float(conf),\n","#             })\n","\n","#             if max_examples is not None and len(disagreements) >= max_examples:\n","#                 break\n","\n","#     df_disagreements = pd.DataFrame(disagreements)\n","#     return df_disagreements\n","\n","# CKPT_PATH = GOOGLE_DRIVE_PATH + \"/checkpoint-26733\"\n","\n","# high_conf_disagreements = get_high_conf_disagreements(\n","#     ckpt_dir=CKPT_PATH,\n","#     split=\"test\",\n","#     threshold=0.0,\n","#     max_examples=30,\n","#     text_column=\"text\",\n","# )\n","\n","# high_conf_disagreements.head()\n","\n","# high_conf_disagreements.to_csv(GOOGLE_DRIVE_PATH + \"/pretrained_transformer_high_conf_disagreements_val.csv\", index=False)\n"],"metadata":{"id":"cTu10Jf2K-oy"},"id":"cTu10Jf2K-oy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collect_all_label_fp_fn(\n","    ckpt_dir,\n","    split=\"test\",\n","    text_column=\"text\",\n","    raw_text_column=\"text_raw\",\n","    labels_column=\"label\",\n","    output_csv=None,\n","):\n","    \"\"\"\n","    Collect false positives and false negatives for ALL classes:\n","    - time_critical\n","    - support_and_relief\n","    - non_informative\n","\n","    Saves a single CSV containing:\n","        - raw text / cleaned text\n","        - true label / predicted label\n","        - predicted probability\n","        - only rows where prediction != gold\n","        - also prints test-set macro F1\n","    \"\"\"\n","    if output_csv is None:\n","        output_csv = GOOGLE_DRIVE_PATH + \"/deberta_sr_ni_fp_fn_test.csv\"\n","\n","    # 1. Load model checkpoint\n","    model_ckpt = AutoModelForSequenceClassification.from_pretrained(\n","        ckpt_dir,\n","        num_labels=len(label2id),\n","        id2label=id2label,\n","        label2id=label2id,\n","    )\n","\n","    # 2. Evaluation-only Trainer\n","    eval_args = TrainingArguments(\n","        output_dir=\".\",\n","        per_device_eval_batch_size=64,\n","        report_to=\"none\",\n","    )\n","\n","    eval_trainer = Trainer(\n","        model=model_ckpt,\n","        args=eval_args,\n","        tokenizer=deberta_tokenizer,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    # 3. Load dataset split\n","    test_ds = tokenized_datasets[split]\n","\n","    # 4. Predict\n","    pred_output = eval_trainer.predict(test_ds)\n","    logits = pred_output.predictions\n","    metrics = pred_output.metrics    # <-- metrics dict from Trainer\n","    print('hello\"')\n","    print(metrics)\n","\n","    # 5. Convert logits  probs  predictions\n","    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n","    pred_ids = probs.argmax(axis=-1)\n","\n","    # 6. True labels and text\n","    true_ids = np.array(test_ds[labels_column])\n","    texts = test_ds[text_column]\n","    raw_texts = test_ds[raw_text_column]\n","\n","    # 7. Collect only FP/FN rows\n","    records = []\n","\n","    for idx, (raw_text, txt, y_true, y_pred, p_vec) in enumerate(\n","        zip(raw_texts, texts, true_ids, pred_ids, probs)\n","    ):\n","        if int(y_true) == int(y_pred):\n","            continue  # skip correct predictions\n","        if int(y_true) == 1 and int(y_pred) == 2:\n","           # only keep prediction support_and_relief vs non_informative\n","            records.append({\n","                \"text\": txt,\n","                \"text_raw\": raw_text,\n","                \"true_label\": id2label[int(y_true)],\n","                \"pred_label\": id2label[int(y_pred)],\n","                \"pred_prob_pred_label\": float(p_vec[y_pred]),\n","            })\n","\n","    df = pd.DataFrame.from_records(records)\n","    df.to_csv(output_csv, index=False)\n","    print(f\"Saved {len(df)} FP/FN rows to {output_csv}\")\n","\n","    return df\n"],"metadata":{"id":"6uQq_V1sRUTl"},"id":"6uQq_V1sRUTl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = collect_all_label_fp_fn(\n","    ckpt_dir=GOOGLE_DRIVE_PATH + \"/checkpoint-26733\",\n","    split=\"test\",\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"8t9YFfHhRVJM","executionInfo":{"status":"ok","timestamp":1764426346505,"user_tz":-540,"elapsed":67287,"user":{"displayName":"Jade Kim","userId":"13751362502685406790"}},"outputId":"77fc430d-be47-46d8-bcf5-58bd40b1d501"},"id":"8t9YFfHhRVJM","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3146094883.py:40: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  eval_trainer = Trainer(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n","  warnings.warn(warn_msg)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["hello\"\n","{'test_loss': 0.44402939081192017, 'test_model_preparation_time': 0.0017, 'test_accuracy': 0.8876838765503317, 'test_precision': 0.8433949219130819, 'test_recall': 0.8624641484876118, 'test_f1': 0.8525004007830286, 'test_runtime': 46.2598, 'test_samples_per_second': 46.866, 'test_steps_per_second': 0.735}\n","Saved 268 FP/FN rows to /content/drive/MyDrive/dl-twitter-crisis/deberta_sr_ni_fp_fn_test.csv\n"]}]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V6E1","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.19"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3347e59154364107886b56bc5b3927f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb3dbaee5fef431f9d57273518248154","IPY_MODEL_ad1c93327f3f4b8996b9cebb9b429d3b","IPY_MODEL_f98e19ffbb604c3bb05d9628123729b3"],"layout":"IPY_MODEL_991f5350dfbc4621839755096ce73cb7"}},"eb3dbaee5fef431f9d57273518248154":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b6f125867c44f77b343f0c584e21ed0","placeholder":"","style":"IPY_MODEL_0c9c5359daf5454dae9bb276947ca4b9","value":"tokenizer_config.json:100%"}},"ad1c93327f3f4b8996b9cebb9b429d3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6be01b9e2814f5c95f8c8b5177472db","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a9b2437468c4c459451d26f083bb82d","value":52}},"f98e19ffbb604c3bb05d9628123729b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d20fefa490f4712b79e5850e4db4434","placeholder":"","style":"IPY_MODEL_ec22e2b2cace4c5ba47938081d7c3fa3","value":"52.0/52.0[00:00&lt;00:00,11.0kB/s]"}},"991f5350dfbc4621839755096ce73cb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b6f125867c44f77b343f0c584e21ed0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c9c5359daf5454dae9bb276947ca4b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6be01b9e2814f5c95f8c8b5177472db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a9b2437468c4c459451d26f083bb82d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d20fefa490f4712b79e5850e4db4434":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec22e2b2cace4c5ba47938081d7c3fa3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc76acfd5771491eaa0c424f45840896":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c528b3ceb96147f4bfe13168aa722c45","IPY_MODEL_bba699805f5044eb9bba145eaa3845b0","IPY_MODEL_297e4cd1497b480aa44204f20a29538b"],"layout":"IPY_MODEL_0456b343f3aa4cb69085a758999d2613"}},"c528b3ceb96147f4bfe13168aa722c45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea9c3351df0741148a83faa401120e96","placeholder":"","style":"IPY_MODEL_fce827022b644d879f2af94a27ad2849","value":"config.json:100%"}},"bba699805f5044eb9bba145eaa3845b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34c45e10b019464697ab6521f63df1d8","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19f357cafbfe4d4cb8f02a874c613f0e","value":579}},"297e4cd1497b480aa44204f20a29538b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_533cac6222634549b600fc1ab82b8cf5","placeholder":"","style":"IPY_MODEL_a1fa295037bf48d9ae53f071317a5269","value":"579/579[00:00&lt;00:00,143kB/s]"}},"0456b343f3aa4cb69085a758999d2613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea9c3351df0741148a83faa401120e96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fce827022b644d879f2af94a27ad2849":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34c45e10b019464697ab6521f63df1d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19f357cafbfe4d4cb8f02a874c613f0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"533cac6222634549b600fc1ab82b8cf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1fa295037bf48d9ae53f071317a5269":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"143e39d360bc40c6880a77495ed08bed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ed4baddc7b042578c0e452af2565252","IPY_MODEL_facbd4007f734bdf83050de57fc817c5","IPY_MODEL_faaa7be6c0ab4a0fa38bdbcd50a19cec"],"layout":"IPY_MODEL_8d65195791a045e7984c0f3e76f95136"}},"4ed4baddc7b042578c0e452af2565252":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c73f87272e7c414098bead380de835d3","placeholder":"","style":"IPY_MODEL_8299c98977834fb5a40d5cefadf7bef8","value":"spm.model:100%"}},"facbd4007f734bdf83050de57fc817c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dafe8b0ce4994a00b59795440753c0ef","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d339bf0a38354a4a8d0885b94610e6b9","value":2464616}},"faaa7be6c0ab4a0fa38bdbcd50a19cec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b50326d8de3646d59f39fd2448874498","placeholder":"","style":"IPY_MODEL_bb8649f5bccd4a74af721f7cb52adf9f","value":"2.46M/2.46M[00:00&lt;00:00,3.79MB/s]"}},"8d65195791a045e7984c0f3e76f95136":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c73f87272e7c414098bead380de835d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8299c98977834fb5a40d5cefadf7bef8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dafe8b0ce4994a00b59795440753c0ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d339bf0a38354a4a8d0885b94610e6b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b50326d8de3646d59f39fd2448874498":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb8649f5bccd4a74af721f7cb52adf9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}